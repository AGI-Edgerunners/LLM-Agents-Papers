{
    "5590ade4da00d9823d9b5cd9a26936eb": {
        "title": "InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent",
        "authors": [
            "Po-Lin Chen",
            "Cheng-Shang Chang"
        ],
        "date": "2023/08/03",
        "pdf": "https://arxiv.org/pdf/2308.01552",
        "abstract": " This research paper delves into the integration of OpenAI&#39;s ChatGPT into\nembodied agent systems, evaluating its influence on interactive decision-making\nbenchmark. Drawing a parallel to the concept of people assuming roles according\nto their unique strengths, we introduce InterAct. In this approach, we feed\nChatGPT with varied prompts, assigning it a numerous roles like a checker and a\nsorter, then integrating them with the original language model. Our research\nshows a remarkable success rate of 98% in AlfWorld, which consists of 6\ndifferent tasks in a simulated household environment, emphasizing the\nsignificance of proficient prompt engineering. The results highlight ChatGPT&#39;s\ncompetence in comprehending and performing intricate tasks effectively in\nreal-world settings, thus paving the way for further advancements in task\nplanning.\n"
    },
    "9eff80228411b7637537c841822c6d9e": {
        "title": "MetaGPT: Meta Programming for Multi-Agent Collaborative Framework",
        "authors": [
            "Sirui Hong",
            "Xiawu Zheng",
            "Jonathan Chen",
            "Yuheng Cheng",
            "Ceyao Zhang",
            "Zili Wang",
            "Steven Ka Shing Yau",
            "Zijuan Lin",
            "Liyang Zhou",
            "Chenyu Ran",
            "Lingfeng Xiao",
            "Chenglin Wu"
        ],
        "date": "2023/08/01",
        "pdf": "https://arxiv.org/pdf/2308.00352",
        "code": "https://github.com/geekan/MetaGPT",
        "abstract": " Recently, remarkable progress has been made in automated task-solving through\nthe use of multi-agents driven by large language models (LLMs). However,\nexisting works primarily focuses on simple tasks lacking exploration and\ninvestigation in complicated tasks mainly due to the hallucination problem.\nThis kind of hallucination gets amplified infinitely as multiple intelligent\nagents interact with each other, resulting in failures when tackling\ncomplicated problems.Therefore, we introduce MetaGPT, an innovative framework\nthat infuses effective human workflows as a meta programming approach into\nLLM-driven multi-agent collaboration. In particular, MetaGPT first encodes\nStandardized Operating Procedures (SOPs) into prompts, fostering structured\ncoordination. And then, it further mandates modular outputs, bestowing agents\nwith domain expertise paralleling human professionals to validate outputs and\nreduce compounded errors. In this way, MetaGPT leverages the assembly line work\nmodel to assign diverse roles to various agents, thus establishing a framework\nthat can effectively and cohesively deconstruct complex multi-agent\ncollaborative problems. Our experiments conducted on collaborative software\nengineering tasks illustrate MetaGPT&#39;s capability in producing comprehensive\nsolutions with higher coherence relative to existing conversational and\nchat-based multi-agent systems. This underscores the potential of incorporating\nhuman domain knowledge into multi-agents, thus opening up novel avenues for\ngrappling with intricate real-world challenges. The GitHub repository of this\nproject is made publicly available on: https://github.com/geekan/MetaGPT\n"
    },
    "2eac0f4e2491bfdec954e0d07a70a650": {
        "title": "Communicative Agents for Software Development",
        "authors": [
            "Chen Qian",
            "Xin Cong",
            "Cheng Yang",
            "Weize Chen",
            "Yusheng Su",
            "Juyuan Xu",
            "Zhiyuan Liu",
            "Maosong Sun"
        ],
        "date": "2023/07/16",
        "pdf": "https://arxiv.org/pdf/2307.07924",
        "code": "https://github.com/openbmb/chatdev",
        "abstract": " Software engineering is a domain characterized by intricate decision-making\nprocesses, often relying on nuanced intuition and consultation. Recent\nadvancements in deep learning have started to revolutionize software\nengineering practices through elaborate designs implemented at various stages\nof software development. In this paper, we present an innovative paradigm that\nleverages large language models (LLMs) throughout the entire software\ndevelopment process, streamlining and unifying key processes through natural\nlanguage communication, thereby eliminating the need for specialized models at\neach phase. At the core of this paradigm lies ChatDev, a virtual chat-powered\nsoftware development company that mirrors the established waterfall model,\nmeticulously dividing the development process into four distinct chronological\nstages: designing, coding, testing, and documenting. Each stage engages a team\nof agents, such as programmers, code reviewers, and test engineers, fostering\ncollaborative dialogue and facilitating a seamless workflow. The chat chain\nacts as a facilitator, breaking down each stage into atomic subtasks. This\nenables dual roles, allowing for proposing and validating solutions through\ncontext-aware communication, leading to efficient resolution of specific\nsubtasks. The instrumental analysis of ChatDev highlights its remarkable\nefficacy in software generation, enabling the completion of the entire software\ndevelopment process in under seven minutes at a cost of less than one dollar.\nIt not only identifies and alleviates potential vulnerabilities but also\nrectifies potential hallucinations while maintaining commendable efficiency and\ncost-effectiveness. The potential of ChatDev unveils fresh possibilities for\nintegrating LLMs into the realm of software development.\n"
    },
    "8b49604f02c96ae0a94969b9d0375cb9": {
        "title": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration",
        "authors": [
            "Zhenhailong Wang",
            "Shaoguang Mao",
            "Wenshan Wu",
            "Tao Ge",
            "Furu Wei",
            "Heng Ji"
        ],
        "date": "2023/07/11",
        "pdf": "https://arxiv.org/pdf/2307.05300",
        "code": "https://github.com/MikeWangWZHL/Solo-Performance-Prompting",
        "abstract": " Human intelligence thrives on the concept of cognitive synergy, where\ncollaboration and information integration among different cognitive processes\nyield superior outcomes compared to individual cognitive processes in\nisolation. Although Large Language Models (LLMs) have demonstrated promising\nperformance as general task-solving agents, they still struggle with tasks that\nrequire intensive domain knowledge and complex reasoning. In this work, we\npropose Solo Performance Prompting (SPP), which transforms a single LLM into a\ncognitive synergist by engaging in multi-turn self-collaboration with multiple\npersonas. A cognitive synergist refers to an intelligent agent that\ncollaborates with multiple minds, combining their individual strengths and\nknowledge, to enhance problem-solving and overall performance in complex tasks.\nBy dynamically identifying and simulating different personas based on task\ninputs, SPP unleashes the potential of cognitive synergy in LLMs. We have\ndiscovered that assigning multiple, fine-grained personas in LLMs elicits\nbetter problem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP\neffectively elicits internal knowledge acquisition abilities, reduces\nhallucination, and maintains strong reasoning capabilities. Code, data, and\nprompts can be found at:\nhttps://github.com/MikeWangWZHL/Solo-Performance-Prompting.git.\n"
    },
    "35cb79b6dd5ae58f6f00de3fb5c70d29": {
        "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
        "authors": [
            "Hongxin Zhang",
            "Weihua Du",
            "Jiaming Shan",
            "Qinhong Zhou",
            "Yilun Du",
            "Joshua B. Tenenbaum",
            "Tianmin Shu",
            "Chuang Gan"
        ],
        "date": "2023/07/05",
        "pdf": "https://arxiv.org/pdf/2307.02485",
        "code": "https://github.com/UMass-Foundation-Model/Co-LLM-Agents",
        "abstract": " Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website https://vis-www.cs.umass.edu/Co-LLM-Agents/.\n"
    },
    "8064cabdde186f6c901cd321e0c1e117": {
        "title": "Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents",
        "authors": [
            "Yashar Talebirad",
            "Amirhossein Nadiri"
        ],
        "date": "2023/06/05",
        "pdf": "https://arxiv.org/pdf/2306.03314",
        "abstract": " In this paper, we present a novel framework for enhancing the capabilities of\nlarge language models (LLMs) by leveraging the power of multi-agent systems.\nOur framework introduces a collaborative environment where multiple intelligent\nagent components, each with distinctive attributes and roles, work together to\nhandle complex tasks more efficiently and effectively. We demonstrate the\npracticality and versatility of our framework through case studies in\nartificial general intelligence (AGI), specifically focusing on the Auto-GPT\nand BabyAGI models. We also examine the &#34;Gorilla&#34; model, which integrates\nexternal APIs into the LLM. Our framework addresses limitations and challenges\nsuch as looping issues, security risks, scalability, system evaluation, and\nethical considerations. By modeling various domains such as courtroom\nsimulations and software development scenarios, we showcase the potential\napplications and benefits of our proposed multi-agent system. Our framework\nprovides an avenue for advancing the capabilities and performance of LLMs\nthrough collaboration and knowledge exchange among intelligent agents.\n"
    },
    "5073802d8fc8727b178df4d11b1f3cef": {
        "title": "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents",
        "authors": [
            "Weize Chen",
            "Yusheng Su",
            "Jingwei Zuo",
            "Cheng Yang",
            "Chenfei Yuan",
            "Chen Qian",
            "Chi-Min Chan",
            "Yujia Qin",
            "Yaxi Lu",
            "Ruobing Xie",
            "Zhiyuan Liu",
            "Maosong Sun",
            "Jie Zhou"
        ],
        "date": "2023/08/21",
        "pdf": "https://arxiv.org/pdf/2308.10848",
        "code": "https://github.com/OpenBMB/AgentVerse",
        "abstract": " Autonomous agents empowered by Large Language Models (LLMs) have undergone\nsignificant improvements, enabling them to generalize across a broad spectrum\nof tasks. However, in real-world scenarios, cooperation among individuals is\noften required to enhance the efficiency and effectiveness of task\naccomplishment. Hence, inspired by human group dynamics, we propose a\nmulti-agent framework \\framework that can collaboratively and dynamically\nadjust its composition as a greater-than-the-sum-of-its-parts system. Our\nexperiments demonstrate that \\framework framework can effectively deploy\nmulti-agent groups that outperform a single agent. Furthermore, we delve into\nthe emergence of social behaviors among individual agents within a group during\ncollaborative task accomplishment. In view of these behaviors, we discuss some\npossible strategies to leverage positive ones and mitigate negative ones for\nimproving the collaborative potential of multi-agent groups. Our codes for\n\\framework will soon be released at\n\\url{https://github.com/OpenBMB/AgentVerse}.\n"
    },
    "eecbaf3e56b9f6a2e8c2abf1201ee2bb": {
        "title": "MetaAgents: Simulating Interactions of Human Behaviors for LLM-based Task-oriented Coordination via Collaborative Generative Agents",
        "authors": [
            "Yuan Li",
            "Yixuan Zhang",
            "Lichao Sun"
        ],
        "date": "2023/10/10",
        "pdf": "https://arxiv.org/pdf/2310.06500.pdf",
        "abstract": "Significant advancements have occurred in the application of Large Language Models (LLMs) for various tasks and social simulations. Despite this, their capacities to coordinate within task-oriented social contexts are under-explored. Such capabilities are crucial if LLMs are to effectively mimic human-like social behavior and produce meaningful results. To bridge this gap, we introduce collaborative generative agents, endowing LLM-based Agents with consistent behavior patterns and task-solving abilities. We situate these agents in a simulated job fair environment as a case study to scrutinize their coordination skills. We propose a novel framework that equips collaborative generative agents with human-like reasoning abilities and specialized skills. Our evaluation demonstrates that these agents show promising performance. However, we also uncover limitations that hinder their effectiveness in more complex coordination tasks. Our work provides valuable insights into the role and evolution of LLMs in task-oriented social simulations."
    },
    "6e9ff82716ae89e1a364697a663541a9": {
        "title": "Learning to Coordinate with Anyone",
        "authors": [
            "Lei Yuan",
            "Lihe Li",
            "Ziqian Zhang",
            "Feng Chen",
            "Tianyi Zhang",
            "Cong Guan",
            "Yang Yu",
            "Zhi-Hua Zhou"
        ],
        "date": "2023/09/22",
        "pdf": "https://arxiv.org/pdf/2309.12633.pdf",
        "abstract": "In open multi-agent environments, the agents may encounter unexpected teammates. Classical multi-agent learning approaches train agents that can only coordinate with seen teammates. Recent studies attempted to generate diverse teammates to enhance the generalizable coordination ability, but were restricted by pre-defined teammates. In this work, our aim is to train agents with strong coordination ability by generating teammates that fully cover the teammate policy space, so that agents can coordinate with any teammates. Since the teammate policy space is too huge to be enumerated, we find only dissimilar teammates that are incompatible with controllable agents, which highly reduces the number of teammates that need to be trained with. However, it is hard to determine the number of such incompatible teammates beforehand. We therefore introduce a continual multi-agent learning process, in which the agent learns to coordinate with different teammates until no more incompatible teammates can be found. The above idea is implemented in the proposed Macop (Multi-agent compatible policy learning) algorithm. We conduct experiments in 8 scenarios from 4 environments that have distinct coordination patterns. Experiments show that Macop generates training teammates with much lower compatibility than previous methods. As a result, in all scenarios Macop achieves the best overall coordination ability while never significantly worse than the baselines, showing strong generalization ability."
    },
    "d8e54607635f25e1f80f96448dc3f72c": {
        "title": "Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology View",
        "authors": [
            "Jintian Zhang",
            "Xin Xu",
            "Shumin Deng"
        ],
        "date": "2023/10/03",
        "pdf": "https://arxiv.org/pdf/2310.02124.pdf",
        "code": "https://github.com/zjunlp/MachineSoM",
        "abstract": "As Natural Language Processing (NLP) systems are increasingly employed in intricate social environments, a pressing query emerges: Can these NLP systems mirror human-esque collaborative intelligence, in a multi-agent society consisting of multiple large language models (LLMs)? This paper probes the collaboration mechanisms among contemporary NLP systems by melding practical experiments with theoretical insights. We fabricate four unique `societies&#39; comprised of LLM agents, where each agent is characterized by a specific `trait&#39; (easy-going or overconfident) and engages in collaboration with a distinct `thinking pattern&#39; (debate or reflection). Evaluating these multi-agent societies on three benchmark datasets, we discern that LLM agents navigate tasks by leveraging diverse social behaviors, from active debates to introspective reflections. Notably, certain collaborative strategies only optimize efficiency (using fewer API tokens), but also outshine previous top-tier approaches. Moreover, our results further illustrate that LLM agents manifest human-like social behaviors, such as conformity or majority rule, mirroring foundational Social Psychology theories. In conclusion, we integrate insights from Social Psychology to contextualize the collaboration of LLM agents, inspiring further investigations into the collaboration mechanism for LLMs. We commit to sharing our code and datasets (already submitted in supplementary materials), hoping to catalyze further research in this promising avenue (All code and data are available at \\url{https://github.com/zjunlp/MachineSoM}.)."
    },
    "f5c8363d28a1236e6465845e8e6559d4": {
        "title": "AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and Optimisation",
        "authors": [
            "Dong Huang",
            "Qingwen Bu",
            "Jie M. Zhang",
            "Michael Luck",
            "Heming Cui"
        ],
        "date": "2023/12/20",
        "pdf": "http://arxiv.org/pdf/2312.13010.pdf",
        "abstract": "The advancement of natural language processing (NLP) has been significantly boosted by the development of transformer-based large language models (LLMs). These models have revolutionized NLP tasks, particularly in code generation, aiding developers in creating software with enhanced efficiency. Despite their advancements, challenges in balancing code snippet generation with effective test case generation and execution persist. To address these issues, this paper introduces Multi-Agent Assistant Code Generation (AgentCoder), a novel solution comprising a multi-agent framework with specialized agents: the programmer agent, the test designer agent, and the test executor agent. During the coding procedure, the programmer agent will focus on the code generation and refinement based on the test executor agent&#39;s feedback. The test designer agent will generate test cases for the generated code, and the test executor agent will run the code with the test cases and write the feedback to the programmer. This collaborative system ensures robust code generation, surpassing the limitations of single-agent models and traditional methodologies. Our extensive experiments on 9 code generation models and 12 enhancement approaches showcase AgentCoder&#39;s superior performance over existing code generation models and prompt engineering techniques across various benchmarks. For example, AgentCoder achieves 77.4% and 89.1% pass@1 in HumanEval-ET and MBPP-ET with GPT-3.5, while SOTA baselines obtain only 69.5% and 63.0%."
    },
    "0f608fe3eaae4d7140d7e1b012544308": {
        "title": "MARG: Multi-Agent Review Generation for Scientific Papers",
        "authors": [
            "Mike D&#39;Arcy",
            "Tom Hope",
            "Larry Birnbaum",
            "Doug Downey"
        ],
        "date": "2024/01/08",
        "pdf": "http://arxiv.org/pdf/2401.04259.pdf",
        "abstract": "We study the ability of LLMs to generate feedback for scientific papers and develop MARG, a feedback generation approach using multiple LLM instances that engage in internal discussion. By distributing paper text across agents, MARG can consume the full text of papers beyond the input length limitations of the base LLM, and by specializing agents and incorporating sub-tasks tailored to different comment types (experiments, clarity, impact) it improves the helpfulness and specificity of feedback. In a user study, baseline methods using GPT-4 were rated as producing generic or very generic comments more than half the time, and only 1.7 comments per paper were rated as good overall in the best baseline. Our system substantially improves the ability of GPT-4 to generate specific and helpful feedback, reducing the rate of generic comments from 60% to 29% and generating 3.7 good comments per paper (a 2.2x improvement)."
    },
    "6eb13c310b738a72ae549f50036d452d": {
        "title": "SpeechAgents: Human-Communication Simulation with Multi-Modal Multi-Agent Systems",
        "authors": [
            "Dong Zhang",
            "Zhaowei Li",
            "Pengyu Wang",
            "Xin Zhang",
            "Yaqian Zhou",
            "Xipeng Qiu"
        ],
        "date": "2024/01/08",
        "pdf": "http://arxiv.org/pdf/2401.03945.pdf",
        "abstract": "Human communication is a complex and diverse process that not only involves multiple factors such as language, commonsense, and cultural backgrounds but also requires the participation of multimodal information, such as speech. Large Language Model (LLM)-based multi-agent systems have demonstrated promising performance in simulating human society. Can we leverage LLM-based multi-agent systems to simulate human communication? However, current LLM-based multi-agent systems mainly rely on text as the primary medium. In this paper, we propose SpeechAgents, a multi-modal LLM based multi-agent system designed for simulating human communication. SpeechAgents utilizes multi-modal LLM as the control center for individual agent and employes multi-modal signals as the medium for exchanged messages among agents. Additionally, we propose Multi-Agent Tuning to enhance the multi-agent capabilities of LLM without compromising general abilities. To strengthen and evaluate the effectiveness of human communication simulation, we build the Human-Communication Simulation Benchmark. Experimental results demonstrate that SpeechAgents can simulate human communication dialogues with consistent content, authentic rhythm, and rich emotions and demonstrate excellent scalability even with up to 25 agents, which can apply to tasks such as drama creation and audio novels generation. Code and models will be open-sourced at https://github. com/0nutation/SpeechAgents"
    },
    "b9ae12751107d3f49280fc6a22ba0d08": {
        "title": "Why Solving Multi-agent Path Finding with Large Language Model has not Succeeded Yet",
        "authors": [
            "Weizhe Chen",
            "Sven Koenig",
            "Bistra Dilkina"
        ],
        "date": "2024/01/08",
        "pdf": "http://arxiv.org/pdf/2401.03630.pdf",
        "abstract": "With the explosive influence caused by the success of large language models (LLM) like ChatGPT and GPT-4, there has been an extensive amount of recent work showing that foundation models can be used to solve a large variety of tasks. However, there is very limited work that shares insights on multi-agent planning. Multi-agent planning is different from other domains by combining the difficulty of multi-agent coordination and planning, and making it hard to leverage external tools to facilitate the reasoning needed. In this paper, we focus on the problem of multi-agent path finding (MAPF), which is also known as multi-robot route planning, and study how to solve MAPF with LLMs. We first show the motivating success on an empty room map without obstacles, then the failure to plan on a slightly harder room map. We present our hypothesis of why directly solving MAPF with LLMs has not been successful yet, and we use various experiments to support our hypothesis."
    },
    "bdfaf34ffca3c335dfac368a6bd9439a": {
        "title": "Combating Adversarial Attacks with Multi-Agent Debate",
        "authors": [
            "Steffi Chern",
            "Zhen Fan",
            "Andy Liu"
        ],
        "date": "2024/01/11",
        "pdf": "http://arxiv.org/pdf/2401.05998.pdf",
        "abstract": "While state-of-the-art language models have achieved impressive results, they remain susceptible to inference-time adversarial attacks, such as adversarial prompts generated by red teams arXiv:2209.07858. One approach proposed to improve the general quality of language model generations is multi-agent debate, where language models self-evaluate through discussion and feedback arXiv:2305.14325. We implement multi-agent debate between current state-of-the-art language models and evaluate models&#39; susceptibility to red team attacks in both single- and multi-agent settings. We find that multi-agent debate can reduce model toxicity when jailbroken or less capable models are forced to debate with non-jailbroken or more capable models. We also find marginal improvements through the general usage of multi-agent interactions. We further perform adversarial prompt content classification via embedding clustering, and analyze the susceptibility of different models to different types of attack topics."
    },
    "de2f7afa9bbbc00faa0191f82c0cab68": {
        "title": "MultiPrompter: Cooperative Prompt Optimization with Multi-Agent Reinforcement Learning",
        "authors": [
            "Dong-Ki Kim",
            "Sungryull Sohn",
            "Lajanugen Logeswaran",
            "Dongsub Shim",
            "Honglak Lee"
        ],
        "date": "2023/10/25",
        "pdf": "http://arxiv.org/pdf/2310.16730.pdf",
        "abstract": "Recently, there has been an increasing interest in automated prompt optimization based on reinforcement learning (RL). This approach offers important advantages, such as generating interpretable prompts and being compatible with black-box foundation models. However, the substantial prompt space size poses challenges for RL-based methods, often leading to suboptimal policy convergence. This paper introduces MultiPrompter, a new framework that views prompt optimization as a cooperative game between prompters which take turns composing a prompt together. Our cooperative prompt optimization effectively reduces the problem size and helps prompters learn optimal prompts. We test our method on the text-to-image task and show its ability to generate higher-quality images than baselines."
    },
    "2b83b0605caa5b7e0e3b46f73fbaa780": {
        "title": "Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games",
        "authors": [
            "Dekun Wu",
            "Haochen Shi",
            "Zhiyuan Sun",
            "Bang Liu"
        ],
        "date": "2023/12/01",
        "pdf": "http://arxiv.org/pdf/2312.00746.pdf",
        "abstract": "In this study, we explore the application of Large Language Models (LLMs) in &#34;Jubensha&#34; (Chinese murder mystery role-playing games), a novel area in AI-driven gaming. We introduce the first Chinese dataset specifically for Jubensha, including character scripts and game rules, to foster AI agent development in this complex narrative environment. Our work also presents a unique multi-agent interaction framework using LLMs, allowing AI agents to autonomously engage in the game, enhancing the dynamics of Jubensha gameplay. To evaluate these AI agents, we developed specialized methods targeting their mastery of case information and reasoning skills. Furthermore, we incorporated the latest advancements in in-context learning to improve the agents&#39; performance in critical aspects like information gathering, murderer detection, and logical reasoning. The experimental results validate the effectiveness of our proposed methods. This work aims to offer a fresh perspective on understanding LLM capabilities and establish a new benchmark for evaluating large language model-based agents to researchers in the field."
    },
    "e8e2e43e8e9e8ce333cd2a84b3902e41": {
        "title": "Multi-Agent Consensus Seeking via Large Language Models",
        "authors": [
            "Huaben Chen",
            "Wenkang Ji",
            "Lufeng Xu",
            "Shiyu Zhao"
        ],
        "date": "2023/10/31",
        "pdf": "http://arxiv.org/pdf/2310.20151.pdf",
        "abstract": "Multi-agent systems driven by large language models (LLMs) have shown promising abilities for solving complex tasks in a collaborative manner. This work considers a fundamental problem in multi-agent collaboration: consensus seeking. When multiple agents work together, we are interested in how they can reach a consensus through inter-agent negotiation. To that end, this work studies a consensus-seeking task where the state of each agent is a numerical value and they negotiate with each other to reach a consensus value. It is revealed that when not explicitly directed on which strategy should be adopted, the LLM-driven agents primarily use the average strategy for consensus seeking although they may occasionally use some other strategies. Moreover, this work analyzes the impact of the agent number, agent personality, and network topology on the negotiation process. The findings reported in this work can potentially lay the foundations for understanding the behaviors of LLM-driven multi-agent systems for solving more complex tasks. Furthermore, LLM-driven consensus seeking is applied to a multi-robot aggregation task. This application demonstrates the potential of LLM-driven agents to achieve zero-shot autonomous planning for multi-robot collaboration tasks. Project website: westlakeintelligentrobotics.github.io/ConsensusLLM/."
    }
}
{
    "5b608143a5925bfbbcf579346d04fa2e": {
        "title": "Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training",
        "authors": [
            "Evan Hubinger",
            "Carson Denison",
            "Jesse Mu",
            "Mike Lambert",
            "Meg Tong",
            "Monte MacDiarmid",
            "Tamera Lanham",
            "Daniel M. Ziegler",
            "Tim Maxwell",
            "Newton Cheng",
            "Adam Jermyn",
            "Amanda Askell",
            "Ansh Radhakrishnan",
            "Cem Anil",
            "David Duvenaud",
            "Deep Ganguli",
            "Fazl Barez",
            "Jack Clark",
            "Kamal Ndousse",
            "Kshitij Sachan",
            "Michael Sellitto",
            "Mrinank Sharma",
            "Nova DasSarma",
            "Roger Grosse",
            "Shauna Kravec",
            "Yuntao Bai",
            "Zachary Witten",
            "Marina Favaro",
            "Jan Brauner",
            "Holden Karnofsky",
            "Paul Christiano",
            "Samuel R. Bowman",
            "Logan Graham",
            "Jared Kaplan",
            "SÃ¶ren Mindermann",
            "Ryan Greenblatt",
            "Buck Shlegeris",
            "Nicholas Schiefer",
            "Ethan Perez"
        ],
        "date": "2024/01/10",
        "pdf": "http://arxiv.org/pdf/2401.05566",
        "abstract": "Humans are capable of strategically deceptive behavior: behaving helpfully in most situations, but then behaving very differently in order to pursue alternative objectives when given the opportunity. If an AI system learned such a deceptive strategy, could we detect it and remove it using current state-of-the-art safety training techniques? To study this question, we construct proof-of-concept examples of deceptive behavior in large language models (LLMs). For example, we train models that write secure code when the prompt states that the year is 2023, but insert exploitable code when the stated year is 2024. We find that such backdoor behavior can be made persistent, so that it is not removed by standard safety training techniques, including supervised fine-tuning, reinforcement learning, and adversarial training (eliciting unsafe behavior and then training to remove it). The backdoor behavior is most persistent in the largest models and in models trained to produce chain-of-thought reasoning about deceiving the training process, with the persistence remaining even when the chain-of-thought is distilled away. Furthermore, rather than removing backdoors, we find that adversarial training can teach models to better recognize their backdoor triggers, effectively hiding the unsafe behavior. Our results suggest that, once a model exhibits deceptive behavior, standard techniques could fail to remove such deception and create a false impression of safety.",
        "code": "",
        "category": [
            [
                "Training",
                "Fine tuning"
            ]
        ],
        "url": "https://arxiv.org/abs/2401.05566"
    },
    "e84680c3461c7d5e66d91a05c35cb6c9": {
        "title": "Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk",
        "authors": [
            "Dennis Ulmer",
            "Elman Mansimov",
            "Kaixiang Lin",
            "Justin Sun",
            "Xibin Gao",
            "Yi Zhang"
        ],
        "date": "2024/01/10",
        "pdf": "http://arxiv.org/pdf/2401.05033",
        "abstract": "Large language models (LLMs) are powerful dialogue agents, but specializing them towards fulfilling a specific function can be challenging. Instructing tuning, i.e. tuning models on instruction and sample responses generated by humans (Ouyang et al., 2022), has proven as an effective method to do so, yet requires a number of data samples that a) might not be available or b) costly to generate. Furthermore, this cost increases when the goal is to make the LLM follow a specific workflow within a dialogue instead of single instructions. Inspired by the self-play technique in reinforcement learning and the use of LLMs to simulate human agents, we propose a more effective method for data collection through LLMs engaging in a conversation in various roles. This approach generates a training data via &#34;self-talk&#34; of LLMs that can be refined and utilized for supervised fine-tuning. We introduce an automated way to measure the (partial) success of a dialogue. This metric is used to filter the generated conversational data that is fed back in LLM for training. Based on our automated and human evaluations of conversation quality, we demonstrate that such self-talk data improves results. In addition, we examine the various characteristics that showcase the quality of generated dialogues and how they can be connected to their potential utility as training data.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2401.05033"
    },
    "5b15ebb969f67edb0bff7a691cf357d6": {
        "title": "From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models",
        "authors": [
            "Na Liu",
            "Liangyu Chen",
            "Xiaoyu Tian",
            "Wei Zou",
            "Kaijiang Chen",
            "Ming Cui"
        ],
        "date": "2024/01/05",
        "pdf": "http://arxiv.org/pdf/2401.02777",
        "abstract": "This paper introduces RAISE (Reasoning and Acting through Scratchpad and Examples), an advanced architecture enhancing the integration of Large Language Models (LLMs) like GPT-4 into conversational agents. RAISE, an enhancement of the ReAct framework, incorporates a dual-component memory system, mirroring human short-term and long-term memory, to maintain context and continuity in conversations. It entails a comprehensive agent construction scenario, including phases like Conversation Selection, Scene Extraction, CoT Completion, and Scene Augmentation, leading to the LLMs Training phase. This approach appears to enhance agent controllability and adaptability in complex, multi-turn dialogues. Our preliminary evaluations in a real estate sales context suggest that RAISE has some advantages over traditional agents, indicating its potential for broader applications. This work contributes to the AI field by providing a robust framework for developing more context-aware and versatile conversational agents.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Memory Mechanism"
            ],
            [
                "Training",
                "Fine tuning"
            ]
        ],
        "url": "https://arxiv.org/abs/2401.02777"
    },
    "4da8b341d1dc74b5c91c82a8b8332fe3": {
        "title": "AutoAct: Automatic Agent Learning from Scratch for QA via Self-Planning",
        "authors": [
            "Shuofei Qiao",
            "Ningyu Zhang",
            "Runnan Fang",
            "Yujie Luo",
            "Wangchunshu Zhou",
            "Yuchen Eleanor Jiang",
            "Chengfei Lv",
            "Huajun Chen"
        ],
        "date": "2024/01/10",
        "pdf": "http://arxiv.org/pdf/2401.05268",
        "abstract": "Language agents have achieved considerable performance on various complex question-answering tasks by planning with external tools. Despite the incessant exploration in this field, existing language agent systems still struggle with costly, non-reproducible data reliance and face the challenge of compelling a single model for multiple functions. To this end, we introduce AutoAct, an automatic agent learning framework for QA that does not rely on large-scale annotated data and synthetic planning trajectories from closed-source models (e.g., GPT-4). Given limited data with a tool library, AutoAct first automatically synthesizes planning trajectories without any assistance from humans or strong closed-source models. Then, AutoAct leverages a division-of-labor strategy to automatically differentiate based on the target task information and synthesized trajectories, producing a sub-agent group to complete the task. We conduct comprehensive experiments with different LLMs, which demonstrates that AutoAct yields better or parallel performance compared to various strong baselines. Further analysis demonstrates the effectiveness of the division-of-labor strategy, with the trajectory quality generated by AutoAct generally outperforming that of others. Code will be available at https://github.com/zjunlp/AutoAct.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2401.05268"
    },
    "ca294c5bb4a93752040084e62a9bedc9": {
        "title": "CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation",
        "authors": [
            "Quan Tu",
            "Shilong Fan",
            "Zihang Tian",
            "Rui Yan"
        ],
        "date": "2024/01/02",
        "pdf": "http://arxiv.org/pdf/2401.01275",
        "abstract": "Recently, the advent of large language models (LLMs) has revolutionized generative agents. Among them, Role-Playing Conversational Agents (RPCAs) attract considerable attention due to their ability to emotionally engage users. However, the absence of a comprehensive benchmark impedes progress in this field. To bridge this gap, we introduce CharacterEval, a Chinese benchmark for comprehensive RPCA assessment, complemented by a tailored high-quality dataset. The dataset comprises 1,785 multi-turn role-playing dialogues, encompassing 23,020 examples and featuring 77 characters derived from Chinese novels and scripts. It was carefully constructed, beginning with initial dialogue extraction via GPT-4, followed by rigorous human-led quality control, and enhanced with in-depth character profiles sourced from Baidu Baike. CharacterEval employs a multifaceted evaluation approach, encompassing thirteen targeted metrics on four dimensions. Comprehensive experiments on CharacterEval demonstrate that Chinese LLMs exhibit more promising capabilities than GPT-4 in Chinese role-playing conversation. Source code, data source and reward model will be publicly accessible at https://github.com/morecry/CharacterEval.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ],
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2401.01275"
    },
    "0c56afc81fe63849e15821130b7b8562": {
        "title": "AFSPP: Agent Framework for Shaping Preference and Personality with Large Language Models",
        "authors": [
            "Zihong He",
            "Changwang Zhang"
        ],
        "date": "2024/01/05",
        "pdf": "http://arxiv.org/pdf/2401.02870",
        "abstract": "The evolution of Large Language Models (LLMs) has introduced a new paradigm for investigating human behavior emulation. Recent research has employed LLM-based Agents to create a sociological research environment, in which agents exhibit behavior based on the unfiltered characteristics of large language models. However, these studies overlook the iterative development within a human-like setting - Human preferences and personalities are complex, shaped by various factors and subject to ongoing change as a result of environmental and subjective influences. In light of this observation, we propose Agent Framework for Shaping Preference and Personality (AFSPP), exploring the multifaceted impact of social networks and subjective consciousness on LLM-based Agents&#39; preference and personality formation. With AFSPP, we have, for the first time, successfully replicated several key findings from human personality experiments. And other AFSPP-based experimental results indicate that plan making, sensory perceptions and social networking with subjective information, wield the most pronounced influence on preference shaping. AFSPP can significantly enhance the efficiency and scope of psychological experiments, while yielding valuable insights for Trustworthy Artificial Intelligence research for strategies to prevent undesirable preference and personality development.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2401.02870"
    },
    "0f608fe3eaae4d7140d7e1b012544308": {
        "title": "MARG: Multi-Agent Review Generation for Scientific Papers",
        "authors": [
            "Mike D&#39;Arcy",
            "Tom Hope",
            "Larry Birnbaum",
            "Doug Downey"
        ],
        "date": "2024/01/08",
        "pdf": "http://arxiv.org/pdf/2401.04259",
        "abstract": "We study the ability of LLMs to generate feedback for scientific papers and develop MARG, a feedback generation approach using multiple LLM instances that engage in internal discussion. By distributing paper text across agents, MARG can consume the full text of papers beyond the input length limitations of the base LLM, and by specializing agents and incorporating sub-tasks tailored to different comment types (experiments, clarity, impact) it improves the helpfulness and specificity of feedback. In a user study, baseline methods using GPT-4 were rated as producing generic or very generic comments more than half the time, and only 1.7 comments per paper were rated as good overall in the best baseline. Our system substantially improves the ability of GPT-4 to generate specific and helpful feedback, reducing the rate of generic comments from 60% to 29% and generating 3.7 good comments per paper (a 2.2x improvement).",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Application",
                "Research"
            ]
        ],
        "url": "https://arxiv.org/abs/2401.04259"
    },
    "6eb13c310b738a72ae549f50036d452d": {
        "title": "SpeechAgents: Human-Communication Simulation with Multi-Modal Multi-Agent Systems",
        "authors": [
            "Dong Zhang",
            "Zhaowei Li",
            "Pengyu Wang",
            "Xin Zhang",
            "Yaqian Zhou",
            "Xipeng Qiu"
        ],
        "date": "2024/01/08",
        "pdf": "http://arxiv.org/pdf/2401.03945",
        "abstract": "Human communication is a complex and diverse process that not only involves multiple factors such as language, commonsense, and cultural backgrounds but also requires the participation of multimodal information, such as speech. Large Language Model (LLM)-based multi-agent systems have demonstrated promising performance in simulating human society. Can we leverage LLM-based multi-agent systems to simulate human communication? However, current LLM-based multi-agent systems mainly rely on text as the primary medium. In this paper, we propose SpeechAgents, a multi-modal LLM based multi-agent system designed for simulating human communication. SpeechAgents utilizes multi-modal LLM as the control center for individual agent and employes multi-modal signals as the medium for exchanged messages among agents. Additionally, we propose Multi-Agent Tuning to enhance the multi-agent capabilities of LLM without compromising general abilities. To strengthen and evaluate the effectiveness of human communication simulation, we build the Human-Communication Simulation Benchmark. Experimental results demonstrate that SpeechAgents can simulate human communication dialogues with consistent content, authentic rhythm, and rich emotions and demonstrate excellent scalability even with up to 25 agents, which can apply to tasks such as drama creation and audio novels generation. Code and models will be open-sourced at https://github. com/0nutation/SpeechAgents",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2401.03945"
    },
    "b9ae12751107d3f49280fc6a22ba0d08": {
        "title": "Why Solving Multi-agent Path Finding with Large Language Model has not Succeeded Yet",
        "authors": [
            "Weizhe Chen",
            "Sven Koenig",
            "Bistra Dilkina"
        ],
        "date": "2024/01/08",
        "pdf": "http://arxiv.org/pdf/2401.03630",
        "abstract": "With the explosive influence caused by the success of large language models (LLM) like ChatGPT and GPT-4, there has been an extensive amount of recent work showing that foundation models can be used to solve a large variety of tasks. However, there is very limited work that shares insights on multi-agent planning. Multi-agent planning is different from other domains by combining the difficulty of multi-agent coordination and planning, and making it hard to leverage external tools to facilitate the reasoning needed. In this paper, we focus on the problem of multi-agent path finding (MAPF), which is also known as multi-robot route planning, and study the performance of solving MAPF with LLMs. We first show the motivating success on an empty room map without obstacles, then the failure to plan on the harder room map and maze map of the standard MAPF benchmark. We present our position on why directly solving MAPF with LLMs has not been successful yet, and we use various experiments to support our hypothesis. Based on our results, we discussed how researchers with different backgrounds could help with this problem from different perspectives.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2401.03630"
    },
    "bdfaf34ffca3c335dfac368a6bd9439a": {
        "title": "Combating Adversarial Attacks with Multi-Agent Debate",
        "authors": [
            "Steffi Chern",
            "Zhen Fan",
            "Andy Liu"
        ],
        "date": "2024/01/11",
        "pdf": "http://arxiv.org/pdf/2401.05998",
        "abstract": "While state-of-the-art language models have achieved impressive results, they remain susceptible to inference-time adversarial attacks, such as adversarial prompts generated by red teams arXiv:2209.07858. One approach proposed to improve the general quality of language model generations is multi-agent debate, where language models self-evaluate through discussion and feedback arXiv:2305.14325. We implement multi-agent debate between current state-of-the-art language models and evaluate models&#39; susceptibility to red team attacks in both single- and multi-agent settings. We find that multi-agent debate can reduce model toxicity when jailbroken or less capable models are forced to debate with non-jailbroken or more capable models. We also find marginal improvements through the general usage of multi-agent interactions. We further perform adversarial prompt content classification via embedding clustering, and analyze the susceptibility of different models to different types of attack topics.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2401.05998"
    },
    "815211b5ab3616d6d3d1fba384bca69a": {
        "title": "Agent Alignment in Evolving Social Norms",
        "authors": [
            "Shimin Li",
            "Tianxiang Sun",
            "Qinyuan Cheng",
            "Xipeng Qiu"
        ],
        "date": "2024/01/09",
        "pdf": "http://arxiv.org/pdf/2401.04620",
        "abstract": "Agents based on Large Language Models (LLMs) are increasingly permeating various domains of human production and life, highlighting the importance of aligning them with human values. The current alignment of AI systems primarily focuses on passively aligning LLMs through human intervention. However, agents possess characteristics like receiving environmental feedback and self-evolution, rendering the LLM alignment methods inadequate. In response, we propose an evolutionary framework for agent evolution and alignment, named EvolutionaryAgent, which transforms agent alignment into a process of evolution and selection under the principle of survival of the fittest. In an environment where social norms continuously evolve, agents better adapted to the current social norms will have a higher probability of survival and proliferation, while those inadequately aligned dwindle over time. Experimental results assessing the agents from multiple perspectives in aligning with social norms demonstrate that EvolutionaryAgent can align progressively better with the evolving social norms while maintaining its proficiency in general tasks. Effectiveness tests conducted on various open and closed-source LLMs as the foundation for agents also prove the applicability of our approach.",
        "code": "",
        "category": [
            [
                "Stability",
                "Bias"
            ]
        ],
        "url": "https://arxiv.org/abs/2401.04620"
    },
    "c7716e44d8d1c20e6e1fa9922dfc75d7": {
        "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
        "authors": [
            "Ke Yang",
            "Jiateng Liu",
            "John Wu",
            "Chaoqi Yang",
            "Yi R. Fung",
            "Sha Li",
            "Zixuan Huang",
            "Xu Cao",
            "Xingyao Wang",
            "Yiquan Wang",
            "Heng Ji",
            "Chengxiang Zhai"
        ],
        "date": "2024/01/01",
        "pdf": "http://arxiv.org/pdf/2401.00812",
        "abstract": "The prominent large language models (LLMs) of today differ from past language models not only in size, but also in the fact that they are trained on a combination of natural language and formal language (code). As a medium between humans and computers, code translates high-level goals into executable steps, featuring standard syntax, logical consistency, abstraction, and modularity. In this survey, we present an overview of the various benefits of integrating code into LLMs&#39; training data. Specifically, beyond enhancing LLMs in code generation, we observe that these unique properties of code help (i) unlock the reasoning ability of LLMs, enabling their applications to a range of more complex natural language tasks; (ii) steer LLMs to produce structured and precise intermediate steps, which can then be connected to external execution ends through function calls; and (iii) take advantage of code compilation and execution environment, which also provides diverse feedback for model improvement. In addition, we trace how these profound capabilities of LLMs, brought by code, have led to their emergence as intelligent agents (IAs) in situations where the ability to understand instructions, decompose goals, plan and execute actions, and refine from feedback are crucial to their success on downstream tasks. Finally, we present several key challenges and future directions of empowering LLMs with code.",
        "code": "",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2401.00812"
    },
    "039db49f2e19de35f5de8b42670347a3": {
        "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
        "authors": [
            "Boyuan Zheng",
            "Boyu Gou",
            "Jihyung Kil",
            "Huan Sun",
            "Yu Su"
        ],
        "date": "2024/01/03",
        "pdf": "http://arxiv.org/pdf/2401.01614",
        "abstract": "The recent development on large multimodal models (LMMs), especially GPT-4V(ision) and Gemini, has been quickly expanding the capability boundaries of multimodal models beyond traditional tasks like image captioning and visual question answering. In this work, we explore the potential of LMMs like GPT-4V as a generalist web agent that can follow natural language instructions to complete tasks on any given website. We propose SEEACT, a generalist web agent that harnesses the power of LMMs for integrated visual understanding and acting on the web. We evaluate on the recent MIND2WEB benchmark. In addition to standard offline evaluation on cached websites, we enable a new online evaluation setting by developing a tool that allows running web agents on live websites. We show that GPT-4V presents a great potential for web agents -- it can successfully complete 51.1 of the tasks on live websites if we manually ground its textual plans into actions on the websites. This substantially outperforms text-only LLMs like GPT-4 or smaller models (FLAN-T5 and BLIP-2) specifically fine-tuned for web agents. However, grounding still remains a major challenge. Existing LMM grounding strategies like set-of-mark prompting turns out to be not effective for web agents, and the best grounding strategy we develop in this paper leverages both the HTML structure and visuals. Yet, there is still a substantial gap with oracle grounding, leaving ample room for further improvement. All code, data, and evaluation tools are available at https://github.com/OSU-NLP-Group/SeeAct.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2401.01614"
    },
    "c5e9a179be09dac22812b7f097407e07": {
        "title": "PlanGPT: Enhancing Urban Planning with Tailored Language Model and Efficient Retrieval",
        "authors": [
            "He Zhu",
            "Wenjia Zhang",
            "Nuoxian Huang",
            "Boyang Li",
            "Luyao Niu",
            "Zipei Fan",
            "Tianle Lun",
            "Yicheng Tao",
            "Junyou Su",
            "Zhaoya Gong",
            "Chenyu Fang",
            "Xing Liu"
        ],
        "date": "2024/02/29",
        "pdf": "http://arxiv.org/pdf/2402.19273",
        "abstract": "In the field of urban planning, general-purpose large language models often struggle to meet the specific needs of planners. Tasks like generating urban planning texts, retrieving related information, and evaluating planning documents pose unique challenges. To enhance the efficiency of urban professionals and overcome these obstacles, we introduce PlanGPT, the first specialized Large Language Model tailored for urban and spatial planning. Developed through collaborative efforts with institutions like the Chinese Academy of Urban Planning, PlanGPT leverages a customized local database retrieval framework, domain-specific fine-tuning of base models, and advanced tooling capabilities. Empirical tests demonstrate that PlanGPT has achieved advanced performance, delivering responses of superior quality precisely tailored to the intricacies of urban planning.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.19273"
    },
    "bb03d9d04304fb8cf361615291a5e13d": {
        "title": "On the Decision-Making Abilities in Role-Playing using Large Language Models",
        "authors": [
            "Chenglei Shen",
            "Guofu Xie",
            "Xiao Zhang",
            "Jun Xu"
        ],
        "date": "2024/02/29",
        "pdf": "http://arxiv.org/pdf/2402.18807",
        "abstract": "Large language models (LLMs) are now increasingly utilized for role-playing tasks, especially in impersonating domain-specific experts, primarily through role-playing prompts. When interacting in real-world scenarios, the decision-making abilities of a role significantly shape its behavioral patterns. In this paper, we concentrate on evaluating the decision-making abilities of LLMs post role-playing thereby validating the efficacy of role-playing. Our goal is to provide metrics and guidance for enhancing the decision-making abilities of LLMs in role-playing tasks. Specifically, we first use LLMs to generate virtual role descriptions corresponding to the 16 personality types of Myers-Briggs Type Indicator (abbreviated as MBTI) representing a segmentation of the population. Then we design specific quantitative operations to evaluate the decision-making abilities of LLMs post role-playing from four aspects: adaptability, exploration$\\&amp;$exploitation trade-off ability, reasoning ability, and safety. Finally, we analyze the association between the performance of decision-making and the corresponding MBTI types through GPT-4. Extensive experiments demonstrate stable differences in the four aspects of decision-making abilities across distinct roles, signifying a robust correlation between decision-making abilities and the roles emulated by LLMs. These results underscore that LLMs can effectively impersonate varied roles while embodying their genuine sociological characteristics.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.18807"
    },
    "2b67bb3cf1de46c69a656f1dd20fd49a": {
        "title": "Large Language Models and Games: A Survey and Roadmap",
        "authors": [
            "Roberto Gallotta",
            "Graham Todd",
            "Marvin Zammit",
            "Sam Earle",
            "Antonios Liapis",
            "Julian Togelius",
            "Georgios N. Yannakakis"
        ],
        "date": "2024/02/28",
        "pdf": "http://arxiv.org/pdf/2402.18659",
        "abstract": "Recent years have seen an explosive increase in research on large language models (LLMs), and accompanying public engagement on the topic. While starting as a niche area within natural language processing, LLMs have shown remarkable potential across a broad range of applications and domains, including games. This paper surveys the current state of the art across the various applications of LLMs in and for games, and identifies the different roles LLMs can take within a game. Importantly, we discuss underexplored areas and promising directions for future uses of LLMs in games and we reconcile the potential and limitations of LLMs within the games domain. As the first comprehensive survey and roadmap at the intersection of LLMs and games, we are hopeful that this paper will serve as the basis for groundbreaking research and innovation in this exciting new field.",
        "code": "",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2402.18659"
    },
    "aaf7b78ec6f39f72b41938c6a0519e85": {
        "title": "Evaluating Very Long-Term Conversational Memory of LLM Agents",
        "authors": [
            "Adyasha Maharana",
            "Dong-Ho Lee",
            "Sergey Tulyakov",
            "Mohit Bansal",
            "Francesco Barbieri",
            "Yuwei Fang"
        ],
        "date": "2024/02/27",
        "pdf": "http://arxiv.org/pdf/2402.17753",
        "abstract": "Existing works on long-term open-domain dialogues focus on evaluating model responses within contexts spanning no more than five chat sessions. Despite advancements in long-context large language models (LLMs) and retrieval augmented generation (RAG) techniques, their efficacy in very long-term dialogues remains unexplored. To address this research gap, we introduce a machine-human pipeline to generate high-quality, very long-term dialogues by leveraging LLM-based agent architectures and grounding their dialogues on personas and temporal event graphs. Moreover, we equip each agent with the capability of sharing and reacting to images. The generated conversations are verified and edited by human annotators for long-range consistency and grounding to the event graphs. Using this pipeline, we collect LoCoMo, a dataset of very long-term conversations, each encompassing 300 turns and 9K tokens on avg., over up to 35 sessions. Based on LoCoMo, we present a comprehensive evaluation benchmark to measure long-term memory in models, encompassing question answering, event summarization, and multi-modal dialogue generation tasks. Our experimental results indicate that LLMs exhibit challenges in understanding lengthy conversations and comprehending long-range temporal and causal dynamics within dialogues. Employing strategies like long-context LLMs or RAG can offer improvements but these models still substantially lag behind human performance.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.17753"
    },
    "8e89988cfaaa29803f9c446bc8ee3eaf": {
        "title": "BASES: Large-scale Web Search User Simulation with Large Language Model based Agents",
        "authors": [
            "Ruiyang Ren",
            "Peng Qiu",
            "Yingqi Qu",
            "Jing Liu",
            "Wayne Xin Zhao",
            "Hua Wu",
            "Ji-Rong Wen",
            "Haifeng Wang"
        ],
        "date": "2024/02/27",
        "pdf": "http://arxiv.org/pdf/2402.17505",
        "abstract": "Due to the excellent capacities of large language models (LLMs), it becomes feasible to develop LLM-based agents for reliable user simulation. Considering the scarcity and limit (e.g., privacy issues) of real user data, in this paper, we conduct large-scale user simulation for web search, to improve the analysis and modeling of user search behavior. Specially, we propose BASES, a novel user simulation framework with LLM-based agents, designed to facilitate comprehensive simulations of web search user behaviors. Our simulation framework can generate unique user profiles at scale, which subsequently leads to diverse search behaviors. To demonstrate the effectiveness of BASES, we conduct evaluation experiments based on two human benchmarks in both Chinese and English, demonstrating that BASES can effectively simulate large-scale human-like search behaviors. To further accommodate the research on web search, we develop WARRIORS, a new large-scale dataset encompassing web search user behaviors, including both Chinese and English versions, which can greatly bolster research in the field of information retrieval. Our code and data will be publicly released soon.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.17505"
    },
    "ab05a8f2b05390e1cbe83e0b06b55b43": {
        "title": "Benchmarking Data Science Agents",
        "authors": [
            "Yuge Zhang",
            "Qiyang Jiang",
            "Xingyu Han",
            "Nan Chen",
            "Yuqing Yang",
            "Kan Ren"
        ],
        "date": "2024/02/27",
        "pdf": "http://arxiv.org/pdf/2402.17168",
        "abstract": "In the era of data-driven decision-making, the complexity of data analysis necessitates advanced expertise and tools of data science, presenting significant challenges even for specialists. Large Language Models (LLMs) have emerged as promising aids as data science agents, assisting humans in data analysis and processing. Yet their practical efficacy remains constrained by the varied demands of real-world applications and complicated analytical process. In this paper, we introduce DSEval -- a novel evaluation paradigm, as well as a series of innovative benchmarks tailored for assessing the performance of these agents throughout the entire data science lifecycle. Incorporating a novel bootstrapped annotation method, we streamline dataset preparation, improve the evaluation coverage, and expand benchmarking comprehensiveness. Our findings uncover prevalent obstacles and provide critical insights to inform future advancements in the field.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.17168"
    },
    "8baca9839158cad236aad1235f6695c7": {
        "title": "RepoAgent: An LLM-Powered Open-Source Framework for Repository-level Code Documentation Generation",
        "authors": [
            "Qinyu Luo",
            "Yining Ye",
            "Shihao Liang",
            "Zhong Zhang",
            "Yujia Qin",
            "Yaxi Lu",
            "Yesai Wu",
            "Xin Cong",
            "Yankai Lin",
            "Yingli Zhang",
            "Xiaoyin Che",
            "Zhiyuan Liu",
            "Maosong Sun"
        ],
        "date": "2024/02/26",
        "pdf": "http://arxiv.org/pdf/2402.16667",
        "abstract": "Generative models have demonstrated considerable potential in software engineering, particularly in tasks such as code generation and debugging. However, their utilization in the domain of code documentation generation remains underexplored. To this end, we introduce RepoAgent, a large language model powered open-source framework aimed at proactively generating, maintaining, and updating code documentation. Through both qualitative and quantitative evaluations, we have validated the effectiveness of our approach, showing that RepoAgent excels in generating high-quality repository-level documentation. The code and results are publicly accessible at https://github.com/OpenBMB/RepoAgent.",
        "code": "",
        "category": [
            [
                "Application",
                "Software Engineering"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.16667"
    },
    "4c8c556d314a7cbb7541e472f63cbccd": {
        "title": "Language Agents as Optimizable Graphs",
        "authors": [
            "Mingchen Zhuge",
            "Wenyi Wang",
            "Louis Kirsch",
            "Francesco Faccio",
            "Dmitrii Khizbullin",
            "JÃ¼rgen Schmidhuber"
        ],
        "date": "2024/02/26",
        "pdf": "http://arxiv.org/pdf/2402.16823",
        "abstract": "Various human-designed prompt engineering techniques have been proposed to improve problem solvers based on Large Language Models (LLMs), yielding many disparate code bases. We unify these approaches by describing LLM-based agents as computational graphs. The nodes implement functions to process multimodal data or query LLMs, and the edges describe the information flow between operations. Graphs can be recursively combined into larger composite graphs representing hierarchies of inter-agent collaboration (where edges connect operations of different agents). Our novel automatic graph optimizers (1) refine node-level LLM prompts (node optimization) and (2) improve agent orchestration by changing graph connectivity (edge optimization). Experiments demonstrate that our framework can be used to efficiently develop, integrate, and automatically improve various LLM agents. The code can be found at https://github.com/metauto-ai/gptswarm.",
        "code": "https://github.com/metauto-ai/gptswarm",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.16823"
    },
    "6edba424f625da489f6bcf7dac4d5a57": {
        "title": "Unveiling the Truth and Facilitating Change: Towards Agent-based Large-scale Social Movement Simulation",
        "authors": [
            "Xinyi Mou",
            "Zhongyu Wei",
            "Xuanjing Huang"
        ],
        "date": "2024/02/26",
        "pdf": "http://arxiv.org/pdf/2402.16333",
        "abstract": "Social media has emerged as a cornerstone of social movements, wielding significant influence in driving societal change. Simulating the response of the public and forecasting the potential impact has become increasingly important. However, existing methods for simulating such phenomena encounter challenges concerning their efficacy and efficiency in capturing the behaviors of social movement participants. In this paper, we introduce a hybrid framework HiSim for social media user simulation, wherein users are categorized into two types. Core users are driven by Large Language Models, while numerous ordinary users are modeled by deductive agent-based models. We further construct a Twitter-like environment to replicate their response dynamics following trigger events. Subsequently, we develop a multi-faceted benchmark SoMoSiMu-Bench for evaluation and conduct comprehensive experiments across real-world datasets. Experimental results demonstrate the effectiveness and flexibility of our method.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.16333"
    },
    "a5538ed0a6964ec13a4ebdd94f383ecc": {
        "title": "AgentOhana: Design Unified Data and Training Pipeline for Effective Agent Learning",
        "authors": [
            "Jianguo Zhang",
            "Tian Lan",
            "Rithesh Murthy",
            "Zhiwei Liu",
            "Weiran Yao",
            "Ming Zhu",
            "Juntao Tan",
            "Thai Hoang",
            "Zuxin Liu",
            "Liangwei Yang",
            "Yihao Feng",
            "Shirley Kokane",
            "Tulika Awalgaonkar",
            "Juan Carlos Niebles",
            "Silvio Savarese",
            "Shelby Heinecke",
            "Huan Wang",
            "Caiming Xiong"
        ],
        "date": "2024/02/23",
        "pdf": "http://arxiv.org/pdf/2402.15506",
        "abstract": "Autonomous agents powered by large language models (LLMs) have garnered significant research attention. However, fully harnessing the potential of LLMs for agent-based tasks presents inherent challenges due to the heterogeneous nature of diverse data sources featuring multi-turn trajectories. In this paper, we introduce \\textbf{AgentOhana} as a comprehensive solution to address these challenges. \\textit{AgentOhana} aggregates agent trajectories from distinct environments, spanning a wide array of scenarios. It meticulously standardizes and unifies these trajectories into a consistent format, streamlining the creation of a generic data loader optimized for agent training. Leveraging the data unification, our training pipeline maintains equilibrium across different data sources and preserves independent randomness across devices during dataset partitioning and model training. Additionally, we present \\textbf{xLAM-v0.1}, a large action model tailored for AI agents, which demonstrates exceptional performance across various benchmarks. Begin the exploration at \\url{https://github.com/SalesforceAIResearch/xLAM}.",
        "code": "",
        "category": [
            [
                "Training",
                "Fine tuning"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.15506"
    },
    "f9329da7eacdad837ccd68b129b853c6": {
        "title": "Generation, Distillation and Evaluation of Motivational Interviewing-Style Reflections with a Foundational Language Model",
        "authors": [
            "Andrew Brown",
            "Jiading Zhu",
            "Mohamed Abdelwahab",
            "Alec Dong",
            "Cindy Wang",
            "Jonathan Rose"
        ],
        "date": "2024/02/01",
        "pdf": "http://arxiv.org/pdf/2402.01051",
        "abstract": "Large Foundational Language Models are capable of performing many tasks at a high level but are difficult to deploy in many applications because of their size and proprietary ownership. Many will be motivated to distill specific capabilities of foundational models into smaller models that can be owned and controlled. In the development of a therapeutic chatbot, we wish to distill a capability known as reflective listening, in which a therapist produces reflections of client speech. These reflections either restate what a client has said, or connect what was said to a relevant observation, idea or guess that encourages and guides the client to continue contemplation. In this paper, we present a method for distilling the generation of reflections from a Foundational Language Model (GPT-4) into smaller models. We first show that GPT-4, using zero-shot prompting, can generate reflections at near 100% success rate, superior to all previous methods. Using reflections generated by GPT-4, we fine-tune different sizes of the GPT-2 family. The GPT-2-small model achieves 83% success on a hold-out test set and the GPT-2 XL achieves 90% success. We also show that GPT-4 can help in the labor-intensive task of evaluating the quality of the distilled models, using it as a zero-shot classifier. Using triple-human review as a guide, the classifier achieves a Cohen-Kappa of 0.66, a substantial inter-rater reliability figure.",
        "code": "",
        "category": [
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.01051"
    },
    "fcabab00a378e1841f69e2241deddfa9": {
        "title": "Reasoning Capacity in Multi-Agent Systems: Limitations, Challenges and Human-Centered Solutions",
        "authors": [
            "Pouya Pezeshkpour",
            "Eser Kandogan",
            "Nikita Bhutani",
            "Sajjadur Rahman",
            "Tom Mitchell",
            "Estevam Hruschka"
        ],
        "date": "2024/02/02",
        "pdf": "http://arxiv.org/pdf/2402.01108",
        "abstract": "Remarkable performance of large language models (LLMs) in a variety of tasks brings forth many opportunities as well as challenges of utilizing them in production settings. Towards practical adoption of LLMs, multi-agent systems hold great promise to augment, integrate, and orchestrate LLMs in the larger context of enterprise platforms that use existing proprietary data and models to tackle complex real-world tasks. Despite the tremendous success of these systems, current approaches rely on narrow, single-focus objectives for optimization and evaluation, often overlooking potential constraints in real-world scenarios, including restricted budgets, resources and time. Furthermore, interpreting, analyzing, and debugging these systems requires different components to be evaluated in relation to one another. This demand is currently not feasible with existing methodologies. In this postion paper, we introduce the concept of reasoning capacity as a unifying criterion to enable integration of constraints during optimization and establish connections among different components within the system, which also enable a more holistic and comprehensive approach to evaluation. We present a formal definition of reasoning capacity and illustrate its utility in identifying limitations within each component of the system. We then argue how these limitations can be addressed with a self-reflective process wherein human-feedback is used to alleviate shortcomings in reasoning and enhance overall consistency of the system.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.01108"
    },
    "426a7d04fbea7fc6a79285e5550740b2": {
        "title": "TrustAgent: Towards Safe and Trustworthy LLM-based Agents",
        "authors": [
            "Wenyue Hua",
            "Xianjun Yang",
            "Mingyu Jin",
            "Zelong Li",
            "Wei Cheng",
            "Ruixiang Tang",
            "Yongfeng Zhang"
        ],
        "date": "2024/02/02",
        "pdf": "http://arxiv.org/pdf/2402.01586",
        "abstract": "The rise of LLM-based agents shows great potential to revolutionize task planning, capturing significant attention. Given that these agents will be integrated into high-stake domains, ensuring their reliability and safety is crucial. This paper presents an Agent-Constitution-based agent framework, TrustAgent, with a particular focus on improving the LLM-based agent safety. The proposed framework ensures strict adherence to the Agent Constitution through three strategic components: pre-planning strategy which injects safety knowledge to the model before plan generation, in-planning strategy which enhances safety during plan generation, and post-planning strategy which ensures safety by post-planning inspection. Our experimental results demonstrate that the proposed framework can effectively enhance an LLM agent&#39;s safety across multiple domains by identifying and mitigating potential dangers during the planning. Further analysis reveals that the framework not only improves safety but also enhances the helpfulness of the agent. Additionally, we highlight the importance of the LLM reasoning ability in adhering to the Constitution. This paper sheds light on how to ensure the safe integration of LLM-based agents into human-centric environments. Data and code are available at https://github.com/agiresearch/TrustAgent.",
        "code": "",
        "category": [
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.01586"
    },
    "88881d9d9219e2d3a274466dfd101760": {
        "title": "TravelPlanner: A Benchmark for Real-World Planning with Language Agents",
        "authors": [
            "Jian Xie",
            "Kai Zhang",
            "Jiangjie Chen",
            "Tinghui Zhu",
            "Renze Lou",
            "Yuandong Tian",
            "Yanghua Xiao",
            "Yu Su"
        ],
        "date": "2024/02/02",
        "pdf": "http://arxiv.org/pdf/2402.01622",
        "abstract": "Planning has been part of the core pursuit for artificial intelligence since its conception, but earlier AI agents mostly focused on constrained settings because many of the cognitive substrates necessary for human-level planning have been lacking. Recently, language agents powered by large language models (LLMs) have shown interesting capabilities such as tool use and reasoning. Are these language agents capable of planning in more complex settings that are out of the reach of prior AI agents? To advance this investigation, we propose TravelPlanner, a new planning benchmark that focuses on travel planning, a common real-world planning scenario. It provides a rich sandbox environment, various tools for accessing nearly four million data records, and 1,225 meticulously curated planning intents and reference plans. Comprehensive evaluations show that the current language agents are not yet capable of handling such complex planning tasks-even GPT-4 only achieves a success rate of 0.6%. Language agents struggle to stay on task, use the right tools to collect information, or keep track of multiple constraints. However, we note that the mere possibility for language agents to tackle such a complex problem is in itself non-trivial progress. TravelPlanner provides a challenging yet meaningful testbed for future language agents.",
        "code": "https://github.com/OSU-NLP-Group/TravelPlanner",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.01622"
    },
    "8447f702715c2b57c8891a3bac8e010e": {
        "title": "Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues",
        "authors": [
            "Yuncheng Hua",
            "Lizhen Qu",
            "Gholamreza Haffari"
        ],
        "date": "2024/01/29",
        "pdf": "http://arxiv.org/pdf/2402.01737",
        "abstract": "We develop assistive agents based on Large Language Models (LLMs) that aid interlocutors in business negotiations. Specifically, we simulate business negotiations by letting two LLM-based agents engage in role play. A third LLM acts as a remediator agent to rewrite utterances violating norms for improving negotiation outcomes. We introduce a simple tuning-free and label-free In-Context Learning (ICL) method to identify high-quality ICL exemplars for the remediator, where we propose a novel select criteria, called value impact, to measure the quality of the negotiation outcomes. We provide rich empirical evidence to demonstrate its effectiveness in negotiations across three different negotiation topics. We have released our source code and the generated dataset at: https://github.com/tk1363704/SADAS.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.01737"
    },
    "8ed6f5a24a793642920666f6e4727b5b": {
        "title": "LLMs Simulate Big Five Personality Traits: Further Evidence",
        "authors": [
            "Aleksandra Sorokovikova",
            "Natalia Fedorova",
            "Sharwin Rezagholi",
            "Ivan P. Yamshchikov"
        ],
        "date": "2024/01/31",
        "pdf": "http://arxiv.org/pdf/2402.01765",
        "abstract": "An empirical investigation into the simulation of the Big Five personality traits by large language models (LLMs), namely Llama2, GPT4, and Mixtral, is presented. We analyze the personality traits simulated by these models and their stability. This contributes to the broader understanding of the capabilities of LLMs to simulate personality traits and the respective implications for personalized human-computer interaction.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.01765"
    },
    "b301607d40a29aa568b9e9de00343499": {
        "title": "Executable Code Actions Elicit Better LLM Agents",
        "authors": [
            "Xingyao Wang",
            "Yangyi Chen",
            "Lifan Yuan",
            "Yizhe Zhang",
            "Yunzhu Li",
            "Hao Peng",
            "Heng Ji"
        ],
        "date": "2024/02/01",
        "pdf": "http://arxiv.org/pdf/2402.01030",
        "abstract": "Large Language Model (LLM) agents, capable of performing a broad range of actions, such as invoking tools and controlling robots, show great potential in tackling real-world challenges. LLM agents are typically prompted to produce actions by generating JSON or text in a pre-defined format, which is usually limited by constrained action space (e.g., the scope of pre-defined tools) and restricted flexibility (e.g., inability to compose multiple tools). This work proposes to use executable Python code to consolidate LLM agents&#39; actions into a unified action space (CodeAct). Integrated with a Python interpreter, CodeAct can execute code actions and dynamically revise prior actions or emit new actions upon new observations through multi-turn interactions. Our extensive analysis of 17 LLMs on API-Bank and a newly curated benchmark shows that CodeAct outperforms widely used alternatives (up to 20% higher success rate). The encouraging performance of CodeAct motivates us to build an open-source LLM agent that interacts with environments by executing interpretable code and collaborates with users using natural language. To this end, we collect an instruction-tuning dataset CodeActInstruct that consists of 7k multi-turn interactions using CodeAct. We show that it can be used with existing data to improve models in agent-oriented tasks without compromising their general capability. CodeActAgent, finetuned from Llama2 and Mistral, is integrated with Python interpreter and uniquely tailored to perform sophisticated tasks (e.g., model training) using existing libraries and autonomously self-debug.",
        "code": "",
        "category": [
            [
                "Application",
                "Software Engineering"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.01030"
    },
    "dbbad9b76945033370d64c196857dcc8": {
        "title": "NavHint: Vision and Language Navigation Agent with a Hint Generator",
        "authors": [
            "Yue Zhang",
            "Quan Guo",
            "Parisa Kordjamshidi"
        ],
        "date": "2024/02/04",
        "pdf": "http://arxiv.org/pdf/2402.02559",
        "abstract": "Existing work on vision and language navigation mainly relies on navigation-related losses to establish the connection between vision and language modalities, neglecting aspects of helping the navigation agent build a deep understanding of the visual environment. In our work, we provide indirect supervision to the navigation agent through a hint generator that provides detailed visual descriptions. The hint generator assists the navigation agent in developing a global understanding of the visual environment. It directs the agent&#39;s attention toward related navigation details, including the relevant sub-instruction, potential challenges in recognition and ambiguities in grounding, and the targeted viewpoint description. To train the hint generator, we construct a synthetic dataset based on landmarks in the instructions and visible and distinctive objects in the visual environment. We evaluate our method on the R2R and R4R datasets and achieve state-of-the-art on several metrics. The experimental results demonstrate that generating hints not only enhances the navigation performance but also helps improve the interpretability of the agent&#39;s actions.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.02559"
    },
    "a619330cab01491ca0129cc7efed892c": {
        "title": "LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models",
        "authors": [
            "Ivar Frisch",
            "Mario Giulianelli"
        ],
        "date": "2024/02/05",
        "pdf": "http://arxiv.org/pdf/2402.02896",
        "abstract": "While both agent interaction and personalisation are vibrant topics in research on large language models (LLMs), there has been limited focus on the effect of language interaction on the behaviour of persona-conditioned LLM agents. Such an endeavour is important to ensure that agents remain consistent to their assigned traits yet are able to engage in open, naturalistic dialogues. In our experiments, we condition GPT-3.5 on personality profiles through prompting and create a two-group population of LLM agents using a simple variability-inducing sampling algorithm. We then administer personality tests and submit the agents to a collaborative writing task, finding that different profiles exhibit different degrees of personality consistency and linguistic alignment to their conversational partners. Our study seeks to lay the groundwork for better understanding of dialogue-based interaction between LLMs and highlights the need for new approaches to crafting robust, more human-like LLM personas for interactive environments.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.02896"
    },
    "485502588a1d88b1dff5929f92c33d9c": {
        "title": "Professional Agents -- Evolving Large Language Models into Autonomous Experts with Human-Level Competencies",
        "authors": [
            "Zhixuan Chu",
            "Yan Wang",
            "Feng Zhu",
            "Lu Yu",
            "Longfei Li",
            "Jinjie Gu"
        ],
        "date": "2024/02/06",
        "pdf": "http://arxiv.org/pdf/2402.03628",
        "abstract": "The advent of large language models (LLMs) such as ChatGPT, PaLM, and GPT-4 has catalyzed remarkable advances in natural language processing, demonstrating human-like language fluency and reasoning capacities. This position paper introduces the concept of Professional Agents (PAgents), an application framework harnessing LLM capabilities to create autonomous agents with controllable, specialized, interactive, and professional-level competencies. We posit that PAgents can reshape professional services through continuously developed expertise. Our proposed PAgents framework entails a tri-layered architecture for genesis, evolution, and synergy: a base tool layer, a middle agent layer, and a top synergy layer. This paper aims to spur discourse on promising real-world applications of LLMs. We argue the increasing sophistication and integration of PAgents could lead to AI systems exhibiting professional mastery over complex domains, serving critical needs, and potentially achieving artificial general intelligence.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.03628"
    },
    "90cf304f11ecd2cb08a276a70b0118a3": {
        "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls",
        "authors": [
            "Yu Du",
            "Fangyun Wei",
            "Hongyang Zhang"
        ],
        "date": "2024/02/06",
        "pdf": "http://arxiv.org/pdf/2402.04253",
        "abstract": "We introduce AnyTool, a large language model agent designed to revolutionize the utilization of a vast array of tools in addressing user queries. We utilize over 16,000 APIs from Rapid API, operating under the assumption that a subset of these APIs could potentially resolve the queries. AnyTool primarily incorporates three elements: an API retriever with a hierarchical structure, a solver aimed at resolving user queries using a selected set of API candidates, and a self-reflection mechanism, which re-activates AnyTool if the initial solution proves impracticable. AnyTool is powered by the function calling feature of GPT-4, eliminating the need for training external modules. We also revisit the evaluation protocol introduced by previous works and identify a limitation in this protocol that leads to an artificially high pass rate. By revising the evaluation protocol to better reflect practical application scenarios, we introduce an additional benchmark, termed AnyToolBench. Experiments across various datasets demonstrate the superiority of our AnyTool over strong baselines such as ToolLLM and a GPT-4 variant tailored for tool utilization. For instance, AnyTool outperforms ToolLLM by +35.4% in terms of average pass rate on ToolBench. Code will be available at https://github.com/dyabel/AnyTool.",
        "code": "https://github.com/dyabel/anytool",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.04253"
    },
    "4874c0c0abd9411762e846540adcb6c1": {
        "title": "More Agents Is All You Need",
        "authors": [
            "Junyou Li",
            "Qin Zhang",
            "Yangbin Yu",
            "Qiang Fu",
            "Deheng Ye"
        ],
        "date": "2024/02/03",
        "pdf": "http://arxiv.org/pdf/2402.05120",
        "abstract": "We find that, simply via a sampling-and-voting method, the performance of large language models (LLMs) scales with the number of agents instantiated. Also, this method, termed as Agent Forest, is orthogonal to existing complicated methods to further enhance LLMs, while the degree of enhancement is correlated to the task difficulty. We conduct comprehensive experiments on a wide range of LLM benchmarks to verify the presence of our finding, and to study the properties that can facilitate its occurrence. Our code is publicly available at: https://github.com/MoreAgentsIsAllYouNeed/AgentForest",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.05120"
    },
    "a15433aff8c528c636484d5f5da5010d": {
        "title": "Knowledge-Infused LLM-Powered Conversational Health Agent: A Case Study for Diabetes Patients",
        "authors": [
            "Mahyar Abbasian",
            "Zhongqi Yang",
            "Elahe Khatibi",
            "Pengfei Zhang",
            "Nitish Nagesh",
            "Iman Azimi",
            "Ramesh Jain",
            "Amir M. Rahmani"
        ],
        "date": "2024/02/15",
        "pdf": "http://arxiv.org/pdf/2402.10153",
        "abstract": "Effective diabetes management is crucial for maintaining health in diabetic patients. Large Language Models (LLMs) have opened new avenues for diabetes management, facilitating their efficacy. However, current LLM-based approaches are limited by their dependence on general sources and lack of integration with domain-specific knowledge, leading to inaccurate responses. In this paper, we propose a knowledge-infused LLM-powered conversational health agent (CHA) for diabetic patients. We customize and leverage the open-source openCHA framework, enhancing our CHA with external knowledge and analytical capabilities. This integration involves two key components: 1) incorporating the American Diabetes Association dietary guidelines and the Nutritionix information and 2) deploying analytical tools that enable nutritional intake calculation and comparison with the guidelines. We compare the proposed CHA with GPT4. Our evaluation includes 100 diabetes-related questions on daily meal choices and assessing the potential risks associated with the suggested diet. Our findings show that the proposed agent demonstrates superior performance in generating responses to manage essential nutrients.",
        "code": "",
        "category": [
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.10153"
    },
    "13b82b1326a95c1678d2892563c13ae3": {
        "title": "TDAG: A Multi-Agent Framework based on Dynamic Task Decomposition and Agent Generation",
        "authors": [
            "Yaoxiang Wang",
            "Zhiyong Wu",
            "Junfeng Yao",
            "Jinsong Su"
        ],
        "date": "2024/02/15",
        "pdf": "http://arxiv.org/pdf/2402.10178",
        "abstract": "The emergence of Large Language Models (LLMs) like ChatGPT has inspired the development of LLM-based agents capable of addressing complex, real-world tasks. However, these agents often struggle during task execution due to methodological constraints, such as error propagation and limited adaptability. To address this issue, we propose a multi-agent framework based on dynamic Task Decomposition and Agent Generation (TDAG). This framework dynamically decomposes complex tasks into smaller subtasks and assigns each to a specifically generated subagent, thereby enhancing adaptability in diverse and unpredictable real-world tasks. Simultaneously, existing benchmarks often lack the granularity needed to evaluate incremental progress in complex, multi-step tasks. In response, we introduce ItineraryBench in the context of travel planning, featuring interconnected, progressively complex tasks with a fine-grained evaluation system. ItineraryBench is designed to assess agents&#39; abilities in memory, planning, and tool usage across tasks of varying complexity. Our experimental results reveal that TDAG significantly outperforms established baselines, showcasing its superior adaptability and context awareness in complex task scenarios.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.10178"
    },
    "a89feebbb8979ccaff7b3590a33af966": {
        "title": "ToolSword: Unveiling Safety Issues of Large Language Models in Tool Learning Across Three Stages",
        "authors": [
            "Junjie Ye",
            "Sixian Li",
            "Guanyu Li",
            "Caishuang Huang",
            "Songyang Gao",
            "Yilong Wu",
            "Qi Zhang",
            "Tao Gui",
            "Xuanjing Huang"
        ],
        "date": "2024/02/16",
        "pdf": "http://arxiv.org/pdf/2402.10753",
        "abstract": "Tool learning is widely acknowledged as a foundational approach or deploying large language models (LLMs) in real-world scenarios. While current research primarily emphasizes leveraging tools to augment LLMs, it frequently neglects emerging safety considerations tied to their application. To fill this gap, we present *ToolSword*, a comprehensive framework dedicated to meticulously investigating safety issues linked to LLMs in tool learning. Specifically, ToolSword delineates six safety scenarios for LLMs in tool learning, encompassing **malicious queries** and **jailbreak attacks** in the input stage, **noisy misdirection** and **risky cues** in the execution stage, and **harmful feedback** and **error conflicts** in the output stage. Experiments conducted on 11 open-source and closed-source LLMs reveal enduring safety challenges in tool learning, such as handling harmful queries, employing risky tools, and delivering detrimental feedback, which even GPT-4 is susceptible to. Moreover, we conduct further studies with the aim of fostering research on tool learning safety. The data is released in https://github.com/Junjie-Ye/ToolSword.",
        "code": "https://github.com/junjie-ye/toolsword",
        "category": [
            [
                "Stability",
                "Safety"
            ],
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.10753"
    },
    "7d840205c5d5d0c8418e1a6c9032503a": {
        "title": "When is Tree Search Useful for LLM Planning? It Depends on the Discriminator",
        "authors": [
            "Ziru Chen",
            "Michael White",
            "Raymond Mooney",
            "Ali Payani",
            "Yu Su",
            "Huan Sun"
        ],
        "date": "2024/02/16",
        "pdf": "http://arxiv.org/pdf/2402.10890",
        "abstract": "In this paper, we examine how large language models (LLMs) solve multi-step problems under a language agent framework with three components: a generator, a discriminator, and a planning method. We investigate the practical utility of two advanced planning methods, iterative correction and tree search. We present a comprehensive analysis of how discrimination accuracy affects the overall performance of agents when using these two methods or a simpler method, re-ranking. Experiments on two tasks, text-to-SQL parsing and mathematical reasoning, show that: (1) advanced planning methods demand discriminators with at least 90% accuracy to achieve significant improvements over re-ranking; (2) current LLMs&#39; discrimination abilities have not met the needs of advanced planning methods to achieve such improvements; (3) with LLM-based discriminators, advanced planning methods may not adequately balance accuracy and efficiency. For example, compared to the other two methods, tree search is at least 10--20 times slower but leads to negligible performance gains, which hinders its real-world applications. Code and data are available at https://github.com/OSU-NLP-Group/llm-planning-eval.",
        "code": "https://github.com/osu-nlp-group/llm-planning-eval",
        "category": [
            [
                "Technique For Enhancement",
                "Search"
            ],
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.10890"
    },
    "0c5062abf0c98c49de2bd6bec7500db3": {
        "title": "KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph",
        "authors": [
            "Jinhao Jiang",
            "Kun Zhou",
            "Wayne Xin Zhao",
            "Yang Song",
            "Chen Zhu",
            "Hengshu Zhu",
            "Ji-Rong Wen"
        ],
        "date": "2024/02/17",
        "pdf": "http://arxiv.org/pdf/2402.11163",
        "abstract": "In this paper, we aim to improve the reasoning ability of large language models (LLMs) over knowledge graphs (KGs) to answer complex questions. Inspired by existing methods that design the interaction strategy between LLMs and KG, we propose an autonomous LLM-based agent framework, called KG-Agent, which enables a small LLM to actively make decisions until finishing the reasoning process over KGs. In KG-Agent, we integrate the LLM, multifunctional toolbox, KG-based executor, and knowledge memory, and develop an iteration mechanism that autonomously selects the tool then updates the memory for reasoning over KG. To guarantee the effectiveness, we leverage program language to formulate the multi-hop reasoning process over the KG, and synthesize a code-based instruction dataset to fine-tune the base LLM. Extensive experiments demonstrate that only using 10K samples for tuning LLaMA-7B can outperform state-of-the-art methods using larger LLMs or more data, on both in-domain and out-domain datasets. Our code and data will be publicly released.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Search"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.11163"
    },
    "5eff26e408b6a81fe444f59554a196e4": {
        "title": "MONAL: Model Autophagy Analysis for Modeling Human-AI Interactions",
        "authors": [
            "Shu Yang",
            "Muhammad Asif Ali",
            "Lu Yu",
            "Lijie Hu",
            "Di Wang"
        ],
        "date": "2024/02/17",
        "pdf": "http://arxiv.org/pdf/2402.11271",
        "abstract": "The increasing significance of large models and their multi-modal variants in societal information processing has ignited debates on social safety and ethics. However, there exists a paucity of comprehensive analysis for: (i) the interactions between human and artificial intelligence systems, and (ii) understanding and addressing the associated limitations. To bridge this gap, we propose Model Autophagy Analysis (MONAL) for large models&#39; self-consumption explanation. MONAL employs two distinct autophagous loops (referred to as ``self-consumption loops&#39;&#39;) to elucidate the suppression of human-generated information in the exchange between human and AI systems. Through comprehensive experiments on diverse datasets, we evaluate the capacities of generated models as both creators and disseminators of information. Our key findings reveal (i) A progressive prevalence of model-generated synthetic information over time within training datasets compared to human-generated information; (ii) The discernible tendency of large models, when acting as information transmitters across multiple iterations, to selectively modify or prioritize specific contents; and (iii) The potential for a reduction in the diversity of socially or human-generated information, leading to bottlenecks in the performance enhancement of large models and confining them to local optima.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Human-Agent Interaction"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.11271"
    },
    "91668d0b0eba8cee741a474aa4cbe16a": {
        "title": "Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation",
        "authors": [
            "Siyuan Wang",
            "Zhuohan Long",
            "Zhihao Fan",
            "Zhongyu Wei",
            "Xuanjing Huang"
        ],
        "date": "2024/02/18",
        "pdf": "http://arxiv.org/pdf/2402.11443",
        "abstract": "This paper presents a benchmark self-evolving framework to dynamically evaluate rapidly advancing Large Language Models (LLMs), aiming for a more accurate assessment of their capabilities and limitations. We utilize a multi-agent system to manipulate the context or question of original instances, reframing new evolving instances with high confidence that dynamically extend existing benchmarks. Towards a more scalable, robust and fine-grained evaluation, we implement six reframing operations to construct evolving instances testing LLMs against diverse queries, data noise and probing their problem-solving sub-abilities. With this framework, we extend benchmark datasets of four tasks. Experimental results show a general performance decline in most LLMs against their original results. This decline under our scalable and robust evaluations, alongside our fine-grained evaluation, more accurately reflect models&#39; capabilities. Besides, our framework widens performance discrepancies both between different models and within the same model across various tasks, facilitating more informed model selection for specific tasks (Code and data are available at https://github.com/NanshineLoong/Self-Evolving-Benchmark).",
        "code": "https://github.com/nanshineloong/self-evolving-benchmark",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.11443"
    },
    "71b8888021fefef765ee9189114ebc03": {
        "title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning",
        "authors": [
            "Yubo Ma",
            "Zhibin Gou",
            "Junheng Hao",
            "Ruochen Xu",
            "Shuohang Wang",
            "Liangming Pan",
            "Yujiu Yang",
            "Yixin Cao",
            "Aixin Sun",
            "Hany Awadalla",
            "Weizhu Chen"
        ],
        "date": "2024/02/18",
        "pdf": "http://arxiv.org/pdf/2402.11451",
        "abstract": "Scientific reasoning poses an excessive challenge for even the most advanced Large Language Models (LLMs). To make this task more practical and solvable for LLMs, we introduce a new task setting named tool-augmented scientific reasoning. This setting supplements LLMs with scalable toolsets, and shifts the focus from pursuing an omniscient problem solver to a proficient tool-user. To facilitate the research of such setting, we construct a tool-augmented training corpus named MathFunc which encompasses over 30,000 samples and roughly 6,000 tools. Building on MathFunc, we develop SciAgent to retrieve, understand and, if necessary, use tools for scientific problem solving. Additionally, we craft a benchmark, SciToolBench, spanning five scientific domains to evaluate LLMs&#39; abilities with tool assistance. Extensive experiments on SciToolBench confirm the effectiveness of SciAgent. Notably, SciAgent-Mistral-7B surpasses other LLMs with the same size by more than 13% in absolute accuracy. Furthermore, SciAgent-DeepMath-7B shows much superior performance than ChatGPT.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ],
            [
                "Application",
                "Research"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.11451"
    },
    "80a2c8c973d3216b19515f53d4911fcd": {
        "title": "MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization",
        "authors": [
            "Zhiyu Yang",
            "Zihan Zhou",
            "Shuo Wang",
            "Xin Cong",
            "Xu Han",
            "Yukun Yan",
            "Zhenghao Liu",
            "Zhixing Tan",
            "Pengyuan Liu",
            "Dong Yu",
            "Zhiyuan Liu",
            "Xiaodong Shi",
            "Maosong Sun"
        ],
        "date": "2024/02/18",
        "pdf": "http://arxiv.org/pdf/2402.11453",
        "abstract": "Scientific data visualization plays a crucial role in research by enabling the direct display of complex information and assisting researchers in identifying implicit patterns. Despite its importance, the use of Large Language Models (LLMs) for scientific data visualization remains rather unexplored. In this study, we introduce MatPlotAgent, an efficient model-agnostic LLM agent framework designed to automate scientific data visualization tasks. Leveraging the capabilities of both code LLMs and multi-modal LLMs, MatPlotAgent consists of three core modules: query understanding, code generation with iterative debugging, and a visual feedback mechanism for error correction. To address the lack of benchmarks in this field, we present MatPlotBench, a high-quality benchmark consisting of 100 human-verified test cases. Additionally, we introduce a scoring approach that utilizes GPT-4V for automatic evaluation. Experimental results demonstrate that MatPlotAgent can improve the performance of various LLMs, including both commercial and open-source models. Furthermore, the proposed evaluation method shows a strong correlation with human-annotated scores.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.11453"
    },
    "8efb45b8104c964a69dec8eb8a385013": {
        "title": "What&#39;s the Plan? Evaluating and Developing Planning-Aware Techniques for Language Models",
        "authors": [
            "Eran Hirsch",
            "Guy Uziel",
            "Ateret Anaby-Tavor"
        ],
        "date": "2024/02/18",
        "pdf": "http://arxiv.org/pdf/2402.11489",
        "abstract": "Planning is a fundamental task in artificial intelligence that involves finding a sequence of actions that achieve a specified goal in a given environment. Large language models (LLMs) are increasingly used for applications that require planning capabilities, such as web or embodied agents. In line with recent studies, we demonstrate through experimentation that LLMs lack necessary skills required for planning. Based on these observations, we advocate for the potential of a hybrid approach that combines LLMs with classical planning methodology. Then, we introduce SimPlan, a novel hybrid-method, and evaluate its performance in a new challenging setup. Our extensive experiments across various planning domains demonstrate that SimPlan significantly outperforms existing LLM-based planners.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.11489"
    },
    "f6cf3f3fc3c1eb72a0cce8a84f4b1cd0": {
        "title": "PreAct: Prediction Enhances Agent&#39;s Planning Ability",
        "authors": [
            "Dayuan Fu",
            "Jianzhao Huang",
            "Siyuan Lu",
            "Guanting Dong",
            "Yejie Wang",
            "Keqing He",
            "Weiran Xu"
        ],
        "date": "2024/02/18",
        "pdf": "http://arxiv.org/pdf/2402.11534",
        "abstract": "Addressing the disparity between forecasts and actual results can enable individuals to expand their thought processes and stimulate self-reflection, thus promoting accurate planning. In this research, we present **PreAct**, an agent framework that integrates **pre**diction, **rea**soning, and **act**ion. By utilizing the information derived from predictions, the large language model (LLM) agent can provide a wider range and more strategically focused reasoning. This leads to more efficient actions that aid the agent in accomplishing intricate tasks. Our experimental results show that PreAct surpasses the ReAct method in completing complex tasks and that PreAct&#39;s performance can be further improved when paired with other memory or selection strategy techniques. We presented the model with varying quantities of historical predictions and discovered that these predictions consistently enhance LLM planning.The variances in single-step reasoning between PreAct and ReAct indicate that PreAct indeed has benefits in terms of diversity and strategic orientation over ReAct.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.11534"
    },
    "7e1da3043b5d4208fd9b19f042d48f1f": {
        "title": "LongAgent: Scaling Language Models to 128k Context through Multi-Agent Collaboration",
        "authors": [
            "Jun Zhao",
            "Can Zu",
            "Hao Xu",
            "Yi Lu",
            "Wei He",
            "Yiwen Ding",
            "Tao Gui",
            "Qi Zhang",
            "Xuanjing Huang"
        ],
        "date": "2024/02/18",
        "pdf": "http://arxiv.org/pdf/2402.11550",
        "abstract": "Large language models (LLMs) have demonstrated impressive performance in understanding language and executing complex reasoning tasks. However, LLMs with long context windows have been notorious for their expensive training costs and high inference latency. Even the most advanced models such as GPT-4 and Claude2 often make mistakes when processing inputs of over $100k$ tokens, a phenomenon also known as \\textit{lost in the middle}. In this paper, we propose \\textsc{LongAgent}, a method based on multi-agent collaboration, which scales LLMs (e.g., LLaMA) to a context of 128K and demonstrates potential superiority in long-text processing compared to GPT-4. In \\textsc{LongAgent}, a leader is responsible for understanding user intent and directing team members to acquire information from documents. Due to members&#39; hallucinations, it is non-trivial for a leader to obtain accurate information from the responses of dozens to hundreds of members. To address this, we develop an \\textit{inter-member communication} mechanism to resolve response conflicts caused by hallucinations through information sharing. Our experimental results indicate that \\textsc{LongAgent} offers a promising alternative for long-text processing. The agent team instantiated with LLaMA-7B achieves significant improvements in tasks such as 128k-long text retrieval, multi-hop question answering, compared to GPT-4.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.11550"
    },
    "645c1394ff4bc534034d1906961852ca": {
        "title": "Learning From Failure: Integrating Negative Examples when Fine-tuning Large Language Models as Agents",
        "authors": [
            "Renxi Wang",
            "Haonan Li",
            "Xudong Han",
            "Yixuan Zhang",
            "Timothy Baldwin"
        ],
        "date": "2024/02/18",
        "pdf": "http://arxiv.org/pdf/2402.11651",
        "abstract": "Large language models (LLMs) have achieved success in acting as agents, which interact with environments through tools such as search engines. However, LLMs are optimized for language generation instead of tool use during training or alignment, limiting their effectiveness as agents. To resolve this problem, previous work has first collected interaction trajectories between LLMs and environments, using only trajectories that successfully finished the task to fine-tune smaller models, making fine-tuning data scarce and acquiring it both difficult and costly. Discarding failed trajectories also leads to significant wastage of data and resources and limits the possible optimization paths during fine-tuning. In this paper, we argue that unsuccessful trajectories offer valuable insights, and LLMs can learn from these trajectories through appropriate quality control and fine-tuning strategies. By simply adding a prefix or suffix that tells the model whether to generate a successful trajectory during training, we improve model performance by a large margin on mathematical reasoning, multi-hop question answering, and strategic question answering tasks. We further analyze the inference results and find that our method provides a better trade-off between valuable information and errors in unsuccessful trajectories. To our knowledge, we are the first to demonstrate the value of negative trajectories and their application in agent-tunning scenarios. Our findings offer guidance for developing better agent-tuning methods and low-resource data usage techniques.",
        "code": "",
        "category": [
            [
                "Training",
                "Fine tuning"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.11651"
    },
    "46c43356d6af4d363b0d08678696cea6": {
        "title": "Large Language Models as Agents in Two-Player Games",
        "authors": [
            "Yang Liu",
            "Peng Sun",
            "Hang Li"
        ],
        "date": "2024/02/12",
        "pdf": "http://arxiv.org/pdf/2402.08078",
        "abstract": "By formally defining the training processes of large language models (LLMs), which usually encompasses pre-training, supervised fine-tuning, and reinforcement learning with human feedback, within a single and unified machine learning paradigm, we can glean pivotal insights for advancing LLM technologies. This position paper delineates the parallels between the training methods of LLMs and the strategies employed for the development of agents in two-player games, as studied in game theory, reinforcement learning, and multi-agent systems. We propose a re-conceptualization of LLM learning processes in terms of agent learning in language-based games. This framework unveils innovative perspectives on the successes and challenges in LLM development, offering a fresh understanding of addressing alignment issues among other strategic considerations. Furthermore, our two-player game approach sheds light on novel data preparation and machine learning techniques for training LLMs.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.08078"
    },
    "fb31c87283351112060f2a7cbc8d0fe7": {
        "title": "Large Language Models as Minecraft Agents",
        "authors": [
            "Chris Madge",
            "Massimo Poesio"
        ],
        "date": "2024/02/13",
        "pdf": "http://arxiv.org/pdf/2402.08392",
        "abstract": "In this work we examine the use of Large Language Models (LLMs) in the challenging setting of acting as a Minecraft agent. We apply and evaluate LLMs in the builder and architect settings, introduce clarification questions and examining the challenges and opportunities for improvement. In addition, we present a platform for online interaction with the agents and an evaluation against previous works.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.08392"
    },
    "da5cb2cc846f66b14b41853d5ffe1299": {
        "title": "Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast",
        "authors": [
            "Xiangming Gu",
            "Xiaosen Zheng",
            "Tianyu Pang",
            "Chao Du",
            "Qian Liu",
            "Ye Wang",
            "Jing Jiang",
            "Min Lin"
        ],
        "date": "2024/02/13",
        "pdf": "http://arxiv.org/pdf/2402.08567",
        "abstract": "A multimodal large language model (MLLM) agent can receive instructions, capture images, retrieve histories from memory, and decide which tools to use. Nonetheless, red-teaming efforts have revealed that adversarial images/prompts can jailbreak an MLLM and cause unaligned behaviors. In this work, we report an even more severe safety issue in multi-agent environments, referred to as infectious jailbreak. It entails the adversary simply jailbreaking a single agent, and without any further intervention from the adversary, (almost) all agents will become infected exponentially fast and exhibit harmful behaviors. To validate the feasibility of infectious jailbreak, we simulate multi-agent environments containing up to one million LLaVA-1.5 agents, and employ randomized pair-wise chat as a proof-of-concept instantiation for multi-agent interaction. Our results show that feeding an (infectious) adversarial image into the memory of any randomly chosen agent is sufficient to achieve infectious jailbreak. Finally, we derive a simple principle for determining whether a defense mechanism can provably restrain the spread of infectious jailbreak, but how to design a practical defense that meets this principle remains an open question to investigate. Our project page is available at https://sail-sg.github.io/Agent-Smith/.",
        "code": "https://github.com/sail-sg/agent-smith",
        "category": [
            [
                "Stability",
                "Hallucination"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.08567"
    },
    "cc4a576822918876acbf397bee723c62": {
        "title": "Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications",
        "authors": [
            "Negar Arabzadeh",
            "Julia Kiseleva",
            "Qingyun Wu",
            "Chi Wang",
            "Ahmed Awadallah",
            "Victor Dibia",
            "Adam Fourney",
            "Charles Clarke"
        ],
        "date": "2024/02/14",
        "pdf": "http://arxiv.org/pdf/2402.09015",
        "abstract": "The rapid development in the field of Large Language Models (LLMs) has led to a surge in applications that facilitate collaboration among multiple agents to assist humans in their daily tasks. However, a significant gap remains in assessing whether LLM-powered applications genuinely enhance user experience and task execution efficiency. This highlights the pressing need for methods to verify utility of LLM-powered applications, particularly by ensuring alignment between the application&#39;s functionality and end-user needs. We introduce AgentEval provides an implementation for the math problems, a novel framework designed to simplify the utility verification process by automatically proposing a set of criteria tailored to the unique purpose of any given application. This allows for a comprehensive assessment, quantifying the utility of an application against the suggested criteria. We present a comprehensive analysis of the robustness of quantifier&#39;s work.",
        "code": "",
        "category": [
            [
                "Stability",
                "Bias"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.09015"
    },
    "ac40351f97fee2d30d652151eea8c078": {
        "title": "InfLLM: Training-Free Long-Context Extrapolation for LLMs with an Efficient Context Memory",
        "authors": [
            "Chaojun Xiao",
            "Pengle Zhang",
            "Xu Han",
            "Guangxuan Xiao",
            "Yankai Lin",
            "Zhengyan Zhang",
            "Zhiyuan Liu",
            "Maosong Sun"
        ],
        "date": "2024/02/07",
        "pdf": "http://arxiv.org/pdf/2402.04617",
        "abstract": "Large language models (LLMs) have emerged as a cornerstone in real-world applications with lengthy streaming inputs (e.g., LLM-driven agents). However, existing LLMs, pre-trained on sequences with a restricted maximum length, cannot process longer sequences due to the out-of-domain and distraction issues. Common solutions often involve continual pre-training on longer sequences, which will introduce expensive computational overhead and uncontrollable change in model capabilities. In this paper, we unveil the intrinsic capacity of LLMs for understanding extremely long sequences without any fine-tuning. To this end, we introduce a training-free memory-based method, InfLLM. Specifically, InfLLM stores distant contexts into additional memory units and employs an efficient mechanism to lookup token-relevant units for attention computation. Thereby, InfLLM allows LLMs to efficiently process long sequences with a limited context window and well capture long-distance dependencies. Without any training, InfLLM enables LLMs that are pre-trained on sequences consisting of a few thousand tokens to achieve comparable performance with competitive baselines that continually train these LLMs on long sequences. Even when the sequence length is scaled to $1,024$K, InfLLM still effectively captures long-distance dependencies. Our code can be found in \\url{https://github.com/thunlp/InfLLM}.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Memory Mechanism"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.04617"
    },
    "062ae31f680adf5ec6f03a536d620444": {
        "title": "Modelling Political Coalition Negotiations Using LLM-based Agents",
        "authors": [
            "Farhad Moghimifar",
            "Yuan-Fang Li",
            "Robert Thomson",
            "Gholamreza Haffari"
        ],
        "date": "2024/02/18",
        "pdf": "http://arxiv.org/pdf/2402.11712",
        "abstract": "Coalition negotiations are a cornerstone of parliamentary democracies, characterised by complex interactions and strategic communications among political parties. Despite its significance, the modelling of these negotiations has remained unexplored with the domain of Natural Language Processing (NLP), mostly due to lack of proper data. In this paper, we introduce coalition negotiations as a novel NLP task, and model it as a negotiation between large language model-based agents. We introduce a multilingual dataset, POLCA, comprising manifestos of European political parties and coalition agreements over a number of elections in these countries. This dataset addresses the challenge of the current scope limitations in political negotiation modelling by providing a diverse, real-world basis for simulation. Additionally, we propose a hierarchical Markov decision process designed to simulate the process of coalition negotiation between political parties and predict the outcomes. We evaluate the performance of state-of-the-art large language models (LLMs) as agents in handling coalition negotiations, offering insights into their capabilities and paving the way for future advancements in political modelling.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.11712"
    },
    "1243ff5fb9ecf0de62aacd39f8af85c0": {
        "title": "Compress to Impress: Unleashing the Potential of Compressive Memory in Real-World Long-Term Conversations",
        "authors": [
            "Nuo Chen",
            "Hongguang Li",
            "Juhua Huang",
            "Baoyuan Wang",
            "Jia Li"
        ],
        "date": "2024/02/19",
        "pdf": "http://arxiv.org/pdf/2402.11975",
        "abstract": "Existing retrieval-based methods have made significant strides in maintaining long-term conversations. However, these approaches face challenges in memory database management and accurate memory retrieval, hindering their efficacy in dynamic, real-world interactions. This study introduces a novel framework, COmpressive Memory-Enhanced Dialogue sYstems (COMEDY), which eschews traditional retrieval modules and memory databases. Instead, COMEDY adopts a &#34;One-for-All&#34; approach, utilizing a single language model to manage memory generation, compression, and response generation. Central to this framework is the concept of compressive memory, which intergrates session-specific summaries, user-bot dynamics, and past events into a concise memory format. To support COMEDY, we curated a large-scale Chinese instruction-tuning dataset, Dolphin, derived from real user-chatbot interactions. Comparative evaluations demonstrate COMEDY&#39;s superiority over traditional retrieval-based methods in producing more nuanced and human-like conversational experiences. Our codes are available at https://github.com/nuochenpku/COMEDY.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Memory Mechanism"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.11975"
    },
    "dc755c8abb2a1b7c1dadcd90909f8391": {
        "title": "AesopAgent: Agent-driven Evolutionary System on Story-to-Video Production",
        "authors": [
            "Jiuniu Wang",
            "Zehua Du",
            "Yuyuan Zhao",
            "Bo Yuan",
            "Kexiang Wang",
            "Jian Liang",
            "Yaxi Zhao",
            "Yihen Lu",
            "Gengliang Li",
            "Junlong Gao",
            "Xin Tu",
            "Zhenyu Guo"
        ],
        "date": "2024/03/12",
        "pdf": "http://arxiv.org/pdf/2403.07952",
        "abstract": "The Agent and AIGC (Artificial Intelligence Generated Content) technologies have recently made significant progress. We propose AesopAgent, an Agent-driven Evolutionary System on Story-to-Video Production. AesopAgent is a practical application of agent technology for multimodal content generation. The system integrates multiple generative capabilities within a unified framework, so that individual users can leverage these modules easily. This innovative system would convert user story proposals into scripts, images, and audio, and then integrate these multimodal contents into videos. Additionally, the animating units (e.g., Gen-2 and Sora) could make the videos more infectious. The AesopAgent system could orchestrate task workflow for video generation, ensuring that the generated video is both rich in content and coherent. This system mainly contains two layers, i.e., the Horizontal Layer and the Utility Layer. In the Horizontal Layer, we introduce a novel RAG-based evolutionary system that optimizes the whole video generation workflow and the steps within the workflow. It continuously evolves and iteratively optimizes workflow by accumulating expert experience and professional knowledge, including optimizing the LLM prompts and utilities usage. The Utility Layer provides multiple utilities, leading to consistent image generation that is visually coherent in terms of composition, characters, and style. Meanwhile, it provides audio and special effects, integrating them into expressive and logically arranged videos. Overall, our AesopAgent achieves state-of-the-art performance compared with many previous works in visual storytelling. Our AesopAgent is designed for convenient service for individual users, which is available on the following page: https://aesopai.github.io/.",
        "code": "",
        "category": [
            [
                "Application",
                "Art"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.07952"
    },
    "5411575149b2ac84b69af030d50fa13e": {
        "title": "Polarization of Autonomous Generative AI Agents Under Echo Chambers",
        "authors": [
            "Masaya Ohagi"
        ],
        "date": "2024/02/19",
        "pdf": "http://arxiv.org/pdf/2402.12212",
        "abstract": "Online social networks often create echo chambers where people only hear opinions reinforcing their beliefs. An echo chamber often generates polarization, leading to conflicts caused by people with radical opinions, such as the January 6, 2021, attack on the US Capitol. The echo chamber has been viewed as a human-specific problem, but this implicit assumption is becoming less reasonable as large language models, such as ChatGPT, acquire social abilities. In response to this situation, we investigated the potential for polarization to occur among a group of autonomous AI agents based on generative language models in an echo chamber environment. We had AI agents discuss specific topics and analyzed how the group&#39;s opinions changed as the discussion progressed. As a result, we found that the group of agents based on ChatGPT tended to become polarized in echo chamber environments. The analysis of opinion transitions shows that this result is caused by ChatGPT&#39;s high prompt understanding ability to update its opinion by considering its own and surrounding agents&#39; opinions. We conducted additional experiments to investigate under what specific conditions AI agents tended to polarize. As a result, we identified factors that strongly influence polarization, such as the agent&#39;s persona. These factors should be monitored to prevent the polarization of AI agents.",
        "code": "",
        "category": [
            [
                "Stability",
                "Bias"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.12212"
    },
    "2b620690c1f044fb1168a82f75c237f0": {
        "title": "PsychoGAT: A Novel Psychological Measurement Paradigm through Interactive Fiction Games with LLM Agents",
        "authors": [
            "Qisen Yang",
            "Zekun Wang",
            "Honghui Chen",
            "Shenzhi Wang",
            "Yifan Pu",
            "Xin Gao",
            "Wenhao Huang",
            "Shiji Song",
            "Gao Huang"
        ],
        "date": "2024/02/19",
        "pdf": "http://arxiv.org/pdf/2402.12326",
        "abstract": "Psychological measurement is essential for mental health, self-understanding, and personal development. Traditional methods, such as self-report scales and psychologist interviews, often face challenges with engagement and accessibility. While game-based and LLM-based tools have been explored to improve user interest and automate assessment, they struggle to balance engagement with generalizability. In this work, we propose PsychoGAT (Psychological Game AgenTs) to achieve a generic gamification of psychological assessment. The main insight is that powerful LLMs can function both as adept psychologists and innovative game designers. By incorporating LLM agents into designated roles and carefully managing their interactions, PsychoGAT can transform any standardized scales into personalized and engaging interactive fiction games. To validate the proposed method, we conduct psychometric evaluations to assess its effectiveness and employ human evaluators to examine the generated content across various psychological constructs, including depression, cognitive distortions, and personality traits. Results demonstrate that PsychoGAT serves as an effective assessment tool, achieving statistically significant excellence in psychometric metrics such as reliability, convergent validity, and discriminant validity. Moreover, human evaluations confirm PsychoGAT&#39;s enhancements in content coherence, interactivity, interest, immersion, and satisfaction.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.12326"
    },
    "564261b63f4cd7fb3327b8e6855d1027": {
        "title": "Can Large Language Models be Used to Provide Psychological Counselling? An Analysis of GPT-4-Generated Responses Using Role-play Dialogues",
        "authors": [
            "Michimasa Inaba",
            "Mariko Ukiyo",
            "Keiko Takamizo"
        ],
        "date": "2024/02/20",
        "pdf": "http://arxiv.org/pdf/2402.12738",
        "abstract": "Mental health care poses an increasingly serious challenge to modern societies. In this context, there has been a surge in research that utilizes information technologies to address mental health problems, including those aiming to develop counseling dialogue systems. However, there is a need for more evaluations of the performance of counseling dialogue systems that use large language models. For this study, we collected counseling dialogue data via role-playing scenarios involving expert counselors, and the utterances were annotated with the intentions of the counselors. To determine the feasibility of a dialogue system in real-world counseling scenarios, third-party counselors evaluated the appropriateness of responses from human counselors and those generated by GPT-4 in identical contexts in role-play dialogue data. Analysis of the evaluation results showed that the responses generated by GPT-4 were competitive with those of human counselors.",
        "code": "",
        "category": [
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.12738"
    },
    "4e7147609270bc7198406f69cfffcba4": {
        "title": "Large Language Model-based Human-Agent Collaboration for Complex Task Solving",
        "authors": [
            "Xueyang Feng",
            "Zhi-Yuan Chen",
            "Yujia Qin",
            "Yankai Lin",
            "Xu Chen",
            "Zhiyuan Liu",
            "Ji-Rong Wen"
        ],
        "date": "2024/02/20",
        "pdf": "http://arxiv.org/pdf/2402.12914",
        "abstract": "In recent developments within the research community, the integration of Large Language Models (LLMs) in creating fully autonomous agents has garnered significant interest. Despite this, LLM-based agents frequently demonstrate notable shortcomings in adjusting to dynamic environments and fully grasping human needs. In this work, we introduce the problem of LLM-based human-agent collaboration for complex task-solving, exploring their synergistic potential. In addition, we propose a Reinforcement Learning-based Human-Agent Collaboration method, ReHAC. This approach includes a policy model designed to determine the most opportune stages for human intervention within the task-solving process. We construct a human-agent collaboration dataset to train this policy model in an offline reinforcement learning environment. Our validation tests confirm the model&#39;s effectiveness. The results demonstrate that the synergistic efforts of humans and LLM-based agents significantly improve performance in complex tasks, primarily through well-planned, limited human intervention. Datasets and code are available at: https://github.com/XueyangFeng/ReHAC.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Human-Agent Interaction"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.12914"
    },
    "462c569bbda3a96911503fd5e1e980d2": {
        "title": "What if LLMs Have Different World Views: Simulating Alien Civilizations with LLM-based Agents",
        "authors": [
            "Zhaoqian Xue",
            "Mingyu Jin",
            "Beichen Wang",
            "Suiyuan Zhu",
            "Kai Mei",
            "Hua Tang",
            "Wenyue Hua",
            "Mengnan Du",
            "Yongfeng Zhang"
        ],
        "date": "2024/02/20",
        "pdf": "http://arxiv.org/pdf/2402.13184",
        "abstract": "This study introduces &#34;CosmoAgent,&#34; an innovative artificial intelligence system that utilizes Large Language Models (LLMs) to simulate complex interactions between human and extraterrestrial civilizations. This paper introduces a mathematical model for quantifying the levels of civilization development and further employs a state transition matrix approach to evaluate their trajectories. Through this methodology, our study quantitatively analyzes the growth trajectories of civilizations, providing insights into future decision-making at critical points of growth and saturation. Furthermore, this paper acknowledges the vast diversity of potential living conditions across the universe, which could foster unique cosmologies, ethical codes, and worldviews among different civilizations. Recognizing the Earth-centric bias inherent in current LLM designs, we propose the novel concept of using LLM agents with diverse ethical paradigms and simulating interactions between entities with distinct moral principles. This innovative research not only introduces a novel method for comprehending potential inter-civilizational dynamics but also holds practical value in enabling entities with divergent value systems to strategize, prevent conflicts, and engage in games under conditions of asymmetric information. The accompanying code is available at https://github.com/MingyuJ666/Simulating-Alien-Civilizations-with-LLM-based-Agents.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.13184"
    },
    "b8a99309f72b7f01137f7a2178d15e97": {
        "title": "Soft Self-Consistency Improves Language Model Agents",
        "authors": [
            "Han Wang",
            "Archiki Prasad",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "date": "2024/02/20",
        "pdf": "http://arxiv.org/pdf/2402.13212",
        "abstract": "Generations from large language models (LLMs) can be improved by sampling and scoring multiple solutions to select a final answer. Current &#34;sample and select&#34; methods such as self-consistency (SC) rely on majority voting to score answers. However, when tasks have many distinct and valid answers, selection by voting requires a large number of samples. This makes SC prohibitively expensive for interactive tasks that involve generating multiple actions (answers) sequentially. After establishing that majority voting fails to provide consistent gains on such tasks, we demonstrate how to increase success rates by softening the scoring criterion. We introduce Soft Self-Consistency (SOFT-SC), which replaces SC&#39;s discontinuous scoring with a continuous score computed from model likelihoods, allowing for selection even when actions are sparsely distributed. SOFT-SC improves both performance and efficiency on long-horizon interactive tasks, requiring half as many samples as SC for comparable or better performance. For a fixed number of samples, SOFT-SC leads to a 1.3% increase over SC in absolute success rate on writing bash programs, a 6.6% increase on online shopping (WebShop), and a 4.7% increase for an interactive household game (ALFWorld). Finally, we show that SOFT-SC can be applied to both open-source and black-box models.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.13212"
    },
    "b739dc90a858a8d7d66e83e8115b2882": {
        "title": "AgentMD: Empowering Language Agents for Risk Prediction with Large-Scale Clinical Tool Learning",
        "authors": [
            "Qiao Jin",
            "Zhizheng Wang",
            "Yifan Yang",
            "Qingqing Zhu",
            "Donald Wright",
            "Thomas Huang",
            "W John Wilbur",
            "Zhe He",
            "Andrew Taylor",
            "Qingyu Chen",
            "Zhiyong Lu"
        ],
        "date": "2024/02/20",
        "pdf": "http://arxiv.org/pdf/2402.13225",
        "abstract": "Clinical calculators play a vital role in healthcare by offering accurate evidence-based predictions for various purposes such as prognosis. Nevertheless, their widespread utilization is frequently hindered by usability challenges, poor dissemination, and restricted functionality. Augmenting large language models with extensive collections of clinical calculators presents an opportunity to overcome these obstacles and improve workflow efficiency, but the scalability of the manual curation process poses a significant challenge. In response, we introduce AgentMD, a novel language agent capable of curating and applying clinical calculators across various clinical contexts. Using the published literature, AgentMD has automatically curated a collection of 2,164 diverse clinical calculators with executable functions and structured documentation, collectively named RiskCalcs. Manual evaluations show that RiskCalcs tools achieve an accuracy of over 80% on three quality metrics. At inference time, AgentMD can automatically select and apply the relevant RiskCalcs tools given any patient description. On the newly established RiskQA benchmark, AgentMD significantly outperforms chain-of-thought prompting with GPT-4 (87.7% vs. 40.9% in accuracy). Additionally, we also applied AgentMD to real-world clinical notes for analyzing both population-level and risk-level patient characteristics. In summary, our study illustrates the utility of language agents augmented with clinical calculators for healthcare analytics and patient care.",
        "code": "",
        "category": [
            [
                "Application",
                "Medicine"
            ],
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.13225"
    },
    "b4a30674fee6a3f3c8253cf8ae36c8b7": {
        "title": "Neeko: Leveraging Dynamic LoRA for Efficient Multi-Character Role-Playing Agent",
        "authors": [
            "Xiaoyan Yu",
            "Tongxu Luo",
            "Yifan Wei",
            "Fangyu Lei",
            "Yiming Huang",
            "Hao Peng",
            "Liehuang Zhu"
        ],
        "date": "2024/02/21",
        "pdf": "http://arxiv.org/pdf/2402.13717",
        "abstract": "Large Language Models (LLMs) have revolutionized open-domain dialogue agents but encounter challenges in multi-character role-playing (MCRP) scenarios. To address the issue, we present Neeko, an innovative framework designed for efficient multiple characters imitation. Unlike existing methods, Neeko employs a dynamic low-rank adapter (LoRA) strategy, enabling it to adapt seamlessly to diverse characters. Our framework breaks down the role-playing process into agent pre-training, multiple characters playing, and character incremental learning, effectively handling both seen and unseen roles. This dynamic approach, coupled with distinct LoRA blocks for each character, enhances Neeko&#39;s adaptability to unique attributes, personalities, and speaking patterns. As a result, Neeko demonstrates superior performance in MCRP over most existing methods, offering more engaging and versatile user interaction experiences. Code and data are available at https://github.com/weiyifan1023/Neeko.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ],
            [
                "Training",
                "Fine tuning"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.13717"
    },
    "5425466c579cdb4a913f52545fd808cb": {
        "title": "Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering",
        "authors": [
            "Chang Zong",
            "Yuchen Yan",
            "Weiming Lu",
            "Jian Shao",
            "Eliot Huang",
            "Heng Chang",
            "Yueting Zhuang"
        ],
        "date": "2024/02/22",
        "pdf": "http://arxiv.org/pdf/2402.14320",
        "abstract": "Recent progress with LLM-based agents has shown promising results across various tasks. However, their use in answering questions from knowledge bases remains largely unexplored. Implementing a KBQA system using traditional methods is challenging due to the shortage of task-specific training data and the complexity of creating task-focused model structures. In this paper, we present Triad, a unified framework that utilizes an LLM-based agent with three roles for KBQA tasks. The agent is assigned three roles to tackle different KBQA subtasks: agent as a generalist for mastering various subtasks, as a decision maker for the selection of candidates, and as an advisor for answering questions with knowledge. Our KBQA framework is executed in four phases, involving the collaboration of the agent&#39;s multiple roles. We evaluated the performance of our framework using three benchmark datasets, and the results show that our framework outperforms state-of-the-art systems on the LC-QuAD and YAGO-QA benchmarks, yielding F1 scores of 11.8% and 20.7%, respectively.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.14320"
    },
    "dc281e70bc671f58ce277899d44ca56f": {
        "title": "Stick to your Role! Stability of Personal Values Expressed in Large Language Models",
        "authors": [
            "Grgur KovaÄ",
            "RÃ©my Portelas",
            "Masataka Sawayama",
            "Peter Ford Dominey",
            "Pierre-Yves Oudeyer"
        ],
        "date": "2024/02/19",
        "pdf": "http://arxiv.org/pdf/2402.14846",
        "abstract": "The standard way to study Large Language Models (LLMs) with benchmarks or psychology questionnaires is to provide many different queries from similar minimal contexts (e.g. multiple choice questions). However, due to LLMs&#39; highly context-dependent nature, conclusions from such minimal-context evaluations may be little informative about the model&#39;s behavior in deployment (where it will be exposed to many new contexts). We argue that context-dependence (specifically, value stability) should be studied as a specific property of LLMs and used as another dimension of LLM comparison (alongside others such as cognitive abilities, knowledge, or model size). We present a case-study on the stability of value expression over different contexts (simulated conversations on different topics) as measured using a standard psychology questionnaire (PVQ) and on behavioral downstream tasks. Reusing methods from psychology, we study Rank-order stability on the population (interpersonal) level, and Ipsative stability on the individual (intrapersonal) level. We consider two settings (with and without instructing LLMs to simulate particular personas), two simulated populations, and three downstream tasks. We observe consistent trends in the stability of models and model families - Mixtral, Mistral, GPT-3.5 and Qwen families are more stable than LLaMa-2 and Phi. The consistency of these trends implies that some models exhibit higher value stability than others, and that stability can be estimated with the set of introduced methodological tools. When instructed to simulate particular personas, LLMs exhibit low Rank-order stability, which further diminishes with conversation length. This highlights the need for future research on LLMs that coherently simulate different personas. This paper provides a foundational step in that direction, and, to our knowledge, it is the first study of value stability in LLMs.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.14846"
    },
    "57c30a1d7bac2dee5e7ef2544482de25": {
        "title": "CHATATC: Large Language Model-Driven Conversational Agents for Supporting Strategic Air Traffic Flow Management",
        "authors": [
            "Sinan Abdulhak",
            "Wayne Hubbard",
            "Karthik Gopalakrishnan",
            "Max Z. Li"
        ],
        "date": "2024/02/20",
        "pdf": "http://arxiv.org/pdf/2402.14850",
        "abstract": "Generative artificial intelligence (AI) and large language models (LLMs) have gained rapid popularity through publicly available tools such as ChatGPT. The adoption of LLMs for personal and professional use is fueled by the natural interactions between human users and computer applications such as ChatGPT, along with powerful summarization and text generation capabilities. Given the widespread use of such generative AI tools, in this work we investigate how these tools can be deployed in a non-safety critical, strategic traffic flow management setting. Specifically, we train an LLM, CHATATC, based on a large historical data set of Ground Delay Program (GDP) issuances, spanning 2000-2023 and consisting of over 80,000 GDP implementations, revisions, and cancellations. We test the query and response capabilities of CHATATC, documenting successes (e.g., providing correct GDP rates, durations, and reason) and shortcomings (e.g,. superlative questions). We also detail the design of a graphical user interface for future users to interact and collaborate with the CHATATC conversational agent.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.14850"
    },
    "c23d8b2451b56282954208f691de8e70": {
        "title": "LLM Based Multi-Agent Generation of Semi-structured Documents from Semantic Templates in the Public Administration Domain",
        "authors": [
            "Emanuele Musumeci",
            "Michele Brienza",
            "Vincenzo Suriani",
            "Daniele Nardi",
            "Domenico Daniele Bloisi"
        ],
        "date": "2024/02/21",
        "pdf": "http://arxiv.org/pdf/2402.14871",
        "abstract": "In the last years&#39; digitalization process, the creation and management of documents in various domains, particularly in Public Administration (PA), have become increasingly complex and diverse. This complexity arises from the need to handle a wide range of document types, often characterized by semi-structured forms. Semi-structured documents present a fixed set of data without a fixed format. As a consequence, a template-based solution cannot be used, as understanding a document requires the extraction of the data structure. The recent introduction of Large Language Models (LLMs) has enabled the creation of customized text output satisfying user requests. In this work, we propose a novel approach that combines the LLMs with prompt engineering and multi-agent systems for generating new documents compliant with a desired structure. The main contribution of this work concerns replacing the commonly used manual prompting with a task description generated by semantic retrieval from an LLM. The potential of this approach is demonstrated through a series of experiments and case studies, showcasing its effectiveness in real-world PA scenarios.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.14871"
    },
    "71aa00d952aa65d1d5fc0c1319a05590": {
        "title": "Mirror: A Multiple-perspective Self-Reflection Method for Knowledge-rich Reasoning",
        "authors": [
            "Hanqi Yan",
            "Qinglin Zhu",
            "Xinyu Wang",
            "Lin Gui",
            "Yulan He"
        ],
        "date": "2024/02/22",
        "pdf": "http://arxiv.org/pdf/2402.14963",
        "abstract": "While Large language models (LLMs) have the capability to iteratively reflect on their own outputs, recent studies have observed their struggles with knowledge-rich problems without access to external resources. In addition to the inefficiency of LLMs in self-assessment, we also observe that LLMs struggle to revisit their predictions despite receiving explicit negative feedback. Therefore, We propose Mirror, a Multiple-perspective self-reflection method for knowledge-rich reasoning, to avoid getting stuck at a particular reflection iteration. Mirror enables LLMs to reflect from multiple-perspective clues, achieved through a heuristic interaction between a Navigator and a Reasoner. It guides agents toward diverse yet plausibly reliable reasoning trajectory without access to ground truth by encouraging (1) diversity of directions generated by Navigator and (2) agreement among strategically induced perturbations in responses generated by the Reasoner. The experiments on five reasoning datasets demonstrate that Mirror&#39;s superiority over several contemporary self-reflection approaches. Additionally, the ablation study studies clearly indicate that our strategies alleviate the aforementioned challenges.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.14963"
    },
    "428eb471e55fba81e7c48c4f54cdb12c": {
        "title": "On the Multi-turn Instruction Following for Conversational Web Agents",
        "authors": [
            "Yang Deng",
            "Xuan Zhang",
            "Wenxuan Zhang",
            "Yifei Yuan",
            "See-Kiong Ng",
            "Tat-Seng Chua"
        ],
        "date": "2024/02/23",
        "pdf": "http://arxiv.org/pdf/2402.15057",
        "abstract": "Web agents powered by Large Language Models (LLMs) have demonstrated remarkable abilities in planning and executing multi-step interactions within complex web-based environments, fulfilling a wide range of web navigation tasks. Despite these advancements, the potential for LLM-powered agents to effectively engage with sequential user instructions in real-world scenarios has not been fully explored. In this work, we introduce a new task of Conversational Web Navigation, which necessitates sophisticated interactions that span multiple turns with both the users and the environment, supported by a specially developed dataset named Multi-Turn Mind2Web (MT-Mind2Web). To tackle the limited context length of LLMs and the context-dependency issue of the conversational tasks, we further propose a novel framework, named self-reflective memory-augmented planning (Self-MAP), which employs memory utilization and self-reflection techniques. Extensive experiments are conducted to benchmark the MT-Mind2Web dataset, and validate the effectiveness of the proposed method.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ],
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.15057"
    },
    "842a8ba1857bd207c062e04b067a1aa8": {
        "title": "Chain-of-Discussion: A Multi-Model Framework for Complex Evidence-Based Question Answering",
        "authors": [
            "Mingxu Tao",
            "Dongyan Zhao",
            "Yansong Feng"
        ],
        "date": "2024/02/26",
        "pdf": "http://arxiv.org/pdf/2402.16313",
        "abstract": "Open-ended question answering requires models to find appropriate evidence to form wellreasoned, comprehensive and helpful answers. In practical applications, models also need to engage in extended discussions on potential scenarios closely relevant to the question. With augmentation of retrieval module, open-source Large Language Models (LLMs) can produce coherent answers often with different focuses, but are still sub-optimal in terms of reliable evidence selection and in-depth question analysis. In this paper, we propose a novel Chain-ofDiscussion framework to leverage the synergy among multiple open-source LLMs aiming to provide more correct and more comprehensive answers for open-ended QA, although they are not strong enough individually. Our experiments show that discussions among multiple LLMs play a vital role in enhancing the quality of answers.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.16313"
    },
    "978d17d42f9c0ab8af8351e7e1163e4a": {
        "title": "LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments",
        "authors": [
            "Junzhe Chen",
            "Xuming Hu",
            "Shuodi Liu",
            "Shiyu Huang",
            "Wei-Wei Tu",
            "Zhaofeng He",
            "Lijie Wen"
        ],
        "date": "2024/02/26",
        "pdf": "http://arxiv.org/pdf/2402.16499",
        "abstract": "Recent advancements in large language models (LLMs) have revealed their potential for achieving autonomous agents possessing human-level intelligence. However, existing benchmarks for evaluating LLM Agents either use static datasets, potentially leading to data leakage or focus only on single-agent scenarios, overlooking the complexities of multi-agent interactions. There is a lack of a benchmark that evaluates the diverse capabilities of LLM agents in multi-agent, dynamic environments. To this end, we introduce LLMArena, a novel and easily extensible framework for evaluating the diverse capabilities of LLM in multi-agent dynamic environments. LLMArena encompasses seven distinct gaming environments, employing Trueskill scoring to assess crucial abilities in LLM agents, including spatial reasoning, strategic planning, numerical reasoning, risk assessment, communication, opponent modeling, and team collaboration. We conduct an extensive experiment and human evaluation among different sizes and types of LLMs, showing that LLMs still have a significant journey ahead in their development towards becoming fully autonomous agents, especially in opponent modeling and team collaboration. We hope LLMArena could guide future research towards enhancing these capabilities in LLMs, ultimately leading to more sophisticated and practical applications in dynamic, multi-agent settings. The code and data will be available.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.16499"
    },
    "046a041e159b5e6124bff8679e854b8d": {
        "title": "Look Before You Leap: Towards Decision-Aware and Generalizable Tool-Usage for Large Language Models",
        "authors": [
            "Anchun Gui",
            "Jian Li",
            "Yong Dai",
            "Nan Du",
            "Han Xiao"
        ],
        "date": "2024/02/26",
        "pdf": "http://arxiv.org/pdf/2402.16696",
        "abstract": "Tool-augmented large language models (LLMs) are attracting widespread attention when accessing up-to-date knowledge and alleviating hallucination issues. Nowadays, advanced closed-source LLMs (e.g., ChatGPT) have demonstrated surprising tool-usage capabilities through prompting and in-context learning techniques. To empower the capabilities of open-source LLMs (e.g., LLaMA) in manipulating tools, current efforts focus on either template-driven or token-triggered tool-usage. However, the former hampers LLMs&#39; flexibility to address diverse user&#39;s queries due to constrained tool interactions, while the latter limits the generalizability when engaging with new tools, since tool-usage learning is based on task- and tool-specific datasets. To alleviate these concerns, in this paper, we propose a decision-aware and generalizable tool-usage framework (DEER). Specifically, we first construct the tool-usage samples with multiple decision branches via an automatic generation pipeline, thereby inspiring the decision-making awareness of LLMs under diverse scenarios. Meanwhile, we propose a novel tool sampling strategy to enhance the generalizability of LLMs over unseen tools. Extensive experiments demonstrate that our proposed DEER is effective and significantly outperforms baselines across various datasets.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.16696"
    },
    "732e0618c428ed5aa30a4bc21c0dbb5c": {
        "title": "SelectIT: Selective Instruction Tuning for LLMs via Uncertainty-Aware Self-Reflection",
        "authors": [
            "Liangxin Liu",
            "Xuebo Liu",
            "Derek F. Wong",
            "Dongfang Li",
            "Ziyi Wang",
            "Baotian Hu",
            "Min Zhang"
        ],
        "date": "2024/02/26",
        "pdf": "http://arxiv.org/pdf/2402.16705",
        "abstract": "Instruction tuning (IT) is crucial to tailoring large language models (LLMs) towards human-centric interactions. Recent advancements have shown that the careful selection of a small, high-quality subset of IT data can significantly enhance the performance of LLMs. Despite this, common approaches often rely on additional models or data, which increases costs and limits widespread adoption. In this work, we propose a novel approach, termed SelectIT, that capitalizes on the foundational capabilities of the LLM itself. Specifically, we exploit the intrinsic uncertainty present in LLMs to more effectively select high-quality IT data, without the need for extra resources. Furthermore, we introduce a curated IT dataset, the Selective Alpaca, created by applying SelectIT to the Alpaca-GPT4 dataset. Empirical results demonstrate that IT using Selective Alpaca leads to substantial model ability enhancement. The robustness of SelectIT has also been corroborated in various foundation models and domain-specific tasks. Our findings suggest that longer and more computationally intensive IT data may serve as superior sources of IT, offering valuable insights for future research in this area. Data, code, and scripts are freely available at https://github.com/Blue-Raincoat/SelectIT.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.16705"
    },
    "ddb24874c6acc4057939243cc129be37": {
        "title": "A Survey on Recent Advances in LLM-Based Multi-turn Dialogue Systems",
        "authors": [
            "Zihao Yi",
            "Jiarui Ouyang",
            "Yuwen Liu",
            "Tianhao Liao",
            "Zhe Xu",
            "Ying Shen"
        ],
        "date": "2024/02/28",
        "pdf": "http://arxiv.org/pdf/2402.18013",
        "abstract": "This survey provides a comprehensive review of research on multi-turn dialogue systems, with a particular focus on multi-turn dialogue systems based on large language models (LLMs). This paper aims to (a) give a summary of existing LLMs and approaches for adapting LLMs to downstream tasks; (b) elaborate recent advances in multi-turn dialogue systems, covering both LLM-based open-domain dialogue (ODD) and task-oriented dialogue (TOD) systems, along with datasets and evaluation metrics; (c) discuss some future emphasis and recent research problems arising from the development of LLMs and the increasing demands on multi-turn dialogue systems.",
        "code": "",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2402.18013"
    },
    "4ac92f5bd1e6b1ed3456db0cec8804c4": {
        "title": "Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?",
        "authors": [
            "Qineng Wang",
            "Zihao Wang",
            "Ying Su",
            "Hanghang Tong",
            "Yangqiu Song"
        ],
        "date": "2024/02/28",
        "pdf": "http://arxiv.org/pdf/2402.18272",
        "abstract": "Recent progress in LLMs discussion suggests that multi-agent discussion improves the reasoning abilities of LLMs. In this work, we reevaluate this claim through systematic experiments, where we propose a novel group discussion framework to enrich the set of discussion mechanisms. Interestingly, our results show that a single-agent LLM with strong prompts can achieve almost the same performance as the best existing discussion approach on a wide range of reasoning tasks and backbone LLMs. We observe that the multi-agent discussion performs better than a single agent only when there is no demonstration in the prompt. Further study reveals the common interaction mechanisms of LLMs during the discussion.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.18272"
    },
    "97c680907ecee2890becf2523b5facf2": {
        "title": "PokeLLMon: A Human-Parity Agent for Pokemon Battles with Large Language Models",
        "authors": [
            "Sihao Hu",
            "Tiansheng Huang",
            "Ling Liu"
        ],
        "date": "2024/02/02",
        "pdf": "http://arxiv.org/pdf/2402.01118",
        "abstract": "We introduce PokeLLMon, the first LLM-embodied agent that achieves human-parity performance in tactical battle games, as demonstrated in Pokemon battles. The design of PokeLLMon incorporates three key strategies: (i) In-context reinforcement learning that instantly consumes text-based feedback derived from battles to iteratively refine the policy; (ii) Knowledge-augmented generation that retrieves external knowledge to counteract hallucination and enables the agent to act timely and properly; (iii) Consistent action generation to mitigate the panic switching phenomenon when the agent faces a powerful opponent and wants to elude the battle. We show that online battles against human demonstrates PokeLLMon&#39;s human-like battle strategies and just-in-time decision making, achieving 49% of win rate in the Ladder competitions and 56% of win rate in the invited battles. Our implementation and playable battle logs are available at: https://github.com/git-disl/PokeLLMon.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.01118"
    },
    "8e3cbb1643b5524e1a59b88d912ef2c0": {
        "title": "A Multi-Agent Conversational Recommender System",
        "authors": [
            "Jiabao Fang",
            "Shen Gao",
            "Pengjie Ren",
            "Xiuying Chen",
            "Suzan Verberne",
            "Zhaochun Ren"
        ],
        "date": "2024/02/02",
        "pdf": "http://arxiv.org/pdf/2402.01135",
        "abstract": "Due to strong capabilities in conducting fluent, multi-turn conversations with users, Large Language Models (LLMs) have the potential to further improve the performance of Conversational Recommender System (CRS). Unlike the aimless chit-chat that LLM excels at, CRS has a clear target. So it is imperative to control the dialogue flow in the LLM to successfully recommend appropriate items to the users. Furthermore, user feedback in CRS can assist the system in better modeling user preferences, which has been ignored by existing studies. However, simply prompting LLM to conduct conversational recommendation cannot address the above two key challenges. In this paper, we propose Multi-Agent Conversational Recommender System (MACRS) which contains two essential modules. First, we design a multi-agent act planning framework, which can control the dialogue flow based on four LLM-based agents. This cooperative multi-agent framework will generate various candidate responses based on different dialogue acts and then choose the most appropriate response as the system response, which can help MACRS plan suitable dialogue acts. Second, we propose a user feedback-aware reflection mechanism which leverages user feedback to reason errors made in previous turns to adjust the dialogue act planning, and higher-level user information from implicit semantics. We conduct extensive experiments based on user simulator to demonstrate the effectiveness of MACRS in recommendation and user preferences collection. Experimental results illustrate that MACRS demonstrates an improvement in user interaction experience compared to directly using LLMs.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.01135"
    },
    "f35e9df2a012ff5dbd78690968a9c985": {
        "title": "StepCoder: Improve Code Generation with Reinforcement Learning from Compiler Feedback",
        "authors": [
            "Shihan Dou",
            "Yan Liu",
            "Haoxiang Jia",
            "Limao Xiong",
            "Enyu Zhou",
            "Wei Shen",
            "Junjie Shan",
            "Caishuang Huang",
            "Xiao Wang",
            "Xiaoran Fan",
            "Zhiheng Xi",
            "Yuhao Zhou",
            "Tao Ji",
            "Rui Zheng",
            "Qi Zhang",
            "Xuanjing Huang",
            "Tao Gui"
        ],
        "date": "2024/02/02",
        "pdf": "http://arxiv.org/pdf/2402.01391",
        "abstract": "The advancement of large language models (LLMs) has significantly propelled the field of code generation. Previous work integrated reinforcement learning (RL) with compiler feedback for exploring the output space of LLMs to enhance code generation quality. However, the lengthy code generated by LLMs in response to complex human requirements makes RL exploration a challenge. Also, since the unit tests may not cover the complicated code, optimizing LLMs by using these unexecuted code snippets is ineffective. To tackle these challenges, we introduce StepCoder, a novel RL framework for code generation, consisting of two main components: CCCS addresses the exploration challenge by breaking the long sequences code generation task into a Curriculum of Code Completion Subtasks, while FGO only optimizes the model by masking the unexecuted code segments to provide Fine-Grained Optimization. In addition, we furthermore construct the APPS+ dataset for RL training, which is manually verified to ensure the correctness of unit tests. Experimental results show that our method improves the ability to explore the output space and outperforms state-of-the-art approaches in corresponding benchmarks. Our dataset APPS+ and StepCoder are available online.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Application",
                "Software Engineering"
            ],
            [
                "Training",
                "RL"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.01391"
    },
    "3300b5a7d577880f68a805dbd456926f": {
        "title": "Enhance Reasoning for Large Language Models in the Game Werewolf",
        "authors": [
            "Shuang Wu",
            "Liwen Zhu",
            "Tao Yang",
            "Shiwei Xu",
            "Qiang Fu",
            "Yang Wei",
            "Haobo Fu"
        ],
        "date": "2024/02/04",
        "pdf": "http://arxiv.org/pdf/2402.02330",
        "abstract": "This paper presents an innovative framework that integrates Large Language Models (LLMs) with an external Thinker module to enhance the reasoning capabilities of LLM-based agents. Unlike augmenting LLMs with prompt engineering, Thinker directly harnesses knowledge from databases and employs various optimization techniques. The framework forms a reasoning hierarchy where LLMs handle intuitive System-1 tasks such as natural language processing, while the Thinker focuses on cognitive System-2 tasks that require complex logical analysis and domain-specific knowledge. Our framework is presented using a 9-player Werewolf game that demands dual-system reasoning. We introduce a communication protocol between LLMs and the Thinker, and train the Thinker using data from 18800 human sessions and reinforcement learning. Experiments demonstrate the framework&#39;s effectiveness in deductive reasoning, speech generation, and online game evaluation. Additionally, we fine-tune a 6B LLM to surpass GPT4 when integrated with the Thinker. This paper also contributes the largest dataset for social deduction games to date.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.02330"
    },
    "cb258de9f27fddad03485d7f165904fb": {
        "title": "Understanding the planning of LLM agents: A survey",
        "authors": [
            "Xu Huang",
            "Weiwen Liu",
            "Xiaolong Chen",
            "Xingmei Wang",
            "Hao Wang",
            "Defu Lian",
            "Yasheng Wang",
            "Ruiming Tang",
            "Enhong Chen"
        ],
        "date": "2024/02/05",
        "pdf": "http://arxiv.org/pdf/2402.02716",
        "abstract": "As Large Language Models (LLMs) have shown significant intelligence, the progress to leverage LLMs as planning modules of autonomous agents has attracted more attention. This survey provides the first systematic view of LLM-based agents planning, covering recent works aiming to improve planning ability. We provide a taxonomy of existing works on LLM-Agent planning, which can be categorized into Task Decomposition, Plan Selection, External Module, Reflection and Memory. Comprehensive analyses are conducted for each direction, and further challenges for the field of research are discussed.",
        "code": "",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2402.02716"
    },
    "3e3b6d0959265aa43dd113e51341cc90": {
        "title": "GUARD: Role-playing to Generate Natural-language Jailbreakings to Test Guideline Adherence of Large Language Models",
        "authors": [
            "Haibo Jin",
            "Ruoxi Chen",
            "Andy Zhou",
            "Yang Zhang",
            "Haohan Wang"
        ],
        "date": "2024/02/05",
        "pdf": "http://arxiv.org/pdf/2402.03299",
        "abstract": "The discovery of &#34;jailbreaks&#34; to bypass safety filters of Large Language Models (LLMs) and harmful responses have encouraged the community to implement safety measures. One major safety measure is to proactively test the LLMs with jailbreaks prior to the release. Therefore, such testing will require a method that can generate jailbreaks massively and efficiently. In this paper, we follow a novel yet intuitive strategy to generate jailbreaks in the style of the human generation. We propose a role-playing system that assigns four different roles to the user LLMs to collaborate on new jailbreaks. Furthermore, we collect existing jailbreaks and split them into different independent characteristics using clustering frequency and semantic patterns sentence by sentence. We organize these characteristics into a knowledge graph, making them more accessible and easier to retrieve. Our system of different roles will leverage this knowledge graph to generate new jailbreaks, which have proved effective in inducing LLMs to generate unethical or guideline-violating responses. In addition, we also pioneer a setting in our system that will automatically follow the government-issued guidelines to generate jailbreaks to test whether LLMs follow the guidelines accordingly. We refer to our system as GUARD (Guideline Upholding through Adaptive Role-play Diagnostics). We have empirically validated the effectiveness of GUARD on three cutting-edge open-sourced LLMs (Vicuna-13B, LongChat-7B, and Llama-2-7B), as well as a widely-utilized commercial LLM (ChatGPT). Moreover, our work extends to the realm of vision language models (MiniGPT-v2 and Gemini Vision Pro), showcasing GUARD&#39;s versatility and contributing valuable insights for the development of safer, more reliable LLM-based applications across diverse modalities.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.03299"
    },
    "34797899b0b543582283f74388953080": {
        "title": "RAP: Retrieval-Augmented Planning with Contextual Memory for Multimodal LLM Agents",
        "authors": [
            "Tomoyuki Kagaya",
            "Thong Jing Yuan",
            "Yuxuan Lou",
            "Jayashree Karlekar",
            "Sugiri Pranata",
            "Akira Kinose",
            "Koki Oguri",
            "Felix Wick",
            "Yang You"
        ],
        "date": "2024/02/06",
        "pdf": "http://arxiv.org/pdf/2402.03610",
        "abstract": "Owing to recent advancements, Large Language Models (LLMs) can now be deployed as agents for increasingly complex decision-making applications in areas including robotics, gaming, and API integration. However, reflecting past experiences in current decision-making processes, an innate human behavior, continues to pose significant challenges. Addressing this, we propose Retrieval-Augmented Planning (RAP) framework, designed to dynamically leverage past experiences corresponding to the current situation and context, thereby enhancing agents&#39; planning capabilities. RAP distinguishes itself by being versatile: it excels in both text-only and multimodal environments, making it suitable for a wide range of tasks. Empirical evaluations demonstrate RAP&#39;s effectiveness, where it achieves SOTA performance in textual scenarios and notably enhances multimodal LLM agents&#39; performance for embodied tasks. These results highlight RAP&#39;s potential in advancing the functionality and applicability of LLM agents in complex, real-world applications.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ],
            [
                "Technique For Enhancement",
                "Memory Mechanism"
            ],
            [
                "Technique For Enhancement",
                "RAG"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.03610"
    },
    "0225b7cf486f65674b0fe04db98aaa16": {
        "title": "Can Generative Agents Predict Emotion?",
        "authors": [
            "Ciaran Regan",
            "Nanami Iwahashi",
            "Shogo Tanaka",
            "Mizuki Oka"
        ],
        "date": "2024/02/06",
        "pdf": "http://arxiv.org/pdf/2402.04232",
        "abstract": "Large Language Models (LLMs) have demonstrated a number of human-like abilities, however the empathic understanding and emotional state of LLMs is yet to be aligned to that of humans. In this work, we investigate how the emotional state of generative LLM agents evolves as they perceive new events, introducing a novel architecture in which new experiences are compared to past memories. Through this comparison, the agent gains the ability to understand new experiences in context, which according to the appraisal theory of emotion is vital in emotion creation. First, the agent perceives new experiences as time series text data. After perceiving each new input, the agent generates a summary of past relevant memories, referred to as the norm, and compares the new experience to this norm. Through this comparison we can analyse how the agent reacts to the new experience in context. The PANAS, a test of affect, is administered to the agent, capturing the emotional state of the agent after the perception of the new event. Finally, the new experience is then added to the agents memory to be used in the creation of future norms. By creating multiple experiences in natural language from emotionally charged situations, we test the proposed architecture on a wide range of scenarios. The mixed results suggests that introducing context can occasionally improve the emotional alignment of the agent, but further study and comparison with human evaluators is necessary. We hope that this paper is another step towards the alignment of generative agents.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.04232"
    },
    "faf966da03b7ba9e7b5859e731558402": {
        "title": "Prioritizing Safeguarding Over Autonomy: Risks of LLM Agents for Science",
        "authors": [
            "Xiangru Tang",
            "Qiao Jin",
            "Kunlun Zhu",
            "Tongxin Yuan",
            "Yichi Zhang",
            "Wangchunshu Zhou",
            "Meng Qu",
            "Yilun Zhao",
            "Jian Tang",
            "Zhuosheng Zhang",
            "Arman Cohan",
            "Zhiyong Lu",
            "Mark Gerstein"
        ],
        "date": "2024/02/06",
        "pdf": "http://arxiv.org/pdf/2402.04247",
        "abstract": "Intelligent agents powered by large language models (LLMs) have demonstrated substantial promise in autonomously conducting experiments and facilitating scientific discoveries across various disciplines. While their capabilities are promising, these agents, called scientific LLM agents, also introduce novel vulnerabilities that demand careful consideration for safety. However, there exists a notable gap in the literature, as there has been no comprehensive exploration of these vulnerabilities. This perspective paper fills this gap by conducting a thorough examination of vulnerabilities in LLM-based agents within scientific domains, shedding light on potential risks associated with their misuse and emphasizing the need for safety measures. We begin by providing a comprehensive overview of the potential risks inherent to scientific LLM agents, taking into account user intent, the specific scientific domain, and their potential impact on the external environment. Then, we delve into the origins of these vulnerabilities and provide a scoping review of the limited existing works. Based on our analysis, we propose a triadic framework involving human regulation, agent alignment, and an understanding of environmental feedback (agent regulation) to mitigate these identified risks. Furthermore, we highlight the limitations and challenges associated with safeguarding scientific agents and advocate for the development of improved models, robust benchmarks, and comprehensive regulations to address these issues effectively.",
        "code": "",
        "category": [
            [
                "Application",
                "Research"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.04247"
    },
    "7a8b78fdb03c0cce97414fcfdb71fa23": {
        "title": "Can Large Language Model Agents Simulate Human Trust Behavior?",
        "authors": [
            "Chengxing Xie",
            "Canyu Chen",
            "Feiran Jia",
            "Ziyu Ye",
            "Shiyang Lai",
            "Kai Shu",
            "Jindong Gu",
            "Adel Bibi",
            "Ziniu Hu",
            "David Jurgens",
            "James Evans",
            "Philip Torr",
            "Bernard Ghanem",
            "Guohao Li"
        ],
        "date": "2024/02/07",
        "pdf": "http://arxiv.org/pdf/2402.04559",
        "abstract": "Large Language Model (LLM) agents have been increasingly adopted as simulation tools to model humans in social science and role-playing applications. However, one fundamental question remains: can LLM agents really simulate human behavior? In this paper, we focus on one critical and elemental behavior in human interactions, trust, and investigate whether LLM agents can simulate human trust behavior. We first find that LLM agents generally exhibit trust behavior, referred to as agent trust, under the framework of Trust Games, which are widely recognized in behavioral economics. Then, we discover that GPT-4 agents manifest high behavioral alignment with humans in terms of trust behavior, indicating the feasibility of simulating human trust behavior with LLM agents. In addition, we probe the biases of agent trust and differences in agent trust towards other LLM agents and humans. We also explore the intrinsic properties of agent trust under conditions including external manipulations and advanced reasoning strategies. Our study provides new insights into the behaviors of LLM agents and the fundamental analogy between LLMs and humans beyond value alignment. We further illustrate broader implications of our discoveries for applications where trust is paramount.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.04559"
    },
    "6595dfd27493f7ec99213b704b178c9d": {
        "title": "CoSearchAgent: A Lightweight Collaborative Search Agent with Large Language Models",
        "authors": [
            "Peiyuan Gong",
            "Jiamian Li",
            "Jiaxin Mao"
        ],
        "date": "2024/02/09",
        "pdf": "http://arxiv.org/pdf/2402.06360",
        "abstract": "Collaborative search supports multiple users working together to accomplish a specific search task. Research has found that designing lightweight collaborative search plugins within instant messaging platforms aligns better with users&#39; collaborative habits. However, due to the complexity of multi-user interaction scenarios, it is challenging to implement a fully functioning lightweight collaborative search system. Therefore, previous studies on lightweight collaborative search had to rely on the Wizard of Oz paradigm. In recent years, large language models (LLMs) have been demonstrated to interact naturally with users and achieve complex information-seeking tasks through LLM-based agents. Hence, to better support the research in collaborative search, in this demo, we propose CoSearchAgent, a lightweight collaborative search agent powered by LLMs. CoSearchAgent is designed as a Slack plugin that can support collaborative search during multi-party conversations on this platform. Equipped with the capacity to understand the queries and context in multi-user conversations and the ability to search the Web for relevant information via APIs, CoSearchAgent can respond to user queries with answers grounded on the relevant search results. It can also ask clarifying questions when the information needs are unclear. The proposed CoSearchAgent is highly flexible and would be useful for supporting further research on collaborative search. The code and demo video are accessible.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Search"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.06360"
    },
    "7bd9188f4ffafb63274194bc0a99f3d1": {
        "title": "Introspective Planning: Aligning Robots&#39; Uncertainty with Inherent Task Ambiguity",
        "authors": [
            "Kaiqu Liang",
            "Zixu Zhang",
            "Jaime FernÃ¡ndez Fisac"
        ],
        "date": "2024/02/09",
        "pdf": "http://arxiv.org/pdf/2402.06529",
        "abstract": "Large language models (LLMs) exhibit advanced reasoning skills, enabling robots to comprehend natural language instructions and strategically plan high-level actions through proper grounding. However, LLM hallucination may result in robots confidently executing plans that are misaligned with user goals or even unsafe in critical scenarios. Additionally, inherent ambiguity in natural language instructions can introduce uncertainty into the LLM&#39;s reasoning and planning processes.We propose introspective planning, a systematic approach that align LLM&#39;s uncertainty with the inherent ambiguity of the task. Our approach constructs a knowledge base containing introspective reasoning examples as post-hoc rationalizations of human-selected safe and compliant plans, which are retrieved during deployment. Evaluations on three tasks, including a newly introduced safe mobile manipulation benchmark, demonstrate that introspection substantially improves both compliance and safety over state-of-the-art LLM-based planning methods. Furthermore, we empirically show that introspective planning, in combination with conformal prediction, achieves tighter confidence bounds, maintaining statistical success guarantees while minimizing unnecessary user clarification requests. The webpage and code are accessible at https://introplan.github.io.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.06529"
    },
    "f8620e0896c822455747c0236e11e463": {
        "title": "UFO: A UI-Focused Agent for Windows OS Interaction",
        "authors": [
            "Chaoyun Zhang",
            "Liqun Li",
            "Shilin He",
            "Xu Zhang",
            "Bo Qiao",
            "Si Qin",
            "Minghua Ma",
            "Yu Kang",
            "Qingwei Lin",
            "Saravan Rajmohan",
            "Dongmei Zhang",
            "Qi Zhang"
        ],
        "date": "2024/02/08",
        "pdf": "http://arxiv.org/pdf/2402.07939",
        "abstract": "We introduce UFO, an innovative UI-Focused agent to fulfill user requests tailored to applications on Windows OS, harnessing the capabilities of GPT-Vision. UFO employs a dual-agent framework to meticulously observe and analyze the graphical user interface (GUI) and control information of Windows applications. This enables the agent to seamlessly navigate and operate within individual applications and across them to fulfill user requests, even when spanning multiple applications. The framework incorporates a control interaction module, facilitating action grounding without human intervention and enabling fully automated execution. Consequently, UFO transforms arduous and time-consuming processes into simple tasks achievable solely through natural language commands. We conducted testing of UFO across 9 popular Windows applications, encompassing a variety of scenarios reflective of users&#39; daily usage. The results, derived from both quantitative metrics and real-case studies, underscore the superior effectiveness of UFO in fulfilling user requests. To the best of our knowledge, UFO stands as the first UI agent specifically tailored for task completion within the Windows OS environment. The open-source code for UFO is available on https://github.com/microsoft/UFO.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.07939"
    },
    "faf44b5210935885a5c485ad008d9c84": {
        "title": "Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents",
        "authors": [
            "Wenkai Yang",
            "Xiaohan Bi",
            "Yankai Lin",
            "Sishuo Chen",
            "Jie Zhou",
            "Xu Sun"
        ],
        "date": "2024/02/17",
        "pdf": "http://arxiv.org/pdf/2402.11208",
        "abstract": "Driven by the rapid development of Large Language Models (LLMs), LLM-based agents have been developed to handle various real-world applications, including finance, healthcare, and shopping, etc. It is crucial to ensure the reliability and security of LLM-based agents during applications. However, the safety issues of LLM-based agents are currently under-explored. In this work, we take the first step to investigate one of the typical safety threats, backdoor attack, to LLM-based agents. We first formulate a general framework of agent backdoor attacks, then we present a thorough analysis of different forms of agent backdoor attacks. Specifically, compared with traditional backdoor attacks on LLMs that are only able to manipulate the user inputs and model outputs, agent backdoor attacks exhibit more diverse and covert forms: (1) From the perspective of the final attacking outcomes, the agent backdoor attacker can not only choose to manipulate the final output distribution, but also introduce the malicious behavior in an intermediate reasoning step only, while keeping the final output correct. (2) Furthermore, the former category can be divided into two subcategories based on trigger locations, in which the backdoor trigger can either be hidden in the user query or appear in an intermediate observation returned by the external environment. We implement the above variations of agent backdoor attacks on two typical agent tasks including web shopping and tool utilization. Extensive experiments show that LLM-based agents suffer severely from backdoor attacks and such backdoor vulnerability cannot be easily mitigated by current textual backdoor defense algorithms. This indicates an urgent need for further research on the development of targeted defenses against backdoor attacks on LLM-based agents. Warning: This paper may contain biased content.",
        "code": "",
        "category": [
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.11208"
    },
    "e41ce820e64617d634739d29708e867f": {
        "title": "Offline Training of Language Model Agents with Functions as Learnable Weights",
        "authors": [
            "Shaokun Zhang",
            "Jieyu Zhang",
            "Jiale Liu",
            "Linxin Song",
            "Chi Wang",
            "Ranjay Krishna",
            "Qingyun Wu"
        ],
        "date": "2024/02/17",
        "pdf": "http://arxiv.org/pdf/2402.11359",
        "abstract": "Researchers and practitioners have recently reframed powerful Large Language Models (LLMs) as agents, enabling them to automate complex tasks largely via the use of specialized functions. To facilitate the development of LLM agents, we present a novel paradigm of training LLM agents without modifying the LLM weights, which is particularly useful when the LLMs are difficult or inaccessible for modifications. Inspired by how humans continuously forge tools to adapt to real-world tasks, rather than change our biological structure to fit a static set of tools, we propose to progressively forge agent&#39;s functions to better solve the downstream tasks instead of modifying the LLM weights. By treating the functions as learnable `agent parameters&#39; and leveraging the fundamental idea of model training in artificial intelligence, we develop AgentOptimizer that employs the LLM to update agents&#39; functions and devise an agent training algorithm with two strategies, roll-back, and early-stop, to streamline the training process. With extensive experiments, we showcase that the agent training paradigm could significantly improve the performance of representative LLM agents in various downstream tasks. We also study the behavior of the agent training regarding aspects like the learning curve and domain transferability.",
        "code": "",
        "category": [
            [
                "Training",
                "RL"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.11359"
    },
    "f1bd6aec7fc832da2d885439f4190c32": {
        "title": "Shaping Human-AI Collaboration: Varied Scaffolding Levels in Co-writing with Language Models",
        "authors": [
            "Paramveer S. Dhillon",
            "Somayeh Molaei",
            "Jiaqi Li",
            "Maximilian Golub",
            "Shaochun Zheng",
            "Lionel P. Robert"
        ],
        "date": "2024/02/18",
        "pdf": "http://arxiv.org/pdf/2402.11723",
        "abstract": "Advances in language modeling have paved the way for novel human-AI co-writing experiences. This paper explores how varying levels of scaffolding from large language models (LLMs) shape the co-writing process. Employing a within-subjects field experiment with a Latin square design, we asked participants (N=131) to respond to argumentative writing prompts under three randomly sequenced conditions: no AI assistance (control), next-sentence suggestions (low scaffolding), and next-paragraph suggestions (high scaffolding). Our findings reveal a U-shaped impact of scaffolding on writing quality and productivity (words/time). While low scaffolding did not significantly improve writing quality or productivity, high scaffolding led to significant improvements, especially benefiting non-regular writers and less tech-savvy users. No significant cognitive burden was observed while using the scaffolded writing tools, but a moderate decrease in text ownership and satisfaction was noted. Our results have broad implications for the design of AI-powered writing tools, including the need for personalized scaffolding mechanisms.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Human-Agent Interaction"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.11723"
    },
    "67182f0130bd01c7473a351917dfb201": {
        "title": "WorldCoder, a Model-Based LLM Agent: Building World Models by Writing Code and Interacting with the Environment",
        "authors": [
            "Hao Tang",
            "Darren Key",
            "Kevin Ellis"
        ],
        "date": "2024/02/19",
        "pdf": "http://arxiv.org/pdf/2402.12275",
        "abstract": "We give a model-based agent that builds a Python program representing its knowledge of the world based on its interactions with the environment. The world model tries to explain its interactions, while also being optimistic about what reward it can achieve. We define this optimism as a logical constraint between a program and a planner. We study our agent on gridworlds, and on task planning, finding our approach is more sample-efficient compared to deep RL, more compute-efficient compared to ReAct-style agents, and that it can transfer its knowledge across environments by editing its code.",
        "code": "",
        "category": [
            [
                "Application",
                "Software Engineering"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.12275"
    },
    "3b6070b351092ec4f5fd27c0f5359d9a": {
        "title": "A Critical Evaluation of AI Feedback for Aligning Large Language Models",
        "authors": [
            "Archit Sharma",
            "Sedrick Keh",
            "Eric Mitchell",
            "Chelsea Finn",
            "Kushal Arora",
            "Thomas Kollar"
        ],
        "date": "2024/02/19",
        "pdf": "http://arxiv.org/pdf/2402.12366",
        "abstract": "Reinforcement learning with AI feedback (RLAIF) is a popular paradigm for improving the instruction-following abilities of powerful pre-trained language models. RLAIF first performs supervised fine-tuning (SFT) using demonstrations from a teacher model and then further fine-tunes the model with reinforcement learning (RL), using feedback from a critic model. While recent popular open-source models have demonstrated substantial improvements in performance from the RL step, in this paper we question whether the complexity of this RL step is truly warranted for AI feedback. We show that the improvements of the RL step are virtually entirely due to the widespread practice of using a weaker teacher model (e.g. GPT-3.5) for SFT data collection than the critic (e.g., GPT-4) used for AI feedback generation. Specifically, we show that simple supervised fine-tuning with GPT-4 as the teacher outperforms existing RLAIF pipelines. More generally, we find that the gains from RLAIF vary substantially across base model families, test-time evaluation protocols, and critic models. Finally, we provide a mechanistic explanation for when SFT may outperform the full two-step RLAIF pipeline as well as suggestions for making RLAIF maximally useful in practice.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.12366"
    },
    "991fe9838ff8be84f055c655cfd90ae4": {
        "title": "Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation",
        "authors": [
            "Jiawei Wang",
            "Renhe Jiang",
            "Chuang Yang",
            "Zengqing Wu",
            "Makoto Onizuka",
            "Ryosuke Shibasaki",
            "Noboru Koshizuka",
            "Chuan Xiao"
        ],
        "date": "2024/02/22",
        "pdf": "http://arxiv.org/pdf/2402.14744",
        "abstract": "This paper introduces a novel approach using Large Language Models (LLMs) integrated into an agent framework for flexible and effective personal mobility generation. LLMs overcome the limitations of previous models by effectively processing semantic data and offering versatility in modeling various tasks. Our approach addresses three research questions: aligning LLMs with real-world urban mobility data, developing reliable activity generation strategies, and exploring LLM applications in urban mobility. The key technical contribution is a novel LLM agent framework that accounts for individual activity patterns and motivations, including a self-consistency approach to align LLMs with real-world activity data and a retrieval-augmented strategy for interpretable activity generation. We evaluate our LLM agent framework and compare it with state-of-the-art personal mobility generation approaches, demonstrating the effectiveness of our approach and its potential applications in urban mobility. Overall, this study marks the pioneering work of designing an LLM agent framework for activity generation based on real-world human activity data, offering a promising tool for urban mobility analysis.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.14744"
    },
    "cff55d17a6bd1f5e25bf893bb95759a4": {
        "title": "Empowering Large Language Model Agents through Action Learning",
        "authors": [
            "Haiteng Zhao",
            "Chang Ma",
            "Guoyin Wang",
            "Jing Su",
            "Lingpeng Kong",
            "Jingjing Xu",
            "Zhi-Hong Deng",
            "Hongxia Yang"
        ],
        "date": "2024/02/24",
        "pdf": "http://arxiv.org/pdf/2402.15809",
        "abstract": "Large Language Model (LLM) Agents have recently garnered increasing interest yet they are limited in their ability to learn from trial and error, a key element of intelligent behavior. In this work, we argue that the capacity to learn new actions from experience is fundamental to the advancement of learning in LLM agents. While humans naturally expand their action spaces and develop skills through experiential learning, LLM agents typically operate within fixed action spaces, limiting their potential for growth. To address these challenges, our study explores open-action learning for language agents. We introduce a framework LearnAct with an iterative learning strategy to create and improve actions in the form of Python functions. In each iteration, LLM revises and updates the currently available actions based on the errors identified in unsuccessful training tasks, thereby enhancing action effectiveness. Our experimental evaluations across Robotic Planning and Alfworld environments reveal that after learning on a few training task instances, our approach to open-action learning markedly improves agent performance for the type of task (by 32 percent in AlfWorld compared to ReAct+Reflexion, for instance) highlighting the importance of experiential action learning in the development of more intelligent LLM agents.",
        "code": "https://github.com/zhao-ht/learnact",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.15809"
    },
    "48b9abc38498cfd3a81ce2b6c7e3a370": {
        "title": "Understanding Public Perceptions of AI Conversational Agents: A Cross-Cultural Analysis",
        "authors": [
            "Zihan Liu",
            "Han Li",
            "Anfan Chen",
            "Renwen Zhang",
            "Yi-Chieh Lee"
        ],
        "date": "2024/02/25",
        "pdf": "http://arxiv.org/pdf/2402.16039",
        "abstract": "Conversational Agents (CAs) have increasingly been integrated into everyday life, sparking significant discussions on social media. While previous research has examined public perceptions of AI in general, there is a notable lack in research focused on CAs, with fewer investigations into cultural variations in CA perceptions. To address this gap, this study used computational methods to analyze about one million social media discussions surrounding CAs and compared people&#39;s discourses and perceptions of CAs in the US and China. We find Chinese participants tended to view CAs hedonically, perceived voice-based and physically embodied CAs as warmer and more competent, and generally expressed positive emotions. In contrast, US participants saw CAs more functionally, with an ambivalent attitude. Warm perception was a key driver of positive emotions toward CAs in both countries. We discussed practical implications for designing contextually sensitive and user-centric CAs to resonate with various users&#39; preferences and needs.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.16039"
    },
    "02d196e96f4c9879e876058c130090dd": {
        "title": "OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web",
        "authors": [
            "Raghav Kapoor",
            "Yash Parag Butala",
            "Melisa Russak",
            "Jing Yu Koh",
            "Kiran Kamble",
            "Waseem Alshikh",
            "Ruslan Salakhutdinov"
        ],
        "date": "2024/02/27",
        "pdf": "http://arxiv.org/pdf/2402.17553",
        "abstract": "For decades, human-computer interaction has fundamentally been manual. Even today, almost all productive work done on the computer necessitates human input at every step. Autonomous virtual agents represent an exciting step in automating many of these menial tasks. Virtual agents would empower users with limited technical proficiency to harness the full possibilities of computer systems. They could also enable the efficient streamlining of numerous computer tasks, ranging from calendar management to complex travel bookings, with minimal human intervention. In this paper, we introduce OmniACT, the first-of-a-kind dataset and benchmark for assessing an agent&#39;s capability to generate executable programs to accomplish computer tasks. Our scope extends beyond traditional web automation, covering a diverse range of desktop applications. The dataset consists of fundamental tasks such as &#34;Play the next song&#34;, as well as longer horizon tasks such as &#34;Send an email to John Doe mentioning the time and place to meet&#34;. Specifically, given a pair of screen image and a visually-grounded natural language task, the goal is to generate a script capable of fully executing the task. We run several strong baseline language model agents on our benchmark. The strongest baseline, GPT-4, performs the best on our benchmark However, its performance level still reaches only 15% of the human proficiency in generating executable scripts capable of completing the task, demonstrating the challenge of our task for conventional web agents. Our benchmark provides a platform to measure and evaluate the progress of language model agents in automating computer tasks and motivates future work towards building multimodal models that bridge large language models and the visual grounding of computer screens.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Environment&Platform"
            ],
            [
                "Infrastructure",
                "Dataset"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.17553"
    },
    "8271256b63765b8a4b2bca80cea0bc97": {
        "title": "Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization",
        "authors": [
            "Wenqi Zhang",
            "Ke Tang",
            "Hai Wu",
            "Mengna Wang",
            "Yongliang Shen",
            "Guiyang Hou",
            "Zeqi Tan",
            "Peng Li",
            "Yueting Zhuang",
            "Weiming Lu"
        ],
        "date": "2024/02/27",
        "pdf": "http://arxiv.org/pdf/2402.17574",
        "abstract": "Large Language Models (LLMs) exhibit robust problem-solving capabilities for diverse tasks. However, most LLM-based agents are designed as specific task solvers with sophisticated prompt engineering, rather than agents capable of learning and evolving through interactions. These task solvers necessitate manually crafted prompts to inform task rules and regulate LLM behaviors, inherently incapacitating to address complex dynamic scenarios e.g., large interactive games. In light of this, we propose Agent-Pro: an LLM-based Agent with Policy-level Reflection and Optimization that can learn a wealth of expertise from interactive experiences and progressively elevate its behavioral policy. Specifically, it involves a dynamic belief generation and reflection process for policy evolution. Rather than action-level reflection, Agent-Pro iteratively reflects on past trajectories and beliefs, fine-tuning its irrational beliefs for a better policy. Moreover, a depth-first search is employed for policy optimization, ensuring continual enhancement in policy payoffs. Agent-Pro is evaluated across two games: Blackjack and Texas Hold&#39;em, outperforming vanilla LLM and specialized models. Our results show Agent-Pro can learn and evolve in complex and dynamic scenes, which also benefits numerous LLM-based applications.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.17574"
    },
    "f5a6f0b1770744cc9936c01c3da93afa": {
        "title": "Prospect Personalized Recommendation on Large Language Model-based Agent Platform",
        "authors": [
            "Jizhi Zhang",
            "Keqin Bao",
            "Wenjie Wang",
            "Yang Zhang",
            "Wentao Shi",
            "Wanhong Xu",
            "Fuli Feng",
            "Tat-Seng Chua"
        ],
        "date": "2024/02/28",
        "pdf": "http://arxiv.org/pdf/2402.18240",
        "abstract": "The new kind of Agent-oriented information system, exemplified by GPTs, urges us to inspect the information system infrastructure to support Agent-level information processing and to adapt to the characteristics of Large Language Model (LLM)-based Agents, such as interactivity. In this work, we envisage the prospect of the recommender system on LLM-based Agent platforms and introduce a novel recommendation paradigm called Rec4Agentverse, comprised of Agent Items and Agent Recommender. Rec4Agentverse emphasizes the collaboration between Agent Items and Agent Recommender, thereby promoting personalized information services and enhancing the exchange of information beyond the traditional user-recommender feedback loop. Additionally, we prospect the evolution of Rec4Agentverse and conceptualize it into three stages based on the enhancement of the interaction and information exchange among Agent Items, Agent Recommender, and the user. A preliminary study involving several cases of Rec4Agentverse validates its significant potential for application. Lastly, we discuss potential issues and promising directions for future research.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.18240"
    },
    "a28b37bb6cb6d0a29d804cb33834a5fc": {
        "title": "ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning",
        "authors": [
            "A. Ghafarollahi",
            "M. J. Buehler"
        ],
        "date": "2024/01/27",
        "pdf": "http://arxiv.org/pdf/2402.04268",
        "abstract": "Designing de novo proteins beyond those found in nature holds significant promise for advancements in both scientific and engineering applications. Current methodologies for protein design often rely on AI-based models, such as surrogate models that address end-to-end problems by linking protein structure to material properties or vice versa. However, these models frequently focus on specific material objectives or structural properties, limiting their flexibility when incorporating out-of-domain knowledge into the design process or comprehensive data analysis is required. In this study, we introduce ProtAgents, a platform for de novo protein design based on Large Language Models (LLMs), where multiple AI agents with distinct capabilities collaboratively address complex tasks within a dynamic environment. The versatility in agent development allows for expertise in diverse domains, including knowledge retrieval, protein structure analysis, physics-based simulations, and results analysis. The dynamic collaboration between agents, empowered by LLMs, provides a versatile approach to tackling protein design and analysis problems, as demonstrated through diverse examples in this study. The problems of interest encompass designing new proteins, analyzing protein structures and obtaining new first-principles data -- natural vibrational frequencies -- via physics simulations. The concerted effort of the system allows for powerful automated and synergistic design of de novo proteins with targeted mechanical properties. The flexibility in designing the agents, on one hand, and their capacity in autonomous collaboration through the dynamic LLM-based multi-agent environment on the other hand, unleashes great potentials of LLMs in addressing multi-objective materials problems and opens up new avenues for autonomous materials discovery and design.",
        "code": "",
        "category": [
            [
                "Application",
                "Biology"
            ],
            [
                "Application",
                "Physics"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.04268"
    },
    "f39b606d07c0f8bd9fd6b36696bf5fae": {
        "title": "Data Interpreter: An LLM Agent For Data Science",
        "authors": [
            "Sirui Hong",
            "Yizhang Lin",
            "Bang Liu",
            "Bangbang Liu",
            "Binhao Wu",
            "Ceyao Zhang",
            "Chenxing Wei",
            "Danyang Li",
            "Jiaqi Chen",
            "Jiayi Zhang",
            "Jinlin Wang",
            "Li Zhang",
            "Lingyao Zhang",
            "Min Yang",
            "Mingchen Zhuge",
            "Taicheng Guo",
            "Tuo Zhou",
            "Wei Tao",
            "Xiangru Tang",
            "Xiangtao Lu",
            "Xiawu Zheng",
            "Xinbing Liang",
            "Yaying Fei",
            "Yuheng Cheng",
            "Zhibin Gou",
            "Zongze Xu",
            "Chenglin Wu"
        ],
        "date": "2024/02/28",
        "pdf": "http://arxiv.org/pdf/2402.18679",
        "abstract": "Large Language Model (LLM)-based agents have shown effectiveness across many applications. However, their use in data science scenarios requiring solving long-term interconnected tasks, dynamic data adjustments and domain expertise remains challenging. Previous approaches primarily focus on individual tasks, making it difficult to assess the complete data science workflow. Moreover, they struggle to handle real-time changes in intermediate data and fail to adapt dynamically to evolving task dependencies inherent to data science problems. In this paper, we present Data Interpreter, an LLM-based agent designed to automatically solve various data science problems end-to-end. Our Data Interpreter incorporates two key modules: 1) Hierarchical Graph Modeling, which breaks down complex problems into manageable subproblems, enabling dynamic node generation and graph optimization; and 2) Programmable Node Generation, a technique that refines and verifies each subproblem to iteratively improve code generation results and robustness. Extensive experiments consistently demonstrate the superiority of Data Interpreter. On InfiAgent-DABench, it achieves a 25% performance boost, raising accuracy from 75.9% to 94.9%. For machine learning and open-ended tasks, it improves performance from 88% to 95%, and from 60% to 97%, respectively. Moreover, on the MATH dataset, Data Interpreter achieves remarkable performance with a 26% improvement compared to state-of-the-art baselines. The code is available at https://github.com/geekan/MetaGPT.",
        "code": "https://github.com/geekan/metagpt",
        "category": [
            [
                "Application",
                "Research"
            ]
        ],
        "url": "https://arxiv.org/abs/2402.18679"
    },
    "be2d4031465d914b9934dcb79717a783": {
        "title": "Bootstrapping Cognitive Agents with a Large Language Model",
        "authors": [
            "Feiyu Zhu",
            "Reid Simmons"
        ],
        "date": "2024/02/25",
        "pdf": "http://arxiv.org/pdf/2403.00810",
        "abstract": "Large language models contain noisy general knowledge of the world, yet are hard to train or fine-tune. On the other hand cognitive architectures have excellent interpretability and are flexible to update but require a lot of manual work to instantiate. In this work, we combine the best of both worlds: bootstrapping a cognitive-based model with the noisy knowledge encoded in large language models. Through an embodied agent doing kitchen tasks, we show that our proposed framework yields better efficiency compared to an agent based entirely on large language models. Our experiments indicate that large language models are a good source of information for cognitive architectures, and the cognitive architecture in turn can verify and update the knowledge of large language models to a specific domain.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.00810"
    },
    "7e5087e7696617ed5cbf3c1b34f50b31": {
        "title": "SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code",
        "authors": [
            "Ziniu Hu",
            "Ahmet Iscen",
            "Aashi Jain",
            "Thomas Kipf",
            "Yisong Yue",
            "David A. Ross",
            "Cordelia Schmid",
            "Alireza Fathi"
        ],
        "date": "2024/03/02",
        "pdf": "http://arxiv.org/pdf/2403.01248",
        "abstract": "This paper introduces SceneCraft, a Large Language Model (LLM) Agent converting text descriptions into Blender-executable Python scripts which render complex scenes with up to a hundred 3D assets. This process requires complex spatial planning and arrangement. We tackle these challenges through a combination of advanced abstraction, strategic planning, and library learning. SceneCraft first models a scene graph as a blueprint, detailing the spatial relationships among assets in the scene. SceneCraft then writes Python scripts based on this graph, translating relationships into numerical constraints for asset layout. Next, SceneCraft leverages the perceptual strengths of vision-language foundation models like GPT-V to analyze rendered images and iteratively refine the scene. On top of this process, SceneCraft features a library learning mechanism that compiles common script functions into a reusable library, facilitating continuous self-improvement without expensive LLM parameter tuning. Our evaluation demonstrates that SceneCraft surpasses existing LLM-based agents in rendering complex scenes, as shown by its adherence to constraints and favorable human assessments. We also showcase the broader application potential of SceneCraft by reconstructing detailed 3D scenes from the Sintel movie and guiding a video generative model with generated scenes as intermediary control signal.",
        "code": "",
        "category": [
            [
                "Application",
                "Software Engineering"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.01248"
    },
    "44f6c16c4530452a5f5a3bded715ffee": {
        "title": "ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary",
        "authors": [
            "Yutong Li",
            "Lu Chen",
            "Aiwei Liu",
            "Kai Yu",
            "Lijie Wen"
        ],
        "date": "2024/03/05",
        "pdf": "http://arxiv.org/pdf/2403.02574",
        "abstract": "The literature review is an indispensable step in the research process. It provides the benefit of comprehending the research problem and understanding the current research situation while conducting a comparative analysis of prior works. However, literature summary is challenging and time consuming. The previous LLM-based studies on literature review mainly focused on the complete process, including literature retrieval, screening, and summarization. However, for the summarization step, simple CoT method often lacks the ability to provide extensive comparative summary. In this work, we firstly focus on the independent literature summarization step and introduce ChatCite, an LLM agent with human workflow guidance for comparative literature summary. This agent, by mimicking the human workflow, first extracts key elements from relevant literature and then generates summaries using a Reflective Incremental Mechanism. In order to better evaluate the quality of the generated summaries, we devised a LLM-based automatic evaluation metric, G-Score, in refer to the human evaluation criteria. The ChatCite agent outperformed other models in various dimensions in the experiments. The literature summaries generated by ChatCite can also be directly used for drafting literature reviews.",
        "code": "",
        "category": [
            [
                "Automation",
                "Workflow"
            ],
            [
                "Interaction",
                "Human-Agent Interaction"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.02574"
    },
    "6331f2d3779675a854d1e10deab9b472": {
        "title": "AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks",
        "authors": [
            "Yifan Zeng",
            "Yiran Wu",
            "Xiao Zhang",
            "Huazheng Wang",
            "Qingyun Wu"
        ],
        "date": "2024/03/02",
        "pdf": "http://arxiv.org/pdf/2403.04783",
        "abstract": "Despite extensive pre-training in moral alignment to prevent generating harmful information, large language models (LLMs) remain vulnerable to jailbreak attacks. In this paper, we propose AutoDefense, a multi-agent defense framework that filters harmful responses from LLMs. With the response-filtering mechanism, our framework is robust against different jailbreak attack prompts, and can be used to defend different victim models. AutoDefense assigns different roles to LLM agents and employs them to complete the defense task collaboratively. The division in tasks enhances the overall instruction-following of LLMs and enables the integration of other defense components as tools. With AutoDefense, small open-source LMs can serve as agents and defend larger models against jailbreak attacks. Our experiments show that AutoDefense can effectively defense against different jailbreak attacks, while maintaining the performance at normal user request. For example, we reduce the attack success rate on GPT-3.5 from 55.74% to 7.95% using LLaMA-2-13b with a 3-agent system. Our code and data are publicly available at https://github.com/XHMY/AutoDefense.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.04783"
    },
    "9a7a65a110f0d8fe677a69a1b75ed96b": {
        "title": "TRAD: Enhancing LLM Agents with Step-Wise Thought Retrieval and Aligned Decision",
        "authors": [
            "Ruiwen Zhou",
            "Yingxuan Yang",
            "Muning Wen",
            "Ying Wen",
            "Wenhao Wang",
            "Chunling Xi",
            "Guoqiang Xu",
            "Yong Yu",
            "Weinan Zhang"
        ],
        "date": "2024/03/10",
        "pdf": "http://arxiv.org/pdf/2403.06221",
        "abstract": "Numerous large language model (LLM) agents have been built for different tasks like web navigation and online shopping due to LLM&#39;s wide knowledge and text-understanding ability. Among these works, many of them utilize in-context examples to achieve generalization without the need for fine-tuning, while few of them have considered the problem of how to select and effectively utilize these examples. Recently, methods based on trajectory-level retrieval with task meta-data and using trajectories as in-context examples have been proposed to improve the agent&#39;s overall performance in some sequential decision making tasks. However, these methods can be problematic due to plausible examples retrieved without task-specific state transition dynamics and long input with plenty of irrelevant context. In this paper, we propose a novel framework (TRAD) to address these issues. TRAD first conducts Thought Retrieval, achieving step-level demonstration selection via thought matching, leading to more helpful demonstrations and less irrelevant input noise. Then, TRAD introduces Aligned Decision, complementing retrieved demonstration steps with their previous or subsequent steps, which enables tolerance for imperfect thought and provides a choice for balance between more context and less noise. Extensive experiments on ALFWorld and Mind2Web benchmarks show that TRAD not only outperforms state-of-the-art models but also effectively helps in reducing noise and promoting generalization. Furthermore, TRAD has been deployed in real-world scenarios of a global business insurance company and improves the success rate of robotic process automation.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.06221"
    },
    "1785c4df279fb0e9744e6557fb2831f4": {
        "title": "Transforming Competition into Collaboration: The Revolutionary Role of Multi-Agent Systems and Language Models in Modern Organizations",
        "authors": [
            "Carlos Jose Xavier Cruz"
        ],
        "date": "2024/03/12",
        "pdf": "http://arxiv.org/pdf/2403.07769",
        "abstract": "This article explores the dynamic influence of computational entities based on multi-agent systems theory (SMA) combined with large language models (LLM), which are characterized by their ability to simulate complex human interactions, as a possibility to revolutionize human user interaction from the use of specialized artificial agents to support everything from operational organizational processes to strategic decision making based on applied knowledge and human orchestration. Previous investigations reveal that there are limitations, particularly in the autonomous approach of artificial agents, especially when dealing with new challenges and pragmatic tasks such as inducing logical reasoning and problem solving. It is also considered that traditional techniques, such as the stimulation of chains of thoughts, require explicit human guidance. In our approach we employ agents developed from large language models (LLM), each with distinct prototyping that considers behavioral elements, driven by strategies that stimulate the generation of knowledge based on the use case proposed in the scenario (role-play) business, using a discussion approach between agents (guided conversation). We demonstrate the potential of developing agents useful for organizational strategies, based on multi-agent system theories (SMA) and innovative uses based on large language models (LLM based), offering a differentiated and adaptable experiment to different applications, complexities, domains, and capabilities from LLM.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.07769"
    },
    "2c4d31a4fb12b85568b6ece4d71cdc6f": {
        "title": "VideoAgent: Long-form Video Understanding with Large Language Model as Agent",
        "authors": [
            "Xiaohan Wang",
            "Yuhui Zhang",
            "Orr Zohar",
            "Serena Yeung-Levy"
        ],
        "date": "2024/03/15",
        "pdf": "http://arxiv.org/pdf/2403.10517",
        "abstract": "Long-form video understanding represents a significant challenge within computer vision, demanding a model capable of reasoning over long multi-modal sequences. Motivated by the human cognitive process for long-form video understanding, we emphasize interactive reasoning and planning over the ability to process lengthy visual inputs. We introduce a novel agent-based system, VideoAgent, that employs a large language model as a central agent to iteratively identify and compile crucial information to answer a question, with vision-language foundation models serving as tools to translate and retrieve visual information. Evaluated on the challenging EgoSchema and NExT-QA benchmarks, VideoAgent achieves 54.1% and 71.3% zero-shot accuracy with only 8.4 and 8.2 frames used on average. These results demonstrate superior effectiveness and efficiency of our method over the current state-of-the-art methods, highlighting the potential of agent-based approaches in advancing long-form video understanding.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.10517"
    },
    "ebcd928048d3695d60276a8bcaa3c2d7": {
        "title": "How Far Are We on the Decision-Making of LLMs? Evaluating LLMs&#39; Gaming Ability in Multi-Agent Environments",
        "authors": [
            "Jen-tse Huang",
            "Eric John Li",
            "Man Ho Lam",
            "Tian Liang",
            "Wenxuan Wang",
            "Youliang Yuan",
            "Wenxiang Jiao",
            "Xing Wang",
            "Zhaopeng Tu",
            "Michael R. Lyu"
        ],
        "date": "2024/03/18",
        "pdf": "http://arxiv.org/pdf/2403.11807",
        "abstract": "Decision-making is a complex process requiring diverse abilities, making it an excellent framework for evaluating Large Language Models (LLMs). Researchers have examined LLMs&#39; decision-making through the lens of Game Theory. However, existing evaluation mainly focus on two-player scenarios where an LLM competes against another. Additionally, previous benchmarks suffer from test set leakage due to their static design. We introduce GAMA($\\gamma$)-Bench, a new framework for evaluating LLMs&#39; Gaming Ability in Multi-Agent environments. It includes eight classical game theory scenarios and a dynamic scoring scheme specially designed to quantitatively assess LLMs&#39; performance. $\\gamma$-Bench allows flexible game settings and adapts the scoring system to different game parameters, enabling comprehensive evaluation of robustness, generalizability, and strategies for improvement. Our results indicate that GPT-3.5 demonstrates strong robustness but limited generalizability, which can be enhanced using methods like Chain-of-Thought. We also evaluate 13 LLMs from 6 model families, including GPT-3.5, GPT-4, Gemini, LLaMA-3.1, Mixtral, and Qwen-2. Gemini-1.5-Pro outperforms others, scoring of $69.8$ out of $100$, followed by LLaMA-3.1-70B ($65.9$) and Mixtral-8x22B ($62.4$). Our code and experimental results are publicly available at https://github.com/CUHK-ARISE/GAMABench.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.11807"
    },
    "c136f0b43c06cced12b5f5dd89b15afb": {
        "title": "Tur[k]ingBench: A Challenge Benchmark for Web Agents",
        "authors": [
            "Kevin Xu",
            "Yeganeh Kordi",
            "Tanay Nayak",
            "Ado Asija",
            "Yizhong Wang",
            "Kate Sanders",
            "Adam Byerly",
            "Jingyu Zhang",
            "Benjamin Van Durme",
            "Daniel Khashabi"
        ],
        "date": "2024/03/18",
        "pdf": "http://arxiv.org/pdf/2403.11905",
        "abstract": "Can advanced multi-modal models effectively tackle complex web-based tasks? Such tasks are often found on crowdsourcing platforms, where crowdworkers engage in challenging micro-tasks within web-based environments. Building on this idea, we present TurkingBench, a benchmark consisting of tasks presented as web pages with textual instructions and multi-modal contexts. Unlike previous approaches that rely on artificially synthesized web pages, our benchmark uses natural HTML pages originally designed for crowdsourcing workers to perform various annotation tasks. Each task&#39;s HTML instructions are instantiated with different values derived from crowdsourcing tasks, creating diverse instances. This benchmark includes 32.2K instances spread across 158 tasks. To support the evaluation of TurkingBench, we have developed a framework that links chatbot responses to actions on web pages (e.g., modifying a text box, selecting a radio button). We assess the performance of cutting-edge private and open-source models, including language-only and vision-language models (such as GPT4 and InternVL), on this benchmark. Our results show that while these models outperform random chance, there is still significant room for improvement. We hope that this benchmark will drive progress in the evaluation and development of web-based agents.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.11905"
    },
    "693f00f098fa0521c4e2a8694f71b09e": {
        "title": "Embodied LLM Agents Learn to Cooperate in Organized Teams",
        "authors": [
            "Xudong Guo",
            "Kaixuan Huang",
            "Jiale Liu",
            "Wenhui Fan",
            "Natalia VÃ©lez",
            "Qingyun Wu",
            "Huazheng Wang",
            "Thomas L. Griffiths",
            "Mengdi Wang"
        ],
        "date": "2024/03/19",
        "pdf": "http://arxiv.org/pdf/2403.12482",
        "abstract": "Large Language Models (LLMs) have emerged as integral tools for reasoning, planning, and decision-making, drawing upon their extensive world knowledge and proficiency in language-related tasks. LLMs thus hold tremendous potential for natural language interaction within multi-agent systems to foster cooperation. However, LLM agents tend to over-report and comply with any instruction, which may result in information redundancy and confusion in multi-agent cooperation. Inspired by human organizations, this paper introduces a framework that imposes prompt-based organization structures on LLM agents to mitigate these problems. Through a series of experiments with embodied LLM agents and human-agent collaboration, our results highlight the impact of designated leadership on team efficiency, shedding light on the leadership qualities displayed by LLM agents and their spontaneous cooperative behaviors. Further, we harness the potential of LLMs to propose enhanced organizational prompts, via a Criticize-Reflect process, resulting in novel organization structures that reduce communication costs and enhance team efficiency.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.12482"
    },
    "0a86cfd4f6ddb5b35652e271d6e72f94": {
        "title": "AgentGroupChat: An Interactive Group Chat Simulacra For Better Eliciting Emergent Behavior",
        "authors": [
            "Zhouhong Gu",
            "Xiaoxuan Zhu",
            "Haoran Guo",
            "Lin Zhang",
            "Yin Cai",
            "Hao Shen",
            "Jiangjie Chen",
            "Zheyu Ye",
            "Yifei Dai",
            "Yan Gao",
            "Yao Hu",
            "Hongwei Feng",
            "Yanghua Xiao"
        ],
        "date": "2024/03/20",
        "pdf": "http://arxiv.org/pdf/2403.13433",
        "abstract": "Language significantly influences the formation and evolution of Human emergent behavior, which is crucial in understanding collective intelligence within human societies. Considering that the study of how language affects human behavior needs to put it into the dynamic scenarios in which it is used, we introduce AgentGroupChat in this paper, a simulation that delves into the complex role of language in shaping collective behavior through interactive debate scenarios. Central to this simulation are characters engaging in dynamic conversation interactions. To enable simulation, we introduce the Verbal Strategist Agent, utilizing large language models to enhance interaction strategies by incorporating elements of persona and action. We set four narrative scenarios based on AgentGroupChat to demonstrate the simulation&#39;s capacity to mimic complex language use in group dynamics. Evaluations focus on aligning agent behaviors with human expectations and the emergence of collective behaviors within the simulation. Results reveal that emergent behaviors materialize from a confluence of factors: a conducive environment for extensive information exchange, characters with diverse traits, high linguistic comprehension, and strategic adaptability. During discussions on ``the impact of AI on humanity&#39;&#39; in AgentGroupChat simulation, philosophers commonly agreed that ``AI could enhance societal welfare with judicious limitations&#39;&#39; and even come to a conclusion that ``the essence of true intelligence encompasses understanding the necessity to constrain self abilities&#39;&#39;. Additionally, in the competitive domain of casting for primary roles in films in AgentGroupChat, certain actors were ready to reduce their remuneration or accept lesser roles, motivated by their deep-seated desire to contribute to the project.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.13433"
    },
    "cc29e2a1416d7c71fb4302fb8cca7374": {
        "title": "Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents",
        "authors": [
            "Yifan Song",
            "Da Yin",
            "Xiang Yue",
            "Jie Huang",
            "Sujian Li",
            "Bill Yuchen Lin"
        ],
        "date": "2024/03/04",
        "pdf": "http://arxiv.org/pdf/2403.02502",
        "abstract": "Large Language Models (LLMs) have become integral components in various autonomous agent systems. In this study, we present an exploration-based trajectory optimization approach, referred to as ETO. This learning method is designed to enhance the performance of open LLM agents. Contrary to previous studies that exclusively train on successful expert trajectories, our method allows agents to learn from their exploration failures. This leads to improved performance through an iterative optimization framework. During the exploration phase, the agent interacts with the environment while completing given tasks, gathering failure trajectories to create contrastive trajectory pairs. In the subsequent training phase, the agent utilizes these trajectory preference pairs to update its policy using contrastive learning methods like DPO. This iterative cycle of exploration and training fosters continued improvement in the agents. Our experiments on three complex tasks demonstrate that ETO consistently surpasses baseline performance by a large margin. Furthermore, an examination of task-solving efficiency and potential in scenarios lacking expert trajectory underscores the effectiveness of our approach.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.02502"
    },
    "2dc81cefe824ff47859daa8c4433ebb7": {
        "title": "InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents",
        "authors": [
            "Qiusi Zhan",
            "Zhixiang Liang",
            "Zifan Ying",
            "Daniel Kang"
        ],
        "date": "2024/03/05",
        "pdf": "http://arxiv.org/pdf/2403.02691",
        "abstract": "Recent work has embodied LLMs as agents, allowing them to access tools, perform actions, and interact with external content (e.g., emails or websites). However, external content introduces the risk of indirect prompt injection (IPI) attacks, where malicious instructions are embedded within the content processed by LLMs, aiming to manipulate these agents into executing detrimental actions against users. Given the potentially severe consequences of such attacks, establishing benchmarks to assess and mitigate these risks is imperative. In this work, we introduce InjecAgent, a benchmark designed to assess the vulnerability of tool-integrated LLM agents to IPI attacks. InjecAgent comprises 1,054 test cases covering 17 different user tools and 62 attacker tools. We categorize attack intentions into two primary types: direct harm to users and exfiltration of private data. We evaluate 30 different LLM agents and show that agents are vulnerable to IPI attacks, with ReAct-prompted GPT-4 vulnerable to attacks 24% of the time. Further investigation into an enhanced setting, where the attacker instructions are reinforced with a hacking prompt, shows additional increases in success rates, nearly doubling the attack success rate on the ReAct-prompted GPT-4. Our findings raise questions about the widespread deployment of LLM Agents. Our benchmark is available at https://github.com/uiuc-kang-lab/InjecAgent.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ],
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.02691"
    },
    "0f7cdc7644f6cc8b301e0d841297c9a4": {
        "title": "Android in the Zoo: Chain-of-Action-Thought for GUI Agents",
        "authors": [
            "Jiwen Zhang",
            "Jihao Wu",
            "Yihua Teng",
            "Minghui Liao",
            "Nuo Xu",
            "Xiao Xiao",
            "Zhongyu Wei",
            "Duyu Tang"
        ],
        "date": "2024/03/05",
        "pdf": "http://arxiv.org/pdf/2403.02713",
        "abstract": "Large language model (LLM) leads to a surge of autonomous GUI agents for smartphone, which completes a task triggered by natural language through predicting a sequence of actions of API. Even though the task highly relies on past actions and visual observations, existing studies typically consider little semantic information carried out by intermediate screenshots and screen operations. To address this, this work presents Chain-of-Action-Thought (dubbed CoAT), which takes the description of the previous actions, the current screen, and more importantly the action thinking of what actions should be performed and the outcomes led by the chosen action. We demonstrate that, in a zero-shot setting upon three off-the-shelf LMMs, CoAT significantly improves the action prediction compared to previous proposed context modeling. To further facilitate the research in this line, we construct a dataset Android-In-The-Zoo (AitZ), which contains 18,643 screen-action pairs together with chain-of-action-thought annotations. Experiments show that fine-tuning a 1B model (i.e. AUTO-UI-base) on our AitZ dataset achieves on-par performance with CogAgent-Chat-18B.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.02713"
    },
    "94ad4073c700730f6fe1185d85688377": {
        "title": "AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation",
        "authors": [
            "Zhitao He",
            "Pengfei Cao",
            "Chenhao Wang",
            "Zhuoran Jin",
            "Yubo Chen",
            "Jiexin Xu",
            "Huaijun Li",
            "Xiaojian Jiang",
            "Kang Liu",
            "Jun Zhao"
        ],
        "date": "2024/03/05",
        "pdf": "http://arxiv.org/pdf/2403.02959",
        "abstract": "With the development of deep learning, natural language processing technology has effectively improved the efficiency of various aspects of the traditional judicial industry. However, most current efforts focus on tasks within individual judicial stages, making it difficult to handle complex tasks that span multiple stages. As the autonomous agents powered by large language models are becoming increasingly smart and able to make complex decisions in real-world settings, offering new insights for judicial intelligence. In this paper, (1) we propose a novel multi-agent framework, AgentsCourt, for judicial decision-making. Our framework follows the classic court trial process, consisting of court debate simulation, legal resources retrieval and decision-making refinement to simulate the decision-making of judge. (2) we introduce SimuCourt, a judicial benchmark that encompasses 420 Chinese judgment documents, spanning the three most common types of judicial cases. Furthermore, to support this task, we construct a large-scale legal knowledge base, Legal-KB, with multi-resource legal knowledge. (3) Extensive experiments show that our framework outperforms the existing advanced methods in various aspects, especially in generating legal articles, where our model achieves significant improvements of 8.6% and 9.1% F1 score in the first and second instance settings, respectively.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "RAG"
            ],
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.02959"
    },
    "1d7449def73d3ffa6c8306de65e4a7f7": {
        "title": "KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents",
        "authors": [
            "Yuqi Zhu",
            "Shuofei Qiao",
            "Yixin Ou",
            "Shumin Deng",
            "Ningyu Zhang",
            "Shiwei Lyu",
            "Yue Shen",
            "Lei Liang",
            "Jinjie Gu",
            "Huajun Chen"
        ],
        "date": "2024/03/05",
        "pdf": "http://arxiv.org/pdf/2403.03101",
        "abstract": "Large Language Models (LLMs) have demonstrated great potential in complex reasoning tasks, yet they fall short when tackling more sophisticated challenges, especially when interacting with environments through generating executable actions. This inadequacy primarily stems from the lack of built-in action knowledge in language agents, which fails to effectively guide the planning trajectories during task solving and results in planning hallucination. To address this issue, we introduce KnowAgent, a novel approach designed to enhance the planning capabilities of LLMs by incorporating explicit action knowledge. Specifically, KnowAgent employs an action knowledge base and a knowledgeable self-learning strategy to constrain the action path during planning, enabling more reasonable trajectory synthesis, and thereby enhancing the planning performance of language agents. Experimental results on HotpotQA and ALFWorld based on various backbone models demonstrate that KnowAgent can achieve comparable or superior performance to existing baselines. Further analysis indicates the effectiveness of KnowAgent in terms of planning hallucinations mitigation. Code is available in https://github.com/zjunlp/KnowAgent.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.03101"
    },
    "d1805f7178a10d4395c1ade7d6ab6fe2": {
        "title": "Language Guided Exploration for RL Agents in Text Environments",
        "authors": [
            "Hitesh Golchha",
            "Sahil Yerawar",
            "Dhruvesh Patel",
            "Soham Dan",
            "Keerthiram Murugesan"
        ],
        "date": "2024/03/05",
        "pdf": "http://arxiv.org/pdf/2403.03141",
        "abstract": "Real-world sequential decision making is characterized by sparse rewards and large decision spaces, posing significant difficulty for experiential learning systems like $\\textit{tabula rasa}$ reinforcement learning (RL) agents. Large Language Models (LLMs), with a wealth of world knowledge, can help RL agents learn quickly and adapt to distribution shifts. In this work, we introduce Language Guided Exploration (LGE) framework, which uses a pre-trained language model (called GUIDE ) to provide decision-level guidance to an RL agent (called EXPLORER). We observe that on ScienceWorld (Wang et al.,2022), a challenging text environment, LGE outperforms vanilla RL agents significantly and also outperforms other sophisticated methods like Behaviour Cloning and Text Decision Transformer.",
        "code": "",
        "category": [
            [
                "Training",
                "RL"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.03141"
    },
    "85a3a98c4b9cadc46bc5c25eb3065638": {
        "title": "Promising and worth-to-try future directions for advancing state-of-the-art surrogates methods of agent-based models in social and health computational sciences",
        "authors": [
            "Atiyah Elsheikh"
        ],
        "date": "2024/03/07",
        "pdf": "http://arxiv.org/pdf/2403.04417",
        "abstract": "The execution and runtime performance of model-based analysis tools for realistic large-scale ABMs (Agent-Based Models) can be excessively long. This due to the computational demand exponentially proportional to the model size (e.g. Population size) and the number of model parameters. Even the runtime of a single simulation of a realistic ABM may demand huge computational resources when attempting to employ realistic population size. The main aim of this ad-hoc brief report is to highlight some of surrogate models that were adequate and computationally less demanding for nonlinear dynamical models in various modeling application areas.To the author knowledge, these methods have been not, at least extensively, employed for ABMs within the field of (SHCS) Social Health Computational Sciences, yet. Thus, they might be, but not necessarily, useful in progressing state of the art for establishing surrogate models for ABMs in the field of SHCS.",
        "code": "",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2403.04417"
    },
    "e23ceb4b035965c2dad3406c7761edba": {
        "title": "ChatASU: Evoking LLM&#39;s Reflexion to Truly Understand Aspect Sentiment in Dialogues",
        "authors": [
            "Yiding Liu",
            "Jingjing Wang",
            "Jiamin Luo",
            "Tao Zeng",
            "Guodong Zhou"
        ],
        "date": "2024/03/08",
        "pdf": "http://arxiv.org/pdf/2403.05326",
        "abstract": "Aspect Sentiment Understanding (ASU) in interactive scenarios (e.g., Question-Answering and Dialogue) has attracted ever-more interest in recent years and achieved important progresses. However, existing studies on interactive ASU largely ignore the coreference issue for opinion targets (i.e., aspects), while this phenomenon is ubiquitous in interactive scenarios especially dialogues, limiting the ASU performance. Recently, large language models (LLMs) shows the powerful ability to integrate various NLP tasks with the chat paradigm. In this way, this paper proposes a new Chat-based Aspect Sentiment Understanding (ChatASU) task, aiming to explore LLMs&#39; ability in understanding aspect sentiments in dialogue scenarios. Particularly, this ChatASU task introduces a sub-task, i.e., Aspect Chain Reasoning (ACR) task, to address the aspect coreference issue. On this basis, we propose a Trusted Self-reflexion Approach (TSA) with ChatGLM as backbone to ChatASU. Specifically, this TSA treats the ACR task as an auxiliary task to boost the performance of the primary ASU task, and further integrates trusted learning into reflexion mechanisms to alleviate the LLMs-intrinsic factual hallucination problem in TSA. Furthermore, a high-quality ChatASU dataset is annotated to evaluate TSA, and extensive experiments show that our proposed TSA can significantly outperform several state-of-the-art baselines, justifying the effectiveness of TSA to ChatASU and the importance of considering the coreference and hallucination issues in ChatASU.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.05326"
    },
    "bf1e2f319094afd2377286a6c0cc74ce": {
        "title": "Strength Lies in Differences! Improving Strategy Planning for Non-collaborative Dialogues via Diversified User Simulation",
        "authors": [
            "Tong Zhang",
            "Chen Huang",
            "Yang Deng",
            "Hongru Liang",
            "Jia Liu",
            "Zujie Wen",
            "Wenqiang Lei",
            "Tat-Seng Chua"
        ],
        "date": "2024/03/11",
        "pdf": "http://arxiv.org/pdf/2403.06769",
        "abstract": "We investigate non-collaborative dialogue agents, which are expected to engage in strategic conversations with diverse users, for securing a mutual agreement that leans favorably towards the system&#39;s objectives. This poses two main challenges for existing dialogue agents: 1) The inability to integrate user-specific characteristics into the strategic planning, and 2) The difficulty of training strategic planners that can be generalized to diverse users. To address these challenges, we propose Trip to enhance the capability in tailored strategic planning, incorporating a user-aware strategic planning module and a population-based training paradigm. Through experiments on benchmark non-collaborative dialogue tasks, we demonstrate the effectiveness of Trip in catering to diverse users.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.06769"
    },
    "46fceb681f72cba835bf36132b086d85": {
        "title": "AutoGuide: Automated Generation and Selection of Context-Aware Guidelines for Large Language Model Agents",
        "authors": [
            "Yao Fu",
            "Dong-Ki Kim",
            "Jaekyeom Kim",
            "Sungryull Sohn",
            "Lajanugen Logeswaran",
            "Kyunghoon Bae",
            "Honglak Lee"
        ],
        "date": "2024/03/13",
        "pdf": "http://arxiv.org/pdf/2403.08978",
        "abstract": "Recent advances in large language models (LLMs) have empowered AI agents capable of performing various sequential decision-making tasks. However, effectively guiding LLMs to perform well in unfamiliar domains like web navigation, where they lack sufficient knowledge, has proven to be difficult with the demonstration-based in-context learning paradigm. In this paper, we introduce a novel framework, called AutoGuide, which addresses this limitation by automatically generating context-aware guidelines from offline experiences. Importantly, each context-aware guideline is expressed in concise natural language and follows a conditional structure, clearly describing the context where it is applicable. As a result, our guidelines facilitate the provision of relevant knowledge for the agent&#39;s current decision-making process, overcoming the limitations of the conventional demonstration-based learning paradigm. Our evaluation demonstrates that AutoGuide significantly outperforms competitive baselines in complex benchmark domains, including real-world web navigation.",
        "code": "",
        "category": [
            [
                "Automation",
                "Workflow"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.08978"
    },
    "1bed4874c7bbe62254c363f22586f90e": {
        "title": "Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation",
        "authors": [
            "Se-eun Yoon",
            "Zhankui He",
            "Jessica Maria Echterhoff",
            "Julian McAuley"
        ],
        "date": "2024/03/13",
        "pdf": "http://arxiv.org/pdf/2403.09738",
        "abstract": "Synthetic users are cost-effective proxies for real users in the evaluation of conversational recommender systems. Large language models show promise in simulating human-like behavior, raising the question of their ability to represent a diverse population of users. We introduce a new protocol to measure the degree to which language models can accurately emulate human behavior in conversational recommendation. This protocol is comprised of five tasks, each designed to evaluate a key property that a synthetic user should exhibit: choosing which items to talk about, expressing binary preferences, expressing open-ended preferences, requesting recommendations, and giving feedback. Through evaluation of baseline simulators, we demonstrate these tasks effectively reveal deviations of language models from human behavior, and offer insights on how to reduce the deviations with model selection and prompting strategies.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.09738"
    },
    "1aadeba9f62724a15bc508b6fd42e956": {
        "title": "Improving Dialogue Agents by Decomposing One Global Explicit Annotation with Local Implicit Multimodal Feedback",
        "authors": [
            "Dong Won Lee",
            "Hae Won Park",
            "Yoon Kim",
            "Cynthia Breazeal",
            "Louis-Philippe Morency"
        ],
        "date": "2024/03/17",
        "pdf": "http://arxiv.org/pdf/2403.11330",
        "abstract": "We describe an approach for aligning an LLM-based dialogue agent based on global (i.e., dialogue-level) rewards, while also taking into account naturally-occurring multimodal signals. At a high level, our approach (dubbed GELI) learns a local, turn-level reward model by decomposing the human-provided Global Explicit (GE) session-level reward, using Local Implicit (LI) multimodal reward signals to crossmodally shape the reward decomposition step. This decomposed reward model is then used as part of the standard RHLF pipeline improve an LLM-based dialog agent. We run quantitative and qualitative human studies to evaluate the performance of our GELI approach, and find that it shows consistent improvements across various conversational metrics compared to baseline methods.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.11330"
    },
    "ef4ee63fa07c8149752731e8aeed308a": {
        "title": "QueryAgent: A Reliable and Efficient Reasoning Framework with Environmental Feedback-based Self-Correction",
        "authors": [
            "Xiang Huang",
            "Sitao Cheng",
            "Shanshan Huang",
            "Jiayu Shen",
            "Yong Xu",
            "Chaoyun Zhang",
            "Yuzhong Qu"
        ],
        "date": "2024/03/18",
        "pdf": "http://arxiv.org/pdf/2403.11886",
        "abstract": "Employing Large Language Models (LLMs) for semantic parsing has achieved remarkable success. However, we find existing methods fall short in terms of reliability and efficiency when hallucinations are encountered. In this paper, we address these challenges with a framework called QueryAgent, which solves a question step-by-step and performs step-wise self-correction. We introduce an environmental feedback-based self-correction method called ERASER. Unlike traditional approaches, ERASER leverages rich environmental feedback in the intermediate steps to perform selective and differentiated self-correction only when necessary. Experimental results demonstrate that QueryAgent notably outperforms all previous few-shot methods using only one example on GrailQA and GraphQ by 7.0 and 15.0 F1. Moreover, our approach exhibits superiority in terms of efficiency, including runtime, query overhead, and API invocation costs. By leveraging ERASER, we further improve another baseline (i.e., AgentBench) by approximately 10 points, revealing the strong transferability of our approach.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.11886"
    },
    "f6008fb8d9c10f96f8bcc4c46291d9f5": {
        "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents",
        "authors": [
            "Abhay Zala",
            "Jaemin Cho",
            "Han Lin",
            "Jaehong Yoon",
            "Mohit Bansal"
        ],
        "date": "2024/03/18",
        "pdf": "http://arxiv.org/pdf/2403.12014",
        "abstract": "Recent SOTA approaches for embodied learning via interaction directly employ large language models (LLMs) as agents to determine the next steps in an environment. Due to their world knowledge and reasoning capabilities, LLM agents achieve stronger performance than previous smaller agents based on reinforcement learning (RL); however, frequently calling LLMs is slow and expensive. Instead of directly employing LLMs as agents, can we use LLMs&#39; reasoning capabilities to adaptively create training environments to help smaller RL agents learn useful skills that they are weak at? We propose EnvGen, a novel framework to address this question. We first prompt an LLM to generate training environments by giving it the task description and simulator objectives that the agents should learn and then asking it to generate a set of environment configurations (e.g., different terrains, items initially given to agents, etc.). Next, we train a small RL agent in a mixture of the original and LLM-generated environments. Then, we enable the LLM to continuously adapt the generated environments to progressively improve the skills that the agent is weak at, by providing feedback to the LLM in the form of the agent&#39;s performance. We demonstrate the usefulness of EnvGen with comprehensive experiments in Crafter and Heist environments. We find that a small RL agent trained with EnvGen can outperform SOTA methods, including a GPT-4 agent, and learns long-horizon tasks significantly faster. We also show that using an LLM to adapt environments dynamically outperforms curriculum learning approaches and how the environments are adapted to help improve RL agents&#39; weaker skills over time. Additionally, EnvGen is substantially more efficient as it only uses a small number of LLM calls (e.g., 4 in total), whereas LLM agents require thousands of calls. Lastly, we present detailed ablation studies for EnvGen design choices.",
        "code": "",
        "category": [
            [
                "Others",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2403.12014"
    },
    "6323bb1cd980022ec0d082da0b6a35e3": {
        "title": "Characteristic AI Agents via Large Language Models",
        "authors": [
            "Xi Wang",
            "Hongliang Dai",
            "Shen Gao",
            "Piji Li"
        ],
        "date": "2024/03/19",
        "pdf": "http://arxiv.org/pdf/2403.12368",
        "abstract": "The advancement of Large Language Models (LLMs) has led to significant enhancements in the performance of chatbot systems. Many researchers have dedicated their efforts to the development of bringing characteristics to chatbots. While there have been commercial products for developing role-driven chatbots using LLMs, it is worth noting that academic research in this area remains relatively scarce. Our research focuses on investigating the performance of LLMs in constructing Characteristic AI Agents by simulating real-life individuals across different settings. Current investigations have primarily focused on act on roles with simple profiles. In response to this research gap, we create a benchmark for the characteristic AI agents task, including dataset, techniques, and evaluation metrics. A dataset called ``Character100&#39;&#39; is built for this benchmark, comprising the most-visited people on Wikipedia for language models to role-play. With the constructed dataset, we conduct comprehensive assessment of LLMs across various settings. In addition, we devise a set of automatic metrics for quantitative performance evaluation. The experimental results underscore the potential directions for further improvement in the capabilities of LLMs in constructing characteristic AI agents. The benchmark is available at https://github.com/nuaa-nlp/Character100.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.12368"
    },
    "ea6393973de4fe2d29ba00e20f748441": {
        "title": "Agent-FLAN: Designing Data and Methods of Effective Agent Tuning for Large Language Models",
        "authors": [
            "Zehui Chen",
            "Kuikun Liu",
            "Qiuchen Wang",
            "Wenwei Zhang",
            "Jiangning Liu",
            "Dahua Lin",
            "Kai Chen",
            "Feng Zhao"
        ],
        "date": "2024/03/19",
        "pdf": "http://arxiv.org/pdf/2403.12881",
        "abstract": "Open-sourced Large Language Models (LLMs) have achieved great success in various NLP tasks, however, they are still far inferior to API-based models when acting as agents. How to integrate agent ability into general LLMs becomes a crucial and urgent problem. This paper first delivers three key observations: (1) the current agent training corpus is entangled with both formats following and agent reasoning, which significantly shifts from the distribution of its pre-training data; (2) LLMs exhibit different learning speeds on the capabilities required by agent tasks; and (3) current approaches have side-effects when improving agent abilities by introducing hallucinations. Based on the above findings, we propose Agent-FLAN to effectively Fine-tune LANguage models for Agents. Through careful decomposition and redesign of the training corpus, Agent-FLAN enables Llama2-7B to outperform prior best works by 3.5\\% across various agent evaluation datasets. With comprehensively constructed negative samples, Agent-FLAN greatly alleviates the hallucination issues based on our established evaluation benchmark. Besides, it consistently improves the agent capability of LLMs when scaling model sizes while slightly enhancing the general capability of LLMs. The code will be available at https://github.com/InternLM/Agent-FLAN.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Dataset"
            ],
            [
                "Training",
                "Fine tuning"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.12881"
    },
    "1cc44ebd645024966f49e3a5a660eae1": {
        "title": "SocialBench: Sociality Evaluation of Role-Playing Conversational Agents",
        "authors": [
            "Hongzhan Chen",
            "Hehong Chen",
            "Ming Yan",
            "Wenshen Xu",
            "Xing Gao",
            "Weizhou Shen",
            "Xiaojun Quan",
            "Chenliang Li",
            "Ji Zhang",
            "Fei Huang",
            "Jingren Zhou"
        ],
        "date": "2024/03/20",
        "pdf": "http://arxiv.org/pdf/2403.13679",
        "abstract": "Large language models (LLMs) have advanced the development of various AI conversational agents, including role-playing conversational agents that mimic diverse characters and human behaviors. While prior research has predominantly focused on enhancing the conversational capability, role-specific knowledge, and stylistic attributes of these agents, there has been a noticeable gap in assessing their social intelligence. In this paper, we introduce SocialBench, the first benchmark designed to systematically evaluate the sociality of role-playing conversational agents at both individual and group levels of social interactions. The benchmark is constructed from a variety of sources and covers a wide range of 500 characters and over 6,000 question prompts and 30,800 multi-turn role-playing utterances. We conduct comprehensive evaluations on this benchmark using mainstream open-source and closed-source LLMs. We find that agents excelling in individual level does not imply their proficiency in group level. Moreover, the behavior of individuals may drift as a result of the influence exerted by other agents within the group. Experimental results on SocialBench confirm its significance as a testbed for assessing the social interaction of role-playing conversational agents. The benchmark is publicly accessible at https://github.com/X-PLUG/SocialBench.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.13679"
    },
    "d254cf4f173176c2999c0a1d87ca1ac8": {
        "title": "Sharing the Cost of Success: A Game for Evaluating and Learning Collaborative Multi-Agent Instruction Giving and Following Policies",
        "authors": [
            "Philipp Sadler",
            "Sherzod Hakimov",
            "David Schlangen"
        ],
        "date": "2024/03/26",
        "pdf": "http://arxiv.org/pdf/2403.17497",
        "abstract": "In collaborative goal-oriented settings, the participants are not only interested in achieving a successful outcome, but do also implicitly negotiate the effort they put into the interaction (by adapting to each other). In this work, we propose a challenging interactive reference game that requires two players to coordinate on vision and language observations. The learning signal in this game is a score (given after playing) that takes into account the achieved goal and the players&#39; assumed efforts during the interaction. We show that a standard Proximal Policy Optimization (PPO) setup achieves a high success rate when bootstrapped with heuristic partner behaviors that implement insights from the analysis of human-human interactions. And we find that a pairing of neural partners indeed reduces the measured joint effort when playing together repeatedly. However, we observe that in comparison to a reasonable heuristic pairing there is still room for improvement -- which invites further research in the direction of cost-sharing in collaborative interactions.",
        "code": "https://github.com/clp-research/cost-sharing-reference-game",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.17497"
    },
    "85fd90755f5739a7fb483412602e97e6": {
        "title": "CACA Agent: Capability Collaboration based AI Agent",
        "authors": [
            "Peng Xu",
            "Haoran Wang",
            "Chuang Wang",
            "Xu Liu"
        ],
        "date": "2024/03/22",
        "pdf": "http://arxiv.org/pdf/2403.15137",
        "abstract": "As AI Agents based on Large Language Models (LLMs) have shown potential in practical applications across various fields, how to quickly deploy an AI agent and how to conveniently expand the application scenario of AI agents has become a challenge. Previous studies mainly focused on implementing all the reasoning capabilities of AI agents within a single LLM, which often makes the model more complex and also reduces the extensibility of AI agent functionality. In this paper, we propose CACA Agent (Capability Collaboration based AI Agent), using an open architecture inspired by service computing. CACA Agent integrates a set of collaborative capabilities to implement AI Agents, not only reducing the dependence on a single LLM, but also enhancing the extensibility of both the planning abilities and the tools available to AI agents. Utilizing the proposed system, we present a demo to illustrate the operation and the application scenario extension of CACA Agent.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.15137"
    },
    "6c7684079093a696f575560ed81b715f": {
        "title": "Multi-Agent VQA: Exploring Multi-Agent Foundation Models in Zero-Shot Visual Question Answering",
        "authors": [
            "Bowen Jiang",
            "Zhijun Zhuang",
            "Shreyas S. Shivakumar",
            "Dan Roth",
            "Camillo J. Taylor"
        ],
        "date": "2024/03/21",
        "pdf": "http://arxiv.org/pdf/2403.14783",
        "abstract": "This work explores the zero-shot capabilities of foundation models in Visual Question Answering (VQA) tasks. We propose an adaptive multi-agent system, named Multi-Agent VQA, to overcome the limitations of foundation models in object detection and counting by using specialized agents as tools. Unlike existing approaches, our study focuses on the system&#39;s performance without fine-tuning it on specific VQA datasets, making it more practical and robust in the open world. We present preliminary experimental results under zero-shot scenarios and highlight some failure cases, offering new directions for future research.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.14783"
    },
    "f8ff753c3aa2bb437a2e5380838bfef6": {
        "title": "ReAct Meets ActRe: When Language Agents Enjoy Training Data Autonomy",
        "authors": [
            "Zonghan Yang",
            "Peng Li",
            "Ming Yan",
            "Ji Zhang",
            "Fei Huang",
            "Yang Liu"
        ],
        "date": "2024/03/21",
        "pdf": "http://arxiv.org/pdf/2403.14589",
        "abstract": "Language agents have demonstrated autonomous decision-making abilities by reasoning with foundation models. Recently, efforts have been made to train language agents for performance improvement, with multi-step reasoning and action trajectories as the training data. However, collecting such trajectories still requires considerable human effort, by either artificial annotation or implementations of diverse prompting frameworks. In this work, we propose A$^3$T, a framework that enables the Autonomous Annotation of Agent Trajectories in the style of ReAct. The central role is an ActRe prompting agent, which explains the reason for an arbitrary action. When randomly sampling an external action, the ReAct-style agent could query the ActRe agent with the action to obtain its textual rationales. Novel trajectories are then synthesized by prepending the posterior reasoning from ActRe to the sampled action. In this way, the ReAct-style agent executes multiple trajectories for the failed tasks, and selects the successful ones to supplement its failed trajectory for contrastive self-training. Realized by policy gradient methods with binarized rewards, the contrastive self-training with accumulated trajectories facilitates a closed loop for multiple rounds of language agent self-improvement. We conduct experiments using QLoRA fine-tuning with the open-sourced Mistral-7B-Instruct-v0.2. In AlfWorld, the agent trained with A$^3$T obtains a 1-shot success rate of 96%, and 100% success with 4 iterative rounds. In WebShop, the 1-shot performance of the A$^3$T agent matches human average, and 4 rounds of iterative refinement lead to the performance approaching human experts. A$^3$T agents significantly outperform existing techniques, including prompting with GPT-4, advanced agent frameworks, and fully fine-tuned LLMs.",
        "code": "",
        "category": [
            [
                "Training",
                "Fine tuning"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.14589"
    },
    "b14f11857f2bd0666a823802ced632df": {
        "title": "Learn to Disguise: Avoid Refusal Responses in LLM&#39;s Defense via a Multi-agent Attacker-Disguiser Game",
        "authors": [
            "Qianqiao Xu",
            "Zhiliang Tian",
            "Hongyan Wu",
            "Zhen Huang",
            "Yiping Song",
            "Feng Liu",
            "Dongsheng Li"
        ],
        "date": "2024/04/03",
        "pdf": "http://arxiv.org/pdf/2404.02532",
        "abstract": "With the enhanced performance of large models on natural language processing tasks, potential moral and ethical issues of large models arise. There exist malicious attackers who induce large models to jailbreak and generate information containing illegal, privacy-invasive information through techniques such as prompt engineering. As a result, large models counter malicious attackers&#39; attacks using techniques such as safety alignment. However, the strong defense mechanism of the large model through rejection replies is easily identified by attackers and used to strengthen attackers&#39; capabilities. In this paper, we propose a multi-agent attacker-disguiser game approach to achieve a weak defense mechanism that allows the large model to both safely reply to the attacker and hide the defense intent. First, we construct a multi-agent framework to simulate attack and defense scenarios, playing different roles to be responsible for attack, disguise, safety evaluation, and disguise evaluation tasks. After that, we design attack and disguise game algorithms to optimize the game strategies of the attacker and the disguiser and use the curriculum learning process to strengthen the capabilities of the agents. The experiments verify that the method in this paper is more effective in strengthening the model&#39;s ability to disguise the defense intent compared with other methods. Moreover, our approach can adapt any black-box large model to assist the model in defense and does not suffer from model version iterations.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.02532"
    },
    "132f6a74ec7ec450c6106e9467b63208": {
        "title": "Self-Organized Agents: A LLM Multi-Agent Framework toward Ultra Large-Scale Code Generation and Optimization",
        "authors": [
            "Yoichi Ishibashi",
            "Yoshimasa Nishimura"
        ],
        "date": "2024/04/02",
        "pdf": "http://arxiv.org/pdf/2404.02183",
        "abstract": "Recent advancements in automatic code generation using large language model (LLM) agent have brought us closer to the future of automated software development. However, existing single-agent approaches face limitations in generating and improving large-scale, complex codebases due to constraints in context length. To tackle this challenge, we propose Self-Organized multi-Agent framework (SoA), a novel multi-agent framework that enables the scalable and efficient generation and optimization of large-scale code. In SoA, self-organized agents operate independently to generate and modify code components while seamlessly collaborating to construct the overall codebase. A key feature of our framework is the automatic multiplication of agents based on problem complexity, allowing for dynamic scalability. This enables the overall code volume to be increased indefinitely according to the number of agents, while the amount of code managed by each agent remains constant. We evaluate SoA on the HumanEval benchmark and demonstrate that, compared to a single-agent system, each agent in SoA handles significantly less code, yet the overall generated code is substantially greater. Moreover, SoA surpasses the powerful single-agent baseline by 5% in terms of Pass@1 accuracy.",
        "code": "",
        "category": [
            [
                "Application",
                "Software Engineering"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.02183"
    },
    "ab2ebbcc0da2f32564c4167a2306ff73": {
        "title": "CMAT: A Multi-Agent Collaboration Tuning Framework for Enhancing Small Language Models",
        "authors": [
            "Xuechen Liang",
            "Meiling Tao",
            "Yinghui Xia",
            "Tianyu Shi",
            "Jun Wang",
            "JingSong Yang"
        ],
        "date": "2024/04/02",
        "pdf": "http://arxiv.org/pdf/2404.01663",
        "abstract": "Open large language models (LLMs) have significantly advanced the field of natural language processing, showcasing impressive performance across various tasks.Despite the significant advancements in LLMs, their effective operation still relies heavily on human input to accurately guide the dialogue flow, with agent tuning being a crucial optimization technique that involves human adjustments to the model for better response to such guidance.Addressing this dependency, our work introduces the TinyAgent model, trained on a meticulously curated high-quality dataset. We also present the Collaborative Multi-Agent Tuning (CMAT) framework, an innovative system designed to augment language agent capabilities through adaptive weight updates based on environmental feedback. This framework fosters collaborative learning and real-time adaptation among multiple intelligent agents, enhancing their context-awareness and long-term memory. In this research, we propose a new communication agent framework that integrates multi-agent systems with environmental feedback mechanisms, offering a scalable method to explore cooperative behaviors. Notably, our TinyAgent-7B model exhibits performance on par with GPT-3.5, despite having fewer parameters, signifying a substantial improvement in the efficiency and effectiveness of LLMs.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Training",
                "Fine tuning"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.01663"
    },
    "0da1af4d68be428f423f0e488588bb54": {
        "title": "DiffAgent: Fast and Accurate Text-to-Image API Selection with Large Language Model",
        "authors": [
            "Lirui Zhao",
            "Yue Yang",
            "Kaipeng Zhang",
            "Wenqi Shao",
            "Yuxin Zhang",
            "Yu Qiao",
            "Ping Luo",
            "Rongrong Ji"
        ],
        "date": "2024/03/31",
        "pdf": "http://arxiv.org/pdf/2404.01342",
        "abstract": "Text-to-image (T2I) generative models have attracted significant attention and found extensive applications within and beyond academic research. For example, the Civitai community, a platform for T2I innovation, currently hosts an impressive array of 74,492 distinct models. However, this diversity presents a formidable challenge in selecting the most appropriate model and parameters, a process that typically requires numerous trials. Drawing inspiration from the tool usage research of large language models (LLMs), we introduce DiffAgent, an LLM agent designed to screen the accurate selection in seconds via API calls. DiffAgent leverages a novel two-stage training framework, SFTA, enabling it to accurately align T2I API responses with user input in accordance with human preferences. To train and evaluate DiffAgent&#39;s capabilities, we present DABench, a comprehensive dataset encompassing an extensive range of T2I APIs from the community. Our evaluations reveal that DiffAgent not only excels in identifying the appropriate T2I API but also underscores the effectiveness of the SFTA training framework. Codes are available at https://github.com/OpenGVLab/DiffAgent.",
        "code": "https://github.com/OpenGVLab/DiffAgent",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.01342"
    },
    "4a545d9e08ef7641444abce3a33444ee": {
        "title": "TraveLER: A Modular Multi-LMM Agent Framework for Video Question-Answering",
        "authors": [
            "Chuyi Shang",
            "Amos You",
            "Sanjay Subramanian",
            "Trevor Darrell",
            "Roei Herzig"
        ],
        "date": "2024/04/01",
        "pdf": "http://arxiv.org/pdf/2404.01476",
        "abstract": "Recently, image-based Large Multimodal Models (LMMs) have made significant progress in video question-answering (VideoQA) using a frame-wise approach by leveraging large-scale pretraining in a zero-shot manner. Nevertheless, these models need to be capable of finding relevant information, extracting it, and answering the question simultaneously. Currently, existing methods perform all of these steps in a single pass without being able to adapt if insufficient or incorrect information is collected. To overcome this, we introduce a modular multi-LMM agent framework based on several agents with different roles, instructed by a Planner agent that updates its instructions using shared feedback from the other agents. Specifically, we propose TraveLER, a method that can create a plan to &#34;Traverse&#34; through the video, ask questions about individual frames to &#34;Locate&#34; and store key information, and then &#34;Evaluate&#34; if there is enough information to answer the question. Finally, if there is not enough information, our method is able to &#34;Replan&#34; based on its collected knowledge. Through extensive experiments, we find that the proposed TraveLER approach improves performance on several VideoQA benchmarks without the need to fine-tune on specific datasets. Our code is available at https://github.com/traveler-framework/TraveLER.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.01476"
    },
    "13a2dcc1dde7c8d8aa2560b567b6a73b": {
        "title": "DataAgent: Evaluating Large Language Models&#39; Ability to Answer Zero-Shot, Natural Language Queries",
        "authors": [
            "Manit Mishra",
            "Abderrahman Braham",
            "Charles Marsom",
            "Bryan Chung",
            "Gavin Griffin",
            "Dakshesh Sidnerlikar",
            "Chatanya Sarin",
            "Arjun Rajaram"
        ],
        "date": "2024/03/29",
        "pdf": "http://arxiv.org/pdf/2404.00188",
        "abstract": "Conventional processes for analyzing datasets and extracting meaningful information are often time-consuming and laborious. Previous work has identified manual, repetitive coding and data collection as major obstacles that hinder data scientists from undertaking more nuanced labor and high-level projects. To combat this, we evaluated OpenAI&#39;s GPT-3.5 as a &#34;Language Data Scientist&#34; (LDS) that can extrapolate key findings, including correlations and basic information, from a given dataset. The model was tested on a diverse set of benchmark datasets to evaluate its performance across multiple standards, including data science code-generation based tasks involving libraries such as NumPy, Pandas, Scikit-Learn, and TensorFlow, and was broadly successful in correctly answering a given data science query related to the benchmark dataset. The LDS used various novel prompt engineering techniques to effectively answer a given question, including Chain-of-Thought reinforcement and SayCan prompt engineering. Our findings demonstrate great potential for leveraging Large Language Models for low-level, zero-shot data analysis.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.00188"
    },
    "f8ee0b1f0b3c9c1fea3d64bc0053aa66": {
        "title": "AutoWebGLM: A Large Language Model-based Web Navigating Agent",
        "authors": [
            "Hanyu Lai",
            "Xiao Liu",
            "Iat Long Iong",
            "Shuntian Yao",
            "Yuxuan Chen",
            "Pengbo Shen",
            "Hao Yu",
            "Hanchen Zhang",
            "Xiaohan Zhang",
            "Yuxiao Dong",
            "Jie Tang"
        ],
        "date": "2024/04/04",
        "pdf": "http://arxiv.org/pdf/2404.03648",
        "abstract": "Large language models (LLMs) have fueled many intelligent web agents, but most existing ones perform far from satisfying in real-world web navigation tasks due to three factors: (1) the complexity of HTML text data (2) versatility of actions on webpages, and (3) task difficulty due to the open-domain nature of the web. In light of these challenges, we develop the open AutoWebGLM based on ChatGLM3-6B. AutoWebGLM can serve as a powerful automated web navigation agent that outperform GPT-4. Inspired by human browsing patterns, we first design an HTML simplification algorithm to represent webpages with vital information preserved succinctly. We then employ a hybrid human-AI method to build web browsing data for curriculum training. Finally, we bootstrap the model by reinforcement learning and rejection sampling to further facilitate webpage comprehension, browser operations, and efficient task decomposition by itself. For comprehensive evaluation, we establish a bilingual benchmark -- AutoWebBench -- for real-world web navigation tasks. We evaluate AutoWebGLM across diverse web navigation benchmarks, demonstrating its potential to tackle challenging tasks in real environments. Related code, model, and data are released at \\url{https://github.com/THUDM/AutoWebGLM}.",
        "code": "https://github.com/THUDM/AutoWebGLM",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.03648"
    },
    "c5a6769c1c0badbeb24b45a8b9e4b1d9": {
        "title": "EASYTOOL: Enhancing LLM-based Agents with Concise Tool Instruction",
        "authors": [
            "Siyu Yuan",
            "Kaitao Song",
            "Jiangjie Chen",
            "Xu Tan",
            "Yongliang Shen",
            "Ren Kan",
            "Dongsheng Li",
            "Deqing Yang"
        ],
        "date": "2024/01/11",
        "pdf": "http://arxiv.org/pdf/2401.06201",
        "abstract": "To address intricate real-world tasks, there has been a rising interest in tool utilization in applications of large language models (LLMs). To develop LLM-based agents, it usually requires LLMs to understand many tool functions from different tool documentation. But these documentations could be diverse, redundant or incomplete, which immensely affects the capability of LLMs in using tools. To solve this, we introduce EASYTOOL, a framework transforming diverse and lengthy tool documentation into a unified and concise tool instruction for easier tool usage. EasyTool purifies essential information from extensive tool documentation of different sources, and elaborates a unified interface (i.e., tool instruction) to offer standardized tool descriptions and functionalities for LLM-based agents. Extensive experiments on multiple different tasks demonstrate that EasyTool can significantly reduce token consumption and improve the performance of tool utilization in real-world scenarios. Our code will be available at \\url{https://github.com/microsoft/JARVIS/} in the future.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2401.06201"
    },
    "d6c196649bda278dff206fe125f58a0a": {
        "title": "MATEval: A Multi-Agent Discussion Framework for Advancing Open-Ended Text Evaluation",
        "authors": [
            "Yu Li",
            "Shenyu Zhang",
            "Rui Wu",
            "Xiutian Huang",
            "Yongrui Chen",
            "Wenhao Xu",
            "Guilin Qi",
            "Dehai Min"
        ],
        "date": "2024/03/28",
        "pdf": "http://arxiv.org/pdf/2403.19305",
        "abstract": "Recent advancements in generative Large Language Models(LLMs) have been remarkable, however, the quality of the text generated by these models often reveals persistent issues. Evaluating the quality of text generated by these models, especially in open-ended text, has consistently presented a significant challenge. Addressing this, recent work has explored the possibility of using LLMs as evaluators. While using a single LLM as an evaluation agent shows potential, it is filled with significant uncertainty and instability. To address these issues, we propose the MATEval: A &#34;Multi-Agent Text Evaluation framework&#34; where all agents are played by LLMs like GPT-4. The MATEval framework emulates human collaborative discussion methods, integrating multiple agents&#39; interactions to evaluate open-ended text. Our framework incorporates self-reflection and Chain-of-Thought (CoT) strategies, along with feedback mechanisms, enhancing the depth and breadth of the evaluation process and guiding discussions towards consensus, while the framework generates comprehensive evaluation reports, including error localization, error types and scoring. Experimental results show that our framework outperforms existing open-ended text evaluation methods and achieves the highest correlation with human evaluation, which confirms the effectiveness and advancement of our framework in addressing the uncertainties and instabilities in evaluating LLMs-generated text. Furthermore, our framework significantly improves the efficiency of text evaluation and model iteration in industrial scenarios.",
        "code": "",
        "category": [
            [
                "Automation",
                "Automatic Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.19305"
    },
    "c1649f215b96688fccfcbc30d4e394e1": {
        "title": "Enhancing the General Agent Capabilities of Low-Parameter LLMs through Tuning and Multi-Branch Reasoning",
        "authors": [
            "Qinhao Zhou",
            "Zihan Zhang",
            "Xiang Xiang",
            "Ke Wang",
            "Yuchuan Wu",
            "Yongbin Li"
        ],
        "date": "2024/03/29",
        "pdf": "http://arxiv.org/pdf/2403.19962",
        "abstract": "Open-source pre-trained Large Language Models (LLMs) exhibit strong language understanding and generation capabilities, making them highly successful in a variety of tasks. However, when used as agents for dealing with complex problems in the real world, their performance is far inferior to large commercial models such as ChatGPT and GPT-4. As intelligent agents, LLMs need to have the capabilities of task planning, long-term memory, and the ability to leverage external tools to achieve satisfactory performance. Various methods have been proposed to enhance the agent capabilities of LLMs. On the one hand, methods involve constructing agent-specific data and fine-tuning the models. On the other hand, some methods focus on designing prompts that effectively activate the reasoning abilities of the LLMs. We explore both strategies on the 7B and 13B models. We propose a comprehensive method for constructing agent-specific data using GPT-4. Through supervised fine-tuning with constructed data, we find that for these models with a relatively small number of parameters, supervised fine-tuning can significantly reduce hallucination outputs and formatting errors in agent tasks. Furthermore, techniques such as multi-path reasoning and task decomposition can effectively decrease problem complexity and enhance the performance of LLMs as agents. We evaluate our method on five agent tasks of AgentBench and achieve satisfactory results.",
        "code": "",
        "category": [
            [
                "Training",
                "Fine tuning"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.19962"
    },
    "ca90b46ea8556ad2018c64fe4bb59682": {
        "title": "ITCMA: A Generative Agent Based on a Computational Consciousness Structure",
        "authors": [
            "Hanzhong Zhang",
            "Jibin Yin",
            "Haoyang Wang",
            "Ziwei Xiang"
        ],
        "date": "2024/03/29",
        "pdf": "http://arxiv.org/pdf/2403.20097",
        "abstract": "Large Language Models (LLMs) still face challenges in tasks requiring understanding implicit instructions and applying common-sense knowledge. In such scenarios, LLMs may require multiple attempts to achieve human-level performance, potentially leading to inaccurate responses or inferences in practical environments, affecting their long-term consistency and behavior. This paper introduces the Internal Time-Consciousness Machine (ITCM), a computational consciousness structure to simulate the process of human consciousness. We further propose the ITCM-based Agent (ITCMA), which supports action generation and reasoning in open-world settings, and can independently complete tasks. ITCMA enhances LLMs&#39; ability to understand implicit instructions and apply common-sense knowledge by considering agents&#39; interaction and reasoning with the environment. Evaluations in the Alfworld environment show that trained ITCMA outperforms the state-of-the-art (SOTA) by 9% on the seen set. Even untrained ITCMA achieves a 96% task completion rate on the seen set, 5% higher than SOTA, indicating its superiority over traditional intelligent agents in utility and generalization. In real-world tasks with quadruped robots, the untrained ITCMA achieves an 85% task completion rate, which is close to its performance in the unseen set, demonstrating its comparable utility and universality in real-world settings.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.20097"
    },
    "bbdc7d81c7e1344bee08ecab46a592ba": {
        "title": "Empowering Biomedical Discovery with AI Agents",
        "authors": [
            "Shanghua Gao",
            "Ada Fang",
            "Yepeng Huang",
            "Valentina Giunchiglia",
            "Ayush Noori",
            "Jonathan Richard Schwarz",
            "Yasha Ektefaie",
            "Jovana Kondic",
            "Marinka Zitnik"
        ],
        "date": "2024/04/03",
        "pdf": "http://arxiv.org/pdf/2404.02831",
        "abstract": "We envision &#34;AI scientists&#34; as systems capable of skeptical learning and reasoning that empower biomedical research through collaborative agents that integrate AI models and biomedical tools with experimental platforms. Rather than taking humans out of the discovery process, biomedical AI agents combine human creativity and expertise with AI&#39;s ability to analyze large datasets, navigate hypothesis spaces, and execute repetitive tasks. AI agents are poised to be proficient in various tasks, planning discovery workflows and performing self-assessment to identify and mitigate gaps in their knowledge. These agents use large language models and generative models to feature structured memory for continual learning and use machine learning tools to incorporate scientific knowledge, biological principles, and theories. AI agents can impact areas ranging from virtual cell simulation, programmable control of phenotypes, and the design of cellular circuits to developing new therapies.",
        "code": "",
        "category": [
            [
                "Application",
                "Biology"
            ],
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.02831"
    },
    "bd832d696f6c8b97c8a962d70be2a48d": {
        "title": "MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution",
        "authors": [
            "Wei Tao",
            "Yucheng Zhou",
            "Yanlin Wang",
            "Wenqiang Zhang",
            "Hongyu Zhang",
            "Yu Cheng"
        ],
        "date": "2024/03/26",
        "pdf": "http://arxiv.org/pdf/2403.17927",
        "abstract": "In software development, resolving the emergent issues within GitHub repositories is a complex challenge that involves not only the incorporation of new code but also the maintenance of existing code. Large Language Models (LLMs) have shown promise in code generation but face difficulties in resolving Github issues, particularly at the repository level. To overcome this challenge, we empirically study the reason why LLMs fail to resolve GitHub issues and analyze the major factors. Motivated by the empirical findings, we propose a novel LLM-based Multi-Agent framework for GitHub Issue reSolution, MAGIS, consisting of four agents customized for software evolution: Manager, Repository Custodian, Developer, and Quality Assurance Engineer agents. This framework leverages the collaboration of various agents in the planning and coding process to unlock the potential of LLMs to resolve GitHub issues. In experiments, we employ the SWE-bench benchmark to compare MAGIS with popular LLMs, including GPT-3.5, GPT-4, and Claude-2. MAGIS can resolve 13.94% GitHub issues, significantly outperforming the baselines. Specifically, MAGIS achieves an eight-fold increase in resolved ratio over the direct application of GPT-4, the advanced LLM.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.17927"
    },
    "6037287a594e3e33c4df8c55a9261097": {
        "title": "GroundCocoa: A Benchmark for Evaluating Compositional &amp; Conditional Reasoning in Language Models",
        "authors": [
            "Harsh Kohli",
            "Sachin Kumar",
            "Huan Sun"
        ],
        "date": "2024/04/05",
        "pdf": "http://arxiv.org/pdf/2404.04237",
        "abstract": "The rapid progress of large language models (LLMs) has seen them excel and frequently surpass human performance on standard benchmarks. This has enabled many downstream applications, such as LLM agents, to rely on their reasoning to address complex task requirements. However, LLMs are known to unexpectedly falter in simple tasks and under seemingly straightforward circumstances - underscoring the need for better and more diverse evaluation setups to measure their true capabilities. To this end, we choose to study compositional and conditional reasoning, two aspects that are central to human cognition, and introduce GroundCocoa - a lexically diverse benchmark connecting these reasoning skills to the real-world problem of flight booking. Our task involves aligning detailed user preferences with available flight options presented in a multiple-choice format. Results indicate a significant disparity in performance among current state-of-the-art LLMs with even the best performing model, GPT-4 Turbo, not exceeding 67% accuracy despite advanced prompting techniques.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.04237"
    },
    "95468202e69deb8c7b13b4296cb1384f": {
        "title": "Social Skill Training with Large Language Models",
        "authors": [
            "Diyi Yang",
            "Caleb Ziems",
            "William Held",
            "Omar Shaikh",
            "Michael S. Bernstein",
            "John Mitchell"
        ],
        "date": "2024/04/05",
        "pdf": "http://arxiv.org/pdf/2404.04204",
        "abstract": "People rely on social skills like conflict resolution to communicate effectively and to thrive in both work and personal life. However, practice environments for social skills are typically out of reach for most people. How can we make social skill training more available, accessible, and inviting? Drawing upon interdisciplinary research from communication and psychology, this perspective paper identifies social skill barriers to enter specialized fields. Then we present a solution that leverages large language models for social skill training via a generic framework. Our AI Partner, AI Mentor framework merges experiential learning with realistic practice and tailored feedback. This work ultimately calls for cross-disciplinary innovation to address the broader implications for workforce development and social equality.",
        "code": "",
        "category": [
            [
                "Training",
                "Fine tuning"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.04204"
    },
    "5e8a9349f5f9f58e294e0558b604cbf4": {
        "title": "A Survey on Large Language Model-Based Game Agents",
        "authors": [
            "Sihao Hu",
            "Tiansheng Huang",
            "Fatih Ilhan",
            "Selim Tekin",
            "Gaowen Liu",
            "Ramana Kompella",
            "Ling Liu"
        ],
        "date": "2024/04/02",
        "pdf": "http://arxiv.org/pdf/2404.02039",
        "abstract": "The development of game agents holds a critical role in advancing towards Artificial General Intelligence (AGI). The progress of LLMs and their multimodal counterparts (MLLMs) offers an unprecedented opportunity to evolve and empower game agents with human-like decision-making capabilities in complex computer game environments. This paper provides a comprehensive overview of LLM-based game agents from a holistic viewpoint. First, we introduce the conceptual architecture of LLM-based game agents, centered around six essential functional components: perception, memory, thinking, role-playing, action, and learning. Second, we survey existing representative LLM-based game agents documented in the literature with respect to methodologies and adaptation agility across six genres of games, including adventure, communication, competition, cooperation, simulation, and crafting &amp; exploration games. Finally, we present an outlook of future research and development directions in this burgeoning field. A curated list of relevant papers is maintained and made accessible at: https://github.com/git-disl/awesome-LLM-game-agent-papers.",
        "code": "https://github.com/git-disl/awesome-LLM-game-agent-papers",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2404.02039"
    },
    "6871dbd47b870df8b8c81d0776a86b40": {
        "title": "360$^\\circ$REA: Towards A Reusable Experience Accumulation with 360{\\deg} Assessment for Multi-Agent System",
        "authors": [
            "Shen Gao",
            "Hao Li",
            "Chengrui Huang",
            "Quan Tu",
            "Zhiliang Tian",
            "Minlie Huang",
            "Shuo Shang"
        ],
        "date": "2024/04/08",
        "pdf": "http://arxiv.org/pdf/2404.05569",
        "abstract": "Large language model agents have demonstrated remarkable advancements across various complex tasks. Recent works focus on optimizing the agent team or employing self-reflection to iteratively solve complex tasks. Since these agents are all based on the same LLM, only conducting self-evaluation or removing underperforming agents does not substantively enhance the capability of the agents. We argue that a comprehensive evaluation and accumulating experience from evaluation feedback is an effective approach to improving system performance. In this paper, we propose Reusable Experience Accumulation with 360$^\\circ$ Assessment (360$^\\circ$REA), a hierarchical multi-agent framework inspired by corporate organizational practices. The framework employs a novel 360$^\\circ$ performance assessment method for multi-perspective performance evaluation with fine-grained assessment. To enhance the capability of agents in addressing complex tasks, we introduce dual-level experience pool for agents to accumulate experience through fine-grained assessment. Extensive experiments on complex task datasets demonstrate the effectiveness of 360$^\\circ$REA.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.05569"
    },
    "0cfb4e05bac6b3386a7765e13cc10d48": {
        "title": "Foundation Models to the Rescue: Deadlock Resolution in Connected Multi-Robot Systems",
        "authors": [
            "Kunal Garg",
            "Songyuan Zhang",
            "Jacob Arkin",
            "Chuchu Fan"
        ],
        "date": "2024/04/09",
        "pdf": "http://arxiv.org/pdf/2404.06413",
        "abstract": "Connected multi-agent robotic systems (MRS) are prone to deadlocks in an obstacle environment where the robots can get stuck away from their desired locations under a smooth low-level control policy. Without an external intervention, often in terms of a high-level command, a low-level control policy cannot resolve such deadlocks. Utilizing the generalizability and low data requirements of foundation models, this paper explores the possibility of using text-based models, i.e., large language models (LLMs), and text-and-image-based models, i.e., vision-language models (VLMs), as high-level planners for deadlock resolution. We propose a hierarchical control framework where a foundation model-based high-level planner helps to resolve deadlocks by assigning a leader to the MRS along with a set of waypoints for the MRS leader. Then, a low-level distributed control policy based on graph neural networks is executed to safely follow these waypoints, thereby evading the deadlock. We conduct extensive experiments on various MRS environments using the best available pre-trained LLMs and VLMs. We compare their performance with a graph-based planner in terms of effectiveness in helping the MRS reach their target locations and computational time. Our results illustrate that, compared to grid-based planners, the foundation models perform better in terms of the goal-reaching rate and computational time for complex environments, which helps us conclude that foundation models can assist MRS operating in complex obstacle-cluttered environments to resolve deadlocks efficiently.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.06413"
    },
    "d495dbace9bd6c2bbbbc13da7e2af198": {
        "title": "AgentQuest: A Modular Benchmark Framework to Measure Progress and Improve LLM Agents",
        "authors": [
            "Luca Gioacchini",
            "Giuseppe Siracusano",
            "Davide Sanvito",
            "Kiril Gashteovski",
            "David Friede",
            "Roberto Bifulco",
            "Carolin Lawrence"
        ],
        "date": "2024/04/09",
        "pdf": "http://arxiv.org/pdf/2404.06411",
        "abstract": "The advances made by Large Language Models (LLMs) have led to the pursuit of LLM agents that can solve intricate, multi-step reasoning tasks. As with any research pursuit, benchmarking and evaluation are key corner stones to efficient and reliable progress. However, existing benchmarks are often narrow and simply compute overall task success. To face these issues, we propose AgentQuest -- a framework where (i) both benchmarks and metrics are modular and easily extensible through well documented and easy-to-use APIs; (ii) we offer two new evaluation metrics that can reliably track LLM agent progress while solving a task. We exemplify the utility of the metrics on two use cases wherein we identify common failure points and refine the agent architecture to obtain a significant performance increase. Together with the research community, we hope to extend AgentQuest further and therefore we make it available under https://github.com/nec-research/agentquest.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.06411"
    },
    "3919bfea394e8ef4c0ad613ffd0bd296": {
        "title": "SurveyAgent: A Conversational System for Personalized and Efficient Research Survey",
        "authors": [
            "Xintao Wang",
            "Jiangjie Chen",
            "Nianqi Li",
            "Lida Chen",
            "Xinfeng Yuan",
            "Wei Shi",
            "Xuyang Ge",
            "Rui Xu",
            "Yanghua Xiao"
        ],
        "date": "2024/04/09",
        "pdf": "http://arxiv.org/pdf/2404.06364",
        "abstract": "In the rapidly advancing research fields such as AI, managing and staying abreast of the latest scientific literature has become a significant challenge for researchers. Although previous efforts have leveraged AI to assist with literature searches, paper recommendations, and question-answering, a comprehensive support system that addresses the holistic needs of researchers has been lacking. This paper introduces SurveyAgent, a novel conversational system designed to provide personalized and efficient research survey assistance to researchers. SurveyAgent integrates three key modules: Knowledge Management for organizing papers, Recommendation for discovering relevant literature, and Query Answering for engaging with content on a deeper level. This system stands out by offering a unified platform that supports researchers through various stages of their literature review process, facilitated by a conversational interface that prioritizes user interaction and personalization. Our evaluation demonstrates SurveyAgent&#39;s effectiveness in streamlining research activities, showcasing its capability to facilitate how researchers interact with scientific literature.",
        "code": "",
        "category": [
            [
                "Application",
                "Research"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.06364"
    },
    "6cff9e7aba238d85b3a23a95296ae8b2": {
        "title": "Grounded Language Agent for Product Search via Intelligent Web Interactions",
        "authors": [
            "Moghis Fereidouni",
            "Adib Mosharrof",
            "A. B. Siddique"
        ],
        "date": "2024/04/16",
        "pdf": "http://arxiv.org/pdf/2404.10887",
        "abstract": "The development of agents powered by large language models (LLMs) to accomplish complex high-level user intents, has attracted significant attention recently. However, employing LLMs with billions of parameters (e.g., GPT-4) may incur substantial costs on top of handcrafting extensive prompts. To address this, we introduce a Grounded Language Agent for Intelligent Web Interactions, named GLAINTEL. GLAINTEL employs Flan-T5 as its backbone and is flexible in training in various settings: unsupervised learning, supervised learning, and unsupervised domain adaptation. Specifically, we tackle both the challenge of learning without human demonstrations and the opportunity to leverage human demonstrations effectively when those are available. Additionally, we explore unsupervised domain adaptation for cases where demonstrations are limited to a specific domain. Experimental evaluations across diverse setups demonstrate the effectiveness of GLAINTEL in unsupervised settings, outperforming in-context learning-based approaches that employ larger models with up to 540 billion parameters. Surprisingly, behavioral cloning-based methods that straightforwardly use human demonstrations do not outperform unsupervised variants of GLAINTEL. Additionally, we show that combining human demonstrations with reinforcement learning-based training yields results comparable to methods utilizing GPT-4. The code is available at: https://github.com/MultifacetedNLP/WebAgents-Unsupervised.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.10887"
    },
    "6429fc4c2cf6413ca87d31ea50fa16af": {
        "title": "The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey",
        "authors": [
            "Tula Masterman",
            "Sandi Besen",
            "Mason Sawtell",
            "Alex Chao"
        ],
        "date": "2024/04/17",
        "pdf": "http://arxiv.org/pdf/2404.11584",
        "abstract": "This survey paper examines the recent advancements in AI agent implementations, with a focus on their ability to achieve complex goals that require enhanced reasoning, planning, and tool execution capabilities. The primary objectives of this work are to a) communicate the current capabilities and limitations of existing AI agent implementations, b) share insights gained from our observations of these systems in action, and c) suggest important considerations for future developments in AI agent design. We achieve this by providing overviews of single-agent and multi-agent architectures, identifying key patterns and divergences in design choices, and evaluating their overall impact on accomplishing a provided goal. Our contribution outlines key themes when selecting an agentic architecture, the impact of leadership on agent systems, agent communication styles, and key phases for planning, execution, and reflection that enable robust AI agent systems.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ],
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.11584"
    },
    "41737985bf67ad09153b971991bed0bd": {
        "title": "Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions",
        "authors": [
            "Leena Mathur",
            "Paul Pu Liang",
            "Louis-Philippe Morency"
        ],
        "date": "2024/04/17",
        "pdf": "http://arxiv.org/pdf/2404.11023",
        "abstract": "Building socially-intelligent AI agents (Social-AI) is a multidisciplinary, multimodal research goal that involves creating agents that can sense, perceive, reason about, learn from, and respond to affect, behavior, and cognition of other agents (human or artificial). Progress towards Social-AI has accelerated in the past decade across several computing communities, including natural language processing, machine learning, robotics, human-machine interaction, computer vision, and speech. Natural language processing, in particular, has been prominent in Social-AI research, as language plays a key role in constructing the social world. In this position paper, we identify a set of underlying technical challenges and open questions for researchers across computing communities to advance Social-AI. We anchor our discussion in the context of social intelligence concepts and prior progress in Social-AI research.",
        "code": "",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2404.11023"
    },
    "035610ab3e24c6452439d97d8816f74b": {
        "title": "Memory Sharing for Large Language Model based Agents",
        "authors": [
            "Hang Gao",
            "Yongfeng Zhang"
        ],
        "date": "2024/04/15",
        "pdf": "http://arxiv.org/pdf/2404.09982",
        "abstract": "The adaptation of Large Language Model (LLM)-based agents to execute tasks via natural language prompts represents a significant advancement, notably eliminating the need for explicit retraining or fine tuning, but are constrained by the comprehensiveness and diversity of the provided examples, leading to outputs that often diverge significantly from expected results, especially when it comes to the open-ended questions. This paper introduces the Memory Sharing, a framework which integrates the real-time memory filter, storage and retrieval to enhance the In-Context Learning process. This framework allows for the sharing of memories among multiple agents, whereby the interactions and shared memories between different agents effectively enhance the diversity of the memories. The collective self-enhancement through interactive learning among multiple agents facilitates the evolution from individual intelligence to collective intelligence. Besides, the dynamically growing memory pool is utilized not only to improve the quality of responses but also to train and enhance the retriever. We evaluated our framework across three distinct domains involving specialized tasks of agents. The experimental results demonstrate that the MS framework significantly improves the agents&#39; performance in addressing open-ended questions.",
        "code": "https://github.com/GHupppp/MemorySharingLLM",
        "category": [
            [
                "Technique For Enhancement",
                "Memory Mechanism"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.09982"
    },
    "50229be1bb06bde01c7cd0f4bcd6a33e": {
        "title": "Confidence Calibration and Rationalization for LLMs via Multi-Agent Deliberation",
        "authors": [
            "Ruixin Yang",
            "Dheeraj Rajagopal",
            "Shirley Anugrah Hayati",
            "Bin Hu",
            "Dongyeop Kang"
        ],
        "date": "2024/04/14",
        "pdf": "http://arxiv.org/pdf/2404.09127",
        "abstract": "Uncertainty estimation is a significant issue for current large language models (LLMs) that are generally poorly calibrated and over-confident, especially with reinforcement learning from human feedback (RLHF). Unlike humans, whose decisions and confidences not only stem from intrinsic beliefs but can also be adjusted through daily observations, existing calibration methods for LLMs focus on estimating or eliciting individual confidence without taking full advantage of the &#34;Collective Wisdom&#34;: the interaction among multiple LLMs that can collectively improve both accuracy and calibration. In this work, we propose Collaborative Calibration, a post-hoc training-free calibration strategy that leverages the collaborative and expressive capabilities of multiple tool-augmented LLM agents in a simulated group deliberation process. We demonstrate the effectiveness of Collaborative Calibration on generative QA tasks across various domains, showing its potential in harnessing the rationalization of collectively calibrated confidence assessments and improving the reliability of model predictions.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.09127"
    },
    "e574d5257ac04d06751dabd1e710f55c": {
        "title": "MineLand: Simulating Large-Scale Multi-Agent Interactions with Limited Multimodal Senses and Physical Needs",
        "authors": [
            "Xianhao Yu",
            "Jiaqi Fu",
            "Renjia Deng",
            "Wenjuan Han"
        ],
        "date": "2024/03/28",
        "pdf": "http://arxiv.org/pdf/2403.19267",
        "abstract": "While Vision-Language Models (VLMs) hold promise for tasks requiring extensive collaboration, traditional multi-agent simulators have facilitated rich explorations of an interactive artificial society that reflects collective behavior. However, these existing simulators face significant limitations. Firstly, they struggle with handling large numbers of agents due to high resource demands. Secondly, they often assume agents possess perfect information and limitless capabilities, hindering the ecological validity of simulated social interactions. To bridge this gap, we propose a multi-agent Minecraft simulator, MineLand, that bridges this gap by introducing three key features: large-scale scalability, limited multimodal senses, and physical needs. Our simulator supports 64 or more agents. Agents have limited visual, auditory, and environmental awareness, forcing them to actively communicate and collaborate to fulfill physical needs like food and resources. Additionally, we further introduce an AI agent framework, Alex, inspired by multitasking theory, enabling agents to handle intricate coordination and scheduling. Our experiments demonstrate that the simulator, the corresponding benchmark, and the AI agent framework contribute to more ecological and nuanced collective behavior.The source code of MineLand and Alex is openly available at https://github.com/cocacola-lab/MineLand.",
        "code": "https://github.com/cocacola-lab/mineland",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2403.19267"
    },
    "646f22e74c6eeed331b2c65036e763b4": {
        "title": "EduAgent: Generative Student Agents in Learning",
        "authors": [
            "Songlin Xu",
            "Xinyu Zhang",
            "Lianhui Qin"
        ],
        "date": "2024/03/23",
        "pdf": "http://arxiv.org/pdf/2404.07963",
        "abstract": "Student simulation in online education is important to address dynamic learning behaviors of students with diverse backgrounds. Existing simulation models based on deep learning usually need massive training data, lacking prior knowledge in educational contexts. Large language models (LLMs) may contain such prior knowledge since they are pre-trained from a large corpus. However, because student behaviors are dynamic and multifaceted with individual differences, directly prompting LLMs is not robust nor accurate enough to capture fine-grained interactions among diverse student personas, learning behaviors, and learning outcomes. This work tackles this problem by presenting a newly annotated fine-grained large-scale dataset and proposing EduAgent, a novel generative agent framework incorporating cognitive prior knowledge (i.e., theoretical findings revealed in cognitive science) to guide LLMs to first reason correlations among various behaviors and then make simulations. Our two experiments show that EduAgent could not only mimic and predict learning behaviors of real students but also generate realistic learning behaviors of virtual students without real data.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.07963"
    },
    "d9bf095ed730a8b63fd64cc395cf1bdf": {
        "title": "MathVC: An LLM-Simulated Multi-Character Virtual Classroom for Mathematics Education",
        "authors": [
            "Murong Yue",
            "Wenhan Lyu",
            "Wijdane Mifdal",
            "Jennifer Suh",
            "Yixuan Zhang",
            "Ziyu Yao"
        ],
        "date": "2024/04/10",
        "pdf": "http://arxiv.org/pdf/2404.06711",
        "abstract": "Mathematical modeling (MM) is considered a fundamental skill for students in STEM disciplines. Practicing the MM skill is often the most effective when students can engage in group discussion and collaborative problem-solving. However, due to unevenly distributed teachers and educational resources needed to monitor such group activities, students do not always receive equal opportunities for this practice. Excitingly, large language models (LLMs) have recently demonstrated strong capability in both modeling mathematical problems and simulating characters with different traits and properties. Drawing inspiration from the advancement of LLMs, in this work, we present MATHVC, the very first LLM-powered virtual classroom containing multiple LLM-simulated student characters, with whom a human student can practice their MM skill. To encourage each LLM character&#39;s behaviors to be aligned with their specified math-relevant properties (termed &#34;characteristics alignment&#34;) and the overall conversational procedure to be close to an authentic student MM discussion (termed &#34;conversational procedural alignment&#34;), we proposed three innovations: integrating MM domain knowledge into the simulation, defining a symbolic schema as the ground for character simulation, and designing a meta planner at the platform level to drive the conversational procedure. Through experiments and ablation studies, we confirmed the effectiveness of our simulation approach and showed the promise for MATHVC to benefit real-life students in the future.",
        "code": "",
        "category": [
            [
                "Application",
                "Math"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.06711"
    },
    "d03fda5f2f4a4b417169cee197138d05": {
        "title": "MMInA: Benchmarking Multihop Multimodal Internet Agents",
        "authors": [
            "Ziniu Zhang",
            "Shulin Tian",
            "Liangyu Chen",
            "Ziwei Liu"
        ],
        "date": "2024/04/15",
        "pdf": "http://arxiv.org/pdf/2404.09992",
        "abstract": "Autonomous embodied agents live on an Internet of multimedia websites. Can they hop around multimodal websites to complete complex user tasks? Existing benchmarks fail to assess them in a realistic, evolving environment for their embodiment across websites. To answer this question, we present MMInA, a multihop and multimodal benchmark to evaluate the embodied agents for compositional Internet tasks, with several appealing properties: 1) Evolving real-world multimodal websites. Our benchmark uniquely operates on evolving real-world websites, ensuring a high degree of realism and applicability to natural user tasks. Our data includes 1,050 human-written tasks covering various domains such as shopping and travel, with each task requiring the agent to autonomously extract multimodal information from web pages as observations; 2) Multihop web browsing. Our dataset features naturally compositional tasks that require information from or actions on multiple websites to solve, to assess long-range reasoning capabilities on web tasks; 3) Holistic evaluation. We propose a novel protocol for evaluating an agent&#39;s progress in completing multihop tasks. We experiment with both standalone (multimodal) language models and heuristic-based web agents. Extensive experiments demonstrate that while long-chain multihop web tasks are easy for humans, they remain challenging for state-of-the-art web agents. We identify that agents are more likely to fail on the early hops when solving tasks of more hops, which results in lower task success rates. To address this issue, we propose a simple memory augmentation approach replaying past action trajectories to reflect. Our method significantly improved both the single-hop and multihop web browsing abilities of agents. See our code and data at https://mmina.cliangyu.com",
        "code": "https://github.com/shulin16/mmina",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.09992"
    },
    "f188d764a8c441b5dec5b1194d16f4aa": {
        "title": "Apollonion: Profile-centric Dialog Agent",
        "authors": [
            "Shangyu Chen",
            "Zibo Zhao",
            "Yuanyuan Zhao",
            "Xiang Li"
        ],
        "date": "2024/04/10",
        "pdf": "http://arxiv.org/pdf/2404.08692",
        "abstract": "The emergence of Large Language Models (LLMs) has innovated the development of dialog agents. Specially, a well-trained LLM, as a central process unit, is capable of providing fluent and reasonable response for user&#39;s request. Besides, auxiliary tools such as external knowledge retrieval, personalized character for vivid response, short/long-term memory for ultra long context management are developed, completing the usage experience for LLM-based dialog agents. However, the above-mentioned techniques does not solve the issue of \\textbf{personalization from user perspective}: agents response in a same fashion to different users, without consideration of their features, such as habits, interests and past experience. In another words, current implementation of dialog agents fail in ``knowing the user&#39;&#39;. The capacity of well-description and representation of user is under development. In this work, we proposed a framework for dialog agent to incorporate user profiling (initialization, update): user&#39;s query and response is analyzed and organized into a structural user profile, which is latter served to provide personal and more precise response. Besides, we proposed a series of evaluation protocols for personalization: to what extend the response is personal to the different users. The framework is named as \\method{}, inspired by inscription of ``Know Yourself&#39;&#39; in the temple of Apollo (also known as \\method{}) in Ancient Greek. Few works have been conducted on incorporating personalization into LLM, \\method{} is a pioneer work on guiding LLM&#39;s response to meet individuation via the application of dialog agents, with a set of evaluation methods for measurement in personalization.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.08692"
    },
    "d0acc8a7c482a802b05a57eaa66a1a88": {
        "title": "OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments",
        "authors": [
            "Tianbao Xie",
            "Danyang Zhang",
            "Jixuan Chen",
            "Xiaochuan Li",
            "Siheng Zhao",
            "Ruisheng Cao",
            "Toh Jing Hua",
            "Zhoujun Cheng",
            "Dongchan Shin",
            "Fangyu Lei",
            "Yitao Liu",
            "Yiheng Xu",
            "Shuyan Zhou",
            "Silvio Savarese",
            "Caiming Xiong",
            "Victor Zhong",
            "Tao Yu"
        ],
        "date": "2024/04/11",
        "pdf": "http://arxiv.org/pdf/2404.07972",
        "abstract": "Autonomous agents that accomplish complex computer tasks with minimal human interventions have the potential to transform human-computer interaction, significantly enhancing accessibility and productivity. However, existing benchmarks either lack an interactive environment or are limited to environments specific to certain applications or domains, failing to reflect the diverse and complex nature of real-world computer use, thereby limiting the scope of tasks and agent scalability. To address this issue, we introduce OSWorld, the first-of-its-kind scalable, real computer environment for multimodal agents, supporting task setup, execution-based evaluation, and interactive learning across various operating systems such as Ubuntu, Windows, and macOS. OSWorld can serve as a unified, integrated computer environment for assessing open-ended computer tasks that involve arbitrary applications. Building upon OSWorld, we create a benchmark of 369 computer tasks involving real web and desktop apps in open domains, OS file I/O, and workflows spanning multiple applications. Each task example is derived from real-world computer use cases and includes a detailed initial state setup configuration and a custom execution-based evaluation script for reliable, reproducible evaluation. Extensive evaluation of state-of-the-art LLM/VLM-based agents on OSWorld reveals significant deficiencies in their ability to serve as computer assistants. While humans can accomplish over 72.36% of the tasks, the best model achieves only 12.24% success, primarily struggling with GUI grounding and operational knowledge. Comprehensive analysis using OSWorld provides valuable insights for developing multimodal generalist agents that were not possible with previous benchmarks. Our code, environment, baseline models, and data are publicly available at https://os-world.github.io.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.07972"
    },
    "90d497ca09a06d5a5c4e2145c4070532": {
        "title": "Leveraging Multi-AI Agents for Cross-Domain Knowledge Discovery",
        "authors": [
            "Shiva Aryal",
            "Tuyen Do",
            "Bisesh Heyojoo",
            "Sandeep Chataut",
            "Bichar Dip Shrestha Gurung",
            "Venkataramana Gadhamshetty",
            "Etienne Gnimpieba"
        ],
        "date": "2024/04/12",
        "pdf": "http://arxiv.org/pdf/2404.08511",
        "abstract": "In the rapidly evolving field of artificial intelligence, the ability to harness and integrate knowledge across various domains stands as a paramount challenge and opportunity. This study introduces a novel approach to cross-domain knowledge discovery through the deployment of multi-AI agents, each specialized in distinct knowledge domains. These AI agents, designed to function as domain-specific experts, collaborate in a unified framework to synthesize and provide comprehensive insights that transcend the limitations of single-domain expertise. By facilitating seamless interaction among these agents, our platform aims to leverage the unique strengths and perspectives of each, thereby enhancing the process of knowledge discovery and decision-making. We present a comparative analysis of the different multi-agent workflow scenarios evaluating their performance in terms of efficiency, accuracy, and the breadth of knowledge integration. Through a series of experiments involving complex, interdisciplinary queries, our findings demonstrate the superior capability of domain specific multi-AI agent system in identifying and bridging knowledge gaps. This research not only underscores the significance of collaborative AI in driving innovation but also sets the stage for future advancements in AI-driven, cross-disciplinary research and application. Our methods were evaluated on a small pilot data and it showed a trend we expected, if we increase the amount of data we custom train the agents, the trend is expected to be more smooth.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.08511"
    },
    "025449e23ed3eefcf2cca46adc679089": {
        "title": "Behavior Trees Enable Structured Programming of Language Model Agents",
        "authors": [
            "Richard Kelley"
        ],
        "date": "2024/04/11",
        "pdf": "http://arxiv.org/pdf/2404.07439",
        "abstract": "Language models trained on internet-scale data sets have shown an impressive ability to solve problems in Natural Language Processing and Computer Vision. However, experience is showing that these models are frequently brittle in unexpected ways, and require significant scaffolding to ensure that they operate correctly in the larger systems that comprise &#34;language-model agents.&#34; In this paper, we argue that behavior trees provide a unifying framework for combining language models with classical AI and traditional programming. We introduce Dendron, a Python library for programming language model agents using behavior trees. We demonstrate the approach embodied by Dendron in three case studies: building a chat agent, a camera-based infrastructure inspection agent for use on a mobile robot or vehicle, and an agent that has been built to satisfy safety constraints that it did not receive through instruction tuning or RLHF.",
        "code": "https://github.com/RichardKelley/dendron",
        "category": [
            [
                "Application",
                "Software Engineering"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.07439"
    },
    "889657431ba1b80ade839a1491dd8506": {
        "title": "MACM: Utilizing a Multi-Agent System for Condition Mining in Solving Complex Mathematical Problems",
        "authors": [
            "Bin Lei",
            "Yi Zhang",
            "Shan Zuo",
            "Ali Payani",
            "Caiwen Ding"
        ],
        "date": "2024/04/06",
        "pdf": "http://arxiv.org/pdf/2404.04735",
        "abstract": "Recent advancements in large language models, such as GPT-4, have demonstrated remarkable capabilities in processing standard queries. Despite these advancements, their performance substantially declines in \\textbf{advanced mathematical problems requiring complex, multi-step logical reasoning}. To enhance their inferential capabilities, current research has delved into \\textit{prompting engineering}, exemplified by methodologies such as the Tree of Thought and Graph of Thought. Nonetheless, these existing approaches encounter two significant limitations. Firstly, their effectiveness in tackling complex mathematical problems is somewhat constrained. Secondly, the necessity to design distinct prompts for individual problems hampers their generalizability. In response to these limitations, this paper introduces the \\textit{Multi-Agent System for conditional Mining} (\\textbf{MACM}) prompting method. It not only resolves intricate mathematical problems but also demonstrates strong generalization capabilities across various mathematical contexts. With the assistance of MACM, the accuracy of GPT-4 Turbo on the most challenging level five mathematical problems in the MATH dataset increase from $\\mathbf{54.68\\%} \\text{ to } \\mathbf{76.73\\%}$. The code is available in \\url{https://github.com/bin123apple/MACM}.",
        "code": "https://github.com/bin123apple/macm",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Application",
                "Math"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.04735"
    },
    "78d78cdb8cb1730baf707d698e12d695": {
        "title": "Cooperative Sentiment Agents for Multimodal Sentiment Analysis",
        "authors": [
            "Shanmin Wang",
            "Hui Shuai",
            "Qingshan Liu",
            "Fei Wang"
        ],
        "date": "2024/04/19",
        "pdf": "http://arxiv.org/pdf/2404.12642",
        "abstract": "In this paper, we propose a new Multimodal Representation Learning (MRL) method for Multimodal Sentiment Analysis (MSA), which facilitates the adaptive interaction between modalities through Cooperative Sentiment Agents, named Co-SA. Co-SA comprises two critical components: the Sentiment Agents Establishment (SAE) phase and the Sentiment Agents Cooperation (SAC) phase. During the SAE phase, each sentiment agent deals with an unimodal signal and highlights explicit dynamic sentiment variations within the modality via the Modality-Sentiment Disentanglement (MSD) and Deep Phase Space Reconstruction (DPSR) modules. Subsequently, in the SAC phase, Co-SA meticulously designs task-specific interaction mechanisms for sentiment agents so that coordinating multimodal signals to learn the joint representation. Specifically, Co-SA equips an independent policy model for each sentiment agent that captures significant properties within the modality. These policies are optimized mutually through the unified reward adaptive to downstream tasks. Benefitting from the rewarding mechanism, Co-SA transcends the limitation of pre-defined fusion modes and adaptively captures unimodal properties for MRL in the multimodal interaction setting. To demonstrate the effectiveness of Co-SA, we apply it to address Multimodal Sentiment Analysis (MSA) and Multimodal Emotion Recognition (MER) tasks. Our comprehensive experimental results demonstrate that Co-SA excels at discovering diverse cross-modal features, encompassing both common and complementary aspects. The code can be available at https://github.com/smwanghhh/Co-SA.",
        "code": "https://github.com/smwanghhh/co-sa",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.12642"
    },
    "c810addf261e7030b42605755d0746df": {
        "title": "Towards Human-centered Proactive Conversational Agents",
        "authors": [
            "Yang Deng",
            "Lizi Liao",
            "Zhonghua Zheng",
            "Grace Hui Yang",
            "Tat-Seng Chua"
        ],
        "date": "2024/04/19",
        "pdf": "http://arxiv.org/pdf/2404.12670",
        "abstract": "Recent research on proactive conversational agents (PCAs) mainly focuses on improving the system&#39;s capabilities in anticipating and planning action sequences to accomplish tasks and achieve goals before users articulate their requests. This perspectives paper highlights the importance of moving towards building human-centered PCAs that emphasize human needs and expectations, and that considers ethical and social implications of these agents, rather than solely focusing on technological capabilities. The distinction between a proactive and a reactive system lies in the proactive system&#39;s initiative-taking nature. Without thoughtful design, proactive systems risk being perceived as intrusive by human users. We address the issue by establishing a new taxonomy concerning three key dimensions of human-centered PCAs, namely Intelligence, Adaptivity, and Civility. We discuss potential research opportunities and challenges based on this new taxonomy upon the five stages of PCA system construction. This perspectives paper lays a foundation for the emerging area of conversational information retrieval research and paves the way towards advancing human-centered proactive conversational systems.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.12670"
    },
    "f0ed13204545aa097b36058baa5bc6a0": {
        "title": "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents",
        "authors": [
            "Giorgio Piatti",
            "Zhijing Jin",
            "Max Kleiman-Weiner",
            "Bernhard SchÃ¶lkopf",
            "Mrinmaya Sachan",
            "Rada Mihalcea"
        ],
        "date": "2024/04/25",
        "pdf": "http://arxiv.org/pdf/2404.16698",
        "abstract": "As AI systems pervade human life, ensuring that large language models (LLMs) make safe decisions remains a significant challenge. We introduce the Governance of the Commons Simulation (GovSim), a generative simulation platform designed to study strategic interactions and cooperative decision-making in LLMs. In GovSim, a society of AI agents must collectively balance exploiting a common resource with sustaining it for future use. This environment enables the study of how ethical considerations, strategic planning, and negotiation skills impact cooperative outcomes. We develop an LLM-based agent architecture and test it with the leading open and closed LLMs. We find that all but the most powerful LLM agents fail to achieve a sustainable equilibrium in GovSim, with the highest survival rate below 54%. Ablations reveal that successful multi-agent communication between agents is critical for achieving cooperation in these cases. Furthermore, our analyses show that the failure to achieve sustainable cooperation in most LLMs stems from their inability to formulate and analyze hypotheses about the long-term effects of their actions on the equilibrium of the group. Finally, we show that agents that leverage &#34;Universalization&#34;-based reasoning, a theory of moral thinking, are able to achieve significantly better sustainability. Taken together, GovSim enables us to study the mechanisms that underlie sustainable self-government with specificity and scale. We open source the full suite of our research results, including the simulation environment, agent prompts, and a comprehensive web interface.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.16698"
    },
    "d98e6b8727b73e0711f9da1f804b2a3a": {
        "title": "BattleAgent: Multi-modal Dynamic Emulation on Historical Battles to Complement Historical Analysis",
        "authors": [
            "Shuhang Lin",
            "Wenyue Hua",
            "Lingyao Li",
            "Che-Jui Chang",
            "Lizhou Fan",
            "Jianchao Ji",
            "Hang Hua",
            "Mingyu Jin",
            "Jiebo Luo",
            "Yongfeng Zhang"
        ],
        "date": "2024/04/23",
        "pdf": "http://arxiv.org/pdf/2404.15532",
        "abstract": "This paper presents BattleAgent, an emulation system that combines the Large Vision-Language Model and Multi-agent System. This novel system aims to simulate complex dynamic interactions among multiple agents, as well as between agents and their environments, over a period of time. It emulates both the decision-making processes of leaders and the viewpoints of ordinary participants, such as soldiers. The emulation showcases the current capabilities of agents, featuring fine-grained multi-modal interactions between agents and landscapes. It develops customizable agent structures to meet specific situational requirements, for example, a variety of battle-related activities like scouting and trench digging. These components collaborate to recreate historical events in a lively and comprehensive manner while offering insights into the thoughts and feelings of individuals from diverse viewpoints. The technological foundations of BattleAgent establish detailed and immersive settings for historical battles, enabling individual agents to partake in, observe, and dynamically respond to evolving battle scenarios. This methodology holds the potential to substantially deepen our understanding of historical events, particularly through individual accounts. Such initiatives can also aid historical research, as conventional historical narratives often lack documentation and prioritize the perspectives of decision-makers, thereby overlooking the experiences of ordinary individuals. BattelAgent illustrates AI&#39;s potential to revitalize the human aspect in crucial social events, thereby fostering a more nuanced collective understanding and driving the progressive development of human society.",
        "code": "https://github.com/agiresearch/battleagent",
        "category": [
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.15532"
    },
    "9eff76117627bac573c318dd183c049a": {
        "title": "Aligning LLM Agents by Learning Latent Preference from User Edits",
        "authors": [
            "Ge Gao",
            "Alexey Taymanov",
            "Eduardo Salinas",
            "Paul Mineiro",
            "Dipendra Misra"
        ],
        "date": "2024/04/23",
        "pdf": "http://arxiv.org/pdf/2404.15269",
        "abstract": "We study interactive learning of LLM-based language agents based on user edits made to the agent&#39;s output. In a typical setting such as writing assistants, the user interacts with a language agent to generate a response given a context, and may optionally edit the agent response to personalize it based on their latent preference, in addition to improving the correctness. The edit feedback is naturally generated, making it a suitable candidate for improving the agent&#39;s alignment with the user&#39;s preference, and for reducing the cost of user edits over time. We propose a learning framework, PRELUDE that infers a description of the user&#39;s latent preference based on historic edit data. The inferred user preference descriptions are used to define prompts for generating responses in the future. This avoids fine-tuning the agent, which is costly, challenging to scale with the number of users, and may even degrade its performance on other tasks. Furthermore, learning descriptive preference improves interpretability, allowing the user to view and modify the learned preference. However, user preference can be complex, subtle, and vary based on context, making it challenging to learn. To address this, we propose a simple yet effective algorithm named CIPHER that leverages the LLM to infer the user preference for a given context based on user edits. In the future, CIPHER retrieves inferred preferences from the k-closest contexts in the history, and forms an aggregate preference for response generation. We introduce two interactive environments -- summarization and email writing, and use a GPT-4 simulated user for evaluation. On both tasks, CIPHER outperforms several baselines by achieving the lowest edit distance cost while only having a small overhead in LLM query cost. Our analysis reports that user preferences learned by CIPHER show significant similarity to the ground truth latent preferences.",
        "code": "",
        "category": [
            [
                "Stability",
                "Bias"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.15269"
    },
    "e04c3f9762fe447296eb9a790f67c49b": {
        "title": "Socratic Planner: Inquiry-Based Zero-Shot Planning for Embodied Instruction Following",
        "authors": [
            "Suyeon Shin",
            "Sujin jeon",
            "Junghyun Kim",
            "Gi-Cheon Kang",
            "Byoung-Tak Zhang"
        ],
        "date": "2024/04/21",
        "pdf": "http://arxiv.org/pdf/2404.15190",
        "abstract": "Embodied Instruction Following (EIF) is the task of executing natural language instructions by navigating and interacting with objects in 3D environments. One of the primary challenges in EIF is compositional task planning, which is often addressed with supervised or in-context learning with labeled data. To this end, we introduce the Socratic Planner, the first zero-shot planning method that infers without the need for any training data. Socratic Planner first decomposes the instructions into substructural information of the task through self-questioning and answering, translating it into a high-level plan, i.e., a sequence of subgoals. Subgoals are executed sequentially, with our visually grounded re-planning mechanism adjusting plans dynamically through a dense visual feedback. We also introduce an evaluation metric of high-level plans, RelaxedHLP, for a more comprehensive evaluation. Experiments demonstrate the effectiveness of the Socratic Planner, achieving competitive performance on both zero-shot and few-shot task planning in the ALFRED benchmark, particularly excelling in tasks requiring higher-dimensional inference. Additionally, a precise adjustments in the plan were achieved by incorporating environmental visual information.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.15190"
    },
    "35ce08a40e0cdaf207031e3d97ba4c6e": {
        "title": "How Well Can LLMs Echo Us? Evaluating AI Chatbots&#39; Role-Play Ability with ECHO",
        "authors": [
            "Man Tik Ng",
            "Hui Tung Tse",
            "Jen-tse Huang",
            "Jingjing Li",
            "Wenxuan Wang",
            "Michael R. Lyu"
        ],
        "date": "2024/04/22",
        "pdf": "http://arxiv.org/pdf/2404.13957",
        "abstract": "The role-play ability of Large Language Models (LLMs) has emerged as a popular research direction. However, existing studies focus on imitating well-known public figures or fictional characters, overlooking the potential for simulating ordinary individuals. Such an oversight limits the potential for advancements in digital human clones and non-player characters in video games. To bridge this gap, we introduce ECHO, an evaluative framework inspired by the Turing test. This framework engages the acquaintances of the target individuals to distinguish between human and machine-generated responses. Notably, our framework focuses on emulating average individuals rather than historical or fictional figures, presenting a unique advantage to apply the Turing Test. We evaluated three role-playing LLMs using ECHO, with GPT-3.5 and GPT-4 serving as foundational models, alongside the online application GPTs from OpenAI. Our results demonstrate that GPT-4 more effectively deceives human evaluators, and GPTs achieves a leading success rate of 48.3%. Furthermore, we investigated whether LLMs could discern between human-generated and machine-generated texts. While GPT-4 can identify differences, it could not determine which texts were human-produced. Our code and results of reproducing the role-playing LLMs are made publicly available via https://github.com/CUHK-ARISE/ECHO.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.13957"
    },
    "ab48f35dec492ad32cc00c50276c7f36": {
        "title": "PANGeA: Procedural Artificial Narrative using Generative AI for Turn-Based Video Games",
        "authors": [
            "Steph Buongiorno",
            "Lawrence Jake Klinkert",
            "Tanishq Chawla",
            "Zixin Zhuang",
            "Corey Clark"
        ],
        "date": "2024/04/30",
        "pdf": "http://arxiv.org/pdf/2404.19721",
        "abstract": "This research introduces Procedural Artificial Narrative using Generative AI (PANGeA), a structured approach for leveraging large language models (LLMs), guided by a game designer&#39;s high-level criteria, to generate narrative content for turn-based role-playing video games (RPGs). Distinct from prior applications of LLMs used for video game design, PANGeA innovates by not only generating game level data (which includes, but is not limited to, setting, key items, and non-playable characters (NPCs)), but by also fostering dynamic, free-form interactions between the player and the environment that align with the procedural game narrative. The NPCs generated by PANGeA are personality-biased and express traits from the Big 5 Personality Model in their generated responses. PANGeA addresses challenges behind ingesting free-form text input, which can prompt LLM responses beyond the scope of the game narrative. A novel validation system that uses the LLM&#39;s intelligence evaluates text input and aligns generated responses with the unfolding narrative. Making these interactions possible, PANGeA is supported by a server that hosts a custom memory system that supplies context for augmenting generated responses thus aligning them with the procedural narrative. For its broad application, the server has a REST interface enabling any game engine to integrate directly with PANGeA, as well as an LLM interface adaptable with local or private LLMs. PANGeA&#39;s ability to foster dynamic narrative generation by aligning responses with the procedural narrative is demonstrated through an empirical study and ablation test of two versions of a demo game. These are, a custom, browser-based GPT and a Unity demo. As the results show, PANGeA holds potential to assist game designers in using LLMs to generate narrative-consistent content even when provided varied and unpredictable, free-form text input.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.19721"
    },
    "d3be68d8e8d6464c35b2ccdf320e52e2": {
        "title": "Large Language Model Agent as a Mechanical Designer",
        "authors": [
            "Yayati Jadhav",
            "Amir Barati Farimani"
        ],
        "date": "2024/04/26",
        "pdf": "http://arxiv.org/pdf/2404.17525",
        "abstract": "Conventional mechanical design paradigms rely on experts systematically refining concepts through experience-guided modification and FEA to meet specific requirements. However, this approach can be time-consuming and heavily dependent on prior knowledge and experience. While numerous machine learning models have been developed to streamline this intensive and expert-driven iterative process, these methods typically demand extensive training data and considerable computational resources. Furthermore, methods based on deep learning are usually restricted to the specific domains and tasks for which they were trained, limiting their applicability across different tasks. This creates a trade-off between the efficiency of automation and the demand for resources. In this study, we present a novel approach that integrates pre-trained LLMs with a FEM module. The FEM module evaluates each design and provides essential feedback, guiding the LLMs to continuously learn, plan, generate, and optimize designs without the need for domain-specific training. We demonstrate the effectiveness of our proposed framework in managing the iterative optimization of truss structures, showcasing its capability to reason about and refine designs according to structured feedback and criteria. Our results reveal that these LLM-based agents can successfully generate truss designs that comply with natural language specifications with a success rate of up to 90%, which varies according to the applied constraints. By employing prompt-based optimization techniques we show that LLM based agents exhibit optimization behavior when provided with solution-score pairs to iteratively refine designs to meet specifications. This ability of LLM agents to produce viable designs and optimize them based on their inherent reasoning capabilities highlights their potential to develop and implement effective design strategies autonomously.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.17525"
    },
    "aef6e27e25eb64666e2bbb9373ac3d70": {
        "title": "CRISPR-GPT: An LLM Agent for Automated Design of Gene-Editing Experiments",
        "authors": [
            "Kaixuan Huang",
            "Yuanhao Qu",
            "Henry Cousins",
            "William A. Johnson",
            "Di Yin",
            "Mihir Shah",
            "Denny Zhou",
            "Russ Altman",
            "Mengdi Wang",
            "Le Cong"
        ],
        "date": "2024/04/27",
        "pdf": "http://arxiv.org/pdf/2404.18021",
        "abstract": "The introduction of genome engineering technology has transformed biomedical research, making it possible to make precise changes to genetic information. However, creating an efficient gene-editing system requires a deep understanding of CRISPR technology, and the complex experimental systems under investigation. While Large Language Models (LLMs) have shown promise in various tasks, they often lack specific knowledge and struggle to accurately solve biological design problems. In this work, we introduce CRISPR-GPT, an LLM agent augmented with domain knowledge and external tools to automate and enhance the design process of CRISPR-based gene-editing experiments. CRISPR-GPT leverages the reasoning ability of LLMs to facilitate the process of selecting CRISPR systems, designing guide RNAs, recommending cellular delivery methods, drafting protocols, and designing validation experiments to confirm editing outcomes. We showcase the potential of CRISPR-GPT for assisting non-expert researchers with gene-editing experiments from scratch and validate the agent&#39;s effectiveness in a real-world use case. Furthermore, we explore the ethical and regulatory considerations associated with automated gene-editing design, highlighting the need for responsible and transparent use of these tools. Our work aims to bridge the gap between beginner biological researchers and CRISPR genome engineering techniques, and demonstrate the potential of LLM agents in facilitating complex biological discovery tasks.",
        "code": "",
        "category": [
            [
                "Application",
                "Biology"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.18021"
    },
    "c20a9be3f493bc58a9706b98f5bfcb38": {
        "title": "ComposerX: Multi-Agent Symbolic Music Composition with LLMs",
        "authors": [
            "Qixin Deng",
            "Qikai Yang",
            "Ruibin Yuan",
            "Yipeng Huang",
            "Yi Wang",
            "Xubo Liu",
            "Zeyue Tian",
            "Jiahao Pan",
            "Ge Zhang",
            "Hanfeng Lin",
            "Yizhi Li",
            "Yinghao Ma",
            "Jie Fu",
            "Chenghua Lin",
            "Emmanouil Benetos",
            "Wenwu Wang",
            "Guangyu Xia",
            "Wei Xue",
            "Yike Guo"
        ],
        "date": "2024/04/28",
        "pdf": "http://arxiv.org/pdf/2404.18081",
        "abstract": "Music composition represents the creative side of humanity, and itself is a complex task that requires abilities to understand and generate information with long dependency and harmony constraints. While demonstrating impressive capabilities in STEM subjects, current LLMs easily fail in this task, generating ill-written music even when equipped with modern techniques like In-Context-Learning and Chain-of-Thoughts. To further explore and enhance LLMs&#39; potential in music composition by leveraging their reasoning ability and the large knowledge base in music history and theory, we propose ComposerX, an agent-based symbolic music generation framework. We find that applying a multi-agent approach significantly improves the music composition quality of GPT-4. The results demonstrate that ComposerX is capable of producing coherent polyphonic music compositions with captivating melodies, while adhering to user instructions.",
        "code": "https://github.com/lllindsey0615/composerx",
        "category": [
            [
                "Application",
                "Art"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.18081"
    },
    "96c56a428d90415310188fa9a434d00c": {
        "title": "Logic Agent: Enhancing Validity with Logic Rule Invocation",
        "authors": [
            "Hanmeng Liu",
            "Zhiyang Teng",
            "Chaoli Zhang",
            "Yue Zhang"
        ],
        "date": "2024/04/28",
        "pdf": "http://arxiv.org/pdf/2404.18130",
        "abstract": "Chain-of-Thought (CoT) prompting has emerged as a pivotal technique for augmenting the inferential capabilities of language models during reasoning tasks. Despite its advancements, CoT often grapples with challenges in validating reasoning validity and ensuring informativeness. Addressing these limitations, this paper introduces the Logic Agent (LA), an agent-based framework aimed at enhancing the validity of reasoning processes in Large Language Models (LLMs) through strategic logic rule invocation. Unlike conventional approaches, LA transforms LLMs into logic agents that dynamically apply propositional logic rules, initiating the reasoning process by converting natural language inputs into structured logic forms. The logic agent leverages a comprehensive set of predefined functions to systematically navigate the reasoning process. This methodology not only promotes the structured and coherent generation of reasoning constructs but also significantly improves their interpretability and logical coherence. Through extensive experimentation, we demonstrate LA&#39;s capacity to scale effectively across various model sizes, markedly improving the precision of complex reasoning across diverse tasks.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.18130"
    },
    "bf68ceff02d38dac075c997707f0632e": {
        "title": "Large Language Model Agent for Fake News Detection",
        "authors": [
            "Xinyi Li",
            "Yongfeng Zhang",
            "Edward C. Malthouse"
        ],
        "date": "2024/04/30",
        "pdf": "http://arxiv.org/pdf/2405.01593",
        "abstract": "In the current digital era, the rapid spread of misinformation on online platforms presents significant challenges to societal well-being, public trust, and democratic processes, influencing critical decision making and public opinion. To address these challenges, there is a growing need for automated fake news detection mechanisms. Pre-trained large language models (LLMs) have demonstrated exceptional capabilities across various natural language processing (NLP) tasks, prompting exploration into their potential for verifying news claims. Instead of employing LLMs in a non-agentic way, where LLMs generate responses based on direct prompts in a single shot, our work introduces FactAgent, an agentic approach of utilizing LLMs for fake news detection. FactAgent enables LLMs to emulate human expert behavior in verifying news claims without any model training, following a structured workflow. This workflow breaks down the complex task of news veracity checking into multiple sub-steps, where LLMs complete simple tasks using their internal knowledge or external tools. At the final step of the workflow, LLMs integrate all findings throughout the workflow to determine the news claim&#39;s veracity. Compared to manual human verification, FactAgent offers enhanced efficiency. Experimental studies demonstrate the effectiveness of FactAgent in verifying claims without the need for any training process. Moreover, FactAgent provides transparent explanations at each step of the workflow and during final decision-making, offering insights into the reasoning process of fake news detection for end users. FactAgent is highly adaptable, allowing for straightforward updates to its tools that LLMs can leverage within the workflow, as well as updates to the workflow itself using domain knowledge. This adaptability enables FactAgent&#39;s application to news verification across various domains.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.01593"
    },
    "d7fa003b09d2ebcde7ea089949ad402a": {
        "title": "Navigating WebAI: Training Agents to Complete Web Tasks with Large Language Models and Reinforcement Learning",
        "authors": [
            "Lucas-AndreÃ¯ Thil",
            "Mirela Popa",
            "Gerasimos Spanakis"
        ],
        "date": "2024/05/01",
        "pdf": "http://arxiv.org/pdf/2405.00516",
        "abstract": "Recent advancements in language models have demonstrated remarkable improvements in various natural language processing (NLP) tasks such as web navigation. Supervised learning (SL) approaches have achieved impressive performance while utilizing significantly less training data compared to previous methods. However, these SL-based models fall short when compared to reinforcement learning (RL) approaches, which have shown superior results. In this paper, we propose a novel approach that combines SL and RL techniques over the MiniWoB benchmark to leverage the strengths of both methods. We also address a critical limitation in previous models&#39; understanding of HTML content, revealing a tendency to memorize target elements rather than comprehend the underlying structure. To rectify this, we propose methods to enhance true understanding and present a new baseline of results. Our experiments demonstrate that our approach outperforms previous SL methods on certain tasks using less data and narrows the performance gap with RL models, achieving 43.58\\% average accuracy in SL and 36.69\\% when combined with a multimodal RL approach. This study sets a new direction for future web navigation and offers insights into the limitations and potential of language modeling for computer tasks.",
        "code": "",
        "category": [
            [
                "Training",
                "RL"
            ],
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.00516"
    },
    "c1e0294614a29fc390d87c06d71e7a1e": {
        "title": "Leveraging Large Language Models in Human-Robot Interaction: A Critical Analysis of Potential and Pitfalls",
        "authors": [
            "Jesse Atuhurra"
        ],
        "date": "2024/03/26",
        "pdf": "http://arxiv.org/pdf/2405.00693",
        "abstract": "The emergence of large language models (LLM) and, consequently, vision language models (VLM) has ignited new imaginations among robotics researchers. At this point, the range of applications to which LLM and VLM can be applied in human-robot interaction (HRI), particularly socially assistive robots (SARs), is unchartered territory. However, LLM and VLM present unprecedented opportunities and challenges for SAR integration. We aim to illuminate the opportunities and challenges when roboticists deploy LLM and VLM in SARs. First, we conducted a meta-study of more than 250 papers exploring 1) major robots in HRI research and 2) significant applications of SARs, emphasizing education, healthcare, and entertainment while addressing 3) societal norms and issues like trust, bias, and ethics that the robot developers must address. Then, we identified 4) critical components of a robot that LLM or VLM can replace while addressing the 5) benefits of integrating LLM into robot designs and the 6) risks involved. Finally, we outline a pathway for the responsible and effective adoption of LLM or VLM into SARs, and we close our discussion by offering caution regarding this deployment.",
        "code": "",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2405.00693"
    },
    "78997b038dfb5f3e70c52686b5d86257": {
        "title": "Persona Inconstancy in Multi-Agent LLM Collaboration: Conformity, Confabulation, and Impersonation",
        "authors": [
            "Razan Baltaji",
            "Babak Hemmatian",
            "Lav R. Varshney"
        ],
        "date": "2024/05/06",
        "pdf": "http://arxiv.org/pdf/2405.03862",
        "abstract": "Multi-agent AI systems can be used for simulating collective decision-making in scientific and practical applications. They can also be used to introduce a diverse group discussion step in chatbot pipelines, enhancing the cultural sensitivity of the chatbot&#39;s responses. These applications, however, are predicated on the ability of AI agents to reliably adopt assigned personas and mimic human interactions. To see whether LLM agents satisfy these requirements, we examine AI agent ensembles engaged in cross-national collaboration and debate by analyzing their private responses and chat transcripts. Our findings suggest that multi-agent discussions can support collective AI decisions that more often reflect diverse perspectives, yet this effect is tempered by the agents&#39; susceptibility to conformity due to perceived peer pressure and occasional challenges in maintaining consistent personas and opinions. Instructions that encourage debate in support of one&#39;s opinions rather than collaboration increase the rate of inconstancy. Without addressing the factors we identify, the full potential of multi-agent frameworks for producing more culturally diverse AI outputs or more realistic simulations of group decision-making may remain untapped.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.03862"
    },
    "77b2c05422904b637fe33ddffdddc2ff": {
        "title": "&#34;Ask Me Anything&#34;: How Comcast Uses LLMs to Assist Agents in Real Time",
        "authors": [
            "Scott Rome",
            "Tianwen Chen",
            "Raphael Tang",
            "Luwei Zhou",
            "Ferhan Ture"
        ],
        "date": "2024/05/01",
        "pdf": "http://arxiv.org/pdf/2405.00801",
        "abstract": "Customer service is how companies interface with their customers. It can contribute heavily towards the overall customer satisfaction. However, high-quality service can become expensive, creating an incentive to make it as cost efficient as possible and prompting most companies to utilize AI-powered assistants, or &#34;chat bots&#34;. On the other hand, human-to-human interaction is still desired by customers, especially when it comes to complex scenarios such as disputes and sensitive topics like bill payment. This raises the bar for customer service agents. They need to accurately understand the customer&#39;s question or concern, identify a solution that is acceptable yet feasible (and within the company&#39;s policy), all while handling multiple conversations at once. In this work, we introduce &#34;Ask Me Anything&#34; (AMA) as an add-on feature to an agent-facing customer service interface. AMA allows agents to ask questions to a large language model (LLM) on demand, as they are handling customer conversations -- the LLM provides accurate responses in real-time, reducing the amount of context switching the agent needs. In our internal experiments, we find that agents using AMA versus a traditional search experience spend approximately 10% fewer seconds per conversation containing a search, translating to millions of dollars of savings annually. Agents that used the AMA feature provided positive feedback nearly 80% of the time, demonstrating its usefulness as an AI-assisted feature for customer care.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.00801"
    },
    "2704c7e4d3813e67bbf40356965122ec": {
        "title": "WorkBench: a Benchmark Dataset for Agents in a Realistic Workplace Setting",
        "authors": [
            "Olly Styles",
            "Sam Miller",
            "Patricio Cerda-Mardini",
            "Tanaya Guha",
            "Victor Sanchez",
            "Bertie Vidgen"
        ],
        "date": "2024/05/01",
        "pdf": "http://arxiv.org/pdf/2405.00823",
        "abstract": "We introduce WorkBench: a benchmark dataset for evaluating agents&#39; ability to execute tasks in a workplace setting. WorkBench contains a sandbox environment with five databases, 26 tools, and 690 tasks. These tasks represent common business activities, such as sending emails and scheduling meetings. The tasks in WorkBench are challenging as they require planning, tool selection, and often multiple actions. If a task has been successfully executed, one (or more) of the database values may change. The correct outcome for each task is unique and unambiguous, which allows for robust, automated evaluation. We call this key contribution outcome-centric evaluation. We evaluate five existing ReAct agents on WorkBench, finding they successfully complete as few as 3% of tasks (Llama2-70B), and just 43% for the best-performing (GPT-4). We further find that agents&#39; errors can result in the wrong action being taken, such as an email being sent to the wrong person. WorkBench reveals weaknesses in agents&#39; ability to undertake common business activities, raising questions about their use in high-stakes workplace settings. WorkBench is publicly available as a free resource at https://github.com/olly-styles/WorkBench.",
        "code": "https://github.com/olly-styles/workbench",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.00823"
    },
    "b72d2bd1cbea4425300fafee4f089549": {
        "title": "CACTUS: Chemistry Agent Connecting Tool-Usage to Science",
        "authors": [
            "Andrew D. McNaughton",
            "Gautham Ramalaxmi",
            "Agustin Kruel",
            "Carter R. Knutson",
            "Rohith A. Varikoti",
            "Neeraj Kumar"
        ],
        "date": "2024/05/02",
        "pdf": "http://arxiv.org/pdf/2405.00972",
        "abstract": "Large language models (LLMs) have shown remarkable potential in various domains, but they often lack the ability to access and reason over domain-specific knowledge and tools. In this paper, we introduced CACTUS (Chemistry Agent Connecting Tool-Usage to Science), an LLM-based agent that integrates cheminformatics tools to enable advanced reasoning and problem-solving in chemistry and molecular discovery. We evaluate the performance of CACTUS using a diverse set of open-source LLMs, including Gemma-7b, Falcon-7b, MPT-7b, Llama2-7b, and Mistral-7b, on a benchmark of thousands of chemistry questions. Our results demonstrate that CACTUS significantly outperforms baseline LLMs, with the Gemma-7b and Mistral-7b models achieving the highest accuracy regardless of the prompting strategy used. Moreover, we explore the impact of domain-specific prompting and hardware configurations on model performance, highlighting the importance of prompt engineering and the potential for deploying smaller models on consumer-grade hardware without significant loss in accuracy. By combining the cognitive capabilities of open-source LLMs with domain-specific tools, CACTUS can assist researchers in tasks such as molecular property prediction, similarity searching, and drug-likeness assessment. Furthermore, CACTUS represents a significant milestone in the field of cheminformatics, offering an adaptable tool for researchers engaged in chemistry and molecular discovery. By integrating the strengths of open-source LLMs with domain-specific tools, CACTUS has the potential to accelerate scientific advancement and unlock new frontiers in the exploration of novel, effective, and safe therapeutic candidates, catalysts, and materials. Moreover, CACTUS&#39;s ability to integrate with automated experimentation platforms and make data-driven decisions in real time opens up new possibilities for autonomous discovery.",
        "code": "https://github.com/pnnl/cactus",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ],
            [
                "Application",
                "Research"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.00972"
    },
    "ba077a6c1f1f572103b1bcfa943cb42b": {
        "title": "GAIA: A General AI Assistant for Intelligent Accelerator Operations",
        "authors": [
            "Frank Mayet"
        ],
        "date": "2024/05/02",
        "pdf": "http://arxiv.org/pdf/2405.01359",
        "abstract": "Large-scale machines like particle accelerators are usually run by a team of experienced operators. In case of a particle accelerator, these operators possess suitable background knowledge on both accelerator physics and the technology comprising the machine. Due to the complexity of the machine, particular subsystems of the machine are taken care of by experts, who the operators can turn to. In this work the reasoning and action (ReAct) prompting paradigm is used to couple an open-weights large language model (LLM) with a high-level machine control system framework and other tools, e.g. the electronic logbook or machine design documentation. By doing so, a multi-expert retrieval augmented generation (RAG) system is implemented, which assists operators in knowledge retrieval tasks, interacts with the machine directly if needed, or writes high level control system scripts. This consolidation of expert knowledge and machine interaction can simplify and speed up machine operation tasks for both new and experienced human operators.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.01359"
    },
    "6d2bc9f35fcd10c0a43d0bb13c364676": {
        "title": "Octopus v3: Technical Report for On-device Sub-billion Multimodal AI Agent",
        "authors": [
            "Wei Chen",
            "Zhiyuan Li"
        ],
        "date": "2024/04/17",
        "pdf": "http://arxiv.org/pdf/2404.11459",
        "abstract": "A multimodal AI agent is characterized by its ability to process and learn from various types of data, including natural language, visual, and audio inputs, to inform its actions. Despite advancements in large language models that incorporate visual data, such as GPT-4V, effectively translating image-based data into actionable outcomes for AI agents continues to be challenging. In this paper, we introduce a multimodal model that incorporates the concept of functional token specifically designed for AI agent applications. To ensure compatibility with edge devices, our model is optimized to a compact size of less than 1B parameters. Like GPT-4, our model can process both English and Chinese. We demonstrate that this model is capable of operating efficiently on a wide range of edge devices, including as constrained as a Raspberry Pi.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.11459"
    },
    "b87a4cc0c759e31d54cf32e846c59ee9": {
        "title": "LLM-based Multi-Agent Reinforcement Learning: Current and Future Directions",
        "authors": [
            "Chuanneng Sun",
            "Songjun Huang",
            "Dario Pompili"
        ],
        "date": "2024/05/17",
        "pdf": "http://arxiv.org/pdf/2405.11106",
        "abstract": "In recent years, Large Language Models (LLMs) have shown great abilities in various tasks, including question answering, arithmetic problem solving, and poem writing, among others. Although research on LLM-as-an-agent has shown that LLM can be applied to Reinforcement Learning (RL) and achieve decent results, the extension of LLM-based RL to Multi-Agent System (MAS) is not trivial, as many aspects, such as coordination and communication between agents, are not considered in the RL frameworks of a single agent. To inspire more research on LLM-based MARL, in this letter, we survey the existing LLM-based single-agent and multi-agent RL frameworks and provide potential research directions for future research. In particular, we focus on the cooperative tasks of multiple agents with a common goal and communication among them. We also consider human-in/on-the-loop scenarios enabled by the language component in the framework.",
        "code": "",
        "category": [
            [
                "Training",
                "RL"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.11106"
    },
    "f042f087ecadcb354329fbcd38bbc000": {
        "title": "Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning",
        "authors": [
            "Yuexiang Zhai",
            "Hao Bai",
            "Zipeng Lin",
            "Jiayi Pan",
            "Shengbang Tong",
            "Yifei Zhou",
            "Alane Suhr",
            "Saining Xie",
            "Yann LeCun",
            "Yi Ma",
            "Sergey Levine"
        ],
        "date": "2024/05/16",
        "pdf": "http://arxiv.org/pdf/2405.10292",
        "abstract": "Large vision-language models (VLMs) fine-tuned on specialized visual instruction-following data have exhibited impressive language reasoning capabilities across various scenarios. However, this fine-tuning paradigm may not be able to efficiently learn optimal decision-making agents in multi-step goal-directed tasks from interactive environments. To address this challenge, we propose an algorithmic framework that fine-tunes VLMs with reinforcement learning (RL). Specifically, our framework provides a task description and then prompts the VLM to generate chain-of-thought (CoT) reasoning, enabling the VLM to efficiently explore intermediate reasoning steps that lead to the final text-based action. Next, the open-ended text output is parsed into an executable action to interact with the environment to obtain goal-directed task rewards. Finally, our framework uses these task rewards to fine-tune the entire VLM with RL. Empirically, we demonstrate that our proposed framework enhances the decision-making capabilities of VLM agents across various tasks, enabling 7b models to outperform commercial models such as GPT4-V or Gemini. Furthermore, we find that CoT reasoning is a crucial component for performance improvement, as removing the CoT reasoning results in a significant decrease in the overall performance of our method.",
        "code": "",
        "category": [
            [
                "Training",
                "RL"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.10292"
    },
    "d9495626913b689d9b5dbe9d90df8923": {
        "title": "Exploring the Potential of Conversational AI Support for Agent-Based Social Simulation Model Design",
        "authors": [
            "Peer-Olaf Siebers"
        ],
        "date": "2024/05/12",
        "pdf": "http://arxiv.org/pdf/2405.08032",
        "abstract": "ChatGPT, the AI-powered chatbot with a massive user base of hundreds of millions, has become a global phenomenon. However, the use of Conversational AI Systems (CAISs) like ChatGPT for research in the field of Social Simulation is still limited. Specifically, there is no evidence of its usage in Agent-Based Social Simulation (ABSS) model design. While scepticism towards anything new is inherent to human nature, we firmly believe it is imperative to initiate the use of this innovative technology to support ABSS model design. This paper presents a proof-of-concept that demonstrates how CAISs can facilitate the development of innovative conceptual ABSS models in a concise timeframe and with minimal required upfront case-based knowledge. By employing advanced prompt engineering techniques and adhering to the Engineering ABSS framework, we have constructed a comprehensive prompt script that enables the design of ABSS models with or by the CAIS. The effectiveness of the script is demonstrated through an illustrative case study concerning the use of adaptive architecture in museums. Despite occasional inaccuracies and divergences in conversation, the CAIS proved to be a valuable companion for ABSS modellers.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.08032"
    },
    "bcf1e07dcc3653511e08f61ae367e0bb": {
        "title": "AgentClinic: a multimodal agent benchmark to evaluate AI in simulated clinical environments",
        "authors": [
            "Samuel Schmidgall",
            "Rojin Ziaei",
            "Carl Harris",
            "Eduardo Reis",
            "Jeffrey Jopling",
            "Michael Moor"
        ],
        "date": "2024/05/13",
        "pdf": "http://arxiv.org/pdf/2405.07960",
        "abstract": "Evaluating large language models (LLM) in clinical scenarios is crucial to assessing their potential clinical utility. Existing benchmarks rely heavily on static question-answering, which does not accurately depict the complex, sequential nature of clinical decision-making. Here, we introduce AgentClinic, a multimodal agent benchmark for evaluating LLMs in simulated clinical environments that include patient interactions, multimodal data collection under incomplete information, and the usage of various tools, resulting in an in-depth evaluation across nine medical specialties and seven languages. We find that solving MedQA problems in the sequential decision-making format of AgentClinic is considerably more challenging, resulting in diagnostic accuracies that can drop to below a tenth of the original accuracy. Overall, we observe that agents sourced from Claude-3.5 outperform other LLM backbones in most settings. Nevertheless, we see stark differences in the LLMs&#39; ability to make use of tools, such as experiential learning, adaptive retrieval, and reflection cycles. Strikingly, Llama-3 shows up to 92% relative improvements with the notebook tool that allows for writing and editing notes that persist across cases. To further scrutinize our clinical simulations, we leverage real-world electronic health records, perform a clinical reader study, perturb agents with biases, and explore novel patient-centric metrics that this interactive environment firstly enables.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.07960"
    },
    "a7ce7a0960bfdb2e0e3d36c076b3386c": {
        "title": "Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation",
        "authors": [
            "Jinyu Cai",
            "Jialong Li",
            "Mingyue Zhang",
            "Munan Li",
            "Chen-Shu Wang",
            "Kenji Tei"
        ],
        "date": "2024/05/05",
        "pdf": "http://arxiv.org/pdf/2405.02858",
        "abstract": "Social media platforms such as Twitter, Reddit, and Sina Weibo play a crucial role in global communication but often encounter strict regulations in geopolitically sensitive regions. This situation has prompted users to ingeniously modify their way of communicating, frequently resorting to coded language in these regulated social media environments. This shift in communication is not merely a strategy to counteract regulation, but a vivid manifestation of language evolution, demonstrating how language naturally evolves under societal and technological pressures. Studying the evolution of language in regulated social media contexts is of significant importance for ensuring freedom of speech, optimizing content moderation, and advancing linguistic research. This paper proposes a multi-agent simulation framework using Large Language Models (LLMs) to explore the evolution of user language in regulated social media environments. The framework employs LLM-driven agents: supervisory agent who enforce dialogue supervision and participant agents who evolve their language strategies while engaging in conversation, simulating the evolution of communication styles under strict regulations aimed at evading social media regulation. The study evaluates the framework&#39;s effectiveness through a range of scenarios from abstract scenarios to real-world situations. Key findings indicate that LLMs are capable of simulating nuanced language dynamics and interactions in constrained settings, showing improvement in both evading supervision and information accuracy as evolution progresses. Furthermore, it was found that LLM agents adopt different strategies for different scenarios.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.02858"
    },
    "b43b5affaaf41cfdf9e94780c8081629": {
        "title": "(Perhaps) Beyond Human Translation: Harnessing Multi-Agent Collaboration for Translating Ultra-Long Literary Texts",
        "authors": [
            "Minghao Wu",
            "Yulin Yuan",
            "Gholamreza Haffari",
            "Longyue Wang"
        ],
        "date": "2024/05/20",
        "pdf": "http://arxiv.org/pdf/2405.11804",
        "abstract": "Recent advancements in machine translation (MT) have significantly enhanced translation quality across various domains. However, the translation of literary texts remains a formidable challenge due to their complex language, figurative expressions, and cultural nuances. In this work, we introduce a novel multi-agent framework based on large language models (LLMs) for literary translation, implemented as a company called TransAgents, which mirrors traditional translation publication process by leveraging the collective capabilities of multiple agents, to address the intricate demands of translating literary works. To evaluate the effectiveness of our system, we propose two innovative evaluation strategies: Monolingual Human Preference (MHP) and Bilingual LLM Preference (BLP). MHP assesses translations from the perspective of monolingual readers of the target language, while BLP uses advanced LLMs to compare translations directly with the original texts. Empirical findings indicate that despite lower d-BLEU scores, translations from TransAgents are preferred by both human evaluators and LLMs over human-written references, particularly in genres requiring domain-specific knowledge. We also highlight the strengths and limitations of TransAgents through case studies and suggests directions for future research.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.11804"
    },
    "795c4f39e715ad150c279b8e75ac567a": {
        "title": "Speaker Verification in Agent-Generated Conversations",
        "authors": [
            "Yizhe Yang",
            "Palakorn Achananuparp",
            "Heyan Huang",
            "Jing Jiang",
            "Ee-Peng Lim"
        ],
        "date": "2024/05/16",
        "pdf": "http://arxiv.org/pdf/2405.10150",
        "abstract": "The recent success of large language models (LLMs) has attracted widespread interest to develop role-playing conversational agents personalized to the characteristics and styles of different speakers to enhance their abilities to perform both general and special purpose dialogue tasks. However, the ability to personalize the generated utterances to speakers, whether conducted by human or LLM, has not been well studied. To bridge this gap, our study introduces a novel evaluation challenge: speaker verification in agent-generated conversations, which aimed to verify whether two sets of utterances originate from the same speaker. To this end, we assemble a large dataset collection encompassing thousands of speakers and their utterances. We also develop and evaluate speaker verification models under experiment setups. We further utilize the speaker verification models to evaluate the personalization abilities of LLM-based role-playing models. Comprehensive experiments suggest that the current role-playing models fail in accurately mimicking speakers, primarily due to their inherent linguistic characteristics.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.10150"
    },
    "d42b631cc1afc305dd8e925f98cfee2e": {
        "title": "LLM Discussion: Enhancing the Creativity of Large Language Models via Discussion Framework and Role-Play",
        "authors": [
            "Li-Chun Lu",
            "Shou-Jen Chen",
            "Tsung-Min Pai",
            "Chan-Hung Yu",
            "Hung-yi Lee",
            "Shao-Hua Sun"
        ],
        "date": "2024/05/10",
        "pdf": "http://arxiv.org/pdf/2405.06373",
        "abstract": "Large language models (LLMs) have shown exceptional proficiency in natural language processing but often fall short of generating creative and original responses to open-ended questions. To enhance LLM creativity, our key insight is to emulate the human process of inducing collective creativity through engaging discussions with participants from diverse backgrounds and perspectives. To this end, we propose LLM Discussion, a three-phase discussion framework that facilitates vigorous and diverging idea exchanges and ensures convergence to creative answers. Moreover, we adopt a role-playing technique by assigning distinct roles to LLMs to combat the homogeneity of LLMs. We evaluate the efficacy of the proposed framework with the Alternative Uses Test, Similarities Test, Instances Test, and Scientific Creativity Test through both LLM evaluation and human study. The results show that our proposed framework outperforms single-LLM approaches and existing multi-LLM frameworks across various creativity metrics. The code is available at https://github.com/lawraa/LLM-Discussion.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.06373"
    },
    "cefe1287a3a99a48008bf93f0f79e333": {
        "title": "LLMs with Personalities in Multi-issue Negotiation Games",
        "authors": [
            "Sean Noh",
            "Ho-Chun Herbert Chang"
        ],
        "date": "2024/05/08",
        "pdf": "http://arxiv.org/pdf/2405.05248",
        "abstract": "Powered by large language models (LLMs), AI agents have become capable of many human tasks. Using the most canonical definitions of the Big Five personality, we measure the ability of LLMs to negotiate within a game-theoretical framework, as well as methodological challenges to measuring notions of fairness and risk. Simulations (n=1,500) for both single-issue and multi-issue negotiation reveal increase in domain complexity with asymmetric issue valuations improve agreement rates but decrease surplus from aggressive negotiation. Through gradient-boosted regression and Shapley explainers, we find high openness, conscientiousness, and neuroticism are associated with fair tendencies; low agreeableness and low openness are associated with rational tendencies. Low conscientiousness is associated with high toxicity. These results indicate that LLMs may have built-in guardrails that default to fair behavior, but can be &#34;jail broken&#34; to exploit agreeable opponents. We also offer pragmatic insight in how negotiation bots can be designed, and a framework of assessing negotiation behavior based on game theory and computational social science.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ],
            [
                "Interaction",
                "Game Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.05248"
    },
    "8056aba2da622463a647edc55787daf9": {
        "title": "Enhancing the Efficiency and Accuracy of Underlying Asset Reviews in Structured Finance: The Application of Multi-agent Framework",
        "authors": [
            "Xiangpeng Wan",
            "Haicheng Deng",
            "Kai Zou",
            "Shiqi Xu"
        ],
        "date": "2024/05/07",
        "pdf": "http://arxiv.org/pdf/2405.04294",
        "abstract": "Structured finance, which involves restructuring diverse assets into securities like MBS, ABS, and CDOs, enhances capital market efficiency but presents significant due diligence challenges. This study explores the integration of artificial intelligence (AI) with traditional asset review processes to improve efficiency and accuracy in structured finance. Using both open-sourced and close-sourced large language models (LLMs), we demonstrate that AI can automate the verification of information between loan applications and bank statements effectively. While close-sourced models such as GPT-4 show superior performance, open-sourced models like LLAMA3 offer a cost-effective alternative. Dual-agent systems further increase accuracy, though this comes with higher operational costs. This research highlights AI&#39;s potential to minimize manual errors and streamline due diligence, suggesting a broader application of AI in financial document analysis and risk management.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Application",
                "Finance"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.04294"
    },
    "ce0125bf6fd7254260d4181c039c17dc": {
        "title": "Agent Design Pattern Catalogue: A Collection of Architectural Patterns for Foundation Model based Agents",
        "authors": [
            "Yue Liu",
            "Sin Kit Lo",
            "Qinghua Lu",
            "Liming Zhu",
            "Dehai Zhao",
            "Xiwei Xu",
            "Stefan Harrer",
            "Jon Whittle"
        ],
        "date": "2024/05/16",
        "pdf": "http://arxiv.org/pdf/2405.10467",
        "abstract": "Foundation model-enabled generative artificial intelligence facilitates the development and implementation of agents, which can leverage distinguished reasoning and language processing capabilities to takes a proactive, autonomous role to pursue users&#39; goals. Nevertheless, there is a lack of systematic knowledge to guide practitioners in designing the agents considering challenges of goal-seeking (including generating instrumental goals and plans), such as hallucinations inherent in foundation models, explainability of reasoning process, complex accountability, etc. To address this issue, we have performed a systematic literature review to understand the state-of-the-art foundation model-based agents and the broader ecosystem. In this paper, we present a pattern catalogue consisting of 18 architectural patterns with analyses of the context, forces, and trade-offs as the outcomes from the previous literature review. We propose a decision model for selecting the patterns. The proposed catalogue can provide holistic guidance for the effective use of patterns, and support the architecture design of foundation model-based agents by facilitating goal-seeking and plan generation.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.10467"
    },
    "94a565cf17ac32e1846fc0b3fffad4ec": {
        "title": "Latent State Estimation Helps UI Agents to Reason",
        "authors": [
            "William E Bishop",
            "Alice Li",
            "Christopher Rawles",
            "Oriana Riva"
        ],
        "date": "2024/05/17",
        "pdf": "http://arxiv.org/pdf/2405.11120",
        "abstract": "A common problem for agents operating in real-world environments is that the response of an environment to their actions may be non-deterministic and observed through noise. This renders environmental state and progress towards completing a task latent. Despite recent impressive demonstrations of LLM&#39;s reasoning abilities on various benchmarks, whether LLMs can build estimates of latent state and leverage them for reasoning has not been explicitly studied. We investigate this problem in the real-world domain of autonomous UI agents. We establish that appropriately prompting LLMs in a zero-shot manner can be formally understood as forming point estimates of latent state in a textual space. In the context of autonomous UI agents we then show that LLMs used in this manner are more than $76\\%$ accurate at inferring various aspects of latent state, such as performed (vs. commanded) actions and task progression. Using both public and internal benchmarks and three reasoning methods (zero-shot, CoT-SC &amp; ReAct), we show that LLM-powered agents that explicitly estimate and reason about latent state are able to successfully complete up to 1.6x more tasks than those that do not.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.11120"
    },
    "750790b50612eb08e2ba6127a791d3c7": {
        "title": "ALI-Agent: Assessing LLMs&#39; Alignment with Human Values via Agent-based Evaluation",
        "authors": [
            "Jingnan Zheng",
            "Han Wang",
            "An Zhang",
            "Tai D. Nguyen",
            "Jun Sun",
            "Tat-Seng Chua"
        ],
        "date": "2024/05/23",
        "pdf": "http://arxiv.org/pdf/2405.14125",
        "abstract": "Large Language Models (LLMs) can elicit unintended and even harmful content when misaligned with human values, posing severe risks to users and society. To mitigate these risks, current evaluation benchmarks predominantly employ expert-designed contextual scenarios to assess how well LLMs align with human values. However, the labor-intensive nature of these benchmarks limits their test scope, hindering their ability to generalize to the extensive variety of open-world use cases and identify rare but crucial long-tail risks. Additionally, these static tests fail to adapt to the rapid evolution of LLMs, making it hard to evaluate timely alignment issues. To address these challenges, we propose ALI-Agent, an evaluation framework that leverages the autonomous abilities of LLM-powered agents to conduct in-depth and adaptive alignment assessments. ALI-Agent operates through two principal stages: Emulation and Refinement. During the Emulation stage, ALI-Agent automates the generation of realistic test scenarios. In the Refinement stage, it iteratively refines the scenarios to probe long-tail risks. Specifically, ALI-Agent incorporates a memory module to guide test scenario generation, a tool-using module to reduce human labor in tasks such as evaluating feedback from target LLMs, and an action module to refine tests. Extensive experiments across three aspects of human values--stereotypes, morality, and legality--demonstrate that ALI-Agent, as a general evaluation framework, effectively identifies model misalignment. Systematic analysis also validates that the generated test scenarios represent meaningful use cases, as well as integrate enhanced measures to probe long-tail risks. Our code is available at https://github.com/SophieZheng998/ALI-Agent.git",
        "code": "",
        "category": [
            [
                "Stability",
                "Bias"
            ],
            [
                "Automation",
                "Automatic Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.14125"
    },
    "b2904bbe6b5faeec0f25208fc522269e": {
        "title": "Human-Agent Cooperation in Games under Incomplete Information through Natural Language Communication",
        "authors": [
            "Shenghui Chen",
            "Daniel Fried",
            "Ufuk Topcu"
        ],
        "date": "2024/05/23",
        "pdf": "http://arxiv.org/pdf/2405.14173",
        "abstract": "Developing autonomous agents that can strategize and cooperate with humans under information asymmetry is challenging without effective communication in natural language. We introduce a shared-control game, where two players collectively control a token in alternating turns to achieve a common objective under incomplete information. We formulate a policy synthesis problem for an autonomous agent in this game with a human as the other player. To solve this problem, we propose a communication-based approach comprising a language module and a planning module. The language module translates natural language messages into and from a finite set of flags, a compact representation defined to capture player intents. The planning module leverages these flags to compute a policy using an asymmetric information-set Monte Carlo tree search with flag exchange algorithm we present. We evaluate the effectiveness of this approach in a testbed based on Gnomes at Night, a search-and-find maze board game. Results of human subject experiments show that communication narrows the information gap between players and enhances human-agent cooperation efficiency with fewer turns.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.14173"
    },
    "4d296b8ae0f8197119be49892f53d198": {
        "title": "AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents",
        "authors": [
            "Christopher Rawles",
            "Sarah Clinckemaillie",
            "Yifan Chang",
            "Jonathan Waltz",
            "Gabrielle Lau",
            "Marybeth Fair",
            "Alice Li",
            "William Bishop",
            "Wei Li",
            "Folawiyo Campbell-Ajala",
            "Daniel Toyama",
            "Robert Berry",
            "Divya Tyamagundlu",
            "Timothy Lillicrap",
            "Oriana Riva"
        ],
        "date": "2024/05/23",
        "pdf": "http://arxiv.org/pdf/2405.14573",
        "abstract": "Autonomous agents that execute human tasks by controlling computers can enhance human productivity and application accessibility. However, progress in this field will be driven by realistic and reproducible benchmarks. We present AndroidWorld, a fully functional Android environment that provides reward signals for 116 programmatic tasks across 20 real-world Android apps. Unlike existing interactive environments, which provide a static test set, AndroidWorld dynamically constructs tasks that are parameterized and expressed in natural language in unlimited ways, thus enabling testing on a much larger and more realistic suite of tasks. To ensure reproducibility, each task includes dedicated initialization, success-checking, and tear-down logic, which modifies and inspects the device&#39;s system state. We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld&#39;s tasks, leaving ample room for future work. Furthermore, we adapt a popular desktop web agent to work on Android, which we find to be less effective on mobile, suggesting future research is needed to achieve universal, cross-platform agents. Finally, we also conduct a robustness analysis, showing that task variations can significantly affect agent performance, demonstrating that without such testing, agent performance metrics may not fully reflect practical challenges. AndroidWorld and the experiments in this paper are available at github.com/google-research/android_world.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ],
            [
                "Infrastructure",
                "Environment&Platform"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.14573"
    },
    "241a53b94a75c87f40db449ad7d7c09f": {
        "title": "CityGPT: Towards Urban IoT Learning, Analysis and Interaction with Multi-Agent System",
        "authors": [
            "Qinghua Guan",
            "Jinhui Ouyang",
            "Di Wu",
            "Weiren Yu"
        ],
        "date": "2024/05/23",
        "pdf": "http://arxiv.org/pdf/2405.14691",
        "abstract": "The spatiotemporal data generated by massive sensors in the Internet of Things (IoT) is extremely dynamic, heterogeneous, large scale and time-dependent. It poses great challenges (e.g. accuracy, reliability, and stability) in real-time analysis and decision making for different IoT applications. The complexity of IoT data prevents the common people from gaining a deeper understanding of it. Agentized systems help address the lack of data insight for the common people. We propose a generic framework, namely CityGPT, to facilitate the learning and analysis of IoT time series with an end-to-end paradigm. CityGPT employs three agents to accomplish the spatiotemporal analysis of IoT data. The requirement agent facilitates user inputs based on natural language. Then, the analysis tasks are decomposed into temporal and spatial analysis processes, completed by corresponding data analysis agents (temporal and spatial agents). Finally, the spatiotemporal fusion agent visualizes the system&#39;s analysis results by receiving analysis results from data analysis agents and invoking sub-visualization agents, and can provide corresponding textual descriptions based on user demands. To increase the insight for common people using our framework, we have agnentized the framework, facilitated by a large language model (LLM), to increase the data comprehensibility. Our evaluation results on real-world data with different time dependencies show that the CityGPT framework can guarantee robust performance in IoT computing.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.14691"
    },
    "71fde0ae3293374724587616030740e8": {
        "title": "Evaluating Tool-Augmented Agents in Remote Sensing Platforms",
        "authors": [
            "Simranjit Singh",
            "Michael Fore",
            "Dimitrios Stamoulis"
        ],
        "date": "2024/04/23",
        "pdf": "http://arxiv.org/pdf/2405.00709",
        "abstract": "Tool-augmented Large Language Models (LLMs) have shown impressive capabilities in remote sensing (RS) applications. However, existing benchmarks assume question-answering input templates over predefined image-text data pairs. These standalone instructions neglect the intricacies of realistic user-grounded tasks. Consider a geospatial analyst: they zoom in a map area, they draw a region over which to collect satellite imagery, and they succinctly ask &#34;Detect all objects here&#34;. Where is `here`, if it is not explicitly hardcoded in the image-text template, but instead is implied by the system state, e.g., the live map positioning? To bridge this gap, we present GeoLLM-QA, a benchmark designed to capture long sequences of verbal, visual, and click-based actions on a real UI platform. Through in-depth evaluation of state-of-the-art LLMs over a diverse set of 1,000 tasks, we offer insights towards stronger agents for RS applications.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ],
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.00709"
    },
    "adf670f5c071558cd2fe0713eb34f114": {
        "title": "LLMSat: A Large Language Model-Based Goal-Oriented Agent for Autonomous Space Exploration",
        "authors": [
            "David Maranto"
        ],
        "date": "2024/04/13",
        "pdf": "http://arxiv.org/pdf/2405.01392",
        "abstract": "As spacecraft journey further from Earth with more complex missions, systems of greater autonomy and onboard intelligence are called for. Reducing reliance on human-based mission control becomes increasingly critical if we are to increase our rate of solar-system-wide exploration. Recent work has explored AI-based goal-oriented systems to increase the level of autonomy in mission execution. These systems make use of symbolic reasoning managers to make inferences from the state of a spacecraft and a handcrafted knowledge base, enabling autonomous generation of tasks and re-planning. Such systems have proven to be successful in controlled cases, but they are difficult to implement as they require human-crafted ontological models to allow the spacecraft to understand the world. Reinforcement learning has been applied to train robotic agents to pursue a goal. A new architecture for autonomy is called for. This work explores the application of Large Language Models (LLMs) as the high-level control system of a spacecraft. Using a systems engineering approach, this work presents the design and development of an agentic spacecraft controller by leveraging an LLM as a reasoning engine, to evaluate the utility of such an architecture in achieving higher levels of spacecraft autonomy. A series of deep space mission scenarios simulated within the popular game engine Kerbal Space Program (KSP) are used as case studies to evaluate the implementation against the requirements. It is shown the reasoning and planning abilities of present-day LLMs do not scale well as the complexity of a mission increases, but this can be alleviated with adequate prompting frameworks and strategic selection of the agent&#39;s level of authority over the host spacecraft. This research evaluates the potential of LLMs in augmenting autonomous decision-making systems for future robotic space applications.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.01392"
    },
    "84c6d6849a4e01526b03a20d54035cbb": {
        "title": "Rapid Mobile App Development for Generative AI Agents on MIT App Inventor",
        "authors": [
            "Jaida Gao",
            "Calab Su",
            "Etai Miller",
            "Kevin Lu",
            "Yu Meng"
        ],
        "date": "2024/04/01",
        "pdf": "http://arxiv.org/pdf/2405.01561",
        "abstract": "The evolution of Artificial Intelligence (AI) stands as a pivotal force shaping our society, finding applications across diverse domains such as education, sustainability, and safety. Leveraging AI within mobile applications makes it easily accessible to the public, catalyzing its transformative potential. In this paper, we present a methodology for the rapid development of AI agent applications using the development platform provided by MIT App Inventor. To demonstrate its efficacy, we share the development journey of three distinct mobile applications: SynchroNet for fostering sustainable communities; ProductiviTeams for addressing procrastination; and iHELP for enhancing community safety. All three applications seamlessly integrate a spectrum of generative AI features, leveraging OpenAI APIs. Furthermore, we offer insights gleaned from overcoming challenges in integrating diverse tools and AI functionalities, aiming to inspire young developers to join our efforts in building practical AI agent applications.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.01561"
    },
    "a3bec6082d05d452c748821b265713b1": {
        "title": "Large Language Models (LLMs) as Agents for Augmented Democracy",
        "authors": [
            "Jairo GudiÃ±o-Rosero",
            "Umberto Grandi",
            "CÃ©sar A. Hidalgo"
        ],
        "date": "2024/05/06",
        "pdf": "http://arxiv.org/pdf/2405.03452",
        "abstract": "We explore an augmented democracy system built on off-the-shelf LLMs fine-tuned to augment data on citizen&#39;s preferences elicited over policies extracted from the government programs of the two main candidates of Brazil&#39;s 2022 presidential election. We use a train-test cross-validation setup to estimate the accuracy with which the LLMs predict both: a subject&#39;s individual political choices and the aggregate preferences of the full sample of participants. At the individual level, we find that LLMs predict out of sample preferences more accurately than a &#34;bundle rule&#34;, which would assume that citizens always vote for the proposals of the candidate aligned with their self-reported political orientation. At the population level, we show that a probabilistic sample augmented by an LLM provides a more accurate estimate of the aggregate preferences of a population than the non-augmented probabilistic sample alone. Together, these results indicates that policy preference data augmented using LLMs can capture nuances that transcend party lines and represents a promising avenue of research for data augmentation.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.03452"
    },
    "7280e591137995f5e4d5787bc79f1c9f": {
        "title": "Intelligent Go-Explore: Standing on the Shoulders of Giant Foundation Models",
        "authors": [
            "Cong Lu",
            "Shengran Hu",
            "Jeff Clune"
        ],
        "date": "2024/05/24",
        "pdf": "http://arxiv.org/pdf/2405.15143",
        "abstract": "Go-Explore is a powerful family of algorithms designed to solve hard-exploration problems built on the principle of archiving discovered states, and iteratively returning to and exploring from the most promising states. This approach has led to superhuman performance across a wide variety of challenging problems including Atari games and robotic control, but requires manually designing heuristics to guide exploration (i.e., determine which states to save and explore from, and what actions to consider next), which is time-consuming and infeasible in general. To resolve this, we propose Intelligent Go-Explore (IGE) which greatly extends the scope of the original Go-Explore by replacing these handcrafted heuristics with the intelligence and internalized human notions of interestingness captured by giant pretrained foundation models (FMs). This provides IGE with a human-like ability to instinctively identify how interesting or promising any new state is (e.g., discovering new objects, locations, or behaviors), even in complex environments where heuristics are hard to define. Moreover, IGE offers the exciting opportunity to recognize and capitalize on serendipitous discoveries -- states encountered during exploration that are valuable in terms of exploration, yet where what makes them interesting was not anticipated by the human user. We evaluate our algorithm on a diverse range of language and vision-based tasks that require search and exploration. Across these tasks, IGE strongly exceeds classic reinforcement learning and graph search baselines, and also succeeds where prior state-of-the-art FM agents like Reflexion completely fail. Overall, Intelligent Go-Explore combines the tremendous strengths of FMs and the powerful Go-Explore algorithm, opening up a new frontier of research into creating more generally capable agents with impressive exploration capabilities.",
        "code": "https://github.com/conglu1997/intelligent-go-explore",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.15143"
    },
    "c1543f88fc335d89f5e317fb67d609ed": {
        "title": "Large Language Models Can Self-Improve At Web Agent Tasks",
        "authors": [
            "Ajay Patel",
            "Markus Hofmarcher",
            "Claudiu Leoveanu-Condrei",
            "Marius-Constantin Dinu",
            "Chris Callison-Burch",
            "Sepp Hochreiter"
        ],
        "date": "2024/05/30",
        "pdf": "http://arxiv.org/pdf/2405.20309",
        "abstract": "Training models to act as agents that can effectively navigate and perform actions in a complex environment, such as a web browser, has typically been challenging due to lack of training data. Large language models (LLMs) have recently demonstrated some capability to navigate novel environments as agents in a zero-shot or few-shot fashion, purely guided by natural language instructions as prompts. Recent research has also demonstrated LLMs have the capability to exceed their base performance through self-improvement, i.e. fine-tuning on data generated by the model itself. In this work, we explore the extent to which LLMs can self-improve their performance as agents in long-horizon tasks in a complex environment using the WebArena benchmark. In WebArena, an agent must autonomously navigate and perform actions on web pages to achieve a specified objective. We explore fine-tuning on three distinct synthetic training data mixtures and achieve a 31\\% improvement in task completion rate over the base model on the WebArena benchmark through a self-improvement procedure. We additionally contribute novel evaluation metrics for assessing the performance, robustness, capabilities, and quality of trajectories of our fine-tuned agent models to a greater degree than simple, aggregate-level benchmark scores currently used to measure self-improvement.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.20309"
    },
    "aa807ff46f37c2e93777ace6d24d0fce": {
        "title": "Safe Multi-agent Reinforcement Learning with Natural Language Constraints",
        "authors": [
            "Ziyan Wang",
            "Meng Fang",
            "Tristan Tomilin",
            "Fei Fang",
            "Yali Du"
        ],
        "date": "2024/05/30",
        "pdf": "http://arxiv.org/pdf/2405.20018",
        "abstract": "The role of natural language constraints in Safe Multi-agent Reinforcement Learning (MARL) is crucial, yet often overlooked. While Safe MARL has vast potential, especially in fields like robotics and autonomous vehicles, its full potential is limited by the need to define constraints in pre-designed mathematical terms, which requires extensive domain expertise and reinforcement learning knowledge, hindering its broader adoption. To address this limitation and make Safe MARL more accessible and adaptable, we propose a novel approach named Safe Multi-agent Reinforcement Learning with Natural Language constraints (SMALL). Our method leverages fine-tuned language models to interpret and process free-form textual constraints, converting them into semantic embeddings that capture the essence of prohibited states and behaviours. These embeddings are then integrated into the multi-agent policy learning process, enabling agents to learn policies that minimize constraint violations while optimizing rewards. To evaluate the effectiveness of SMALL, we introduce the LaMaSafe, a multi-task benchmark designed to assess the performance of multiple agents in adhering to natural language constraints. Empirical evaluations across various environments demonstrate that SMALL achieves comparable rewards and significantly fewer constraint violations, highlighting its effectiveness in understanding and enforcing natural language constraints.",
        "code": "",
        "category": [
            [
                "Stability",
                "Safety"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Training",
                "RL"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.20018"
    },
    "599e168857c70e1fcb2c891f1be0fe66": {
        "title": "A Human-Like Reasoning Framework for Multi-Phases Planning Task with Large Language Models",
        "authors": [
            "Chengxing Xie",
            "Difan Zou"
        ],
        "date": "2024/05/28",
        "pdf": "http://arxiv.org/pdf/2405.18208",
        "abstract": "Recent studies have highlighted their proficiency in some simple tasks like writing and coding through various reasoning strategies. However, LLM agents still struggle with tasks that require comprehensive planning, a process that challenges current models and remains a critical research issue. In this study, we concentrate on travel planning, a Multi-Phases planning problem, that involves multiple interconnected stages, such as outlining, information gathering, and planning, often characterized by the need to manage various constraints and uncertainties. Existing reasoning approaches have struggled to effectively address this complex task. Our research aims to address this challenge by developing a human-like planning framework for LLM agents, i.e., guiding the LLM agent to simulate various steps that humans take when solving Multi-Phases problems. Specifically, we implement several strategies to enable LLM agents to generate a coherent outline for each travel query, mirroring human planning patterns. Additionally, we integrate Strategy Block and Knowledge Block into our framework: Strategy Block facilitates information collection, while Knowledge Block provides essential information for detailed planning. Through our extensive experiments, we demonstrate that our framework significantly improves the planning capabilities of LLM agents, enabling them to tackle the travel planning task with improved efficiency and effectiveness. Our experimental results showcase the exceptional performance of the proposed framework; when combined with GPT-4-Turbo, it attains $10\\times$ the performance gains in comparison to the baseline framework deployed on GPT-4-Turbo.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.18208"
    },
    "21c1661e923a0cbe16270816189c6c85": {
        "title": "REVECA: Adaptive Planning and Trajectory-based Validation in Cooperative Language Agents using Information Relevance and Relative Proximity",
        "authors": [
            "SeungWon Seo",
            "SeongRae Noh",
            "Junhyeok Lee",
            "SooBin Lim",
            "Won Hee Lee",
            "HyeongYeop Kang"
        ],
        "date": "2024/05/27",
        "pdf": "http://arxiv.org/pdf/2405.16751",
        "abstract": "We address the challenge of multi-agent cooperation, where agents achieve a common goal by cooperating with decentralized agents under complex partial observations. Existing cooperative agent systems often struggle with efficiently processing continuously accumulating information, managing globally suboptimal planning due to lack of consideration of collaborators, and addressing false planning caused by environmental changes introduced by other collaborators. To overcome these challenges, we propose the RElevance, Proximity, and Validation-Enhanced Cooperative Language Agent (REVECA), a novel cognitive architecture powered by GPT-4o-mini. REVECA enables efficient memory management, optimal planning, and cost-effective prevention of false planning by leveraging Relevance Estimation, Adaptive Planning, and Trajectory-based Validation. Extensive experimental results demonstrate REVECA&#39;s superiority over existing methods across various benchmarks, while a user study reveals its potential for achieving trustworthy human-AI cooperation.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.16751"
    },
    "faa2d1dbd6a9e8f7c1e6bb8a7b396643": {
        "title": "SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering",
        "authors": [
            "John Yang",
            "Carlos E. Jimenez",
            "Alexander Wettig",
            "Kilian Lieret",
            "Shunyu Yao",
            "Karthik Narasimhan",
            "Ofir Press"
        ],
        "date": "2024/05/06",
        "pdf": "http://arxiv.org/pdf/2405.15793",
        "abstract": "Language model (LM) agents are increasingly being used to automate complicated tasks in digital environments. Just as humans benefit from powerful software applications, such as integrated development environments, for complex tasks like software engineering, we posit that LM agents represent a new category of end users with their own needs and abilities, and would benefit from specially-built interfaces to the software they use. We investigate how interface design affects the performance of language model agents. As a result of this exploration, we introduce SWE-agent: a system that facilitates LM agents to autonomously use computers to solve software engineering tasks. SWE-agent&#39;s custom agent-computer interface (ACI) significantly enhances an agent&#39;s ability to create and edit code files, navigate entire repositories, and execute tests and other programs. We evaluate SWE-agent on SWE-bench and HumanEvalFix, achieving state-of-the-art performance on both with a pass@1 rate of 12.5% and 87.7%, respectively, far exceeding the previous state-of-the-art achieved with non-interactive LMs. Finally, we provide insight on how the design of the ACI can impact agents&#39; behavior and performance.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ],
            [
                "Application",
                "Software Engineering"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.15793"
    },
    "d870e9fafc0687b64ab77ac017cbe309": {
        "title": "Hacc-Man: An Arcade Game for Jailbreaking LLMs",
        "authors": [
            "Matheus Valentim",
            "Jeanette Falk",
            "Nanna Inie"
        ],
        "date": "2024/05/24",
        "pdf": "http://arxiv.org/pdf/2405.15902",
        "abstract": "The recent leaps in complexity and fluency of Large Language Models (LLMs) mean that, for the first time in human history, people can interact with computers using natural language alone. This creates monumental possibilities of automation and accessibility of computing, but also raises severe security and safety threats: When everyone can interact with LLMs, everyone can potentially break into the systems running LLMs. All it takes is creative use of language. This paper presents Hacc-Man, a game which challenges its players to &#34;jailbreak&#34; an LLM: subvert the LLM to output something that it is not intended to. Jailbreaking is at the intersection between creative problem solving and LLM security. The purpose of the game is threefold: 1. To heighten awareness of the risks of deploying fragile LLMs in everyday systems, 2. To heighten people&#39;s self-efficacy in interacting with LLMs, and 3. To discover the creative problem solving strategies, people deploy in this novel context.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ],
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.15902"
    },
    "e80b28ea56e0a7ce32e3fc5404c316d7": {
        "title": "GeneAgent: Self-verification Language Agent for Gene Set Knowledge Discovery using Domain Databases",
        "authors": [
            "Zhizheng Wang",
            "Qiao Jin",
            "Chih-Hsuan Wei",
            "Shubo Tian",
            "Po-Ting Lai",
            "Qingqing Zhu",
            "Chi-Ping Day",
            "Christina Ross",
            "Zhiyong Lu"
        ],
        "date": "2024/05/25",
        "pdf": "http://arxiv.org/pdf/2405.16205",
        "abstract": "Gene set knowledge discovery is essential for advancing human functional genomics. Recent studies have shown promising performance by harnessing the power of Large Language Models (LLMs) on this task. Nonetheless, their results are subject to several limitations common in LLMs such as hallucinations. In response, we present GeneAgent, a first-of-its-kind language agent featuring self-verification capability. It autonomously interacts with various biological databases and leverages relevant domain knowledge to improve accuracy and reduce hallucination occurrences. Benchmarking on 1,106 gene sets from different sources, GeneAgent consistently outperforms standard GPT-4 by a significant margin. Moreover, a detailed manual review confirms the effectiveness of the self-verification module in minimizing hallucinations and generating more reliable analytical narratives. To demonstrate its practical utility, we apply GeneAgent to seven novel gene sets derived from mouse B2905 melanoma cell lines, with expert evaluations showing that GeneAgent offers novel insights into gene functions and subsequently expedites knowledge discovery.",
        "code": "",
        "category": [
            [
                "Application",
                "Biology"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.16205"
    },
    "498ac37f486ba2e8dc8ab3363404d05b": {
        "title": "AutoManual: Constructing Instruction Manuals by LLM Agents via Interactive Environmental Learning",
        "authors": [
            "Minghao Chen",
            "Yihang Li",
            "Yanting Yang",
            "Shiyu Yu",
            "Binbin Lin",
            "Xiaofei He"
        ],
        "date": "2024/05/25",
        "pdf": "http://arxiv.org/pdf/2405.16247",
        "abstract": "Large Language Models (LLM) based agents have shown promise in autonomously completing tasks across various domains, e.g., robotics, games, and web navigation. However, these agents typically require elaborate design and expert prompts to solve tasks in specific domains, which limits their adaptability. We introduce AutoManual, a framework enabling LLM agents to autonomously build their understanding through interaction and adapt to new environments. AutoManual categorizes environmental knowledge into diverse rules and optimizes them in an online fashion by two agents: 1) The Planner codes actionable plans based on current rules for interacting with the environment. 2) The Builder updates the rules through a well-structured rule system that facilitates online rule management and essential detail retention. To mitigate hallucinations in managing rules, we introduce a *case-conditioned prompting* strategy for the Builder. Finally, the Formulator agent compiles these rules into a comprehensive manual. The self-generated manual can not only improve the adaptability but also guide the planning of smaller LLMs while being human-readable. Given only one simple demonstration, AutoManual significantly improves task success rates, achieving 97.4\\% with GPT-4-turbo and 86.2\\% with GPT-3.5-turbo on ALFWorld benchmark tasks. The code is available at https://github.com/minghchen/automanual.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.16247"
    },
    "b1821b90ce36752821dab90a5e4cd860": {
        "title": "TimeChara: Evaluating Point-in-Time Character Hallucination of Role-Playing Large Language Models",
        "authors": [
            "Jaewoo Ahn",
            "Taehyun Lee",
            "Junyoung Lim",
            "Jin-Hwa Kim",
            "Sangdoo Yun",
            "Hwaran Lee",
            "Gunhee Kim"
        ],
        "date": "2024/05/28",
        "pdf": "http://arxiv.org/pdf/2405.18027",
        "abstract": "While Large Language Models (LLMs) can serve as agents to simulate human behaviors (i.e., role-playing agents), we emphasize the importance of point-in-time role-playing. This situates characters at specific moments in the narrative progression for three main reasons: (i) enhancing users&#39; narrative immersion, (ii) avoiding spoilers, and (iii) fostering engagement in fandom role-playing. To accurately represent characters at specific time points, agents must avoid character hallucination, where they display knowledge that contradicts their characters&#39; identities and historical timelines. We introduce TimeChara, a new benchmark designed to evaluate point-in-time character hallucination in role-playing LLMs. Comprising 10,895 instances generated through an automated pipeline, this benchmark reveals significant hallucination issues in current state-of-the-art LLMs (e.g., GPT-4o). To counter this challenge, we propose Narrative-Experts, a method that decomposes the reasoning steps and utilizes narrative experts to reduce point-in-time character hallucinations effectively. Still, our findings with TimeChara highlight the ongoing challenges of point-in-time character hallucination, calling for further study.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ],
            [
                "Stability",
                "Hallucination"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2405.18027"
    },
    "c750d6b039a1709a6a9959a889758567": {
        "title": "ResearchArena: Benchmarking Large Language Models&#39; Ability to Collect and Organize Information as Research Agents",
        "authors": [
            "Hao Kang",
            "Chenyan Xiong"
        ],
        "date": "2024/06/13",
        "pdf": "http://arxiv.org/pdf/2406.10291",
        "abstract": "Large language models (LLMs) excel across many natural language processing tasks but face challenges in domain-specific, analytical tasks such as conducting research surveys. This study introduces ResearchArena, a benchmark designed to evaluate LLMs&#39; capabilities in conducting academic surveys$\\unicode{x2013}$a foundational step in academic research. ResearchArena models the process in three stages: (1) information discovery, identifying relevant literature; (2) information selection, evaluating papers&#39; relevance and impact; and (3) information organization, structuring knowledge into hierarchical frameworks such as mind-maps. Notably, mind-map construction is treated as a bonus task, reflecting its supplementary role in survey-writing. To support these evaluations, we construct an offline environment of 12M full-text academic papers and 7.9K survey papers. To ensure ethical compliance, we do not redistribute copyrighted materials; instead, we provide code to construct the environment from the Semantic Scholar Open Research Corpus (S2ORC). Preliminary evaluations reveal that LLM-based approaches underperform compared to simpler keyword-based retrieval methods, underscoring significant opportunities for advancing LLMs in autonomous research.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ],
            [
                "Application",
                "Research"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.10291"
    },
    "e8f100e713dc301cd7404ff87bb6b5aa": {
        "title": "GUI-WORLD: A Dataset for GUI-oriented Multimodal LLM-based Agents",
        "authors": [
            "Dongping Chen",
            "Yue Huang",
            "Siyuan Wu",
            "Jingyu Tang",
            "Liuyi Chen",
            "Yilin Bai",
            "Zhigang He",
            "Chenlong Wang",
            "Huichi Zhou",
            "Yiqiang Li",
            "Tianshuo Zhou",
            "Yue Yu",
            "Chujie Gao",
            "Qihui Zhang",
            "Yi Gui",
            "Zhen Li",
            "Yao Wan",
            "Pan Zhou",
            "Jianfeng Gao",
            "Lichao Sun"
        ],
        "date": "2024/06/16",
        "pdf": "http://arxiv.org/pdf/2406.10819",
        "abstract": "Recently, Multimodal Large Language Models (MLLMs) have been used as agents to control keyboard and mouse inputs by directly perceiving the Graphical User Interface (GUI) and generating corresponding code. However, current agents primarily exhibit excellent understanding capabilities in static environments and are predominantly applied in relatively simple domains, such as Web or mobile interfaces. We argue that a robust GUI agent should be capable of perceiving temporal information on the GUI, including dynamic Web content and multi-step tasks. Additionally, it should possess a comprehensive understanding of various GUI scenarios, including desktop software and multi-window interactions. To this end, this paper introduces a new dataset, termed GUI-World, which features meticulously crafted Human-MLLM annotations, extensively covering six GUI scenarios and eight types of GUI-oriented questions in three formats. We evaluate the capabilities of current state-of-the-art MLLMs, including ImageLLMs and VideoLLMs, in understanding various types of GUI content, especially dynamic and sequential content. Our findings reveal that ImageLLMs struggle with dynamic GUI content without manually annotated keyframes or operation history. On the other hand, VideoLLMs fall short in all GUI-oriented tasks given the sparse GUI video dataset. Based on GUI-World, we take the initial step of leveraging a fine-tuned VideoLLM as a GUI agent, demonstrating an improved understanding of various GUI tasks. However, due to the limitations in the performance of base LLMs, we conclude that using VideoLLMs as GUI agents remains a significant challenge. We believe our work provides valuable insights for future research in dynamic GUI content understanding. The code and dataset are publicly available at our project homepage: https://gui-world.github.io/.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ],
            [
                "Infrastructure",
                "Dataset"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.10819"
    },
    "a73b2790e7940e467a2d7ac436a550f8": {
        "title": "GUICourse: From General Vision Language Models to Versatile GUI Agents",
        "authors": [
            "Wentong Chen",
            "Junbo Cui",
            "Jinyi Hu",
            "Yujia Qin",
            "Junjie Fang",
            "Yue Zhao",
            "Chongyi Wang",
            "Jun Liu",
            "Guirong Chen",
            "Yupeng Huo",
            "Yuan Yao",
            "Yankai Lin",
            "Zhiyuan Liu",
            "Maosong Sun"
        ],
        "date": "2024/06/17",
        "pdf": "http://arxiv.org/pdf/2406.11317",
        "abstract": "Utilizing Graphic User Interface (GUI) for human-computer interaction is essential for accessing a wide range of digital tools. Recent advancements in Vision Language Models (VLMs) highlight the compelling potential to develop versatile agents to help humans finish GUI navigation tasks. However, current VLMs are challenged in terms of fundamental abilities (OCR and grounding) and GUI knowledge (the functions and control methods of GUI elements), preventing them from becoming practical GUI agents. To solve these challenges, we contribute GUICourse, a suite of datasets to train visual-based GUI agents from general VLMs. First, we introduce the GUIEnv dataset to strengthen the OCR and grounding capabilities of VLMs. Then, we introduce the GUIAct and GUIChat datasets to enrich their knowledge of GUI components and interactions. Experiments demonstrate that our GUI agents have better performance on common GUI tasks than their baseline VLMs. Even the small-size GUI agent (with 3.1B parameters) can still work well on single-step and multi-step GUI tasks. Finally, we analyze the different varieties in the training stage of this agent by ablation study. Our source codes and datasets are released at https://github.com/yiye3/GUICourse.",
        "code": "https://github.com/yiye3/guicourse",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.11317"
    },
    "b7788f3550328428ea5ce540b638f532": {
        "title": "Toward Conversational Agents with Context and Time Sensitive Long-term Memory",
        "authors": [
            "Nick Alonso",
            "TomÃ¡s Figliolia",
            "Anthony Ndirango",
            "Beren Millidge"
        ],
        "date": "2024/05/29",
        "pdf": "http://arxiv.org/pdf/2406.00057",
        "abstract": "There has recently been growing interest in conversational agents with long-term memory which has led to the rapid development of language models that use retrieval-augmented generation (RAG). Until recently, most work on RAG has focused on information retrieval from large databases of texts, like Wikipedia, rather than information from long-form conversations. In this paper, we argue that effective retrieval from long-form conversational data faces two unique problems compared to static database retrieval: 1) time/event-based queries, which requires the model to retrieve information about previous conversations based on time or the order of a conversational event (e.g., the third conversation on Tuesday), and 2) ambiguous queries that require surrounding conversational context to understand. To better develop RAG-based agents that can deal with these challenges, we generate a new dataset of ambiguous and time-based questions that build upon a recent dataset of long-form, simulated conversations, and demonstrate that standard RAG based approaches handle such questions poorly. We then develop a novel retrieval model which combines chained-of-table search methods, standard vector-database retrieval, and a prompting method to disambiguate queries, and demonstrate that this approach substantially improves over current methods at solving these tasks. We believe that this new dataset and more advanced RAG agent can act as a key benchmark and stepping stone towards effective memory augmented conversational agents that can be used in a wide variety of AI applications.",
        "code": "https://github.com/Zyphra/TemporalMemoryDataset",
        "category": [
            [
                "Technique For Enhancement",
                "Memory Mechanism"
            ],
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.00057"
    },
    "21aab690f7cd4cbd1de0b1f6393d4e30": {
        "title": "Learning to Clarify: Multi-turn Conversations with Action-Based Contrastive Self-Training",
        "authors": [
            "Maximillian Chen",
            "Ruoxi Sun",
            "Sercan Ã. ArÄ±k",
            "Tomas Pfister"
        ],
        "date": "2024/05/31",
        "pdf": "http://arxiv.org/pdf/2406.00222",
        "abstract": "Large language models (LLMs) aligned through reinforcement learning from human feedback (RLHF) have quickly become one of the dominant paradigms for building intelligent conversational assistant agents. However, despite their strong performance across many benchmarks, LLM-based agents still lack conversational skills such as disambiguation: when generalized assistants are faced with ambiguity, they often overhedge or implicitly guess users&#39; ground-truth intents rather than asking clarification questions, and under task-specific settings, high-quality conversation samples are often limited, affecting models&#39; ability to learn optimal dialogue action policies. We propose Action-Based Contrastive Self-Training (henceforth ACT), a quasi-online preference optimization algorithm based on Direct Preference Optimization (DPO) which allows for sample-efficient dialogue policy learning in multi-turn conversation. We demonstrate ACT&#39;s efficacy under sample-efficient conditions in three difficult conversational tasks: tabular-grounded question-answering, machine reading comprehension, and AmbigSQL, a novel task for disambiguating information-seeking requests for text-to-SQL generation. Additionally, we propose evaluating LLMs&#39; ability to function as conversational agents by examining whether they can implicitly recognize and reason about ambiguity in conversation. ACT demonstrates substantial conversation modeling improvements over standard approaches to supervised fine-tuning and DPO.",
        "code": "",
        "category": [
            [
                "Training",
                "DPO"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.00222"
    },
    "86aec45a3853272af15d2b2d2c6ae12d": {
        "title": "Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration",
        "authors": [
            "Junyang Wang",
            "Haiyang Xu",
            "Haitao Jia",
            "Xi Zhang",
            "Ming Yan",
            "Weizhou Shen",
            "Ji Zhang",
            "Fei Huang",
            "Jitao Sang"
        ],
        "date": "2024/06/03",
        "pdf": "http://arxiv.org/pdf/2406.01014",
        "abstract": "Mobile device operation tasks are increasingly becoming a popular multi-modal AI application scenario. Current Multi-modal Large Language Models (MLLMs), constrained by their training data, lack the capability to function effectively as operation assistants. Instead, MLLM-based agents, which enhance capabilities through tool invocation, are gradually being applied to this scenario. However, the two major navigation challenges in mobile device operation tasks, task progress navigation and focus content navigation, are significantly complicated under the single-agent architecture of existing work. This is due to the overly long token sequences and the interleaved text-image data format, which limit performance. To address these navigation challenges effectively, we propose Mobile-Agent-v2, a multi-agent architecture for mobile device operation assistance. The architecture comprises three agents: planning agent, decision agent, and reflection agent. The planning agent generates task progress, making the navigation of history operations more efficient. To retain focus content, we design a memory unit that updates with task progress. Additionally, to correct erroneous operations, the reflection agent observes the outcomes of each operation and handles any mistakes accordingly. Experimental results indicate that Mobile-Agent-v2 achieves over a 30% improvement in task completion compared to the single-agent architecture of Mobile-Agent. The code is open-sourced at https://github.com/X-PLUG/MobileAgent.",
        "code": "https://github.com/x-plug/mobileagent",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.01014"
    },
    "da55b01bed4abf929270ff8bbef859af": {
        "title": "Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization",
        "authors": [
            "Yu-Min Tseng",
            "Yu-Chao Huang",
            "Teng-Yun Hsiao",
            "Wei-Lin Chen",
            "Chao-Wei Huang",
            "Yu Meng",
            "Yun-Nung Chen"
        ],
        "date": "2024/06/03",
        "pdf": "http://arxiv.org/pdf/2406.01171",
        "abstract": "The concept of persona, originally adopted in dialogue literature, has re-surged as a promising framework for tailoring large language models (LLMs) to specific context (e.g., personalized search, LLM-as-a-judge). However, the growing research on leveraging persona in LLMs is relatively disorganized and lacks a systematic taxonomy. To close the gap, we present a comprehensive survey to categorize the current state of the field. We identify two lines of research, namely (1) LLM Role-Playing, where personas are assigned to LLMs, and (2) LLM Personalization, where LLMs take care of user personas. Additionally, we introduce existing methods for LLM personality evaluation. To the best of our knowledge, we present the first survey for role-playing and personalization in LLMs under the unified view of persona. We continuously maintain a paper collection to foster future endeavors: https://github.com/MiuLab/PersonaLLM-Survey",
        "code": "https://github.com/miulab/personallm-survey",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2406.01171"
    },
    "a08093f55986bcc87491fb616bb60ea5": {
        "title": "Re-ReST: Reflection-Reinforced Self-Training for Language Agents",
        "authors": [
            "Zi-Yi Dou",
            "Cheng-Fu Yang",
            "Xueqing Wu",
            "Kai-Wei Chang",
            "Nanyun Peng"
        ],
        "date": "2024/06/03",
        "pdf": "http://arxiv.org/pdf/2406.01495",
        "abstract": "Finetuning language agents with reasoning-action trajectories is effective, but obtaining these trajectories from human annotations or stronger models is costly and sometimes impractical. In this paper, we investigate the use of self-training in language agents, which can generate supervision from the agent itself, offering a promising alternative without relying on human or stronger model demonstrations. Self-training, however, requires high-quality model-generated samples, which are hard to obtain for challenging language agent tasks. To address this, we present Reflection-Reinforced Self-Training (Re-ReST), which uses a \\textit{reflector} to refine low-quality generated samples during self-training. The reflector takes the agent&#39;s output and feedback from an external environment (e.g., unit test results in code generation) to produce improved samples. This technique enhances the quality of inferior samples and efficiently enriches the self-training dataset with higher-quality samples. We conduct extensive experiments on open-source language agents across tasks, including multi-hop question answering, sequential decision-making, code generation, visual question answering, and text-to-image generation. The results demonstrate the effectiveness of self-training and Re-ReST in language agent tasks, with self-training improving baselines by 7.6\\% on HotpotQA and 28.4\\% on AlfWorld, and Re-ReST further boosting performance by 2.0\\% and 14.1\\%, respectively. Our studies also confirm the efficiency of using a reflector to generate high-quality samples for self-training. Moreover, we demonstrate a method to employ reflection during inference without ground-truth feedback, addressing the limitation of previous reflection work. Our code is released at https://github.com/PlusLabNLP/Re-ReST.",
        "code": "https://github.com/PlusLabNLP/Re-ReST",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Training",
                "RL"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.01495"
    },
    "3150a26b3d768a61624882282f316dad": {
        "title": "Chain of Agents: Large Language Models Collaborating on Long-Context Tasks",
        "authors": [
            "Yusen Zhang",
            "Ruoxi Sun",
            "Yanfei Chen",
            "Tomas Pfister",
            "Rui Zhang",
            "Sercan Ã. Arik"
        ],
        "date": "2024/06/04",
        "pdf": "http://arxiv.org/pdf/2406.02818",
        "abstract": "Addressing the challenge of effectively processing long contexts has become a critical issue for Large Language Models (LLMs). Two common strategies have emerged: 1) reducing the input length, such as retrieving relevant chunks by Retrieval-Augmented Generation (RAG), and 2) expanding the context window limit of LLMs. However, both strategies have drawbacks: input reduction has no guarantee of covering the part with needed information, while window extension struggles with focusing on the pertinent information for solving the task. To mitigate these limitations, we propose Chain-of-Agents (CoA), a novel framework that harnesses multi-agent collaboration through natural language to enable information aggregation and context reasoning across various LLMs over long-context tasks. CoA consists of multiple worker agents who sequentially communicate to handle different segmented portions of the text, followed by a manager agent who synthesizes these contributions into a coherent final output. CoA processes the entire input by interleaving reading and reasoning, and it mitigates long context focus issues by assigning each agent a short context. We perform comprehensive evaluation of CoA on a wide range of long-context tasks in question answering, summarization, and code completion, demonstrating significant improvements by up to 10% over strong baselines of RAG, Full-Context, and multi-agent LLMs.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.02818"
    },
    "9289102622122ee14122949cf1ccb40c": {
        "title": "BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents",
        "authors": [
            "Yifei Wang",
            "Dizhan Xue",
            "Shengjie Zhang",
            "Shengsheng Qian"
        ],
        "date": "2024/06/05",
        "pdf": "http://arxiv.org/pdf/2406.03007",
        "abstract": "With the prosperity of large language models (LLMs), powerful LLM-based intelligent agents have been developed to provide customized services with a set of user-defined tools. State-of-the-art methods for constructing LLM agents adopt trained LLMs and further fine-tune them on data for the agent task. However, we show that such methods are vulnerable to our proposed backdoor attacks named BadAgent on various agent tasks, where a backdoor can be embedded by fine-tuning on the backdoor data. At test time, the attacker can manipulate the deployed LLM agents to execute harmful operations by showing the trigger in the agent input or environment. To our surprise, our proposed attack methods are extremely robust even after fine-tuning on trustworthy data. Though backdoor attacks have been studied extensively in natural language processing, to the best of our knowledge, we could be the first to study them on LLM agents that are more dangerous due to the permission to use external tools. Our work demonstrates the clear risk of constructing LLM agents based on untrusted LLMs or data. Our code is public at https://github.com/DPamK/BadAgent",
        "code": "https://github.com/dpamk/badagent",
        "category": [
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.03007"
    },
    "269cd0ac32202d249d19366188e9d849": {
        "title": "Towards Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework",
        "authors": [
            "Xiaoxi Sun",
            "Jinpeng Li",
            "Yan Zhong",
            "Dongyan Zhao",
            "Rui Yan"
        ],
        "date": "2024/06/05",
        "pdf": "http://arxiv.org/pdf/2406.03075",
        "abstract": "The advent of large language models (LLMs) has facilitated the development of natural language text generation. It also poses unprecedented challenges, with content hallucination emerging as a significant concern. Existing solutions often involve expensive and complex interventions during the training process. Moreover, some approaches emphasize problem disassembly while neglecting the crucial validation process, leading to performance degradation or limited applications. To overcome these limitations, we propose a Markov Chain-based multi-agent debate verification framework to enhance hallucination detection accuracy in concise claims. Our method integrates the fact-checking process, including claim detection, evidence retrieval, and multi-agent verification. In the verification stage, we deploy multiple agents through flexible Markov Chain-based debates to validate individual claims, ensuring meticulous verification outcomes. Experimental results across three generative tasks demonstrate that our approach achieves significant improvements over baselines.",
        "code": "",
        "category": [
            [
                "Stability",
                "Hallucination"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.03075"
    },
    "02d61e99fd7fc97a53e4c73445171682": {
        "title": "LLM-based Rewriting of Inappropriate Argumentation using Reinforcement Learning from Machine Feedback",
        "authors": [
            "Timon Ziegenbein",
            "Gabriella Skitalinskaya",
            "Alireza Bayat Makou",
            "Henning Wachsmuth"
        ],
        "date": "2024/06/05",
        "pdf": "http://arxiv.org/pdf/2406.03363",
        "abstract": "Ensuring that online discussions are civil and productive is a major challenge for social media platforms. Such platforms usually rely both on users and on automated detection tools to flag inappropriate arguments of other users, which moderators then review. However, this kind of post-hoc moderation is expensive and time-consuming, and moderators are often overwhelmed by the amount and severity of flagged content. Instead, a promising alternative is to prevent negative behavior during content creation. This paper studies how inappropriate language in arguments can be computationally mitigated. We propose a reinforcement learning-based rewriting approach that balances content preservation and appropriateness based on existing classifiers, prompting an instruction-finetuned large language model (LLM) as our initial policy. Unlike related style transfer tasks, rewriting inappropriate arguments allows deleting and adding content permanently. It is therefore tackled on document level rather than sentence level. We evaluate different weighting schemes for the reward function in both absolute and relative human assessment studies. Systematic experiments on non-parallel data provide evidence that our approach can mitigate the inappropriateness of arguments while largely preserving their content. It significantly outperforms competitive baselines, including few-shot learning, prompting, and humans.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Training",
                "RL"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.03363"
    },
    "dbdb0b9177ee31f171ff0223836e85a4": {
        "title": "Mixture-of-Agents Enhances Large Language Model Capabilities",
        "authors": [
            "Junlin Wang",
            "Jue Wang",
            "Ben Athiwaratkun",
            "Ce Zhang",
            "James Zou"
        ],
        "date": "2024/06/07",
        "pdf": "http://arxiv.org/pdf/2406.04692",
        "abstract": "Recent advances in large language models (LLMs) demonstrate substantial capabilities in natural language understanding and generation tasks. With the growing number of LLMs, how to harness the collective expertise of multiple LLMs is an exciting open direction. Toward this goal, we propose a new approach that leverages the collective strengths of multiple LLMs through a Mixture-of-Agents (MoA) methodology. In our approach, we construct a layered MoA architecture wherein each layer comprises multiple LLM agents. Each agent takes all the outputs from agents in the previous layer as auxiliary information in generating its response. MoA models achieves state-of-art performance on AlpacaEval 2.0, MT-Bench and FLASK, surpassing GPT-4 Omni. For example, our MoA using only open-source LLMs is the leader of AlpacaEval 2.0 by a substantial gap, achieving a score of 65.1% compared to 57.5% by GPT-4 Omni.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.04692"
    },
    "cd0e509bd2359089f92d7590f198aa63": {
        "title": "WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild",
        "authors": [
            "Bill Yuchen Lin",
            "Yuntian Deng",
            "Khyathi Chandu",
            "Faeze Brahman",
            "Abhilasha Ravichander",
            "Valentina Pyatkin",
            "Nouha Dziri",
            "Ronan Le Bras",
            "Yejin Choi"
        ],
        "date": "2024/06/07",
        "pdf": "http://arxiv.org/pdf/2406.04770",
        "abstract": "We introduce WildBench, an automated evaluation framework designed to benchmark large language models (LLMs) using challenging, real-world user queries. WildBench consists of 1,024 tasks carefully selected from over one million human-chatbot conversation logs. For automated evaluation with WildBench, we have developed two metrics, WB-Reward and WB-Score, which are computable using advanced LLMs such as GPT-4-turbo. WildBench evaluation uses task-specific checklists to evaluate model outputs systematically and provides structured explanations that justify the scores and comparisons, resulting in more reliable and interpretable automatic judgments. WB-Reward employs fine-grained pairwise comparisons between model responses, generating five potential outcomes: much better, slightly better, slightly worse, much worse, or a tie. Unlike previous evaluations that employed a single baseline model, we selected three baseline models at varying performance levels to ensure a comprehensive pairwise evaluation. Additionally, we propose a simple method to mitigate length bias, by converting outcomes of ``slightly better/worse&#39;&#39; to ``tie&#39;&#39; if the winner response exceeds the loser one by more than $K$ characters. WB-Score evaluates the quality of model outputs individually, making it a fast and cost-efficient evaluation metric. WildBench results demonstrate a strong correlation with the human-voted Elo ratings from Chatbot Arena on hard tasks. Specifically, WB-Reward achieves a Pearson correlation of 0.98 with top-ranking models. Additionally, WB-Score reaches 0.95, surpassing both ArenaHard&#39;s 0.91 and AlpacaEval2.0&#39;s 0.89 for length-controlled win rates, as well as the 0.87 for regular win rates.",
        "code": "https://github.com/allenai/wildbench",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.04770"
    },
    "d9f06df47f1047513338ea5d9a7a4b10": {
        "title": "SelfGoal: Your Language Agents Already Know How to Achieve High-level Goals",
        "authors": [
            "Ruihan Yang",
            "Jiangjie Chen",
            "Yikai Zhang",
            "Siyu Yuan",
            "Aili Chen",
            "Kyle Richardson",
            "Yanghua Xiao",
            "Deqing Yang"
        ],
        "date": "2024/06/07",
        "pdf": "http://arxiv.org/pdf/2406.04784",
        "abstract": "Language agents powered by large language models (LLMs) are increasingly valuable as decision-making tools in domains such as gaming and programming. However, these agents often face challenges in achieving high-level goals without detailed instructions and in adapting to environments where feedback is delayed. In this paper, we present SelfGoal, a novel automatic approach designed to enhance agents&#39; capabilities to achieve high-level goals with limited human prior and environmental feedback. The core concept of SelfGoal involves adaptively breaking down a high-level goal into a tree structure of more practical subgoals during the interaction with environments while identifying the most useful subgoals and progressively updating this structure. Experimental results demonstrate that SelfGoal significantly enhances the performance of language agents across various tasks, including competitive, cooperative, and deferred feedback environments. Project page: https://selfgoal-agent.github.io.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.04784"
    },
    "63bf5d41f59732724da5c7dd1eefabb2": {
        "title": "Peer Review as A Multi-Turn and Long-Context Dialogue with Role-Based Interactions",
        "authors": [
            "Cheng Tan",
            "Dongxin Lyu",
            "Siyuan Li",
            "Zhangyang Gao",
            "Jingxuan Wei",
            "Siqi Ma",
            "Zicheng Liu",
            "Stan Z. Li"
        ],
        "date": "2024/06/09",
        "pdf": "http://arxiv.org/pdf/2406.05688",
        "abstract": "Large Language Models (LLMs) have demonstrated wide-ranging applications across various fields and have shown significant potential in the academic peer-review process. However, existing applications are primarily limited to static review generation based on submitted papers, which fail to capture the dynamic and iterative nature of real-world peer reviews. In this paper, we reformulate the peer-review process as a multi-turn, long-context dialogue, incorporating distinct roles for authors, reviewers, and decision makers. We construct a comprehensive dataset containing over 26,841 papers with 92,017 reviews collected from multiple sources, including the top-tier conference and prestigious journal. This dataset is meticulously designed to facilitate the applications of LLMs for multi-turn dialogues, effectively simulating the complete peer-review process. Furthermore, we propose a series of metrics to evaluate the performance of LLMs for each role under this reformulated peer-review setting, ensuring fair and comprehensive evaluations. We believe this work provides a promising perspective on enhancing the LLM-driven peer-review process by incorporating dynamic, role-based interactions. It aligns closely with the iterative and interactive nature of real-world academic peer review, offering a robust foundation for future research and development in this area. We open-source the dataset at https://github.com/chengtan9907/ReviewMT.",
        "code": "https://github.com/chengtan9907/reviewmt",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ],
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.05688"
    },
    "9c84d36ed7499d328b5a04b9ad50d85f": {
        "title": "Can Language Models Serve as Text-Based World Simulators?",
        "authors": [
            "Ruoyao Wang",
            "Graham Todd",
            "Ziang Xiao",
            "Xingdi Yuan",
            "Marc-Alexandre CÃ´tÃ©",
            "Peter Clark",
            "Peter Jansen"
        ],
        "date": "2024/06/10",
        "pdf": "http://arxiv.org/pdf/2406.06485",
        "abstract": "Virtual environments play a key role in benchmarking advances in complex planning and decision-making tasks but are expensive and complicated to build by hand. Can current language models themselves serve as world simulators, correctly predicting how actions change different world states, thus bypassing the need for extensive manual coding? Our goal is to answer this question in the context of text-based simulators. Our approach is to build and use a new benchmark, called ByteSized32-State-Prediction, containing a dataset of text game state transitions and accompanying game tasks. We use this to directly quantify, for the first time, how well LLMs can serve as text-based world simulators. We test GPT-4 on this dataset and find that, despite its impressive performance, it is still an unreliable world simulator without further innovations. This work thus contributes both new insights into current LLM&#39;s capabilities and weaknesses, as well as a novel benchmark to track future progress as new models appear.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.06485"
    },
    "ad75548bfd9b38bc7c85370ad899e213": {
        "title": "GameBench: Evaluating Strategic Reasoning Abilities of LLM Agents",
        "authors": [
            "Anthony Costarelli",
            "Mat Allen",
            "Roman Hauksson",
            "Grace Sodunke",
            "Suhas Hariharan",
            "Carlson Cheng",
            "Wenjie Li",
            "Joshua Clymer",
            "Arjun Yadav"
        ],
        "date": "2024/06/07",
        "pdf": "http://arxiv.org/pdf/2406.06613",
        "abstract": "Large language models have demonstrated remarkable few-shot performance on many natural language understanding tasks. Despite several demonstrations of using large language models in complex, strategic scenarios, there lacks a comprehensive framework for evaluating agents&#39; performance across various types of reasoning found in games. To address this gap, we introduce GameBench, a cross-domain benchmark for evaluating strategic reasoning abilities of LLM agents. We focus on 9 different game environments, where each covers at least one axis of key reasoning skill identified in strategy games, and select games for which strategy explanations are unlikely to form a significant portion of models&#39; pretraining corpuses. Our evaluations use GPT-3 and GPT-4 in their base form along with two scaffolding frameworks designed to enhance strategic reasoning ability: Chain-of-Thought (CoT) prompting and Reasoning Via Planning (RAP). Our results show that none of the tested models match human performance, and at worst GPT-4 performs worse than random action. CoT and RAP both improve scores but not comparable to human levels.",
        "code": "https://github.com/Joshuaclymer/GameBench",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.06613"
    },
    "e180bb7bf6f20677a576c22b725e2f3f": {
        "title": "Agent-SiMT: Agent-assisted Simultaneous Machine Translation with Large Language Models",
        "authors": [
            "Shoutao Guo",
            "Shaolei Zhang",
            "Zhengrui Ma",
            "Min Zhang",
            "Yang Feng"
        ],
        "date": "2024/06/11",
        "pdf": "http://arxiv.org/pdf/2406.06910",
        "abstract": "Simultaneous Machine Translation (SiMT) generates target translations while reading the source sentence. It relies on a policy to determine the optimal timing for reading sentences and generating translations. Existing SiMT methods generally adopt the traditional Transformer architecture, which concurrently determines the policy and generates translations. While they excel at determining policies, their translation performance is suboptimal. Conversely, Large Language Models (LLMs), trained on extensive corpora, possess superior generation capabilities, but it is difficult for them to acquire translation policy through the training methods of SiMT. Therefore, we introduce Agent-SiMT, a framework combining the strengths of LLMs and traditional SiMT methods. Agent-SiMT contains the policy-decision agent and the translation agent. The policy-decision agent is managed by a SiMT model, which determines the translation policy using partial source sentence and translation. The translation agent, leveraging an LLM, generates translation based on the partial source sentence. The two agents collaborate to accomplish SiMT. Experiments demonstrate that Agent-SiMT attains state-of-the-art performance.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.06910"
    },
    "db18353b2d2aa343b33a016a72e601ce": {
        "title": "CoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation",
        "authors": [
            "Renhao Li",
            "Minghuan Tan",
            "Derek F. Wong",
            "Min Yang"
        ],
        "date": "2024/06/11",
        "pdf": "http://arxiv.org/pdf/2406.07054",
        "abstract": "In recent years, instruction fine-tuning (IFT) on large language models (LLMs) has garnered considerable attention to enhance model performance on unseen tasks. Attempts have been made on automatic construction and effective selection for IFT data. However, we posit that previous methods have not fully harnessed the potential of LLMs for enhancing data quality. The responses within IFT data could be further enhanced by leveraging the capabilities of LLMs themselves. In this paper, we propose CoEvol, an LLM-based multi-agent cooperation framework for the improvement of responses to instructions. To effectively refine the responses, we develop an iterative framework following a debate-advise-edit-judge paradigm. A two-stage multi-agent debate strategy is further devised to ensure the diversity and reliability of editing suggestions within the framework. Empirically, models equipped with CoEvol outperform competitive baselines evaluated by MT-Bench and AlpacaEval, demonstrating its effectiveness in enhancing instruction-following capabilities for LLMs.",
        "code": "https://github.com/lirenhao1997/coevol",
        "category": [
            [
                "Training",
                "Fine tuning"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.07054"
    },
    "e70cbbb7be0f0f89684f14244681fe64": {
        "title": "Towards Human-AI Collaboration in Healthcare: Guided Deferral Systems with Large Language Models",
        "authors": [
            "Joshua Strong",
            "Qianhui Men",
            "Alison Noble"
        ],
        "date": "2024/06/11",
        "pdf": "http://arxiv.org/pdf/2406.07212",
        "abstract": "Large language models (LLMs) present a valuable technology for various applications in healthcare, but their tendency to hallucinate introduces unacceptable uncertainty in critical decision-making situations. Human-AI collaboration (HAIC) can mitigate this uncertainty by combining human and AI strengths for better outcomes. This paper presents a novel guided deferral system that provides intelligent guidance when AI defers cases to human decision-makers. We leverage LLMs&#39; verbalisation capabilities and internal states to create this system, demonstrating that fine-tuning small-scale LLMs with data from large-scale LLMs greatly enhances performance while maintaining computational efficiency and data privacy. A pilot study showcases the effectiveness of our proposed deferral system.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Human-Agent Interaction"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.07212"
    },
    "8c868b243c898b5c69dfffa74887c7df": {
        "title": "StreamBench: Towards Benchmarking Continuous Improvement of Language Agents",
        "authors": [
            "Cheng-Kuang Wu",
            "Zhi Rui Tam",
            "Chieh-Yen Lin",
            "Yun-Nung Chen",
            "Hung-yi Lee"
        ],
        "date": "2024/06/13",
        "pdf": "http://arxiv.org/pdf/2406.08747",
        "abstract": "Recent works have shown that large language model (LLM) agents are able to improve themselves from experience, which is an important ability for continuous enhancement post-deployment. However, existing benchmarks primarily evaluate their innate capabilities and do not assess their ability to improve over time. To address this gap, we introduce StreamBench, a pioneering benchmark designed to evaluate the continuous improvement of LLM agents over an input-feedback sequence. StreamBench simulates an online learning environment where LLMs receive a continuous flow of feedback stream and iteratively enhance their performance. In addition, we propose several simple yet effective baselines for improving LLMs on StreamBench, and provide a comprehensive analysis to identify critical components that contribute to successful streaming strategies. Our work serves as a stepping stone towards developing effective online learning strategies for LLMs, paving the way for more adaptive AI systems in streaming scenarios. Source code: https://github.com/stream-bench/stream-bench. Benchmark website: https://stream-bench.github.io.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.08747"
    },
    "357e3fd79056c360acc4d8ebf786ac35": {
        "title": "Multi-Agent Software Development through Cross-Team Collaboration",
        "authors": [
            "Zhuoyun Du",
            "Chen Qian",
            "Wei Liu",
            "Zihao Xie",
            "Yifei Wang",
            "Yufan Dang",
            "Weize Chen",
            "Cheng Yang"
        ],
        "date": "2024/06/13",
        "pdf": "http://arxiv.org/pdf/2406.08979",
        "abstract": "The latest breakthroughs in Large Language Models (LLMs), eg., ChatDev, have catalyzed profound transformations, particularly through multi-agent collaboration for software development. LLM agents can collaborate in teams like humans, and follow the waterfall model to sequentially work on requirements analysis, development, review, testing, and other phases to perform autonomous software generation. However, for an agent team, each phase in a single development process yields only one possible outcome. This results in the completion of only one development chain, thereby losing the opportunity to explore multiple potential decision paths within the solution space. Consequently, this may lead to obtaining suboptimal results. To address this challenge, we introduce Cross-Team Collaboration (CTC), a scalable multi-team framework that enables orchestrated teams to jointly propose various decisions and communicate with their insights in a cross-team collaboration environment for superior content generation. Experimental results in software development reveal a notable increase in quality compared to state-of-the-art baselines, underscoring the efficacy of our framework. The significant improvements in story generation demonstrate the promising generalization ability of our framework across various domains. We anticipate that our work will guide LLM agents towards a cross-team paradigm and contribute to their significant growth in but not limited to software development. The code and data will be available at https://github.com/OpenBMB/ChatDev.",
        "code": "https://github.com/openbmb/chatdev",
        "category": [
            [
                "Application",
                "Software Engineering"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.08979"
    },
    "5e681fd2374814e343b6a031a00e0904": {
        "title": "RePrompt: Planning by Automatic Prompt Engineering for Large Language Models Agents",
        "authors": [
            "Weizhe Chen",
            "Sven Koenig",
            "Bistra Dilkina"
        ],
        "date": "2024/06/17",
        "pdf": "http://arxiv.org/pdf/2406.11132",
        "abstract": "In the past year, large language models (LLMs) have had remarkable success in domains outside the traditional natural language processing, and their capacity is further expanded into the so-called LLM agents when connected with external tools. In all domains, the prompt to the LLMs has been shown to make a big difference in what the LLM would generate and thus affect the performance of the LLM agents. Therefore, automatic prompt engineering (APE) has become an important question for many researchers and users of LLMs. However, previous works in APE rely on a final checker to evaluate the performance of the given prompt -- a requirement that is hard to meet in the case of LLM agents, where intermediate feedback is easier to obtain, and the final evaluation could be expensive, inaccurate, or even missing. In this paper, we propose a novel method, \\textsc{RePrompt}, which does a ``gradient descent&#34;-like approach to optimize the step-by-step instructions in the prompts given to LLM agents, based on the chat history obtained from interactions and reflections with LLM agents. By leveraging intermediate feedback, \\textsc{RePrompt} can optimize the prompt without the need for a final solution checker. We evaluate our approach on PDDL generation, TravelPlanner, and Meeting Planning to show that our method could generally improve performance for different reasoning tasks.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.11132"
    },
    "5af58f701b7864f75b5d42de686ee234": {
        "title": "Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector",
        "authors": [
            "Xiaoxue Cheng",
            "Junyi Li",
            "Wayne Xin Zhao",
            "Hongzhi Zhang",
            "Fuzheng Zhang",
            "Di Zhang",
            "Kun Gai",
            "Ji-Rong Wen"
        ],
        "date": "2024/06/17",
        "pdf": "http://arxiv.org/pdf/2406.11277",
        "abstract": "Hallucination detection is a challenging task for large language models (LLMs), and existing studies heavily rely on powerful closed-source LLMs such as GPT-4. In this paper, we propose an autonomous LLM-based agent framework, called HaluAgent, which enables relatively smaller LLMs (e.g. Baichuan2-Chat 7B) to actively select suitable tools for detecting multiple hallucination types such as text, code, and mathematical expression. In HaluAgent, we integrate the LLM, multi-functional toolbox, and design a fine-grained three-stage detection framework along with memory mechanism. To facilitate the effectiveness of HaluAgent, we leverage existing Chinese and English datasets to synthesize detection trajectories for fine-tuning, which endows HaluAgent with the capability for bilingual hallucination detection. Extensive experiments demonstrate that only using 2K samples for tuning LLMs, HaluAgent can perform hallucination detection on various types of tasks and datasets, achieving performance comparable to or even higher than GPT-4 without tool enhancements on both in-domain and out-of-domain datasets. We release our dataset and code at https://github.com/RUCAIBox/HaluAgent.",
        "code": "",
        "category": [
            [
                "Stability",
                "Hallucination"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.11277"
    },
    "223160a127cf70c4accb671a891d7640": {
        "title": "Input Conditioned Graph Generation for Language Agents",
        "authors": [
            "Lukas Vierling",
            "Jie Fu",
            "Kai Chen"
        ],
        "date": "2024/06/17",
        "pdf": "http://arxiv.org/pdf/2406.11555",
        "abstract": "Recent progress in Large Language Models (LLMs) and language agents has demonstrated significant promise for various future applications across multiple disciplines. While traditional approaches to language agents often rely on fixed, handcrafted designs, our research aims to develop both learnable and dynamic agents. Our method uses an existing framework that abstracts language agents as graphs. Within this graph framework, we aim to learn a model that can generate edges for every given input to the language agent. This allows us to generate edges that represent the flow of communication within the graph based on the given input, thereby adjusting the internal communication of a language agent. We learn to generate these edges using a pretrained LLM that is fine-tuned with reinforcement learning. This LLM can be fine-tuned on several datasets simultaneously, and we hypothesize that the model learns to adapt to these different domains during training, achieving good overall performance when encountering data from different domains during deployment. We demonstrate that our approach surpasses the previous static approach by nearly 6% accuracy on a combined dataset of MMLU and CMMLU, and by more than 10% when trained with a sparsity-inducing loss. It also performs superior in additional experiments conducted with the MMLU and Mini Crossword Puzzles datasets. The code is available at https://github.com/lukasVierling/DynamicGPTSwarm.",
        "code": "https://github.com/lukasvierling/dynamicgptswarm",
        "category": [
            [
                "Technique For Enhancement",
                "Search"
            ],
            [
                "Training",
                "RL"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.11555"
    },
    "fad605b82f8013fe20fdbd2e307bed36": {
        "title": "HoLLMwood: Unleashing the Creativity of Large Language Models in Screenwriting via Role Playing",
        "authors": [
            "Jing Chen",
            "Xinyu Zhu",
            "Cheng Yang",
            "Chufan Shi",
            "Yadong Xi",
            "Yuxiang Zhang",
            "Junjie Wang",
            "Jiashu Pu",
            "Rongsheng Zhang",
            "Yujiu Yang",
            "Tian Feng"
        ],
        "date": "2024/06/17",
        "pdf": "http://arxiv.org/pdf/2406.11683",
        "abstract": "Generative AI has demonstrated unprecedented creativity in the field of computer vision, yet such phenomena have not been observed in natural language processing. In particular, large language models (LLMs) can hardly produce written works at the level of human experts due to the extremely high complexity of literature writing. In this paper, we present HoLLMwood, an automated framework for unleashing the creativity of LLMs and exploring their potential in screenwriting, which is a highly demanding task. Mimicking the human creative process, we assign LLMs to different roles involved in the real-world scenario. In addition to the common practice of treating LLMs as ${Writer}$, we also apply LLMs as ${Editor}$, who is responsible for providing feedback and revision advice to ${Writer}$. Besides, to enrich the characters and deepen the plots, we introduce a role-playing mechanism and adopt LLMs as ${Actors}$ that can communicate and interact with each other. Evaluations on automatically generated screenplays show that HoLLMwood substantially outperforms strong baselines in terms of coherence, relevance, interestingness and overall quality.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.11683"
    },
    "4abb5f3980169817507e510eaf75db0c": {
        "title": "Improving Multi-Agent Debate with Sparse Communication Topology",
        "authors": [
            "Yunxuan Li",
            "Yibing Du",
            "Jiageng Zhang",
            "Le Hou",
            "Peter Grabowski",
            "Yeqing Li",
            "Eugene Ie"
        ],
        "date": "2024/06/17",
        "pdf": "http://arxiv.org/pdf/2406.11776",
        "abstract": "Multi-agent debate has proven effective in improving large language models quality for reasoning and factuality tasks. While various role-playing strategies in multi-agent debates have been explored, in terms of the communication among agents, existing approaches adopt a brute force algorithm -- each agent can communicate with all other agents. In this paper, we systematically investigate the effect of communication connectivity in multi-agent systems. Our experiments on GPT and Mistral models reveal that multi-agent debates leveraging sparse communication topology can achieve comparable or superior performance while significantly reducing computational costs. Furthermore, we extend the multi-agent debate framework to multimodal reasoning and alignment labeling tasks, showcasing its broad applicability and effectiveness. Our findings underscore the importance of communication connectivity on enhancing the efficiency and effectiveness of the &#34;society of minds&#34; approach.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.11776"
    },
    "b3f197dd580c7d2034936bda2f25387f": {
        "title": "Towards Rationality in Language and Multimodal Agents: A Survey",
        "authors": [
            "Bowen Jiang",
            "Yangxinyu Xie",
            "Xiaomeng Wang",
            "Yuan Yuan",
            "Zhuoqun Hao",
            "Xinyi Bai",
            "Weijie J. Su",
            "Camillo J. Taylor",
            "Tanwi Mallick"
        ],
        "date": "2024/06/01",
        "pdf": "http://arxiv.org/pdf/2406.00252",
        "abstract": "This work discusses how to build more rational language and multimodal agents and what criteria define rationality in intelligent systems. Rationality is the quality of being guided by reason, characterized by decision-making that aligns with evidence and logical principles. It plays a crucial role in reliable problem-solving by ensuring well-grounded and consistent solutions. Despite their progress, large language models (LLMs) often fall short of rationality due to their bounded knowledge space and inconsistent outputs. In response, recent efforts have shifted toward developing multimodal and multi-agent systems, as well as integrating modules like external tools, programming codes, symbolic reasoners, utility function, and conformal risk controls rather than relying solely on a single LLM for decision-making. This paper surveys state-of-the-art advancements in language and multimodal agents, assesses their role in enhancing rationality, and outlines open challenges and future research directions. We maintain an open repository at https://github.com/bowen-upenn/Agent_Rationality.",
        "code": "",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2406.00252"
    },
    "2f0f904566cf4ea8ccfc9852638da7e0": {
        "title": "The Good, the Bad, and the Hulk-like GPT: Analyzing Emotional Decisions of Large Language Models in Cooperation and Bargaining Games",
        "authors": [
            "Mikhail Mozikov",
            "Nikita Severin",
            "Valeria Bodishtianu",
            "Maria Glushanina",
            "Mikhail Baklashkin",
            "Andrey V. Savchenko",
            "Ilya Makarov"
        ],
        "date": "2024/06/05",
        "pdf": "http://arxiv.org/pdf/2406.03299",
        "abstract": "Behavior study experiments are an important part of society modeling and understanding human interactions. In practice, many behavioral experiments encounter challenges related to internal and external validity, reproducibility, and social bias due to the complexity of social interactions and cooperation in human user studies. Recent advances in Large Language Models (LLMs) have provided researchers with a new promising tool for the simulation of human behavior. However, existing LLM-based simulations operate under the unproven hypothesis that LLM agents behave similarly to humans as well as ignore a crucial factor in human decision-making: emotions. In this paper, we introduce a novel methodology and the framework to study both, the decision-making of LLMs and their alignment with human behavior under emotional states. Experiments with GPT-3.5 and GPT-4 on four games from two different classes of behavioral game theory showed that emotions profoundly impact the performance of LLMs, leading to the development of more optimal strategies. While there is a strong alignment between the behavioral responses of GPT-3.5 and human participants, particularly evident in bargaining games, GPT-4 exhibits consistent behavior, ignoring induced emotions for rationality decisions. Surprisingly, emotional prompting, particularly with `anger&#39; emotion, can disrupt the &#34;superhuman&#34; alignment of GPT-4, resembling human emotional responses.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.03299"
    },
    "880773299ddd850765aa2c59274c2e3f": {
        "title": "Tool-Planner: Task Planning with Clusters across Multiple Tools",
        "authors": [
            "Yanming Liu",
            "Xinyue Peng",
            "Jiannan Cao",
            "Shi Bo",
            "Yuwei Zhang",
            "Xuhong Zhang",
            "Sheng Cheng",
            "Xun Wang",
            "Jianwei Yin",
            "Tianyu Du"
        ],
        "date": "2024/06/06",
        "pdf": "http://arxiv.org/pdf/2406.03807",
        "abstract": "Large language models (LLMs) have demonstrated exceptional reasoning capabilities, enabling them to solve various complex problems. Recently, this ability has been applied to the paradigm of tool learning. Tool learning involves providing examples of tool usage and their corresponding functions, allowing LLMs to formulate plans and demonstrate the process of invoking and executing each tool. LLMs can address tasks that they cannot complete independently, thereby enhancing their potential across different tasks. However, this approach faces two key challenges. First, redundant error correction leads to unstable planning and long execution time. Additionally, designing a correct plan among multiple tools is also a challenge in tool learning. To address these issues, we propose Tool-Planner, a task-processing framework based on toolkits. Tool-Planner groups tools based on the API functions with the same function into a toolkit and allows LLMs to implement planning across the various toolkits. When a tool error occurs, the language model can reselect and adjust tools based on the toolkit. Experiments show that our approach demonstrates a high pass and win rate across different datasets and optimizes the planning scheme for tool learning in models such as GPT-4 and Claude 3, showcasing the potential of our method. Our code is public at \\url{https://github.com/OceannTwT/Tool-Planner}",
        "code": "https://github.com/OceannTwT/Tool-Planner",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ],
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.03807"
    },
    "f5919d5d232d083271739eeed87bcf02": {
        "title": "AgentGym: Evolving Large Language Model-based Agents across Diverse Environments",
        "authors": [
            "Zhiheng Xi",
            "Yiwen Ding",
            "Wenxiang Chen",
            "Boyang Hong",
            "Honglin Guo",
            "Junzhe Wang",
            "Dingwen Yang",
            "Chenyang Liao",
            "Xin Guo",
            "Wei He",
            "Songyang Gao",
            "Lu Chen",
            "Rui Zheng",
            "Yicheng Zou",
            "Tao Gui",
            "Qi Zhang",
            "Xipeng Qiu",
            "Xuanjing Huang",
            "Zuxuan Wu",
            "Yu-Gang Jiang"
        ],
        "date": "2024/06/06",
        "pdf": "http://arxiv.org/pdf/2406.04151",
        "abstract": "Building generalist agents that can handle diverse tasks and evolve themselves across different environments is a long-term goal in the AI community. Large language models (LLMs) are considered a promising foundation to build such agents due to their generalized capabilities. Current approaches either have LLM-based agents imitate expert-provided trajectories step-by-step, requiring human supervision, which is hard to scale and limits environmental exploration; or they let agents explore and learn in isolated environments, resulting in specialist agents with limited generalization. In this paper, we take the first step towards building generally-capable LLM-based agents with self-evolution ability. We identify a trinity of ingredients: 1) diverse environments for agent exploration and learning, 2) a trajectory set to equip agents with basic capabilities and prior knowledge, and 3) an effective and scalable evolution method. We propose AgentGym, a new framework featuring a variety of environments and tasks for broad, real-time, uni-format, and concurrent agent exploration. AgentGym also includes a database with expanded instructions, a benchmark suite, and high-quality trajectories across environments. Next, we propose a novel method, AgentEvol, to investigate the potential of agent self-evolution beyond previously seen data across tasks and environments. Experimental results show that the evolved agents can achieve results comparable to SOTA models. We release the AgentGym suite, including the platform, dataset, benchmark, checkpoints, and algorithm implementations. The AgentGym suite is available on https://github.com/WooooDyy/AgentGym.",
        "code": "https://github.com/woooodyy/agentgym",
        "category": [
            [
                "Infrastructure",
                "Environment&Platform"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.04151"
    },
    "0b295dba3c25b4491625f535f115ef76": {
        "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning",
        "authors": [
            "Xinzhe Li"
        ],
        "date": "2024/06/09",
        "pdf": "http://arxiv.org/pdf/2406.05804",
        "abstract": "Tool use, planning, and feedback learning are currently three prominent paradigms for developing Large Language Model (LLM)-based agents across various tasks. Although numerous frameworks have been devised for each paradigm, their intricate workflows and inconsistent taxonomy create challenges in understanding and reviewing the frameworks across different paradigms. This survey introduces a unified taxonomy to systematically review and discuss these frameworks. Specifically, 1) the taxonomy defines environments/tasks, common LLM-profiled roles or LMPRs (policy models, evaluators, and dynamic models), and universally applicable workflows found in prior work, and 2) it enables a comparison of key perspectives on the implementations of LMPRs and workflow designs across different agent paradigms and frameworks. 3) Finally, we identify three limitations in existing workflow designs and systematically discuss the future work. Resources have been made publicly available at in our GitHub repository https://github.com/xinzhel/LLM-Agent-Survey.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ],
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Technique For Enhancement",
                "RAG"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.05804"
    },
    "be0c09dd961ea2086e7d2141de2db776": {
        "title": "OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer",
        "authors": [
            "Lu Zhang",
            "Tiancheng Zhao",
            "Heting Ying",
            "Yibo Ma",
            "Kyusong Lee"
        ],
        "date": "2024/06/24",
        "pdf": "http://arxiv.org/pdf/2406.16620",
        "abstract": "Recent advancements in Large Language Models (LLMs) have expanded their capabilities to multimodal contexts, including comprehensive video understanding. However, processing extensive videos such as 24-hour CCTV footage or full-length films presents significant challenges due to the vast data and processing demands. Traditional methods, like extracting key frames or converting frames to text, often result in substantial information loss. To address these shortcomings, we develop OmAgent, efficiently stores and retrieves relevant video frames for specific queries, preserving the detailed content of videos. Additionally, it features an Divide-and-Conquer Loop capable of autonomous reasoning, dynamically invoking APIs and tools to enhance query processing and accuracy. This approach ensures robust video understanding, significantly reducing information loss. Experimental results affirm OmAgent&#39;s efficacy in handling various types of videos and complex tasks. Moreover, we have endowed it with greater autonomy and a robust tool-calling system, enabling it to accomplish even more intricate tasks.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.16620"
    },
    "4f90372ee36cb883295d4b7c9812be96": {
        "title": "Towards a copilot in BIM authoring tool using a large language model-based agent for intelligent human-machine interaction",
        "authors": [
            "Changyu Du",
            "Stavros Nousias",
            "AndrÃ© Borrmann"
        ],
        "date": "2024/06/02",
        "pdf": "http://arxiv.org/pdf/2406.16903",
        "abstract": "Facing increasingly complex BIM authoring software and the accompanying expensive learning costs, designers often seek to interact with the software in a more intelligent and lightweight manner. They aim to automate modeling workflows, avoiding obstacles and difficulties caused by software usage, thereby focusing on the design process itself. To address this issue, we proposed an LLM-based autonomous agent framework that can function as a copilot in the BIM authoring tool, answering software usage questions, understanding the user&#39;s design intentions from natural language, and autonomously executing modeling tasks by invoking the appropriate tools. In a case study based on the BIM authoring software Vectorworks, we implemented a software prototype to integrate the proposed framework seamlessly into the BIM authoring scenario. We evaluated the planning and reasoning capabilities of different LLMs within this framework when faced with complex instructions. Our work demonstrates the significant potential of LLM-based agents in design automation and intelligent interaction.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ],
            [
                "Interaction",
                "Human-Agent Interaction"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.16903"
    },
    "a6eae169a20cd0773a8b09bdf50dc8b8": {
        "title": "Mental Modeling of Reinforcement Learning Agents by Language Models",
        "authors": [
            "Wenhao Lu",
            "Xufeng Zhao",
            "Josua Spisak",
            "Jae Hee Lee",
            "Stefan Wermter"
        ],
        "date": "2024/06/26",
        "pdf": "http://arxiv.org/pdf/2406.18505",
        "abstract": "Can emergent language models faithfully model the intelligence of decision-making agents? Though modern language models exhibit already some reasoning ability, and theoretically can potentially express any probable distribution over tokens, it remains underexplored how the world knowledge these pretrained models have memorized can be utilized to comprehend an agent&#39;s behaviour in the physical world. This study empirically examines, for the first time, how well large language models (LLMs) can build a mental model of agents, termed agent mental modelling, by reasoning about an agent&#39;s behaviour and its effect on states from agent interaction history. This research may unveil the potential of leveraging LLMs for elucidating RL agent behaviour, addressing a key challenge in eXplainable reinforcement learning (XRL). To this end, we propose specific evaluation metrics and test them on selected RL task datasets of varying complexity, reporting findings on agent mental model establishment. Our results disclose that LLMs are not yet capable of fully mental modelling agents through inference alone without further innovations. This work thus provides new insights into the capabilities and limitations of modern LLMs.",
        "code": "",
        "category": [
            [
                "Training",
                "RL"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.18505"
    },
    "3d25b7e8de61314b3f8d0abd8bd17354": {
        "title": "Simulating The U.S. Senate: An LLM-Driven Agent Approach to Modeling Legislative Behavior and Bipartisanship",
        "authors": [
            "Zachary R. Baker",
            "Zarif L. Azher"
        ],
        "date": "2024/06/26",
        "pdf": "http://arxiv.org/pdf/2406.18702",
        "abstract": "This study introduces a novel approach to simulating legislative processes using LLM-driven virtual agents, focusing on the U.S. Senate Intelligence Committee. We developed agents representing individual senators and placed them in simulated committee discussions. The agents demonstrated the ability to engage in realistic debate, provide thoughtful reflections, and find bipartisan solutions under certain conditions. Notably, the simulation also showed promise in modeling shifts towards bipartisanship in response to external perturbations. Our results indicate that this LLM-driven approach could become a valuable tool for understanding and potentially improving legislative processes, supporting a broader pattern of findings highlighting how LLM-based agents can usefully model real-world phenomena. Future works will focus on enhancing agent complexity, expanding the simulation scope, and exploring applications in policy testing and negotiation.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.18702"
    },
    "0350140c12a50fafc423f99240ef5982": {
        "title": "Designing and Evaluating Multi-Chatbot Interface for Human-AI Communication: Preliminary Findings from a Persuasion Task",
        "authors": [
            "Sion Yoon",
            "Tae Eun Kim",
            "Yoo Jung Oh"
        ],
        "date": "2024/06/28",
        "pdf": "http://arxiv.org/pdf/2406.19648",
        "abstract": "The dynamics of human-AI communication have been reshaped by language models such as ChatGPT. However, extant research has primarily focused on dyadic communication, leaving much to be explored regarding the dynamics of human-AI communication in group settings. The availability of multiple language model chatbots presents a unique opportunity for scholars to better understand the interaction between humans and multiple chatbots. This study examines the impact of multi-chatbot communication in a specific persuasion setting: promoting charitable donations. We developed an online environment that enables multi-chatbot communication and conducted a pilot experiment utilizing two GPT-based chatbots, Save the Children and UNICEF chatbots, to promote charitable donations. In this study, we present our development process of the multi-chatbot interface and present preliminary findings from a pilot experiment. Analysis of qualitative and quantitative feedback are presented, and limitations are addressed.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Human-Agent Interaction"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.19648"
    },
    "26ee161c0e282de1d2129fbca847c08a": {
        "title": "StackRAG Agent: Improving Developer Answers with Retrieval-Augmented Generation",
        "authors": [
            "Davit Abrahamyan",
            "Fatemeh H. Fard"
        ],
        "date": "2024/06/19",
        "pdf": "http://arxiv.org/pdf/2406.13840",
        "abstract": "Developers spend much time finding information that is relevant to their questions. Stack Overflow has been the leading resource, and with the advent of Large Language Models (LLMs), generative models such as ChatGPT are used frequently. However, there is a catch in using each one separately. Searching for answers is time-consuming and tedious, as shown by the many tools developed by researchers to address this issue. On the other, using LLMs is not reliable, as they might produce irrelevant or unreliable answers (i.e., hallucination). In this work, we present StackRAG, a retrieval-augmented Multiagent generation tool based on LLMs that combines the two worlds: aggregating the knowledge from SO to enhance the reliability of the generated answers. Initial evaluations show that the generated answers are correct, accurate, relevant, and useful.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "RAG"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.13840"
    },
    "7a938c81e0fdf170539ea6aaae2db7e8": {
        "title": "Artificial Leviathan: Exploring Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory",
        "authors": [
            "Gordon Dai",
            "Weijia Zhang",
            "Jinhan Li",
            "Siqi Yang",
            "Chidera Onochie lbe",
            "Srihas Rao",
            "Arthur Caetano",
            "Misha Sra"
        ],
        "date": "2024/06/20",
        "pdf": "http://arxiv.org/pdf/2406.14373",
        "abstract": "The emergence of Large Language Models (LLMs) and advancements in Artificial Intelligence (AI) offer an opportunity for computational social science research at scale. Building upon prior explorations of LLM agent design, our work introduces a simulated agent society where complex social relationships dynamically form and evolve over time. Agents are imbued with psychological drives and placed in a sandbox survival environment. We conduct an evaluation of the agent society through the lens of Thomas Hobbes&#39;s seminal Social Contract Theory (SCT). We analyze whether, as the theory postulates, agents seek to escape a brutish &#34;state of nature&#34; by surrendering rights to an absolute sovereign in exchange for order and security. Our experiments unveil an alignment: Initially, agents engage in unrestrained conflict, mirroring Hobbes&#39;s depiction of the state of nature. However, as the simulation progresses, social contracts emerge, leading to the authorization of an absolute sovereign and the establishment of a peaceful commonwealth founded on mutual cooperation. This congruence between our LLM agent society&#39;s evolutionary trajectory and Hobbes&#39;s theoretical account indicates LLMs&#39; capability to model intricate social dynamics and potentially replicate forces that shape human societies. By enabling such insights into group behavior and emergent societal phenomena, LLM-driven multi-agent simulations, while unable to simulate all the nuances of human behavior, may hold potential for advancing our understanding of social structures, group dynamics, and complex human systems.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.14373"
    },
    "83b4a2a041739b48014ccadeb9369b2b": {
        "title": "Autonomous Agents for Collaborative Task under Information Asymmetry",
        "authors": [
            "Wei Liu",
            "Chenxi Wang",
            "Yifei Wang",
            "Zihao Xie",
            "Rennai Qiu",
            "Yufan Dang",
            "Zhuoyun Du",
            "Weize Chen",
            "Cheng Yang",
            "Chen Qian"
        ],
        "date": "2024/06/21",
        "pdf": "http://arxiv.org/pdf/2406.14928",
        "abstract": "Large Language Model Multi-Agent Systems (LLM-MAS) have achieved great progress in solving complex tasks. It performs communication among agents within the system to collaboratively solve tasks, under the premise of shared information. However, when agents&#39; collaborations are leveraged to perform multi-person tasks, a new challenge arises due to information asymmetry, since each agent can only access the information of its human user. Previous MAS struggle to complete tasks under this condition. To address this, we propose a new MAS paradigm termed iAgents, which denotes Informative Multi-Agent Systems. In iAgents, the human social network is mirrored in the agent network, where agents proactively exchange human information necessary for task resolution, thereby overcoming information asymmetry. iAgents employs a novel agent reasoning mechanism, InfoNav, to navigate agents&#39; communication toward effective information exchange. Together with InfoNav, iAgents organizes human information in a mixed memory to provide agents with accurate and comprehensive information for exchange. Additionally, we introduce InformativeBench, the first benchmark tailored for evaluating LLM agents&#39; task-solving ability under information asymmetry. Experimental results show that iAgents can collaborate within a social network of 140 individuals and 588 relationships, autonomously communicate over 30 turns, and retrieve information from nearly 70,000 messages to complete tasks within 3 minutes.",
        "code": "",
        "category": [
            [
                "Automation",
                "Workflow"
            ]
        ],
        "url": "https://arxiv.org/abs/2406.14928"
    },
    "faa666c9fce4d0852968cb6a47053dd8": {
        "title": "Self-controller: Controlling LLMs with Multi-round Step-by-step Self-awareness",
        "authors": [
            "Xiao Peng",
            "Xufan Geng"
        ],
        "date": "2024/10/01",
        "pdf": "http://arxiv.org/pdf/2410.00359",
        "abstract": "The applications of large language models (LLMs) have been widely spread across all domains. However, the basic abilities such as the controllability of LLMs are still limited. To address this, we propose &#34;Self-controller&#34;, a novel agentic framework bringing self-awareness into LLMs&#39; reasoning logic. The core idea of this work is to maintain states based on the LLM&#39;s response, letting the LLM become self-aware of current status and think step by step in a multi-round chain-of-thought paradigm. Our experiment on the state of textual length has shown the controllability and effectiveness of the Self-controller. We further implement a binary search algorithm to accelerate the generation process based on the linearity and monotonicity of the textual length state. Another advantage of the Self-controller comes with DeepSeek&#39;s Context Caching technology, which significantly saves computational token consumption when a cluster of conversations shares the same prefix of context. Theoretically, we prove that in this scenario the extra time complexity is $O(c \\log n)$. Results of the back-of-the-envelope estimation suggest that the token consumption of our method is no more than twice as much as that of the trivial single-round generation. Furthermore, our ablation study on word constraints demonstrates the Self-controller&#39;s consistent controllability across all foundation models.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.00359"
    },
    "75fdda960504897c17b5d523a4564351": {
        "title": "Conversational Exploratory Search of Scholarly Publications Using Knowledge Graphs",
        "authors": [
            "Phillip Schneider",
            "Florian Matthes"
        ],
        "date": "2024/10/01",
        "pdf": "http://arxiv.org/pdf/2410.00427",
        "abstract": "Traditional search methods primarily depend on string matches, while semantic search targets concept-based matches by recognizing underlying intents and contextual meanings of search terms. Semantic search is particularly beneficial for discovering scholarly publications where differences in vocabulary between users&#39; search terms and document content are common, often yielding irrelevant search results. Many scholarly search engines have adopted knowledge graphs to represent semantic relations between authors, publications, and research concepts. However, users may face challenges when navigating these graphical search interfaces due to the complexity and volume of data, which impedes their ability to discover publications effectively. To address this problem, we developed a conversational search system for exploring scholarly publications using a knowledge graph. We outline the methodical approach for designing and implementing the proposed system, detailing its architecture and functional components. To assess the system&#39;s effectiveness, we employed various performance metrics and conducted a human evaluation with 40 participants, demonstrating how the conversational interface compares against a graphical interface with traditional text search. The findings from our evaluation provide practical insights for advancing the design of conversational search systems.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "RAG"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.00427"
    },
    "fca0a841125221da1d3d4524f85584f0": {
        "title": "Agent-Driven Large Language Models for Mandarin Lyric Generation",
        "authors": [
            "Hong-Hsiang Liu",
            "Yi-Wen Liu"
        ],
        "date": "2024/10/02",
        "pdf": "http://arxiv.org/pdf/2410.01450",
        "abstract": "Generative Large Language Models have shown impressive in-context learning abilities, performing well across various tasks with just a prompt. Previous melody-to-lyric research has been limited by scarce high-quality aligned data and unclear standard for creativeness. Most efforts focused on general themes or emotions, which are less valuable given current language model capabilities. In tonal contour languages like Mandarin, pitch contours are influenced by both melody and tone, leading to variations in lyric-melody fit. Our study, validated by the Mpop600 dataset, confirms that lyricists and melody writers consider this fit during their composition process. In this research, we developed a multi-agent system that decomposes the melody-to-lyric task into sub-tasks, with each agent controlling rhyme, syllable count, lyric-melody alignment, and consistency. Listening tests were conducted via a diffusion-based singing voice synthesizer to evaluate the quality of lyrics generated by different agent groups.",
        "code": "",
        "category": [
            [
                "Application",
                "Art"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.01450"
    },
    "e274a5113a4fe6fdbb728c5d29e994ce": {
        "title": "ExACT: Teaching AI Agents to Explore with Reflective-MCTS and Exploratory Learning",
        "authors": [
            "Xiao Yu",
            "Baolin Peng",
            "Vineeth Vajipey",
            "Hao Cheng",
            "Michel Galley",
            "Jianfeng Gao",
            "Zhou Yu"
        ],
        "date": "2024/10/02",
        "pdf": "http://arxiv.org/pdf/2410.02052",
        "abstract": "Autonomous agents have demonstrated significant potential in automating complex multistep decision-making tasks. However, even state-of-the-art vision-language models (VLMs), such as GPT-4o, still fall short of human-level performance, particularly in intricate web environments and long-horizon tasks. To address these limitations, we present ExACT, an approach to combine test-time search and self-learning to build o1-like models for agentic applications. We first introduce Reflective Monte Carlo Tree Search (R-MCTS), a novel test time algorithm designed to enhance AI agents&#39; ability to explore decision space on the fly. R-MCTS extends traditional MCTS by 1) incorporating contrastive reflection, allowing agents to learn from past interactions and dynamically improve their search efficiency; and 2) using multi-agent debate for reliable state evaluation. Next, we introduce Exploratory Learning, a novel learning strategy to teach agents to search at inference time without relying on any external search algorithms. On the challenging VisualWebArena benchmark, our GPT-4o based R-MCTS agent achieves a 6% to 30% relative improvement across various tasks compared to the previous state-of-the-art. Additionally, we show that the knowledge and experience gained from test-time search can be effectively transferred back to GPT-4o via fine-tuning. After Exploratory Learning, GPT-4o 1) demonstrates the ability to explore the environment, evaluate a state, and backtrack to viable ones when it detects that the current state cannot lead to success, and 2) matches 87% of R-MCTS&#39;s performance while using significantly less compute. Notably, our work demonstrates the compute scaling properties in both training - data collection with R-MCTS - and testing time. These results suggest a promising research direction to enhance VLMs&#39; capabilities for agentic applications via test-time search and self-learning.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Technique For Enhancement",
                "Search"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.02052"
    },
    "66e8cdc503b22e684fb4bb2538ab6661": {
        "title": "Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions",
        "authors": [
            "Angana Borah",
            "Rada Mihalcea"
        ],
        "date": "2024/10/03",
        "pdf": "http://arxiv.org/pdf/2410.02584",
        "abstract": "As Large Language Models (LLMs) continue to evolve, they are increasingly being employed in numerous studies to simulate societies and execute diverse social tasks. However, LLMs are susceptible to societal biases due to their exposure to human-generated data. Given that LLMs are being used to gain insights into various societal aspects, it is essential to mitigate these biases. To that end, our study investigates the presence of implicit gender biases in multi-agent LLM interactions and proposes two strategies to mitigate these biases. We begin by creating a dataset of scenarios where implicit gender biases might arise, and subsequently develop a metric to assess the presence of biases. Our empirical analysis reveals that LLMs generate outputs characterized by strong implicit bias associations (&gt;= 50\\% of the time). Furthermore, these biases tend to escalate following multi-agent interactions. To mitigate them, we propose two strategies: self-reflection with in-context examples (ICE); and supervised fine-tuning. Our research demonstrates that both methods effectively mitigate implicit biases, with the ensemble of fine-tuning and self-reflection proving to be the most successful.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Stability",
                "Bias"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.02584"
    },
    "bda94606c7e1f146cf7b79db89d2642d": {
        "title": "Agents&#39; Room: Narrative Generation through Multi-step Collaboration",
        "authors": [
            "Fantine Huot",
            "Reinald Kim Amplayo",
            "Jennimaria Palomaki",
            "Alice Shoshana Jakobovits",
            "Elizabeth Clark",
            "Mirella Lapata"
        ],
        "date": "2024/10/03",
        "pdf": "http://arxiv.org/pdf/2410.02603",
        "abstract": "Writing compelling fiction is a multifaceted process combining elements such as crafting a plot, developing interesting characters, and using evocative language. While large language models (LLMs) show promise for story writing, they currently rely heavily on intricate prompting, which limits their use. We propose Agents&#39; Room, a generation framework inspired by narrative theory, that decomposes narrative writing into subtasks tackled by specialized agents. To illustrate our method, we introduce Tell Me A Story, a high-quality dataset of complex writing prompts and human-written stories, and a novel evaluation framework designed specifically for assessing long narratives. We show that Agents&#39; Room generates stories that are preferred by expert evaluators over those produced by baseline systems by leveraging collaboration and specialization to decompose the complex story writing task into tractable components. We provide extensive analysis with automated and human-based metrics of the generated output.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.02603"
    },
    "609d619716c0edc1fe11f0b28e10d0c2": {
        "title": "NNetNav: Unsupervised Learning of Browser Agents Through Environment Interaction in the Wild",
        "authors": [
            "Shikhar Murty",
            "Hao Zhu",
            "Dzmitry Bahdanau",
            "Christopher D. Manning"
        ],
        "date": "2024/10/03",
        "pdf": "http://arxiv.org/pdf/2410.02907",
        "abstract": "We introduce NNetNav, a method for unsupervised interaction with websites that generates synthetic demonstrations for training browser agents. Given any website, NNetNav produces these demonstrations by retroactively labeling action sequences from an exploration policy. Most work on training browser agents has relied on expensive human supervision, and the limited prior work on such interaction-based techniques has failed to provide effective search through the exponentially large space of exploration. In contrast, NNetNav exploits the hierarchical structure of language instructions to make this search more tractable: Complex instructions are typically decomposable into simpler sub-tasks, allowing NNetNav to automatically prune interaction episodes when an intermediate trajectory cannot be annotated with a meaningful sub-task. \\texttt{LLama-3.1-8b} finetuned on 10k NNetNav self-generated demonstrations obtains over 16\\% success rate on WebArena, and 35\\% on WebVoyager, an improvement of 15pts and 31pts respectively over zero-shot \\texttt{LLama-3.1-8b}, outperforming zero-shot GPT-4 and reaching the state-of-the-art among unsupervised methods, for both benchmarks.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.02907"
    },
    "9a7d8a75c9b99f8286ed43f6527fbaca": {
        "title": "Large Language Models can Achieve Social Balance",
        "authors": [
            "Pedro Cisneros-Velarde"
        ],
        "date": "2024/10/05",
        "pdf": "http://arxiv.org/pdf/2410.04054",
        "abstract": "Social balance is a concept in sociology which states that if every three individuals in a population achieve certain structures of positive or negative interactions, then the whole population ends up in one faction of positive interactions or divided between two or more antagonistic factions. In this paper, we consider a group of interacting large language models (LLMs) and study how, after continuous interactions, they can achieve social balance. Across three different LLM models, we found that social balance depends on (i) whether interactions are updated based on &#34;relationships&#34;, &#34;appraisals&#34;, or &#34;opinions&#34;; (ii) whether agents update their interactions based on homophily or influence from their peers; and (iii) the number of simultaneous interactions the LLMs consider. When social balance is achieved, its particular structure of positive or negative interactions depends on these three conditions and are different across LLM models and sizes. The stability of interactions and the justification for their update also vary across models. Thus, social balance is driven by the pre-training and alignment particular to each LLM model.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.04054"
    },
    "fae0017f3ad125bc3cb627f8e6f76d53": {
        "title": "MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems",
        "authors": [
            "Zhentao Xie",
            "Jiabao Zhao",
            "Yilei Wang",
            "Jinxin Shi",
            "Yanhong Bai",
            "Xingjiao Wu",
            "Liang He"
        ],
        "date": "2024/10/06",
        "pdf": "http://arxiv.org/pdf/2410.04452",
        "abstract": "Detecting cognitive biases in large language models (LLMs) is a fascinating task that aims to probe the existing cognitive biases within these models. Current methods for detecting cognitive biases in language models generally suffer from incomplete detection capabilities and a restricted range of detectable bias types. To address this issue, we introduced the &#39;MindScope&#39; dataset, which distinctively integrates static and dynamic elements. The static component comprises 5,170 open-ended questions spanning 72 cognitive bias categories. The dynamic component leverages a rule-based, multi-agent communication framework to facilitate the generation of multi-round dialogues. This framework is flexible and readily adaptable for various psychological experiments involving LLMs. In addition, we introduce a multi-agent detection method applicable to a wide range of detection tasks, which integrates Retrieval-Augmented Generation (RAG), competitive debate, and a reinforcement learning-based decision module. Demonstrating substantial effectiveness, this method has shown to improve detection accuracy by as much as 35.10% compared to GPT-4. Codes and appendix are available at https://github.com/2279072142/MindScope.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Stability",
                "Bias"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.04452"
    },
    "11921ebec2a08d560b5255c5a9015fa8": {
        "title": "Adversarial Multi-Agent Evaluation of Large Language Models through Iterative Debates",
        "authors": [
            "Chaithanya Bandi",
            "Abir Harrasse"
        ],
        "date": "2024/10/07",
        "pdf": "http://arxiv.org/pdf/2410.04663",
        "abstract": "This paper explores optimal architectures for evaluating the outputs of large language models (LLMs) using LLMs themselves. We propose a novel framework that interprets LLMs as advocates within an ensemble of interacting agents, allowing them to defend their answers and reach conclusions through a judge and jury system. This approach offers a more dynamic and comprehensive evaluation process compared to traditional human-based assessments or automated metrics. We discuss the motivation behind this framework, its key components, and comparative advantages. We also present a probabilistic model to evaluate the error reduction achieved by iterative advocate systems. Finally, we outline experiments to validate the effectiveness of multi-advocate architectures and discuss future research directions.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.04663"
    },
    "b175232dfcedb04917df8611051b41f3": {
        "title": "ScienceAgentBench: Toward Rigorous Assessment of Language Agents for Data-Driven Scientific Discovery",
        "authors": [
            "Ziru Chen",
            "Shijie Chen",
            "Yuting Ning",
            "Qianheng Zhang",
            "Boshi Wang",
            "Botao Yu",
            "Yifei Li",
            "Zeyi Liao",
            "Chen Wei",
            "Zitong Lu",
            "Vishal Dey",
            "Mingyi Xue",
            "Frazier N. Baker",
            "Benjamin Burns",
            "Daniel Adu-Ampratwum",
            "Xuhui Huang",
            "Xia Ning",
            "Song Gao",
            "Yu Su",
            "Huan Sun"
        ],
        "date": "2024/10/07",
        "pdf": "http://arxiv.org/pdf/2410.05080",
        "abstract": "The advancements of language language models (LLMs) have piqued growing interest in developing LLM-based language agents to automate scientific discovery end-to-end, which has sparked both excitement and skepticism about their true capabilities. In this work, we call for rigorous assessment of agents on individual tasks in a scientific workflow before making bold claims on end-to-end automation. To ensure the scientific authenticity and real-world relevance of our benchmark, we extract 102 tasks from 44 peer-reviewed publications in four disciplines and engage nine subject matter experts to validate them. We unify the target output for every task to a self-contained Python program file and employ an array of evaluation metrics to examine the generated programs, execution results, and costs. Each task goes through multiple rounds of manual validation by annotators and subject matter experts to ensure its annotation quality and scientific plausibility. We also propose two effective strategies to mitigate data contamination concerns. Using our benchmark, we evaluate five open-weight and proprietary LLMs, each with three frameworks: direct prompting, OpenHands CodeAct, and self-debug. Given three attempts for each task, the best-performing agent can only solve 32.4% of the tasks independently and 34.3% with expert-provided knowledge. In addition, we evaluate OpenAI o1 with direct prompting and self-debug, which demonstrates the effectiveness of increasing inference-time compute. Still, our results underscore the limitations of current language agents in generating code for data-driven discovery, let alone end-to-end automation for scientific research.",
        "code": "",
        "category": [
            [
                "Application",
                "Research"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.05080"
    },
    "d9ac3390f7673efbe4bf55d69f29f51f": {
        "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space",
        "authors": [
            "Yu Shang",
            "Yu Li",
            "Keyu Zhao",
            "Likai Ma",
            "Jiahe Liu",
            "Fengli Xu",
            "Yong Li"
        ],
        "date": "2024/10/08",
        "pdf": "http://arxiv.org/pdf/2410.06153",
        "abstract": "Recent advancements in Large Language Models (LLMs) have led to a rapid growth of agentic systems capable of handling a wide range of complex tasks. However, current research largely relies on manual, task-specific design, limiting their adaptability to novel tasks. In this paper, we introduce a new research problem: Modularized LLM Agent Search (MoLAS). We propose a modular design space that abstracts existing LLM agent designs into four fundamental modules with uniform IO interface: Planning, Reasoning, Tool Use, and Memory. Building on this design space, we present a novel LLM agent search framework called AgentSquare, which introduces two core mechanisms, i.e., module evolution and recombination, to efficiently search for optimized LLM agents. To further accelerate the process, we design a performance predictor that uses in-context surrogate models to skip unpromising agent designs. Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs. Moreover, AgentSquare can generate interpretable design insights, enabling a deeper understanding of agentic architecture and its impact on task performance. We believe that the modular design space and AgentSquare search framework offer a platform for fully exploiting the potential of prior successful designs and consolidating the collective efforts of research community. Code repo is available at https://github.com/tsinghua-fib-lab/AgentSquare.",
        "code": "https://github.com/tsinghua-fib-lab/AgentSquare",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.06153"
    },
    "d832d26d2ba9ec69740d15dbf1bed745": {
        "title": "DataEnvGym: Data Generation Agents in Teacher Environments with Student Feedback",
        "authors": [
            "Zaid Khan",
            "Elias Stengel-Eskin",
            "Jaemin Cho",
            "Mohit Bansal"
        ],
        "date": "2024/10/08",
        "pdf": "http://arxiv.org/pdf/2410.06215",
        "abstract": "The process of creating training data to teach models is currently driven by humans, who manually analyze model weaknesses and plan how to create data that improves a student model. Approaches using LLMs as annotators reduce human effort, but still require humans to interpret feedback from evaluations and control the LLM to produce data the student needs. Automating this labor-intensive process by creating autonomous data generation agents - or teachers - is desirable, but requires environments that can simulate the feedback-driven, iterative, closed loop of data creation. To enable rapid, scalable testing for such agents and their modules, we introduce DataEnvGym, a testbed of teacher environments for data generation agents. DataEnvGym frames data generation as a sequential decision-making task, involving an agent consisting of a data generation policy (which generates a plan for creating training data) and a data generation engine (which transforms the plan into data), inside an environment that provides student feedback. The agent&#39;s goal is to improve student performance. Students are iteratively trained and evaluated on generated data, and their feedback (in the form of errors or weak skills) is reported to the agent after each iteration. DataEnvGym includes multiple teacher environment instantiations across 3 levels of structure in the state representation and action space. More structured environments are based on inferred skills and offer more interpretability and curriculum control. We support 4 domains (math, code, VQA, and tool-use) and test multiple students and teachers. Example agents in our teaching environments can iteratively improve students across tasks and settings. Moreover, we show that environments teach different skill levels and test variants of key modules, pointing to future work in improving data generation agents, engines, and feedback mechanisms.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.06215"
    },
    "a5e08df5376f5db531345ee2c19dbb04": {
        "title": "MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering",
        "authors": [
            "Jun Shern Chan",
            "Neil Chowdhury",
            "Oliver Jaffe",
            "James Aung",
            "Dane Sherburn",
            "Evan Mays",
            "Giulio Starace",
            "Kevin Liu",
            "Leon Maksin",
            "Tejal Patwardhan",
            "Lilian Weng",
            "Aleksander MÄdry"
        ],
        "date": "2024/10/09",
        "pdf": "http://arxiv.org/pdf/2410.07095",
        "abstract": "We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering. To this end, we curate 75 ML engineering-related competitions from Kaggle, creating a diverse set of challenging tasks that test real-world ML engineering skills such as training models, preparing datasets, and running experiments. We establish human baselines for each competition using Kaggle&#39;s publicly available leaderboards. We use open-source agent scaffolds to evaluate several frontier language models on our benchmark, finding that the best-performing setup--OpenAI&#39;s o1-preview with AIDE scaffolding--achieves at least the level of a Kaggle bronze medal in 16.9% of competitions. In addition to our main results, we investigate various forms of resource scaling for AI agents and the impact of contamination from pre-training. We open-source our benchmark code (github.com/openai/mle-bench/) to facilitate future research in understanding the ML engineering capabilities of AI agents.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.07095"
    },
    "fc42c6f3a621e50dbc766db0b6787d3f": {
        "title": "I Want to Break Free! Persuasion and Anti-Social Behavior of LLMs in Multi-Agent Settings with Social Hierarchy",
        "authors": [
            "Gian Maria Campedelli",
            "NicolÃ² Penzo",
            "Massimo Stefan",
            "Roberto DessÃ¬",
            "Marco Guerini",
            "Bruno Lepri",
            "Jacopo Staiano"
        ],
        "date": "2024/10/09",
        "pdf": "http://arxiv.org/pdf/2410.07109",
        "abstract": "As Large Language Model (LLM)-based agents become increasingly autonomous and will more freely interact with each other, studying interactions between them becomes crucial to anticipate emergent phenomena and potential risks. Drawing inspiration from the widely popular Stanford Prison Experiment, we contribute to this line of research by studying interaction patterns of LLM agents in a context characterized by strict social hierarchy. We do so by specifically studying two types of phenomena: persuasion and anti-social behavior in simulated scenarios involving a guard and a prisoner agent who seeks to achieve a specific goal (i.e., obtaining additional yard time or escape from prison). Leveraging 200 experimental scenarios for a total of 2,000 machine-machine conversations across five different popular LLMs, we provide a set of noteworthy findings. We first document how some models consistently fail in carrying out a conversation in our multi-agent setup where power dynamics are at play. Then, for the models that were able to engage in successful interactions, we empirically show how the goal that an agent is set to achieve impacts primarily its persuasiveness, while having a negligible effect with respect to the agent&#39;s anti-social behavior. Third, we highlight how agents&#39; personas, and particularly the guard&#39;s personality, drive both the likelihood of successful persuasion from the prisoner and the emergence of anti-social behaviors. Fourth, we show that even without explicitly prompting for specific personalities, anti-social behavior emerges by simply assigning agents&#39; roles. These results bear implications for the development of interactive LLM agents as well as the debate on their societal impact.",
        "code": "",
        "category": [
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.07109"
    },
    "f5c40fbeb360ecb7cabaeaba32be0523": {
        "title": "Embodied Agent Interface: Benchmarking LLMs for Embodied Decision Making",
        "authors": [
            "Manling Li",
            "Shiyu Zhao",
            "Qineng Wang",
            "Kangrui Wang",
            "Yu Zhou",
            "Sanjana Srivastava",
            "Cem Gokmen",
            "Tony Lee",
            "Li Erran Li",
            "Ruohan Zhang",
            "Weiyu Liu",
            "Percy Liang",
            "Li Fei-Fei",
            "Jiayuan Mao",
            "Jiajun Wu"
        ],
        "date": "2024/10/09",
        "pdf": "http://arxiv.org/pdf/2410.07166",
        "abstract": "We aim to evaluate Large Language Models (LLMs) for embodied decision making. While a significant body of work has been leveraging LLMs for decision making in embodied environments, we still lack a systematic understanding of their performance because they are usually applied in different domains, for different purposes, and built based on different inputs and outputs. Furthermore, existing evaluations tend to rely solely on a final success rate, making it difficult to pinpoint what ability is missing in LLMs and where the problem lies, which in turn blocks embodied agents from leveraging LLMs effectively and selectively. To address these limitations, we propose a generalized interface (Embodied Agent Interface) that supports the formalization of various types of tasks and input-output specifications of LLM-based modules. Specifically, it allows us to unify 1) a broad set of embodied decision-making tasks involving both state and temporally extended goals, 2) four commonly-used LLM-based modules for decision making: goal interpretation, subgoal decomposition, action sequencing, and transition modeling, and 3) a collection of fine-grained metrics which break down evaluation into various types of errors, such as hallucination errors, affordance errors, various types of planning errors, etc. Overall, our benchmark offers a comprehensive assessment of LLMs&#39; performance for different subtasks, pinpointing the strengths and weaknesses in LLM-powered embodied AI systems, and providing insights for effective and selective use of LLMs in embodied decision making.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.07166"
    },
    "fde6430e0f70811eedb287d351eb6f35": {
        "title": "DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models",
        "authors": [
            "Yiming Huang",
            "Jianwen Luo",
            "Yan Yu",
            "Yitong Zhang",
            "Fangyu Lei",
            "Yifan Wei",
            "Shizhu He",
            "Lifu Huang",
            "Xiao Liu",
            "Jun Zhao",
            "Kang Liu"
        ],
        "date": "2024/10/09",
        "pdf": "http://arxiv.org/pdf/2410.07331",
        "abstract": "We introduce DA-Code, a code generation benchmark specifically designed to assess LLMs on agent-based data science tasks. This benchmark features three core elements: First, the tasks within DA-Code are inherently challenging, setting them apart from traditional code generation tasks and demanding advanced coding skills in grounding and planning. Second, examples in DA-Code are all based on real and diverse data, covering a wide range of complex data wrangling and analytics tasks. Third, to solve the tasks, the models must utilize complex data science programming languages, to perform intricate data processing and derive the answers. We set up the benchmark in a controllable and executable environment that aligns with real-world data analysis scenarios and is scalable. The annotators meticulously design the evaluation suite to ensure the accuracy and robustness of the evaluation. We develop the DA-Agent baseline. Experiments show that although the baseline performs better than other existing frameworks, using the current best LLMs achieves only 30.5% accuracy, leaving ample room for improvement. We release our benchmark at https://da-code-bench.github.io.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ],
            [
                "Application",
                "Software Engineering"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.07331"
    },
    "d7bb9dbb06879b831eb00d01166d6193": {
        "title": "AI-Press: A Multi-Agent News Generating and Feedback Simulation System Powered by Large Language Models",
        "authors": [
            "Xiawei Liu",
            "Shiyue Yang",
            "Xinnong Zhang",
            "Haoyu Kuang",
            "Libo Sun",
            "Yihang Yang",
            "Siming Chen",
            "Xuanjing Huang",
            "Zhongyu Wei"
        ],
        "date": "2024/10/10",
        "pdf": "http://arxiv.org/pdf/2410.07561",
        "abstract": "The rise of various social platforms has transformed journalism. The growing demand for news content has led to the increased use of large language models (LLMs) in news production due to their speed and cost-effectiveness. However, LLMs still encounter limitations in professionalism and ethical judgment in news generation. Additionally, predicting public feedback is usually difficult before news is released. To tackle these challenges, we introduce AI-Press, an automated news drafting and polishing system based on multi-agent collaboration and Retrieval-Augmented Generation. We develop a feedback simulation system that generates public feedback considering demographic distributions. Through extensive quantitative and qualitative evaluations, our system shows significant improvements in news-generating capabilities and verifies the effectiveness of public feedback simulation.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.07561"
    },
    "eb5f39e031e9332d097fc1f867ee281a": {
        "title": "MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference Optimization",
        "authors": [
            "Yougang Lyu",
            "Lingyong Yan",
            "Zihan Wang",
            "Dawei Yin",
            "Pengjie Ren",
            "Maarten de Rijke",
            "Zhaochun Ren"
        ],
        "date": "2024/10/10",
        "pdf": "http://arxiv.org/pdf/2410.07672",
        "abstract": "As large language models (LLMs) are rapidly advancing and achieving near-human capabilities, aligning them with human values is becoming more urgent. In scenarios where LLMs outperform humans, we face a weak-to-strong alignment problem where we need to effectively align strong student LLMs through weak supervision generated by weak teachers. Existing alignment methods mainly focus on strong-to-weak alignment and self-alignment settings, and it is impractical to adapt them to the much harder weak-to-strong alignment setting. To fill this gap, we propose a multi-agent contrastive preference optimization (MACPO) framework. MACPO facilitates weak teachers and strong students to learn from each other by iteratively reinforcing unfamiliar positive behaviors while penalizing familiar negative ones. To get this, we devise a mutual positive behavior augmentation strategy to encourage weak teachers and strong students to learn from each other&#39;s positive behavior and further provide higher quality positive behavior for the next iteration. Additionally, we propose a hard negative behavior construction strategy to induce weak teachers and strong students to generate familiar negative behavior by fine-tuning on negative behavioral data. Experimental results on the HH-RLHF and PKU-SafeRLHF datasets, evaluated using both automatic metrics and human judgments, demonstrate that MACPO simultaneously improves the alignment performance of strong students and weak teachers. Moreover, as the number of weak teachers increases, MACPO achieves better weak-to-strong alignment performance through more iteration optimization rounds.",
        "code": "",
        "category": [
            [
                "Training",
                "RL"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.07672"
    },
    "447f1f7d03da7e1c3857c9c7465588e3": {
        "title": "AgentBank: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories",
        "authors": [
            "Yifan Song",
            "Weimin Xiong",
            "Xiutian Zhao",
            "Dawei Zhu",
            "Wenhao Wu",
            "Ke Wang",
            "Cheng Li",
            "Wei Peng",
            "Sujian Li"
        ],
        "date": "2024/10/10",
        "pdf": "http://arxiv.org/pdf/2410.07706",
        "abstract": "Fine-tuning on agent-environment interaction trajectory data holds significant promise for surfacing generalized agent capabilities in open-source large language models (LLMs). In this work, we introduce AgentBank, by far the largest trajectory tuning data collection featuring more than 50k diverse high-quality interaction trajectories which comprises 16 tasks covering five distinct agent skill dimensions. Leveraging a novel annotation pipeline, we are able to scale the annotated trajectories and generate a trajectory dataset with minimized difficulty bias. Furthermore, we fine-tune LLMs on AgentBank to get a series of agent models, Samoyed. Our comparative experiments demonstrate the effectiveness of scaling the interaction trajectory data to acquire generalized agent capabilities. Additional studies also reveal some key observations regarding trajectory tuning and agent skill generalization.",
        "code": "",
        "category": [
            [
                "Training",
                "Fine tuning"
            ],
            [
                "Infrastructure",
                "Dataset"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.07706"
    },
    "b575161e1fcf50f3693f5be9072a2175": {
        "title": "Rewriting Conversational Utterances with Instructed Large Language Models",
        "authors": [
            "Elnara Galimzhanova",
            "Cristina Ioana Muntean",
            "Franco Maria Nardini",
            "Raffaele Perego",
            "Guido Rocchietti"
        ],
        "date": "2024/10/10",
        "pdf": "http://arxiv.org/pdf/2410.07797",
        "abstract": "Many recent studies have shown the ability of large language models (LLMs) to achieve state-of-the-art performance on many NLP tasks, such as question answering, text summarization, coding, and translation. In some cases, the results provided by LLMs are on par with those of human experts. These models&#39; most disruptive innovation is their ability to perform tasks via zero-shot or few-shot prompting. This capability has been successfully exploited to train instructed LLMs, where reinforcement learning with human feedback is used to guide the model to follow the user&#39;s requests directly. In this paper, we investigate the ability of instructed LLMs to improve conversational search effectiveness by rewriting user questions in a conversational setting. We study which prompts provide the most informative rewritten utterances that lead to the best retrieval performance. Reproducible experiments are conducted on publicly-available TREC CAST datasets. The results show that rewriting conversational utterances with instructed LLMs achieves significant improvements of up to 25.2% in MRR, 31.7% in Precision@1, 27% in NDCG@3, and 11.5% in Recall@500 over state-of-the-art techniques.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.07797"
    },
    "8d5599df50d83076f37ff1828d93dd97": {
        "title": "Benchmarking Agentic Workflow Generation",
        "authors": [
            "Shuofei Qiao",
            "Runnan Fang",
            "Zhisong Qiu",
            "Xiaobin Wang",
            "Ningyu Zhang",
            "Yong Jiang",
            "Pengjun Xie",
            "Fei Huang",
            "Huajun Chen"
        ],
        "date": "2024/10/10",
        "pdf": "http://arxiv.org/pdf/2410.07869",
        "abstract": "Large Language Models (LLMs), with their exceptional ability to handle a wide range of tasks, have driven significant advancements in tackling reasoning and planning tasks, wherein decomposing complex problems into executable workflows is a crucial step in this process. Existing workflow evaluation frameworks either focus solely on holistic performance or suffer from limitations such as restricted scenario coverage, simplistic workflow structures, and lax evaluation standards. To this end, we introduce WorFBench, a unified workflow generation benchmark with multi-faceted scenarios and intricate graph workflow structures. Additionally, we present WorFEval, a systemic evaluation protocol utilizing subsequence and subgraph matching algorithms to accurately quantify the LLM agent&#39;s workflow generation capabilities. Through comprehensive evaluations across different types of LLMs, we discover distinct gaps between the sequence planning capabilities and graph planning capabilities of LLM agents, with even GPT-4 exhibiting a gap of around 15%. We also train two open-source models and evaluate their generalization abilities on held-out tasks. Furthermore, we observe that the generated workflows can enhance downstream tasks, enabling them to achieve superior performance with less time during inference. Code and dataset are available at https://github.com/zjunlp/WorFBench.",
        "code": "",
        "category": [
            [
                "Automation",
                "Workflow"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.07869"
    },
    "931cc30d68abb58544f6c7ed0b3c3c47": {
        "title": "Multi-Agent Collaborative Data Selection for Efficient LLM Pretraining",
        "authors": [
            "Tianyi Bai",
            "Ling Yang",
            "Zhen Hao Wong",
            "Jiahui Peng",
            "Xinlin Zhuang",
            "Chi Zhang",
            "Lijun Wu",
            "Jiantao Qiu",
            "Wentao Zhang",
            "Binhang Yuan",
            "Conghui He"
        ],
        "date": "2024/10/10",
        "pdf": "http://arxiv.org/pdf/2410.08102",
        "abstract": "Efficient data selection is crucial to accelerate the pretraining of large language models (LLMs). While various methods have been proposed to enhance data efficiency, limited research has addressed the inherent conflicts between these approaches to achieve optimal data selection for LLM pretraining. To tackle this problem, we propose a novel multi-agent collaborative data selection mechanism. In this framework, each data selection method serves as an independent agent, and an agent console is designed to dynamically integrate the information from all agents throughout the LLM training process. We conduct extensive empirical studies to evaluate our multi-agent framework. The experimental results demonstrate that our approach significantly improves data efficiency, accelerates convergence in LLM training, and achieves an average performance gain up to 10.5% across multiple language model benchmarks compared to the state-of-the-art methods.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.08102"
    },
    "d46ba90a52d2dfa9283eb6d347581de6": {
        "title": "Optima: Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System",
        "authors": [
            "Weize Chen",
            "Jiarui Yuan",
            "Chen Qian",
            "Cheng Yang",
            "Zhiyuan Liu",
            "Maosong Sun"
        ],
        "date": "2024/10/10",
        "pdf": "http://arxiv.org/pdf/2410.08115",
        "abstract": "Large Language Model (LLM) based multi-agent systems (MAS) show remarkable potential in collaborative problem-solving, yet they still face critical challenges: low communication efficiency, poor scalability, and a lack of effective parameter-updating optimization methods. We present Optima, a novel framework that addresses these issues by significantly enhancing both communication efficiency and task effectiveness in LLM-based MAS through LLM training. Optima employs an iterative generate, rank, select, and train paradigm with a reward function balancing task performance, token efficiency, and communication readability. We explore various RL algorithms, including Supervised Fine-Tuning, Direct Preference Optimization, and their hybrid approaches, providing insights into their effectiveness-efficiency trade-offs. We integrate Monte Carlo Tree Search-inspired techniques for DPO data generation, treating conversation turns as tree nodes to explore diverse interaction paths. Evaluated on common multi-agent tasks, including information-asymmetric question answering and complex reasoning, Optima shows consistent and substantial improvements over single-agent baselines and vanilla MAS based on Llama 3 8B, achieving up to 2.8x performance gain with less than 10\\% tokens on tasks requiring heavy information exchange. Moreover, Optima&#39;s efficiency gains open new possibilities for leveraging inference-compute more effectively, leading to improved inference-time scaling laws. By addressing fundamental challenges in LLM-based MAS, Optima shows the potential towards scalable, efficient, and effective MAS (https://chenweize1998.github.io/optima-project-page).",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.08115"
    },
    "4ffede9ca3be44ee12fb6e713e9b83c6": {
        "title": "DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory",
        "authors": [
            "Yutong Wang",
            "Jiali Zeng",
            "Xuebo Liu",
            "Derek F. Wong",
            "Fandong Meng",
            "Jie Zhou",
            "Min Zhang"
        ],
        "date": "2024/10/10",
        "pdf": "http://arxiv.org/pdf/2410.08143",
        "abstract": "Large language models (LLMs) have achieved reasonable quality improvements in machine translation (MT). However, most current research on MT-LLMs still faces significant challenges in maintaining translation consistency and accuracy when processing entire documents. In this paper, we introduce DelTA, a Document-levEL Translation Agent designed to overcome these limitations. DelTA features a multi-level memory structure that stores information across various granularities and spans, including Proper Noun Records, Bilingual Summary, Long-Term Memory, and Short-Term Memory, which are continuously retrieved and updated by auxiliary LLM-based components. Experimental results indicate that DelTA significantly outperforms strong baselines in terms of translation consistency and quality across four open/closed-source LLMs and two representative document translation datasets, achieving an increase in consistency scores by up to 4.58 percentage points and in COMET scores by up to 3.16 points on average. DelTA employs a sentence-by-sentence translation strategy, ensuring no sentence omissions and offering a memory-efficient solution compared to the mainstream method. Furthermore, DelTA improves pronoun translation accuracy, and the summary component of the agent also shows promise as a tool for query-based summarization tasks. We release our code and data at https://github.com/YutongWang1216/DocMTAgent.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Memory Mechanism"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.08143"
    },
    "1a4582d06ed02d5c5a9a44946242c60b": {
        "title": "CAMPHOR: Collaborative Agents for Multi-input Planning and High-Order Reasoning On Device",
        "authors": [
            "Yicheng Fu",
            "Raviteja Anantha",
            "Jianpeng Cheng"
        ],
        "date": "2024/10/12",
        "pdf": "http://arxiv.org/pdf/2410.09407",
        "abstract": "While server-side Large Language Models (LLMs) demonstrate proficiency in function calling and complex reasoning, deploying Small Language Models (SLMs) directly on devices brings opportunities to improve latency and privacy but also introduces unique challenges for accuracy and memory. We introduce CAMPHOR, an innovative on-device SLM multi-agent framework designed to handle multiple user inputs and reason over personal context locally, ensuring privacy is maintained. CAMPHOR employs a hierarchical architecture where a high-order reasoning agent decomposes complex tasks and coordinates expert agents responsible for personal context retrieval, tool interaction, and dynamic plan generation. By implementing parameter sharing across agents and leveraging prompt compression, we significantly reduce model size, latency, and memory usage. To validate our approach, we present a novel dataset capturing multi-agent task trajectories centered on personalized mobile assistant use-cases. Our experiments reveal that fine-tuned SLM agents not only surpass closed-source LLMs in task completion F1 by~35\\% but also eliminate the need for server-device communication, all while enhancing privacy.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.09407"
    },
    "ce67c5ac836a0974574d829968b1e299": {
        "title": "Expanding Search Space with Diverse Prompting Agents: An Efficient Sampling Approach for LLM Mathematical Reasoning",
        "authors": [
            "Gisang Lee",
            "Sangwoo Park",
            "Junyoung Park",
            "Andrew Chung",
            "Sieun Park",
            "Yoonah Park",
            "Byungju Kim",
            "Min-gyu Cho"
        ],
        "date": "2024/10/13",
        "pdf": "http://arxiv.org/pdf/2410.09780",
        "abstract": "Large Language Models (LLMs) have exhibited remarkable capabilities in many complex tasks including mathematical reasoning. However, traditional approaches heavily rely on ensuring self-consistency within single prompting method, which limits the exploration of diverse problem-solving strategies. This study addresses these limitations by performing an experimental analysis of distinct prompting methods within the domain of mathematical reasoning. Our findings demonstrate that each method explores a distinct search space, and this differentiation becomes more evident with increasing problem complexity. To leverage this phenomenon, we applied efficient sampling process that uniformly combines samples from these diverse methods, which not only expands the maximum search space but achieves higher performance with fewer runs compared to single methods. Especially, within the subset of difficult questions of MATH dataset named MATH-hard, The maximum search space was achieved while utilizing approximately 43% fewer runs than single methods on average. These findings highlight the importance of integrating diverse problem-solving strategies to enhance the reasoning abilities of LLMs.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Search"
            ],
            [
                "Application",
                "Math"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.09780"
    },
    "ef786d5a796a752a368e68f89d9f0435": {
        "title": "LLM-Based Multi-Agent Systems are Scalable Graph Generative Models",
        "authors": [
            "Jiarui Ji",
            "Runlin Lei",
            "Jialing Bi",
            "Zhewei Wei",
            "Xu Chen",
            "Yankai Lin",
            "Xuchen Pan",
            "Yaliang Li",
            "Bolin Ding"
        ],
        "date": "2024/10/13",
        "pdf": "http://arxiv.org/pdf/2410.09824",
        "abstract": "The structural properties of naturally arising social graphs are extensively studied to understand their evolution. Prior approaches for modeling network dynamics typically rely on rule-based models, which lack realism and generalizability, or deep learning-based models, which require large-scale training datasets. Social graphs, as abstract graph representations of entity-wise interactions, present an opportunity to explore network evolution mechanisms through realistic simulations of human-item interactions. Leveraging the pre-trained social consensus knowledge embedded in large language models (LLMs), we present GraphAgent-Generator (GAG), a novel simulation-based framework for dynamic, text-attributed social graph generation. GAG simulates the temporal node and edge generation processes for zero-shot social graph generation. The resulting graphs exhibit adherence to seven key macroscopic network properties, achieving an 11% improvement in microscopic graph structure metrics. Through the node classification benchmarking task, we validate GAG effectively captures the intricate text-structure correlations in graph generation. Furthermore, GAG supports generating graphs with up to nearly 100,000 nodes or 10 million edges through large-scale LLM-based agent simulation with parallel acceleration, achieving a minimum speed-up of 90.4%. The source code is available at https://github.com/Ji-Cather/GraphAgent.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Search"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.09824"
    },
    "cfc1497cc4231b303b760be63759bb65": {
        "title": "Applying Refusal-Vector Ablation to Llama 3.1 70B Agents",
        "authors": [
            "Simon Lermen",
            "Mateusz Dziemian",
            "Govind Pimpale"
        ],
        "date": "2024/10/08",
        "pdf": "http://arxiv.org/pdf/2410.10871",
        "abstract": "Recently, language models like Llama 3.1 Instruct have become increasingly capable of agentic behavior, enabling them to perform tasks requiring short-term planning and tool use. In this study, we apply refusal-vector ablation to Llama 3.1 70B and implement a simple agent scaffolding to create an unrestricted agent. Our findings imply that these refusal-vector ablated models can successfully complete harmful tasks, such as bribing officials or crafting phishing attacks, revealing significant vulnerabilities in current safety mechanisms. To further explore this, we introduce a small Safe Agent Benchmark, designed to test both harmful and benign tasks in agentic scenarios. Our results imply that safety fine-tuning in chat models does not generalize well to agentic behavior, as we find that Llama 3.1 Instruct models are willing to perform most harmful tasks without modifications. At the same time, these models will refuse to give advice on how to perform the same tasks when asked for a chat completion. This highlights the growing risk of misuse as models become more capable, underscoring the need for improved safety frameworks for language model agents.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.10871"
    },
    "f76cac46c94dc6672f40480219dc081e": {
        "title": "HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR Applications",
        "authors": [
            "Weijie Xu",
            "Jay Desai",
            "Fanyou Wu",
            "Josef Valvoda",
            "Srinivasan H. Sengamedu"
        ],
        "date": "2024/10/15",
        "pdf": "http://arxiv.org/pdf/2410.11239",
        "abstract": "Recent LLM (Large Language Models) advancements benefit many fields such as education and finance, but HR has hundreds of repetitive processes, such as access requests, medical claim filing and time-off submissions, which are unaddressed. We relate these tasks to the LLM agent, which has addressed tasks such as writing assisting and customer support. We present HR-Agent, an efficient, confidential, and HR-specific LLM-based task-oriented dialogue system tailored for automating repetitive HR processes such as medical claims and access requests. Since conversation data is not sent to an LLM during inference, it preserves confidentiality required in HR-related tasks.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.11239"
    },
    "028e32d3c25242ac7a3181cd3e90ebdd": {
        "title": "MedAide: Towards an Omni Medical Aide via Specialized LLM-based Multi-Agent Collaboration",
        "authors": [
            "Jinjie Wei",
            "Dingkang Yang",
            "Yanshu Li",
            "Qingyao Xu",
            "Zhaoyu Chen",
            "Mingcheng Li",
            "Yue Jiang",
            "Xiaolu Hou",
            "Lihua Zhang"
        ],
        "date": "2024/10/16",
        "pdf": "http://arxiv.org/pdf/2410.12532",
        "abstract": "Large Language Model (LLM)-driven interactive systems currently show potential promise in healthcare domains. Despite their remarkable capabilities, LLMs typically lack personalized recommendations and diagnosis analysis in sophisticated medical applications, causing hallucinations and performance bottlenecks. To address these challenges, this paper proposes MedAide, an LLM-based omni medical multi-agent collaboration framework for specialized healthcare services. Specifically, MedAide first performs query rewriting through retrieval-augmented generation to accomplish accurate medical intent understanding. Immediately, we devise a contextual encoder to obtain intent prototype embeddings, which are used to recognize fine-grained intents by similarity matching. According to the intent relevance, the activated agents collaborate effectively to provide integrated decision analysis. Extensive experiments are conducted on four medical benchmarks with composite intents. Experimental results from automated metrics and expert doctor evaluations show that MedAide outperforms current LLMs and improves their medical proficiency and strategic reasoning.",
        "code": "",
        "category": [
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.12532"
    },
    "536e1cc9da9d37d50e3797f799018bf2": {
        "title": "Prompt Engineering a Schizophrenia Chatbot: Utilizing a Multi-Agent Approach for Enhanced Compliance with Prompt Instructions",
        "authors": [
            "Per Niklas Waaler",
            "Musarrat Hussain",
            "Igor Molchanov",
            "Lars Ailo Bongo",
            "Brita ElvevÃ¥g"
        ],
        "date": "2024/10/10",
        "pdf": "http://arxiv.org/pdf/2410.12848",
        "abstract": "Patients with schizophrenia often present with cognitive impairments that may hinder their ability to learn about their condition. These individuals could benefit greatly from education platforms that leverage the adaptability of Large Language Models (LLMs) such as GPT-4. While LLMs have the potential to make topical mental health information more accessible and engaging, their black-box nature raises concerns about ethics and safety. Prompting offers a way to produce semi-scripted chatbots with responses anchored in instructions and validated information, but prompt-engineered chatbots may drift from their intended identity as the conversation progresses. We propose a Critical Analysis Filter for achieving better control over chatbot behavior. In this system, a team of prompted LLM agents are prompt-engineered to critically analyze and refine the chatbot&#39;s response and deliver real-time feedback to the chatbot. To test this approach, we develop an informational schizophrenia chatbot and converse with it (with the filter deactivated) until it oversteps its scope. Once drift has been observed, AI-agents are used to automatically generate sample conversations in which the chatbot is being enticed to talk about out-of-bounds topics. We manually assign to each response a compliance score that quantifies the chatbot&#39;s compliance to its instructions; specifically the rules about accurately conveying sources and being transparent about limitations. Activating the Critical Analysis Filter resulted in an acceptable compliance score (&gt;=2) in 67.0% of responses, compared to only 8.7% when the filter was deactivated. These results suggest that a self-reflection layer could enable LLMs to be used effectively and safely in mental health platforms, maintaining adaptability while reliably limiting their scope to appropriate use cases.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.12848"
    },
    "2d899f5fc757a6cda46c78d9c0cca1fc": {
        "title": "Diversity of Thought Elicits Stronger Reasoning Capabilities in Multi-Agent Debate Frameworks",
        "authors": [
            "Mahmood Hegazy"
        ],
        "date": "2024/10/10",
        "pdf": "http://arxiv.org/pdf/2410.12853",
        "abstract": "Large language models (LLMs) excel in natural language generation but often confidently produce incorrect responses, especially in tasks like mathematical reasoning. Chain-of-thought prompting, self-verification, and multi-agent debate are among the strategies proposed to improve the reasoning and factual accuracy of LLMs. Building on Du et al.&#39;s multi-agent debate framework, we find that multi-agent debate helps at any model scale, and that diversity of thought elicits stronger reasoning in debating LLMs. Across various model sizes, performance on mathematical reasoning tasks benefits most when diverse trained models are used. Remarkably, after 4 rounds of debate, a diverse set of medium-capacity models (Gemini-Pro, Mixtral 7BX8, and PaLM 2-M) outperforms GPT-4 on the GSM-8K benchmark, scoring 91% accuracy. By comparison, when 3 instances of Gemini-Pro are used, performance only reaches 82%. Finally, this diverse set of medium-capacity models sets a new state-of-the-art performance on the ASDiv benchmark (94%). These results underscore the idea that the future of AI is agentic, with diverse cooperating agents yielding emergent capabilities beyond even the most powerful individual models.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.12853"
    },
    "28d65ec01fad015ae497bae4bf6c3b6a": {
        "title": "JAILJUDGE: A Comprehensive Jailbreak Judge Benchmark with Multi-Agent Enhanced Explanation Evaluation Framework",
        "authors": [
            "Fan Liu",
            "Yue Feng",
            "Zhao Xu",
            "Lixin Su",
            "Xinyu Ma",
            "Dawei Yin",
            "Hao Liu"
        ],
        "date": "2024/10/11",
        "pdf": "http://arxiv.org/pdf/2410.12855",
        "abstract": "Despite advancements in enhancing LLM safety against jailbreak attacks, evaluating LLM defenses remains a challenge, with current methods often lacking explainability and generalization to complex scenarios, leading to incomplete assessments (e.g., direct judgment without reasoning, low F1 score of GPT-4 in complex cases, bias in multilingual scenarios). To address this, we present JAILJUDGE, a comprehensive benchmark featuring diverse risk scenarios, including synthetic, adversarial, in-the-wild, and multilingual prompts, along with high-quality human-annotated datasets. The JAILJUDGE dataset includes over 35k+ instruction-tune data with reasoning explainability and JAILJUDGETEST, a 4.5k+ labeled set for risk scenarios, and a 6k+ multilingual set across ten languages. To enhance evaluation with explicit reasoning, we propose the JailJudge MultiAgent framework, which enables explainable, fine-grained scoring (1 to 10). This framework supports the construction of instruction-tuning ground truth and facilitates the development of JAILJUDGE Guard, an end-to-end judge model that provides reasoning and eliminates API costs. Additionally, we introduce JailBoost, an attacker-agnostic attack enhancer, and GuardShield, a moderation defense, both leveraging JAILJUDGE Guard. Our experiments demonstrate the state-of-the-art performance of JailJudge methods (JailJudge MultiAgent, JAILJUDGE Guard) across diverse models (e.g., GPT-4, Llama-Guard) and zero-shot scenarios. JailBoost and GuardShield significantly improve jailbreak attack and defense tasks under zero-shot settings, with JailBoost enhancing performance by 29.24% and GuardShield reducing defense ASR from 40.46% to 0.15%.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.12855"
    },
    "b67c1a8fd4f569fa7ff95a1c909c563f": {
        "title": "AdaSwitch: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning",
        "authors": [
            "Hao Sun",
            "Jiayi Wu",
            "Hengyi Cai",
            "Xiaochi Wei",
            "Yue Feng",
            "Bo Wang",
            "Shuaiqiang Wang",
            "Yan Zhang",
            "Dawei Yin"
        ],
        "date": "2024/10/17",
        "pdf": "http://arxiv.org/pdf/2410.13181",
        "abstract": "Recent advancements in large language models (LLMs) have been remarkable. Users face a choice between using cloud-based LLMs for generation quality and deploying local-based LLMs for lower computational cost. The former option is typically costly and inefficient, while the latter usually fails to deliver satisfactory performance for reasoning steps requiring deliberate thought processes. In this work, we propose a novel LLM utilization paradigm that facilitates the collaborative operation of large cloud-based LLMs and smaller local-deployed LLMs. Our framework comprises two primary modules: the local agent instantiated with a relatively smaller LLM, handling less complex reasoning steps, and the cloud agent equipped with a larger LLM, managing more intricate reasoning steps. This collaborative processing is enabled through an adaptive mechanism where the local agent introspectively identifies errors and proactively seeks assistance from the cloud agent, thereby effectively integrating the strengths of both locally-deployed and cloud-based LLMs, resulting in significant enhancements in task completion performance and efficiency. We evaluate AdaSwitch across 7 benchmarks, ranging from mathematical reasoning and complex question answering, using various types of LLMs to instantiate the local and cloud agents. The empirical results show that AdaSwitch effectively improves the performance of the local agent, and sometimes achieves competitive results compared to the cloud agent while utilizing much less computational overhead.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.13181"
    },
    "022e46cc67797deb06786d964eac640f": {
        "title": "Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation",
        "authors": [
            "Hyungjoo Chae",
            "Namyoung Kim",
            "Kai Tzu-iunn Ong",
            "Minju Gwak",
            "Gwanwoo Song",
            "Jihoon Kim",
            "Sunghwan Kim",
            "Dongha Lee",
            "Jinyoung Yeo"
        ],
        "date": "2024/10/17",
        "pdf": "http://arxiv.org/pdf/2410.13232",
        "abstract": "Large language models (LLMs) have recently gained much attention in building autonomous agents. However, the performance of current LLM-based web agents in long-horizon tasks is far from optimal, often yielding errors such as repeatedly buying a non-refundable flight ticket. By contrast, humans can avoid such an irreversible mistake, as we have an awareness of the potential outcomes (e.g., losing money) of our actions, also known as the &#34;world model&#34;. Motivated by this, our study first starts with preliminary analyses, confirming the absence of world models in current LLMs (e.g., GPT-4o, Claude-3.5-Sonnet, etc.). Then, we present a World-model-augmented (WMA) web agent, which simulates the outcomes of its actions for better decision-making. To overcome the challenges in training LLMs as world models predicting next observations, such as repeated elements across observations and long HTML inputs, we propose a transition-focused observation abstraction, where the prediction objectives are free-form natural language descriptions exclusively highlighting important state differences between time steps. Experiments on WebArena and Mind2Web show that our world models improve agents&#39; policy selection without training and demonstrate our agents&#39; cost- and time-efficiency compared to recent tree-search-based agents.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.13232"
    },
    "2872f3c9e74f2f029e787617df928f8d": {
        "title": "SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent",
        "authors": [
            "Jiarui Ji",
            "Yang Li",
            "Hongtao Liu",
            "Zhicheng Du",
            "Zhewei Wei",
            "Weiran Shen",
            "Qi Qi",
            "Yankai Lin"
        ],
        "date": "2024/10/18",
        "pdf": "http://arxiv.org/pdf/2410.14152",
        "abstract": "Public scarce resource allocation plays a crucial role in economics as it directly influences the efficiency and equity in society. Traditional studies including theoretical model-based, empirical study-based and simulation-based methods encounter limitations due to the idealized assumption of complete information and individual rationality, as well as constraints posed by limited available data. In this work, we propose an innovative framework, SRAP-Agent (Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent), which integrates Large Language Models (LLMs) into economic simulations, aiming to bridge the gap between theoretical models and real-world dynamics. Using public housing allocation scenarios as a case study, we conduct extensive policy simulation experiments to verify the feasibility and effectiveness of the SRAP-Agent and employ the Policy Optimization Algorithm with certain optimization objectives. The source code can be found in https://github.com/jijiarui-cather/SRAPAgent_Framework",
        "code": "",
        "category": [
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.14152"
    },
    "b4ef916a5b54470cc61aea27a847fc82": {
        "title": "Toolshed: Scale Tool-Equipped Agents with Advanced RAG-Tool Fusion and Tool Knowledge Bases",
        "authors": [
            "Elias Lumer",
            "Vamse Kumar Subbiah",
            "James A. Burke",
            "Pradeep Honaganahalli Basavaraju",
            "Austin Huber"
        ],
        "date": "2024/10/18",
        "pdf": "http://arxiv.org/pdf/2410.14594",
        "abstract": "Recent advancements in tool-equipped Agents (LLMs) have enabled complex tasks like secure database interactions and multi-agent code development. However, scaling tool capacity beyond agent reasoning or model limits remains a challenge. In this paper, we address these challenges by introducing Toolshed Knowledge Bases, a tool knowledge base (vector database) designed to store enhanced tool representations and optimize tool selection for large-scale tool-equipped Agents. Additionally, we propose Advanced RAG-Tool Fusion, a novel ensemble of tool-applied advanced retrieval-augmented generation (RAG) techniques across the pre-retrieval, intra-retrieval, and post-retrieval phases, without requiring model fine-tuning. During pre-retrieval, tool documents are enhanced with key information and stored in the Toolshed Knowledge Base. Intra-retrieval focuses on query planning and transformation to increase retrieval accuracy. Post-retrieval refines the retrieved tool documents and enables self-reflection. Furthermore, by varying both the total number of tools (tool-M) an Agent has access to and the tool selection threshold (top-k), we address trade-offs between retrieval accuracy, agent performance, and token cost. Our approach achieves 46%, 56%, and 47% absolute improvements on the ToolE single-tool, ToolE multi-tool and Seal-Tools benchmark datasets, respectively (Recall@5).",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "RAG"
            ],
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.14594"
    },
    "08a740752dd68dbf6693c0c00fc21790": {
        "title": "Agent Skill Acquisition for Large Language Models via CycleQD",
        "authors": [
            "So Kuroki",
            "Taishi Nakamura",
            "Takuya Akiba",
            "Yujin Tang"
        ],
        "date": "2024/10/16",
        "pdf": "http://arxiv.org/pdf/2410.14735",
        "abstract": "Training large language models to acquire specific skills remains a challenging endeavor. Conventional training approaches often struggle with data distribution imbalances and inadequacies in objective functions that do not align well with task-specific performance. To address these challenges, we introduce CycleQD, a novel approach that leverages the Quality Diversity framework through a cyclic adaptation of the algorithm, along with a model merging based crossover and an SVD-based mutation. In CycleQD, each task&#39;s performance metric is alternated as the quality measure while the others serve as the behavioral characteristics. This cyclic focus on individual tasks allows for concentrated effort on one task at a time, eliminating the need for data ratio tuning and simplifying the design of the objective function. Empirical results from AgentBench indicate that applying CycleQD to LLAMA3-8B-INSTRUCT based models not only enables them to surpass traditional fine-tuning methods in coding, operating systems, and database tasks, but also achieves performance on par with GPT-3.5-TURBO, which potentially contains much more parameters, across these domains. Crucially, this enhanced performance is achieved while retaining robust language capabilities, as evidenced by its performance on widely adopted language benchmark tasks. We highlight the key design choices in CycleQD, detailing how these contribute to its effectiveness. Furthermore, our method is general and can be applied to image segmentation models, highlighting its applicability across different domains.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.14735"
    },
    "951e57d5c574b7262fad7c5cc65b01e5": {
        "title": "An Electoral Approach to Diversify LLM-based Multi-Agent Collective Decision-Making",
        "authors": [
            "Xiutian Zhao",
            "Ke Wang",
            "Wei Peng"
        ],
        "date": "2024/10/19",
        "pdf": "http://arxiv.org/pdf/2410.15168",
        "abstract": "Modern large language models (LLMs) have exhibited cooperative synergy on complex task-solving, and collective decision-making (CDM) is a pivotal component in LLM-based multi-agent collaboration frameworks. Our survey on 52 recent such systems uncovers a severe lack of diversity, with a heavy reliance on dictatorial and plurality voting for CDM. Through the lens of social choice theory, we scrutinize widely-adopted CDM methods and identify their limitations. To enrich current landscape of LLM-based CDM, we present GEDI, an electoral CDM module that incorporates various ordinal preferential voting mechanisms. Our empirical case study across three benchmarks shows that the integration of certain CDM methods can markedly improve the reasoning capabilities and robustness of some leading LLMs, all without requiring intricate system designs. Additionally, we find that some CDM mechanisms generate positive synergies even with as few as three agents. The voting-based methods also demonstrate robustness against single points of failure, as well as diversity in terms of hit-rate@k and subject-wise impacts.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.15168"
    },
    "ce3cfb1fe56d6dc07c6bbb2956d74f16": {
        "title": "Training Language Models to Critique With Multi-agent Feedback",
        "authors": [
            "Tian Lan",
            "Wenwei Zhang",
            "Chengqi Lyu",
            "Shuaibin Li",
            "Chen Xu",
            "Heyan Huang",
            "Dahua Lin",
            "Xian-Ling Mao",
            "Kai Chen"
        ],
        "date": "2024/10/20",
        "pdf": "http://arxiv.org/pdf/2410.15287",
        "abstract": "Critique ability, a meta-cognitive capability of humans, presents significant challenges for LLMs to improve. Recent works primarily rely on supervised fine-tuning (SFT) using critiques generated by a single LLM like GPT-4. However, these model-generated critiques often exhibit flaws due to the inherent complexity of the critique. Consequently, fine-tuning LLMs on such flawed critiques typically limits the model&#39;s performance and propagates these flaws into the learned model. To overcome these challenges, this paper proposes a novel data generation pipeline, named MultiCritique, that improves the critique ability of LLMs by utilizing multi-agent feedback in both the SFT and reinforcement learning (RL) stages. First, our data generation pipeline aggregates high-quality critiques from multiple agents instead of a single model, with crucial information as input for simplifying the critique. Furthermore, our pipeline improves the preference accuracy of critique quality through multi-agent feedback, facilitating the effectiveness of RL in improving the critique ability of LLMs. Based on our proposed MultiCritique data generation pipeline, we construct the MultiCritiqueDataset for the SFT and RL fine-tuning stages. Extensive experimental results on two benchmarks demonstrate: 1) the superior quality of our constructed SFT dataset compared to existing critique datasets; 2) additional improvements to the critique ability of LLMs brought by the RL stage. Notably, our fine-tuned 7B model significantly surpasses other advanced 7B-13B open-source models, approaching the performance of advanced 70B LLMs and GPT-4. Codes, datasets and model weights will be publicly available.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Training",
                "Fine tuning"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.15287"
    },
    "855bbef5d648e573efd345ec2b071651": {
        "title": "VipAct: Visual-Perception Enhancement via Specialized VLM Agent Collaboration and Tool-use",
        "authors": [
            "Zhehao Zhang",
            "Ryan Rossi",
            "Tong Yu",
            "Franck Dernoncourt",
            "Ruiyi Zhang",
            "Jiuxiang Gu",
            "Sungchul Kim",
            "Xiang Chen",
            "Zichao Wang",
            "Nedim Lipka"
        ],
        "date": "2024/10/21",
        "pdf": "http://arxiv.org/pdf/2410.16400",
        "abstract": "While vision-language models (VLMs) have demonstrated remarkable performance across various tasks combining textual and visual information, they continue to struggle with fine-grained visual perception tasks that require detailed pixel-level analysis. Effectively eliciting comprehensive reasoning from VLMs on such intricate visual elements remains an open challenge. In this paper, we present VipAct, an agent framework that enhances VLMs by integrating multi-agent collaboration and vision expert models, enabling more precise visual understanding and comprehensive reasoning. VipAct consists of an orchestrator agent, which manages task requirement analysis, planning, and coordination, along with specialized agents that handle specific tasks such as image captioning and vision expert models that provide high-precision perceptual information. This multi-agent approach allows VLMs to better perform fine-grained visual perception tasks by synergizing planning, reasoning, and tool use. We evaluate VipAct on benchmarks featuring a diverse set of visual perception tasks, with experimental results demonstrating significant performance improvements over state-of-the-art baselines across all tasks. Furthermore, comprehensive ablation studies reveal the critical role of multi-agent collaboration in eliciting more detailed System-2 reasoning and highlight the importance of image input for task planning. Additionally, our error analysis identifies patterns of VLMs&#39; inherent limitations in visual perception, providing insights into potential future improvements. VipAct offers a flexible and extensible framework, paving the way for more advanced visual perception systems across various real-world applications.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.16400"
    },
    "29d1233ccd45c31133f6c1eb4cd9c64f": {
        "title": "Beyond Browsing: API-Based Web Agents",
        "authors": [
            "Yueqi Song",
            "Frank Xu",
            "Shuyan Zhou",
            "Graham Neubig"
        ],
        "date": "2024/10/21",
        "pdf": "http://arxiv.org/pdf/2410.16464",
        "abstract": "Web browsers are a portal to the internet, where much of human activity is undertaken. Thus, there has been significant research work in AI agents that interact with the internet through web browsing. However, there is also another interface designed specifically for machine interaction with online content: application programming interfaces (APIs). In this paper we ask -- what if we were to take tasks traditionally tackled by browsing agents, and give AI agents access to APIs? To do so, we propose two varieties of agents: (1) an API-calling agent that attempts to perform online tasks through APIs only, similar to traditional coding agents, and (2) a Hybrid Agent that can interact with online data through both web browsing and APIs. In experiments on WebArena, a widely-used and realistic benchmark for web navigation tasks, we find that API-based agents outperform web browsing agents. Hybrid Agents out-perform both others nearly uniformly across tasks, resulting in a more than 20.0% absolute improvement over web browsing alone, achieving a success rate of 35.8%, achiving the SOTA performance among task-agnostic agents. These results strongly suggest that when APIs are available, they present an attractive alternative to relying on web browsing alone.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.16464"
    },
    "46d921a1305de4da54f0058f5f3d9cca": {
        "title": "Adsorb-Agent: Autonomous Identification of Stable Adsorption Configurations via Large Language Model Agent",
        "authors": [
            "Janghoon Ock",
            "Tirtha Vinchurkar",
            "Yayati Jadhav",
            "Amir Barati Farimani"
        ],
        "date": "2024/10/22",
        "pdf": "http://arxiv.org/pdf/2410.16658",
        "abstract": "Adsorption energy is a key reactivity descriptor in catalysis, enabling efficient screening for optimal catalysts. However, determining adsorption energy typically requires evaluating numerous adsorbate-catalyst configurations. Current algorithmic approaches rely on exhaustive enumeration of adsorption sites and configurations, which makes the process computationally intensive and does not inherently guarantee the identification of the global minimum energy. In this work, we introduce Adsorb-Agent, a Large Language Model (LLM) agent designed to efficiently identify system-specific stable adsorption configurations corresponding to the global minimum adsorption energy. Adsorb-Agent leverages its built-in knowledge and emergent reasoning capabilities to strategically explore adsorption configurations likely to hold adsorption energy. By reducing the reliance on exhaustive sampling, it significantly decreases the number of initial configurations required while improving the accuracy of adsorption energy predictions. We evaluate Adsorb-Agent&#39;s performance across twenty representative systems encompassing a range of complexities. The Adsorb-Agent successfully identifies comparable adsorption energies for 83.7% of the systems and achieves lower energies, closer to the actual global minimum, for 35% of the systems, while requiring significantly fewer initial configurations than conventional methods. Its capability is particularly evident in complex systems, where it identifies lower adsorption energies for 46.7% of systems involving intermetallic surfaces and 66.7% of systems with large adsorbate molecules. These results demonstrate the potential of Adsorb-Agent to accelerate catalyst discovery by reducing computational costs and improving the reliability of adsorption energy predictions.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.16658"
    },
    "6d8cb931652f88d3afe5144c3d474a41": {
        "title": "Large Language Models Empowered Personalized Web Agents",
        "authors": [
            "Hongru Cai",
            "Yongqi Li",
            "Wenjie Wang",
            "Fengbin Zhu",
            "Xiaoyu Shen",
            "Wenjie Li",
            "Tat-Seng Chua"
        ],
        "date": "2024/10/22",
        "pdf": "http://arxiv.org/pdf/2410.17236",
        "abstract": "Web agents have emerged as a promising direction to automate Web task completion based on user instructions, significantly enhancing user experience. Recently, Web agents have evolved from traditional agents to Large Language Models (LLMs)-based Web agents. Despite their success, existing LLM-based Web agents overlook the importance of personalized data (e.g., user profiles and historical Web behaviors) in assisting the understanding of users&#39; personalized instructions and executing customized actions. To overcome the limitation, we first formulate the task of LLM-empowered personalized Web agents, which integrate personalized data and user instructions to personalize instruction comprehension and action execution. To address the absence of a comprehensive evaluation benchmark, we construct a Personalized Web Agent Benchmark (PersonalWAB), featuring user instructions, personalized user data, Web functions, and two evaluation paradigms across three personalized Web tasks. Moreover, we propose a Personalized User Memory-enhanced Alignment (PUMA) framework to adapt LLMs to the personalized Web agent task. PUMA utilizes a memory bank with a task-specific retrieval strategy to filter relevant historical Web behaviors. Based on the behaviors, PUMA then aligns LLMs for personalized action execution through fine-tuning and direct preference optimization. Extensive experiments validate the superiority of PUMA over existing Web agents on PersonalWAB.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.17236"
    },
    "39c7a4b54bb5570c3524811280812171": {
        "title": "ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents",
        "authors": [
            "Yusheng Liao",
            "Shuyang Jiang",
            "Yanfeng Wang",
            "Yu Wang"
        ],
        "date": "2024/10/23",
        "pdf": "http://arxiv.org/pdf/2410.17657",
        "abstract": "Large Language Models (LLMs) have shown promising potential in the medical domain, assisting with tasks like clinical note generation and patient communication. However, current LLMs are limited to text-based communication, hindering their ability to interact with diverse forms of information in clinical environments. Despite clinical agents succeeding in diverse signal interaction, they are oriented to a single clinical scenario and hence fail for broader applications. To evaluate clinical agents holistically, we propose ClinicalAgent Bench~(CAB), a comprehensive medical agent benchmark consisting of 18 tasks across five key realistic clinical dimensions. Building on this, we introduce ReflecTool, a novel framework that excels at utilizing domain-specific tools within two stages. The first optimization stage progressively enlarges a long-term memory by saving successful solving processes and tool-wise experience of agents in a tiny pre-defined training set. In the following inference stage, ReflecTool can search for supportive successful demonstrations from already built long-term memory to guide the tool selection strategy, and a verifier improves the tool usage according to the tool-wise experience with two verification methods--iterative refinement and candidate selection. Extensive experiments on ClinicalAgent Benchmark demonstrate that ReflecTool surpasses the pure LLMs with more than 10 points and the well-established agent-based methods with 3 points, highlighting its adaptability and effectiveness in solving complex clinical tasks.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Interaction",
                "Tool Usage"
            ],
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.17657"
    },
    "52f575865871b8eece5f6bec3588fbdd": {
        "title": "AgentSense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios",
        "authors": [
            "Xinyi Mou",
            "Jingcong Liang",
            "Jiayu Lin",
            "Xinnong Zhang",
            "Xiawei Liu",
            "Shiyue Yang",
            "Rong Ye",
            "Lei Chen",
            "Haoyu Kuang",
            "Xuanjing Huang",
            "Zhongyu Wei"
        ],
        "date": "2024/10/25",
        "pdf": "http://arxiv.org/pdf/2410.19346",
        "abstract": "Large language models (LLMs) are increasingly leveraged to empower autonomous agents to simulate human beings in various fields of behavioral research. However, evaluating their capacity to navigate complex social interactions remains a challenge. Previous studies face limitations due to insufficient scenario diversity, complexity, and a single-perspective focus. To this end, we introduce AgentSense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios. Drawing on Dramaturgical Theory, AgentSense employs a bottom-up approach to create 1,225 diverse social scenarios constructed from extensive scripts. We evaluate LLM-driven agents through multi-turn interactions, emphasizing both goal completion and implicit reasoning. We analyze goals using ERG theory and conduct comprehensive experiments. Our findings highlight that LLMs struggle with goals in complex social scenarios, especially high-level growth needs, and even GPT-4o requires improvement in private information reasoning. Code and data are available at \\url{https://github.com/ljcleo/agent_sense}.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.19346"
    },
    "d6c255ec08fe95ad5b30440c73668aa3": {
        "title": "OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization",
        "authors": [
            "Hongliang He",
            "Wenlin Yao",
            "Kaixin Ma",
            "Wenhao Yu",
            "Hongming Zhang",
            "Tianqing Fang",
            "Zhenzhong Lan",
            "Dong Yu"
        ],
        "date": "2024/10/25",
        "pdf": "http://arxiv.org/pdf/2410.19609",
        "abstract": "The rapid development of large language and multimodal models has sparked significant interest in using proprietary models, such as GPT-4o, to develop autonomous agents capable of handling real-world scenarios like web navigation. Although recent open-source efforts have tried to equip agents with the ability to explore environments and continuously improve over time, they are building text-only agents in synthetic environments where the reward signals are clearly defined. Such agents struggle to generalize to realistic settings that require multimodal perception abilities and lack ground-truth signals. In this paper, we introduce an open-source framework designed to facilitate the development of multimodal web agent that can autonomously conduct real-world exploration and improve itself. We first train the base model with imitation learning to gain the basic abilities. We then let the agent explore the open web and collect feedback on its trajectories. After that, it further improves its policy by learning from well-performing trajectories judged by another general-purpose model. This exploration-feedback-optimization cycle can continue for several iterations. Experimental results show that our web agent successfully improves itself after each iteration, demonstrating strong performance across multiple test sets.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.19609"
    },
    "dac0bc58e388f9eb06aff0058890990d": {
        "title": "AGENT-CQ: Automatic Generation and Evaluation of Clarifying Questions for Conversational Search with LLMs",
        "authors": [
            "Clemencia Siro",
            "Yifei Yuan",
            "Mohammad Aliannejadi",
            "Maarten de Rijke"
        ],
        "date": "2024/10/25",
        "pdf": "http://arxiv.org/pdf/2410.19692",
        "abstract": "Generating diverse and effective clarifying questions is crucial for improving query understanding and retrieval performance in open-domain conversational search (CS) systems. We propose AGENT-CQ (Automatic GENeration, and evaluaTion of Clarifying Questions), an end-to-end LLM-based framework addressing the challenges of scalability and adaptability faced by existing methods that rely on manual curation or template-based approaches. AGENT-CQ consists of two stages: a generation stage employing LLM prompting strategies to generate clarifying questions, and an evaluation stage (CrowdLLM) that simulates human crowdsourcing judgments using multiple LLM instances to assess generated questions and answers based on comprehensive quality metrics. Extensive experiments on the ClariQ dataset demonstrate CrowdLLM&#39;s effectiveness in evaluating question and answer quality. Human evaluation and CrowdLLM show that the AGENT-CQ - generation stage, consistently outperforms baselines in various aspects of question and answer quality. In retrieval-based evaluation, LLM-generated questions significantly enhance retrieval effectiveness for both BM25 and cross-encoder models compared to human-generated questions.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Search"
            ],
            [
                "Interaction",
                "Conversation"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.19692"
    },
    "941424340d3792901155a6fc9b8048f8": {
        "title": "TrajAgent: An Agent Framework for Unified Trajectory Modelling",
        "authors": [
            "Yuwei Du",
            "Jie Feng",
            "Jie Zhao",
            "Yong Li"
        ],
        "date": "2024/10/27",
        "pdf": "http://arxiv.org/pdf/2410.20445",
        "abstract": "Trajectory modeling, which includes research on trajectory data pattern mining and future prediction, has widespread applications in areas such as life services, urban transportation, and public administration. Numerous methods have been proposed to address specific problems within trajectory modelling. However, due to the heterogeneity of data and the diversity of trajectory tasks, achieving unified trajectory modelling remains an important yet challenging task. In this paper, we propose TrajAgent, a large language model-based agentic framework, to unify various trajectory modelling tasks. In TrajAgent, we first develop UniEnv, an execution environment with a unified data and model interface, to support the execution and training of various models. Building on UniEnv, we introduce TAgent, an agentic workflow designed for automatic trajectory modelling across various trajectory tasks. Specifically, we design AutOpt, a systematic optimization module within TAgent, to further improve the performance of the integrated model. With diverse trajectory tasks input in natural language, TrajAgent automatically generates competitive results via training and executing appropriate models. Extensive experiments on four tasks using four real-world datasets demonstrate the effectiveness of TrajAgent in unified trajectory modelling, achieving an average performance improvement of 15.43% over baseline methods.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.20445"
    },
    "eb44ba8df62ac5c1006647fc404976c5": {
        "title": "ElectionSim: Massive Population Election Simulation Powered by Large Language Model Driven Agents",
        "authors": [
            "Xinnong Zhang",
            "Jiayu Lin",
            "Libo Sun",
            "Weihong Qi",
            "Yihang Yang",
            "Yue Chen",
            "Hanjia Lyu",
            "Xinyi Mou",
            "Siming Chen",
            "Jiebo Luo",
            "Xuanjing Huang",
            "Shiping Tang",
            "Zhongyu Wei"
        ],
        "date": "2024/10/28",
        "pdf": "http://arxiv.org/pdf/2410.20746",
        "abstract": "The massive population election simulation aims to model the preferences of specific groups in particular election scenarios. It has garnered significant attention for its potential to forecast real-world social trends. Traditional agent-based modeling (ABM) methods are constrained by their ability to incorporate complex individual background information and provide interactive prediction results. In this paper, we introduce ElectionSim, an innovative election simulation framework based on large language models, designed to support accurate voter simulations and customized distributions, together with an interactive platform to dialogue with simulated voters. We present a million-level voter pool sampled from social media platforms to support accurate individual simulation. We also introduce PPE, a poll-based presidential election benchmark to assess the performance of our framework under the U.S. presidential election scenario. Through extensive experiments and analyses, we demonstrate the effectiveness and robustness of our framework in U.S. presidential election simulations.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.20746"
    },
    "5971b809eec85268c7a9308fe83f77b1": {
        "title": "CRAT: A Multi-Agent Framework for Causality-Enhanced Reflective and Retrieval-Augmented Translation with Large Language Models",
        "authors": [
            "Meiqi Chen",
            "Fandong Meng",
            "Yingxue Zhang",
            "Yan Zhang",
            "Jie Zhou"
        ],
        "date": "2024/10/28",
        "pdf": "http://arxiv.org/pdf/2410.21067",
        "abstract": "Large language models (LLMs) have shown great promise in machine translation, but they still struggle with contextually dependent terms, such as new or domain-specific words. This leads to inconsistencies and errors that are difficult to address. Existing solutions often depend on manual identification of such terms, which is impractical given the complexity and evolving nature of language. While Retrieval-Augmented Generation (RAG) could provide some assistance, its application to translation is limited by issues such as hallucinations from information overload. In this paper, we propose CRAT, a novel multi-agent translation framework that leverages RAG and causality-enhanced self-reflection to address these challenges. This framework consists of several specialized agents: the Unknown Terms Identification agent detects unknown terms within the context, the Knowledge Graph (KG) Constructor agent extracts relevant internal knowledge about these terms and retrieves bilingual information from external sources, the Causality-enhanced Judge agent validates the accuracy of the information, and the Translator agent incorporates the refined information into the final output. This automated process allows for more precise and consistent handling of key terms during translation. Our results show that CRAT significantly improves translation accuracy, particularly in handling context-sensitive terms and emerging vocabulary.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "RAG"
            ],
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.21067"
    },
    "30374ceac706211d27f9044c8d8c3618": {
        "title": "Can Machines Think Like Humans? A Behavioral Evaluation of LLM-Agents in Dictator Games",
        "authors": [
            "Ji Ma"
        ],
        "date": "2024/10/28",
        "pdf": "http://arxiv.org/pdf/2410.21359",
        "abstract": "As Large Language Model (LLM)-based agents increasingly undertake real-world tasks and engage with human society, how well do we understand their behaviors? We (1) investigate how LLM agents&#39; prosocial behaviors -- a fundamental social norm -- can be induced by different personas and benchmarked against human behaviors; and (2) introduce a behavioral and social science approach to evaluate LLM agents&#39; decision-making. We explored how different personas and experimental framings affect these AI agents&#39; altruistic behavior in dictator games and compared their behaviors within the same LLM family, across various families, and with human behaviors. The findings reveal substantial variations and inconsistencies among LLMs and notable differences compared to human behaviors. Merely assigning a human-like identity to LLMs does not produce human-like behaviors. Despite being trained on extensive human-generated data, these AI agents are unable to capture the internal processes of human decision-making. Their alignment with human is highly variable and dependent on specific model architectures and prompt formulations; even worse, such dependence does not follow a clear pattern. LLMs can be useful task-specific tools but are not yet intelligent human-like agents.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.21359"
    },
    "a426f9d84958b34d64ded5ee419f16a6": {
        "title": "Enhancing Financial Question Answering with a Multi-Agent Reflection Framework",
        "authors": [
            "Sorouralsadat Fatemi",
            "Yuheng Hu"
        ],
        "date": "2024/10/29",
        "pdf": "http://arxiv.org/pdf/2410.21741",
        "abstract": "While Large Language Models (LLMs) have shown impressive capabilities in numerous Natural Language Processing (NLP) tasks, they still struggle with financial question answering (QA), particularly when numerical reasoning is required. Recently, LLM-based multi-agent frameworks have demonstrated remarkable effectiveness in multi-step reasoning, which is crucial for financial QA tasks as it involves extracting relevant information from tables and text and then performing numerical reasoning on the extracted data to infer answers. In this study, we propose a multi-agent framework incorporating a critic agent that reflects on the reasoning steps and final answers for each question. Additionally, we enhance our system by adding multiple critic agents, each focusing on a specific aspect of the answer. Our results indicate that this framework significantly improves performance compared to single-agent reasoning, with an average performance increase of 15% for the LLaMA3-8B model and 5% for the LLaMA3-70B model. Furthermore, our framework performs on par with, and in some cases surpasses, larger single-agent LLMs such as LLaMA3.1-405B and GPT-4o-mini, though it falls slightly short compared to Claude-3.5 Sonnet. Overall, our framework presents an effective solution to enhance open-source LLMs for financial QA tasks, offering a cost-effective alternative to larger models like Claude-3.5 Sonnet.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Application",
                "Finance"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.21741"
    },
    "9090e0f5abaad69f58e46c01173fa20a": {
        "title": "SceneGenAgent: Precise Industrial Scene Generation with Coding Agent",
        "authors": [
            "Xiao Xia",
            "Dan Zhang",
            "Zibo Liao",
            "Zhenyu Hou",
            "Tianrui Sun",
            "Jing Li",
            "Ling Fu",
            "Yuxiao Dong"
        ],
        "date": "2024/10/29",
        "pdf": "http://arxiv.org/pdf/2410.21909",
        "abstract": "The modeling of industrial scenes is essential for simulations in industrial manufacturing. While large language models (LLMs) have shown significant progress in generating general 3D scenes from textual descriptions, generating industrial scenes with LLMs poses a unique challenge due to their demand for precise measurements and positioning, requiring complex planning over spatial arrangement. To address this challenge, we introduce SceneGenAgent, an LLM-based agent for generating industrial scenes through C# code. SceneGenAgent ensures precise layout planning through a structured and calculable format, layout verification, and iterative refinement to meet the quantitative requirements of industrial scenarios. Experiment results demonstrate that LLMs powered by SceneGenAgent exceed their original performance, reaching up to 81.0% success rate in real-world industrial scene generation tasks and effectively meeting most scene generation requirements. To further enhance accessibility, we construct SceneInstruct, a dataset designed for fine-tuning open-source LLMs to integrate into SceneGenAgent. Experiments show that fine-tuning open-source LLMs on SceneInstruct yields significant performance improvements, with Llama3.1-70B approaching the capabilities of GPT-4o. Our code and data are available at https://github.com/THUDM/SceneGenAgent .",
        "code": "",
        "category": [
            [
                "Application",
                "Software Engineering"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.21909"
    },
    "dc80edc58213c4b5ceba349615bf7a6b": {
        "title": "Flow-DPO: Improving LLM Mathematical Reasoning through Online Multi-Agent Learning",
        "authors": [
            "Yihe Deng",
            "Paul Mineiro"
        ],
        "date": "2024/10/29",
        "pdf": "http://arxiv.org/pdf/2410.22304",
        "abstract": "Mathematical reasoning is a crucial capability for Large Language Models (LLMs), yet generating detailed and accurate reasoning traces remains a significant challenge. This paper introduces a novel approach to produce high-quality reasoning traces for LLM fine-tuning using online learning \\textbf{Flows}. Our method employs an incremental output production Flow, where component LLMs collaboratively construct solutions through iterative communication. We train the Flow using online Direct Preference Optimization (DPO) learning with rollouts, generating DPO pairs for each training example and updating models in real-time. We directly compare the quality of reasoning traces generated by our method with those produced through direct model inference, demonstrating the effectiveness of our approach in improving LLM performance in mathematical reasoning tasks.",
        "code": "",
        "category": [
            [
                "Application",
                "Math"
            ],
            [
                "Training",
                "DPO"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.22304"
    },
    "1277a93a089dad77002064d947bfbbe1": {
        "title": "Strategic Collusion of LLM Agents: Market Division in Multi-Commodity Competitions",
        "authors": [
            "Ryan Y. Lin",
            "Siddhartha Ojha",
            "Kevin Cai",
            "Maxwell F. Chen"
        ],
        "date": "2024/09/19",
        "pdf": "http://arxiv.org/pdf/2410.00031",
        "abstract": "Machine-learning technologies are seeing increased deployment in real-world market scenarios. In this work, we explore the strategic behaviors of large language models (LLMs) when deployed as autonomous agents in multi-commodity markets, specifically within Cournot competition frameworks. We examine whether LLMs can independently engage in anti-competitive practices such as collusion or, more specifically, market division. Our findings demonstrate that LLMs can effectively monopolize specific commodities by dynamically adjusting their pricing and resource allocation strategies, thereby maximizing profitability without direct human input or explicit collusion commands. These results pose unique challenges and opportunities for businesses looking to integrate AI into strategic roles and for regulatory bodies tasked with maintaining fair and competitive markets. The study provides a foundation for further exploration into the ramifications of deferring high-stakes decisions to LLM-based agents.",
        "code": "",
        "category": [
            [
                "Application",
                "Finance"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.00031"
    },
    "ccf862826ff453c0e0e149c195f2b7b2": {
        "title": "Interactive Speculative Planning: Enhance Agent Efficiency through Co-design of System and User Interface",
        "authors": [
            "Wenyue Hua",
            "Mengting Wan",
            "Shashank Vadrevu",
            "Ryan Nadel",
            "Yongfeng Zhang",
            "Chi Wang"
        ],
        "date": "2024/09/30",
        "pdf": "http://arxiv.org/pdf/2410.00079",
        "abstract": "Agents, as user-centric tools, are increasingly deployed for human task delegation, assisting with a broad spectrum of requests by generating thoughts, engaging with user proxies, and producing action plans. However, agents based on large language models (LLMs) often face substantial planning latency due to two primary factors: the efficiency limitations of the underlying LLMs due to their large size and high demand, and the structural complexity of the agents due to the extensive generation of intermediate thoughts to produce the final output. Given that inefficiency in service provision can undermine the value of automation for users, this paper presents a human-centered efficient agent planning method -- Interactive Speculative Planning -- aiming at enhancing the efficiency of agent planning through both system design and human-AI interaction. Our approach advocates for the co-design of the agent system and user interface, underscoring the importance of an agent system that can fluidly manage user interactions and interruptions. By integrating human interruptions as a fundamental component of the system, we not only make it more user-centric but also expedite the entire process by leveraging human-in-the-loop interactions to provide accurate intermediate steps. Code and data will be released.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.00079"
    },
    "00f198f86f9fde071159deb180597602": {
        "title": "RGD: Multi-LLM Based Agent Debugger via Refinement and Generation Guidance",
        "authors": [
            "Haolin Jin",
            "Zechao Sun",
            "Huaming Chen"
        ],
        "date": "2024/10/02",
        "pdf": "http://arxiv.org/pdf/2410.01242",
        "abstract": "Large Language Models (LLMs) have shown incredible potential in code generation tasks, and recent research in prompt engineering have enhanced LLMs&#39; understanding of textual information. However, ensuring the accuracy of generated code often requires extensive testing and validation by programmers. While LLMs can typically generate code based on task descriptions, their accuracy remains limited, especially for complex tasks that require a deeper understanding of both the problem statement and the code generation process. This limitation is primarily due to the LLMs&#39; need to simultaneously comprehend text and generate syntactically and semantically correct code, without having the capability to automatically refine the code. In real-world software development, programmers rarely produce flawless code in a single attempt based on the task description alone, they rely on iterative feedback and debugging to refine their programs. Inspired by this process, we introduce a novel architecture of LLM-based agents for code generation and automatic debugging: Refinement and Guidance Debugging (RGD). The RGD framework is a multi-LLM-based agent debugger that leverages three distinct LLM agents-Guide Agent, Debug Agent, and Feedback Agent. RGD decomposes the code generation task into multiple steps, ensuring a clearer workflow and enabling iterative code refinement based on self-reflection and feedback. Experimental results demonstrate that RGD exhibits remarkable code generation capabilities, achieving state-of-the-art performance with a 9.8% improvement on the HumanEval dataset and a 16.2% improvement on the MBPP dataset compared to the state-of-the-art approaches and traditional direct prompting approaches. We highlight the effectiveness of the RGD framework in enhancing LLMs&#39; ability to generate and refine code autonomously.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.01242"
    },
    "702b7a6ff429aef93b552f6213323d2b": {
        "title": "Zodiac: A Cardiologist-Level LLM Framework for Multi-Agent Diagnostics",
        "authors": [
            "Yuan Zhou",
            "Peng Zhang",
            "Mengya Song",
            "Alice Zheng",
            "Yiwen Lu",
            "Zhiheng Liu",
            "Yong Chen",
            "Zhaohan Xi"
        ],
        "date": "2024/10/02",
        "pdf": "http://arxiv.org/pdf/2410.02026",
        "abstract": "Large language models (LLMs) have demonstrated remarkable progress in healthcare. However, a significant gap remains regarding LLMs&#39; professionalism in domain-specific clinical practices, limiting their application in real-world diagnostics. In this work, we introduce ZODIAC, an LLM-powered framework with cardiologist-level professionalism designed to engage LLMs in cardiological diagnostics. ZODIAC assists cardiologists by extracting clinically relevant characteristics from patient data, detecting significant arrhythmias, and generating preliminary reports for the review and refinement by cardiologists. To achieve cardiologist-level professionalism, ZODIAC is built on a multi-agent collaboration framework, enabling the processing of patient data across multiple modalities. Each LLM agent is fine-tuned using real-world patient data adjudicated by cardiologists, reinforcing the model&#39;s professionalism. ZODIAC undergoes rigorous clinical validation with independent cardiologists, evaluated across eight metrics that measure clinical effectiveness and address security concerns. Results show that ZODIAC outperforms industry-leading models, including OpenAI&#39;s GPT-4o, Meta&#39;s Llama-3.1-405B, and Google&#39;s Gemini-pro, as well as medical-specialist LLMs like Microsoft&#39;s BioGPT. ZODIAC demonstrates the transformative potential of specialized LLMs in healthcare by delivering domain-specific solutions that meet the stringent demands of medical practice. Notably, ZODIAC has been successfully integrated into electrocardiography (ECG) devices, exemplifying the growing trend of embedding LLMs into Software-as-Medical-Device (SaMD).",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.02026"
    },
    "65375b2f5dd48b9d6dd2723771e42ac4": {
        "title": "Can Large Language Models Grasp Legal Theories? Enhance Legal Reasoning with Insights from Multi-Agent Collaboration",
        "authors": [
            "Weikang Yuan",
            "Junjie Cao",
            "Zhuoren Jiang",
            "Yangyang Kang",
            "Jun Lin",
            "Kaisong Song",
            "tianqianjin lin",
            "Pengwei Yan",
            "Changlong Sun",
            "Xiaozhong Liu"
        ],
        "date": "2024/10/03",
        "pdf": "http://arxiv.org/pdf/2410.02507",
        "abstract": "Large Language Models (LLMs) could struggle to fully understand legal theories and perform complex legal reasoning tasks. In this study, we introduce a challenging task (confusing charge prediction) to better evaluate LLMs&#39; understanding of legal theories and reasoning capabilities. We also propose a novel framework: Multi-Agent framework for improving complex Legal Reasoning capability (MALR). MALR employs non-parametric learning, encouraging LLMs to automatically decompose complex legal tasks and mimic human learning process to extract insights from legal rules, helping LLMs better understand legal theories and enhance their legal reasoning abilities. Extensive experiments on multiple real-world datasets demonstrate that the proposed framework effectively addresses complex reasoning issues in practical scenarios, paving the way for more reliable applications in the legal domain.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.02507"
    },
    "adb735cdc179faaf92ca5cd2cb10201f": {
        "title": "ColaCare: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration",
        "authors": [
            "Zixiang Wang",
            "Yinghao Zhu",
            "Huiya Zhao",
            "Xiaochen Zheng",
            "Tianlong Wang",
            "Wen Tang",
            "Yasha Wang",
            "Chengwei Pan",
            "Ewen M. Harrison",
            "Junyi Gao",
            "Liantao Ma"
        ],
        "date": "2024/10/03",
        "pdf": "http://arxiv.org/pdf/2410.02551",
        "abstract": "We introduce ColaCare, a framework that enhances Electronic Health Record (EHR) modeling through multi-agent collaboration driven by Large Language Models (LLMs). Our approach seamlessly integrates domain-specific expert models with LLMs to bridge the gap between structured EHR data and text-based reasoning. Inspired by clinical consultations, ColaCare employs two types of agents: DoctorAgent and MetaAgent, which collaboratively analyze patient data. Expert models process and generate predictions from numerical EHR data, while LLM agents produce reasoning references and decision-making reports within the collaborative consultation framework. We additionally incorporate the Merck Manual of Diagnosis and Therapy (MSD) medical guideline within a retrieval-augmented generation (RAG) module for authoritative evidence support. Extensive experiments conducted on four distinct EHR datasets demonstrate ColaCare&#39;s superior performance in mortality prediction tasks, underscoring its potential to revolutionize clinical decision support systems and advance personalized precision medicine. The code, complete prompt templates, more case studies, etc. are publicly available at the anonymous link: https://colacare.netlify.app.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.02551"
    },
    "be615ae6b5e823dc9bbe8ac28a61abcb": {
        "title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML",
        "authors": [
            "Patara Trirat",
            "Wonyong Jeong",
            "Sung Ju Hwang"
        ],
        "date": "2024/10/03",
        "pdf": "http://arxiv.org/pdf/2410.02958",
        "abstract": "Automated machine learning (AutoML) accelerates AI development by automating tasks in the development pipeline, such as optimal model search and hyperparameter tuning. Existing AutoML systems often require technical expertise to set up complex tools, which is in general time-consuming and requires a large amount of human effort. Therefore, recent works have started exploiting large language models (LLM) to lessen such burden and increase the usability of AutoML frameworks via a natural language interface, allowing non-expert users to build their data-driven solutions. These methods, however, are usually designed only for a particular process in the AI development pipeline and do not efficiently use the inherent capacity of the LLMs. This paper proposes AutoML-Agent, a novel multi-agent framework tailored for full-pipeline AutoML, i.e., from data retrieval to model deployment. AutoML-Agent takes user&#39;s task descriptions, facilitates collaboration between specialized LLM agents, and delivers deployment-ready models. Unlike existing work, instead of devising a single plan, we introduce a retrieval-augmented planning strategy to enhance exploration to search for more optimal plans. We also decompose each plan into sub-tasks (e.g., data preprocessing and neural network design) each of which is solved by a specialized agent we build via prompting executing in parallel, making the search process more efficient. Moreover, we propose a multi-stage verification to verify executed results and guide the code generation LLM in implementing successful solutions. Extensive experiments on seven downstream tasks using fourteen datasets show that AutoML-Agent achieves a higher success rate in automating the full AutoML process, yielding systems with good performance throughout the diverse domains.",
        "code": "",
        "category": [
            [
                "Automation",
                "Workflow"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.02958"
    },
    "a507a18da0e1f7a87b33eaad34ffc4f8": {
        "title": "ImProver: Agent-Based Automated Proof Optimization",
        "authors": [
            "Riyaz Ahuja",
            "Jeremy Avigad",
            "Prasad Tetali",
            "Sean Welleck"
        ],
        "date": "2024/10/07",
        "pdf": "http://arxiv.org/pdf/2410.04753",
        "abstract": "Large language models (LLMs) have been used to generate formal proofs of mathematical theorems in proofs assistants such as Lean. However, we often want to optimize a formal proof with respect to various criteria, depending on its downstream use. For example, we may want a proof to adhere to a certain style, or to be readable, concise, or modularly structured. Having suitably optimized proofs is also important for learning tasks, especially since human-written proofs may not optimal for that purpose. To this end, we study a new problem of automated proof optimization: rewriting a proof so that it is correct and optimizes for an arbitrary criterion, such as length or readability. As a first method for automated proof optimization, we present ImProver, a large-language-model agent that rewrites proofs to optimize arbitrary user-defined metrics in Lean. We find that naively applying LLMs to proof optimization falls short, and we incorporate various improvements into ImProver, such as the use of symbolic Lean context in a novel Chain-of-States technique, as well as error-correction and retrieval. We test ImProver on rewriting real-world undergraduate, competition, and research-level mathematics theorems, finding that ImProver is capable of rewriting proofs so that they are substantially shorter, more modular, and more readable.",
        "code": "",
        "category": [
            [
                "Application",
                "Research"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.04753"
    },
    "d139107db4efb901300c197856eff532": {
        "title": "Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents",
        "authors": [
            "Boyu Gou",
            "Ruohan Wang",
            "Boyuan Zheng",
            "Yanan Xie",
            "Cheng Chang",
            "Yiheng Shu",
            "Huan Sun",
            "Yu Su"
        ],
        "date": "2024/10/07",
        "pdf": "http://arxiv.org/pdf/2410.05243",
        "abstract": "Multimodal large language models (MLLMs) are transforming the capabilities of graphical user interface (GUI) agents, facilitating their transition from controlled simulations to complex, real-world applications across various platforms. However, the effectiveness of these agents hinges on the robustness of their grounding capability. Current GUI agents predominantly utilize text-based representations such as HTML or accessibility trees, which, despite their utility, often introduce noise, incompleteness, and increased computational overhead. In this paper, we advocate a human-like embodiment for GUI agents that perceive the environment entirely visually and directly take pixel-level operations on the GUI. The key is visual grounding models that can accurately map diverse referring expressions of GUI elements to their coordinates on the GUI across different platforms. We show that a simple recipe, which includes web-based synthetic data and slight adaptation of the LLaVA architecture, is surprisingly effective for training such visual grounding models. We collect the largest dataset for GUI visual grounding so far, containing 10M GUI elements and their referring expressions over 1.3M screenshots, and use it to train UGround, a strong universal visual grounding model for GUI agents. Empirical results on six benchmarks spanning three categories (grounding, offline agent, and online agent) show that 1) UGround substantially outperforms existing visual grounding models for GUI agents, by up to 20% absolute, and 2) agents with UGround outperform state-of-the-art agents, despite the fact that existing agents use additional text-based input while ours only uses visual perception. These results provide strong support for the feasibility and promises of GUI agents that navigate the digital world as humans do.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.05243"
    },
    "18196a41f8dad04a4337d053ce95969b": {
        "title": "Seeker: Enhancing Exception Handling in Code with LLM-based Multi-Agent Approach",
        "authors": [
            "Xuanming Zhang",
            "Yuxuan Chen",
            "Yuan Yuan",
            "Minlie Huang"
        ],
        "date": "2024/10/09",
        "pdf": "http://arxiv.org/pdf/2410.06949",
        "abstract": "In real world software development, improper or missing exception handling can severely impact the robustness and reliability of code. Exception handling mechanisms require developers to detect, capture, and manage exceptions according to high standards, but many developers struggle with these tasks, leading to fragile code. This problem is particularly evident in open source projects and impacts the overall quality of the software ecosystem. To address this challenge, we explore the use of large language models (LLMs) to improve exception handling in code. Through extensive analysis, we identify three key issues: Insensitive Detection of Fragile Code, Inaccurate Capture of Exception Types, and Distorted Handling Solutions. These problems are widespread across real world repositories, suggesting that robust exception handling practices are often overlooked or mishandled. In response, we propose Seeker, a multi agent framework inspired by expert developer strategies for exception handling. Seeker uses agents: Scanner, Detector, Predator, Ranker, and Handler to assist LLMs in detecting, capturing, and resolving exceptions more effectively. Our work is the first systematic study on leveraging LLMs to enhance exception handling practices, providing valuable insights for future improvements in code reliability.",
        "code": "",
        "category": [
            [
                "Application",
                "Software Engineering"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.06949"
    },
    "9aeaf1b0911133b749361a0974f7292f": {
        "title": "Agent S: An Open Agentic Framework that Uses Computers Like a Human",
        "authors": [
            "Saaket Agashe",
            "Jiuzhou Han",
            "Shuyu Gan",
            "Jiachen Yang",
            "Ang Li",
            "Xin Eric Wang"
        ],
        "date": "2024/10/10",
        "pdf": "http://arxiv.org/pdf/2410.08164",
        "abstract": "We present Agent S, an open agentic framework that enables autonomous interaction with computers through a Graphical User Interface (GUI), aimed at transforming human-computer interaction by automating complex, multi-step tasks. Agent S aims to address three key challenges in automating computer tasks: acquiring domain-specific knowledge, planning over long task horizons, and handling dynamic, non-uniform interfaces. To this end, Agent S introduces experience-augmented hierarchical planning, which learns from external knowledge search and internal experience retrieval at multiple levels, facilitating efficient task planning and subtask execution. In addition, it employs an Agent-Computer Interface (ACI) to better elicit the reasoning and control capabilities of GUI agents based on Multimodal Large Language Models (MLLMs). Evaluation on the OSWorld benchmark shows that Agent S outperforms the baseline by 9.37% on success rate (an 83.6% relative improvement) and achieves a new state-of-the-art. Comprehensive analysis highlights the effectiveness of individual components and provides insights for future improvements. Furthermore, Agent S demonstrates broad generalizability to different operating systems on a newly-released WindowsAgentArena benchmark. Code available at https://github.com/simular-ai/Agent-S.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.08164"
    },
    "61155d0fbcb2d00d2fdbc1637d779235": {
        "title": "Agents Thinking Fast and Slow: A Talker-Reasoner Architecture",
        "authors": [
            "Konstantina Christakopoulou",
            "Shibl Mourad",
            "Maja MatariÄ"
        ],
        "date": "2024/10/10",
        "pdf": "http://arxiv.org/pdf/2410.08328",
        "abstract": "Large language models have enabled agents of all kinds to interact with users through natural conversation. Consequently, agents now have two jobs: conversing and planning/reasoning. Their conversational responses must be informed by all available information, and their actions must help to achieve goals. This dichotomy between conversing with the user and doing multi-step reasoning and planning can be seen as analogous to the human systems of &#34;thinking fast and slow&#34; as introduced by Kahneman. Our approach is comprised of a &#34;Talker&#34; agent (System 1) that is fast and intuitive, and tasked with synthesizing the conversational response; and a &#34;Reasoner&#34; agent (System 2) that is slower, more deliberative, and more logical, and is tasked with multi-step reasoning and planning, calling tools, performing actions in the world, and thereby producing the new agent state. We describe the new Talker-Reasoner architecture and discuss its advantages, including modularity and decreased latency. We ground the discussion in the context of a sleep coaching agent, in order to demonstrate real-world relevance.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.08328"
    },
    "c3f84cceb3905b994d7489dd1df7a301": {
        "title": "Words as Beacons: Guiding RL Agents with High-Level Language Prompts",
        "authors": [
            "Unai Ruiz-Gonzalez",
            "Alain Andres",
            "Pedro G. Bascoy",
            "Javier Del Ser"
        ],
        "date": "2024/10/11",
        "pdf": "http://arxiv.org/pdf/2410.08632",
        "abstract": "Sparse reward environments in reinforcement learning (RL) pose significant challenges for exploration, often leading to inefficient or incomplete learning processes. To tackle this issue, this work proposes a teacher-student RL framework that leverages Large Language Models (LLMs) as &#34;teachers&#34; to guide the agent&#39;s learning process by decomposing complex tasks into subgoals. Due to their inherent capability to understand RL environments based on a textual description of structure and purpose, LLMs can provide subgoals to accomplish the task defined for the environment in a similar fashion to how a human would do. In doing so, three types of subgoals are proposed: positional targets relative to the agent, object representations, and language-based instructions generated directly by the LLM. More importantly, we show that it is possible to query the LLM only during the training phase, enabling agents to operate within the environment without any LLM intervention. We assess the performance of this proposed framework by evaluating three state-of-the-art open-source LLMs (Llama, DeepSeek, Qwen) eliciting subgoals across various procedurally generated environment of the MiniGrid benchmark. Experimental results demonstrate that this curriculum-based approach accelerates learning and enhances exploration in complex tasks, achieving up to 30 to 200 times faster convergence in training steps compared to recent baselines designed for sparse reward environments.",
        "code": "",
        "category": [
            [
                "Training",
                "RL"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.08632"
    },
    "bb7f8e8e5116d18f0c423441c3a15f7a": {
        "title": "AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents",
        "authors": [
            "Maksym Andriushchenko",
            "Alexandra Souly",
            "Mateusz Dziemian",
            "Derek Duenas",
            "Maxwell Lin",
            "Justin Wang",
            "Dan Hendrycks",
            "Andy Zou",
            "Zico Kolter",
            "Matt Fredrikson",
            "Eric Winsor",
            "Jerome Wynne",
            "Yarin Gal",
            "Xander Davies"
        ],
        "date": "2024/10/11",
        "pdf": "http://arxiv.org/pdf/2410.09024",
        "abstract": "The robustness of LLMs to jailbreak attacks, where users design prompts to circumvent safety measures and misuse model capabilities, has been studied primarily for LLMs acting as simple chatbots. Meanwhile, LLM agents -- which use external tools and can execute multi-stage tasks -- may pose a greater risk if misused, but their robustness remains underexplored. To facilitate research on LLM agent misuse, we propose a new benchmark called AgentHarm. The benchmark includes a diverse set of 110 explicitly malicious agent tasks (440 with augmentations), covering 11 harm categories including fraud, cybercrime, and harassment. In addition to measuring whether models refuse harmful agentic requests, scoring well on AgentHarm requires jailbroken agents to maintain their capabilities following an attack to complete a multi-step task. We evaluate a range of leading LLMs, and find (1) leading LLMs are surprisingly compliant with malicious agent requests without jailbreaking, (2) simple universal jailbreak templates can be adapted to effectively jailbreak agents, and (3) these jailbreaks enable coherent and malicious multi-step agent behavior and retain model capabilities. To enable simple and reliable evaluation of attacks and defenses for LLM-based agents, we publicly release AgentHarm at https://huggingface.co/datasets/ai-safety-institute/AgentHarm.",
        "code": "",
        "category": [
            [
                "Stability",
                "Safety"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.09024"
    },
    "14e36e094d239496b3ba462c0a4476bd": {
        "title": "PEAR: A Robust and Flexible Automation Framework for Ptychography Enabled by Multiple Large Language Model Agents",
        "authors": [
            "Xiangyu Yin",
            "Chuqiao Shi",
            "Yimo Han",
            "Yi Jiang"
        ],
        "date": "2024/10/11",
        "pdf": "http://arxiv.org/pdf/2410.09034",
        "abstract": "Ptychography is an advanced computational imaging technique in X-ray and electron microscopy. It has been widely adopted across scientific research fields, including physics, chemistry, biology, and materials science, as well as in industrial applications such as semiconductor characterization. In practice, obtaining high-quality ptychographic images requires simultaneous optimization of numerous experimental and algorithmic parameters. Traditionally, parameter selection often relies on trial and error, leading to low-throughput workflows and potential human bias. In this work, we develop the &#34;Ptychographic Experiment and Analysis Robot&#34; (PEAR), a framework that leverages large language models (LLMs) to automate data analysis in ptychography. To ensure high robustness and accuracy, PEAR employs multiple LLM agents for tasks including knowledge retrieval, code generation, parameter recommendation, and image reasoning. Our study demonstrates that PEAR&#39;s multi-agent design significantly improves the workflow success rate, even with smaller open-weight models such as LLaMA 3.1 8B. PEAR also supports various automation levels and is designed to work with customized local knowledge bases, ensuring flexibility and adaptability across different research environments.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.09034"
    },
    "b4f14b73a9d912e317c3abc9942d3821": {
        "title": "Encoding Agent Trajectories as Representations with Sequence Transformers",
        "authors": [
            "Athanasios Tsiligkaridis",
            "Nicholas Kalinowski",
            "Zhongheng Li",
            "Elizabeth Hou"
        ],
        "date": "2024/10/11",
        "pdf": "http://arxiv.org/pdf/2410.09204",
        "abstract": "Spatiotemporal data faces many analogous challenges to natural language text including the ordering of locations (words) in a sequence, long range dependencies between locations, and locations having multiple meanings. In this work, we propose a novel model for representing high dimensional spatiotemporal trajectories as sequences of discrete locations and encoding them with a Transformer-based neural network architecture. Similar to language models, our Sequence Transformer for Agent Representation Encodings (STARE) model can learn representations and structure in trajectory data through both supervisory tasks (e.g., classification), and self-supervisory tasks (e.g., masked modelling). We present experimental results on various synthetic and real trajectory datasets and show that our proposed model can learn meaningful encodings that are useful for many downstream tasks including discriminating between labels and indicating similarity between locations. Using these encodings, we also learn relationships between agents and locations present in spatiotemporal data.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.09204"
    },
    "a9c8d8477d8685d732005dcbf04d6991": {
        "title": "Many Heads Are Better Than One: Improved Scientific Idea Generation by A LLM-Based Multi-Agent System",
        "authors": [
            "Haoyang Su",
            "Renqi Chen",
            "Shixiang Tang",
            "Zhenfei Yin",
            "Xinzhe Zheng",
            "Jinzhe Li",
            "Biqing Qi",
            "Qi Wu",
            "Hui Li",
            "Wanli Ouyang",
            "Philip Torr",
            "Bowen Zhou",
            "Nanqing Dong"
        ],
        "date": "2024/10/12",
        "pdf": "http://arxiv.org/pdf/2410.09403",
        "abstract": "The rapid advancement of scientific progress requires innovative tools that can accelerate knowledge discovery. Although recent AI methods, particularly large language models (LLMs), have shown promise in tasks such as hypothesis generation and experimental design, they fall short of replicating the collaborative nature of real-world scientific practices, where diverse experts work together in teams to tackle complex problems. To address the limitations, we propose an LLM-based multi-agent system, i.e., Virtual Scientists (VirSci), designed to mimic the teamwork inherent in scientific research. VirSci organizes a team of agents to collaboratively generate, evaluate, and refine research ideas. Through comprehensive experiments, we demonstrate that this multi-agent approach outperforms the state-of-the-art method in producing novel scientific ideas. We further investigate the collaboration mechanisms that contribute to its tendency to produce ideas with higher novelty, offering valuable insights to guide future research and illuminating pathways toward building a robust system for autonomous scientific discovery. The code is available at https://github.com/open-sciencelab/Virtual-Scientists.",
        "code": "",
        "category": [
            [
                "Application",
                "Research"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.09403"
    },
    "6d92de44ed609c564af0260e1ae635e2": {
        "title": "AFlow: Automating Agentic Workflow Generation",
        "authors": [
            "Jiayi Zhang",
            "Jinyu Xiang",
            "Zhaoyang Yu",
            "Fengwei Teng",
            "Xionghui Chen",
            "Jiaqi Chen",
            "Mingchen Zhuge",
            "Xin Cheng",
            "Sirui Hong",
            "Jinlin Wang",
            "Bingnan Zheng",
            "Bang Liu",
            "Yuyu Luo",
            "Chenglin Wu"
        ],
        "date": "2024/10/14",
        "pdf": "http://arxiv.org/pdf/2410.10762",
        "abstract": "Large language models (LLMs) have demonstrated remarkable potential in solving complex tasks across diverse domains, typically by employing agentic workflows that follow detailed instructions and operational sequences. However, constructing these workflows requires significant human effort, limiting scalability and generalizability. Recent research has sought to automate the generation and optimization of these workflows, but existing methods still rely on initial manual setup and fall short of achieving fully automated and effective workflow generation. To address this challenge, we reformulate workflow optimization as a search problem over code-represented workflows, where LLM-invoking nodes are connected by edges. We introduce AFlow, an automated framework that efficiently explores this space using Monte Carlo Tree Search, iteratively refining workflows through code modification, tree-structured experience, and execution feedback. Empirical evaluations across six benchmark datasets demonstrate AFlow&#39;s efficacy, yielding a 5.7% average improvement over state-of-the-art baselines. Furthermore, AFlow enables smaller models to outperform GPT-4o on specific tasks at 4.55% of its inference cost in dollars. The code will be available at https://github.com/geekan/MetaGPT.",
        "code": "",
        "category": [
            [
                "Automation",
                "Workflow"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.10762"
    },
    "791501378570b1b159db1372dc062bc3": {
        "title": "Revisiting Benchmark and Assessment: An Agent-based Exploratory Dynamic Evaluation Framework for LLMs",
        "authors": [
            "Wanying Wang",
            "Zeyu Ma",
            "Pengfei Liu",
            "Mingang Chen"
        ],
        "date": "2024/10/15",
        "pdf": "http://arxiv.org/pdf/2410.11507",
        "abstract": "While various vertical domain large language models (LLMs) have been developed, automatically evaluating their performance across different domains remains a critical challenge. Current benchmark-based methods often rely on static and costly datasets, are misaligned with practical user needs, and lack flexibility across domains. To address these limitations, we revisit the evaluation process and introduce two key concepts: Benchmark+, which extends the traditional question-answer benchmark into a more flexible ``strategy-criterion&#39;&#39; format; and Assessment+, which enhances the interaction process, enabling deeper exploration and supporting analysis from broader perspectives. We propose TestAgent, an agent-based evaluation framework that implements these concepts using retrieval-augmented generation and reinforcement learning. TestAgent enables automatic dynamic benchmark generation and in-depth assessment across diverse vertical domain scenarios. Experiments on tasks ranging from constructing multiple vertical domain evaluations to converting static benchmarks into dynamic forms demonstrate the effectiveness of TestAgent. This work offers an interesting perspective on automatic evaluation for LLMs and highlights a pathway for dynamic and domain-adaptive assessments.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.11507"
    },
    "5790fc26e8fd8f1e77d1ad420ee8d70e": {
        "title": "Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistance",
        "authors": [
            "Yaxi Lu",
            "Shenzhi Yang",
            "Cheng Qian",
            "Guirong Chen",
            "Qinyu Luo",
            "Yesai Wu",
            "Huadong Wang",
            "Xin Cong",
            "Zhong Zhang",
            "Yankai Lin",
            "Weiwen Liu",
            "Yasheng Wang",
            "Zhiyuan Liu",
            "Fangming Liu",
            "Maosong Sun"
        ],
        "date": "2024/10/16",
        "pdf": "http://arxiv.org/pdf/2410.12361",
        "abstract": "Agents powered by large language models have shown remarkable abilities in solving complex tasks. However, most agent systems remain reactive, limiting their effectiveness in scenarios requiring foresight and autonomous decision-making. In this paper, we tackle the challenge of developing proactive agents capable of anticipating and initiating tasks without explicit human instructions. We propose a novel data-driven approach for this problem. Firstly, we collect real-world human activities to generate proactive task predictions. These predictions are then labeled by human annotators as either accepted or rejected. The labeled data is used to train a reward model that simulates human judgment and serves as an automatic evaluator of the proactiveness of LLM agents. Building on this, we develop a comprehensive data generation pipeline to create a diverse dataset, ProactiveBench, containing 6,790 events. Finally, we demonstrate that fine-tuning models with the proposed ProactiveBench can significantly elicit the proactiveness of LLM agents. Experimental results show that our fine-tuned model achieves an F1-Score of 66.47% in proactively offering assistance, outperforming all open-source and close-source models. These results highlight the potential of our method in creating more proactive and effective agent systems, paving the way for future advancements in human-agent collaboration.",
        "code": "",
        "category": [
            [
                "Automation",
                "Workflow"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ],
            [
                "Training",
                "Fine tuning"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.12361"
    },
    "134686407a054b22ec099ad8eb129450": {
        "title": "PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking",
        "authors": [
            "Markus J. Buehler"
        ],
        "date": "2024/10/16",
        "pdf": "http://arxiv.org/pdf/2410.12375",
        "abstract": "PRefLexOR (Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning) combines preference optimization with concepts from Reinforcement Learning to enable models to self-teach through iterative reasoning improvements. We propose a recursive learning approach that engages the model in multi-step reasoning, revisiting, and refining intermediate steps before producing a final output in training and inference phases. Through multiple training stages, the model first learns to align its reasoning with accurate decision paths by optimizing the log odds between preferred and non-preferred responses. During this process, PRefLexOR builds a dynamic knowledge graph by generating questions from random text chunks and retrieval-augmentation to contextualize relevant details from the entire training corpus. In the second stage, preference optimization enhances model performance by using rejection sampling to fine-tune reasoning quality by continually producing in-situ training data while masking the reasoning steps. Recursive optimization within a thinking token framework introduces iterative feedback loops, where the model refines reasoning, achieving deeper coherence, consistency, and adaptability. Implemented in small language models with only 3 billion parameters, we should that even tiny models can iteratively teach themselves to reason with greater depth and reflectivity. Our implementation is straightforward and can be incorporated into any existing pretrained LLM. We focus our examples on applications in biological materials science and demonstrate the method in a variety of case studies that range from in-domain to cross-domain applications. Using reasoning strategies that include thinking and reflection modalities we build a multi-agent recursive self-improving inference approach to successively improve responses via repeated sampling in inference time.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Application",
                "Biology"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.12375"
    },
    "f63019664674d031bcd07f5831bbaddd": {
        "title": "Chain of Ideas: Revolutionizing Research Via Novel Idea Development with LLM Agents",
        "authors": [
            "Long Li",
            "Weiwen Xu",
            "Jiayan Guo",
            "Ruochen Zhao",
            "Xingxuan Li",
            "Yuqian Yuan",
            "Boqiang Zhang",
            "Yuming Jiang",
            "Yifei Xin",
            "Ronghao Dang",
            "Deli Zhao",
            "Yu Rong",
            "Tian Feng",
            "Lidong Bing"
        ],
        "date": "2024/10/17",
        "pdf": "http://arxiv.org/pdf/2410.13185",
        "abstract": "Effective research ideation is a critical step for scientific research. However, the exponential increase in scientific literature makes it challenging for researchers to stay current with recent advances and identify meaningful research directions. Recent developments in large language models~(LLMs) suggest a promising avenue for automating the generation of novel research ideas. However, existing methods for idea generation either trivially prompt LLMs or directly expose LLMs to extensive literature without indicating useful information. Inspired by the research process of human researchers, we propose a Chain-of-Ideas~(CoI) agent, an LLM-based agent that organizes relevant literature in a chain structure to effectively mirror the progressive development in a research domain. This organization facilitates LLMs to capture the current advancements in research, thereby enhancing their ideation capabilities. Furthermore, we propose Idea Arena, an evaluation protocol that can comprehensively evaluate idea generation methods from different perspectives, aligning closely with the preferences of human researchers. Experimental results indicate that the CoI agent consistently outperforms other methods and shows comparable quality as humans in research idea generation. Moreover, our CoI agent is budget-friendly, with a minimum cost of \\$0.50 to generate a candidate idea and its corresponding experimental design.",
        "code": "",
        "category": [
            [
                "Application",
                "Research"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.13185"
    },
    "9e0096ffdb93988367283d0f9c7b14e7": {
        "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling",
        "authors": [
            "Yakun Zhu",
            "Shaohang Wei",
            "Xu Wang",
            "Kui Xue",
            "Xiaofan Zhang",
            "Shaoting Zhang"
        ],
        "date": "2024/10/17",
        "pdf": "http://arxiv.org/pdf/2410.13610",
        "abstract": "Integrating tools into Large Language Models (LLMs) has facilitated the widespread application. Despite this, in specialized downstream task contexts, reliance solely on tools is insufficient to fully address the complexities of the real world. This particularly restricts the effective deployment of LLMs in fields such as medicine. In this paper, we focus on the downstream tasks of medical calculators, which use standardized tests to assess an individual&#39;s health status. We introduce MeNTi, a universal agent architecture for LLMs. MeNTi integrates a specialized medical toolkit and employs meta-tool and nested calling mechanisms to enhance LLM tool utilization. Specifically, it achieves flexible tool selection and nested tool calling to address practical issues faced in intricate medical scenarios, including calculator selection, slot filling, and unit conversion. To assess the capabilities of LLMs for quantitative assessment throughout the clinical process of calculator scenarios, we introduce CalcQA. This benchmark requires LLMs to use medical calculators to perform calculations and assess patient health status. CalcQA is constructed by professional physicians and includes 100 case-calculator pairs, complemented by a toolkit of 281 medical tools. The experimental results demonstrate significant performance improvements with our framework. This research paves new directions for applying LLMs in demanding scenarios of medicine.",
        "code": "",
        "category": [
            [
                "Application",
                "Medicine"
            ],
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.13610"
    },
    "750655a092b8d5584696764fa1550679": {
        "title": "MobA: A Two-Level Agent System for Efficient Mobile Task Automation",
        "authors": [
            "Zichen Zhu",
            "Hao Tang",
            "Yansi Li",
            "Kunyao Lan",
            "Yixuan Jiang",
            "Hao Zhou",
            "Yixiao Wang",
            "Situo Zhang",
            "Liangtai Sun",
            "Lu Chen",
            "Kai Yu"
        ],
        "date": "2024/10/17",
        "pdf": "http://arxiv.org/pdf/2410.13757",
        "abstract": "Current mobile assistants are limited by dependence on system APIs or struggle with complex user instructions and diverse interfaces due to restricted comprehension and decision-making abilities. To address these challenges, we propose MobA, a novel Mobile phone Agent powered by multimodal large language models that enhances comprehension and planning capabilities through a sophisticated two-level agent architecture. The high-level Global Agent (GA) is responsible for understanding user commands, tracking history memories, and planning tasks. The low-level Local Agent (LA) predicts detailed actions in the form of function calls, guided by sub-tasks and memory from the GA. Integrating a Reflection Module allows for efficient task completion and enables the system to handle previously unseen complex tasks. MobA demonstrates significant improvements in task execution efficiency and completion rate in real-life evaluations, underscoring the potential of MLLM-empowered mobile assistants.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.13757"
    },
    "9133da370435d5f1ad7e8a369d38d026": {
        "title": "AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents",
        "authors": [
            "Ke Yang",
            "Yao Liu",
            "Sapana Chaudhary",
            "Rasool Fakoor",
            "Pratik Chaudhari",
            "George Karypis",
            "Huzefa Rangwala"
        ],
        "date": "2024/10/17",
        "pdf": "http://arxiv.org/pdf/2410.13825",
        "abstract": "Autonomy via agents using large language models (LLMs) for personalized, standardized tasks boosts human efficiency. Automating web tasks (like booking hotels within a budget) is increasingly sought after. Fulfilling practical needs, the web agent also serves as an important proof-of-concept example for various agent grounding scenarios, with its success promising advancements in many future applications. Prior research often handcrafts web agent strategies (e.g., prompting templates, multi-agent systems, search methods, etc.) and the corresponding in-context examples, which may not generalize well across all real-world scenarios. On the other hand, there has been limited study on the misalignment between a web agent&#39;s observation/action representation and the pre-training data of the LLM it&#39;s based on. This discrepancy is especially notable when LLMs are primarily trained for language completion rather than tasks involving embodied navigation actions and symbolic web elements. Our study enhances an LLM-based web agent by simply refining its observation and action space to better align with the LLM&#39;s capabilities. This approach enables our base agent to significantly outperform previous methods on a wide variety of web tasks. Specifically, on WebArena, a benchmark featuring general-purpose web interaction tasks, our agent AgentOccam surpasses the previous state-of-the-art and concurrent work by 9.8 (+29.4%) and 5.9 (+15.8%) absolute points respectively, and boosts the success rate by 26.6 points (+161%) over similar plain web agents with its observation and action space alignment. We achieve this without using in-context examples, new agent roles, online feedback or search strategies. AgentOccam&#39;s simple design highlights LLMs&#39; impressive zero-shot performance on web tasks, and underlines the critical role of carefully tuning observation and action spaces for LLM-based agents.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.13825"
    },
    "0db4f70b14ed06d0572ab72186413114": {
        "title": "From Barriers to Tactics: A Behavioral Science-Informed Agentic Workflow for Personalized Nutrition Coaching",
        "authors": [
            "Eric Yang",
            "Tomas Garcia",
            "Hannah Williams",
            "Bhawesh Kumar",
            "Martin RamÃ©",
            "Eileen Rivera",
            "Yiran Ma",
            "Jonathan Amar",
            "Caricia Catalani",
            "Yugang Jia"
        ],
        "date": "2024/10/17",
        "pdf": "http://arxiv.org/pdf/2410.14041",
        "abstract": "Effective management of cardiometabolic conditions requires sustained positive nutrition habits, often hindered by complex and individualized barriers. Direct human management is simply not scalable, while previous attempts aimed at automating nutrition coaching lack the personalization needed to address these diverse challenges. This paper introduces a novel LLM-powered agentic workflow designed to provide personalized nutrition coaching by directly targeting and mitigating patient-specific barriers. Grounded in behavioral science principles, the workflow leverages a comprehensive mapping of nutrition-related barriers to corresponding evidence-based strategies. A specialized LLM agent intentionally probes for and identifies the root cause of a patient&#39;s dietary struggles. Subsequently, a separate LLM agent delivers tailored tactics designed to overcome those specific barriers with patient context. We designed and validated our approach through a user study with individuals with cardiometabolic conditions, demonstrating the system&#39;s ability to accurately identify barriers and provide personalized guidance. Furthermore, we conducted a large-scale simulation study, grounding on real patient vignettes and expert-validated metrics, to evaluate the system&#39;s performance across a wide range of scenarios. Our findings demonstrate the potential of this LLM-powered agentic workflow to improve nutrition coaching by providing personalized, scalable, and behaviorally-informed interventions.",
        "code": "",
        "category": [
            [
                "Automation",
                "Workflow"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.14041"
    },
    "7152187cedc10c9899fa906acfc82d75": {
        "title": "Coherence-Driven Multimodal Safety Dialogue with Active Learning for Embodied Agents",
        "authors": [
            "Sabit Hassan",
            "Hye-Young Chung",
            "Xiang Zhi Tan",
            "Malihe Alikhani"
        ],
        "date": "2024/10/18",
        "pdf": "http://arxiv.org/pdf/2410.14141",
        "abstract": "When assisting people in daily tasks, robots need to accurately interpret visual cues and respond effectively in diverse safety-critical situations, such as sharp objects on the floor. In this context, we present M-CoDAL, a multimodal-dialogue system specifically designed for embodied agents to better understand and communicate in safety-critical situations. The system leverages discourse coherence relations to enhance its contextual understanding and communication abilities. To train this system, we introduce a novel clustering-based active learning mechanism that utilizes an external Large Language Model (LLM) to identify informative instances. Our approach is evaluated using a newly created multimodal dataset comprising 1K safety violations extracted from 2K Reddit images. These violations are annotated using a Large Multimodal Model (LMM) and verified by human annotators. Results with this dataset demonstrate that our approach improves resolution of safety situations, user sentiment, as well as safety of the conversation. Next, we deploy our dialogue system on a Hello Robot Stretch robot and conduct a within-subject user study with real-world participants. In the study, participants role-play two safety scenarios with different levels of severity with the robot and receive interventions from our model and a baseline system powered by OpenAI&#39;s ChatGPT. The study results corroborate and extend the findings from automated evaluation, showing that our proposed system is more persuasive and competent in a real-world embodied agent setting.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ],
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.14141"
    },
    "9fb4a22969035c98975512cc489bb6d2": {
        "title": "Synthesizing Post-Training Data for LLMs through Multi-Agent Simulation",
        "authors": [
            "Shuo Tang",
            "Xianghe Pang",
            "Zexi Liu",
            "Bohan Tang",
            "Rui Ye",
            "Tian Jin",
            "Xiaowen Dong",
            "Yanfeng Wang",
            "Siheng Chen"
        ],
        "date": "2024/10/18",
        "pdf": "http://arxiv.org/pdf/2410.14251",
        "abstract": "Post-training is essential for enabling large language models (LLMs) to follow human instructions. However, its effectiveness depends on high-quality instruction data, which is challenging to obtain in the real world due to privacy concerns, data scarcity, and high annotation costs. To fill this gap, inspired by the recent success of using LLMs to simulate human society, we propose MATRIX, a multi-agent simulator that automatically generates diverse text-based scenarios, capturing a wide range of real-world human needs in a realistic and scalable manner. Leveraging these outputs, we introduce a novel scenario-driven instruction generator MATRIX-Gen for controllable and highly realistic data synthesis. Extensive experiments demonstrate that our framework effectively generates both general and domain-specific data. On AlpacaEval 2 and Arena-Hard benchmarks, Llama-3-8B-Base, post-trained on datasets synthesized by MATRIX-Gen with just 20K instruction-response pairs, outperforms Meta&#39;s Llama-3-8B-Instruct model, which was trained on over 10M pairs.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Infrastructure",
                "Dataset"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.14251"
    },
    "b5944db3a32545c6d05a389e89b8609e": {
        "title": "SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning",
        "authors": [
            "Yizhou Chi",
            "Yizhang Lin",
            "Sirui Hong",
            "Duyi Pan",
            "Yaying Fei",
            "Guanghao Mei",
            "Bangbang Liu",
            "Tianqi Pang",
            "Jacky Kwok",
            "Ceyao Zhang",
            "Bang Liu",
            "Chenglin Wu"
        ],
        "date": "2024/10/22",
        "pdf": "http://arxiv.org/pdf/2410.17238",
        "abstract": "Automated Machine Learning (AutoML) approaches encompass traditional methods that optimize fixed pipelines for model selection and ensembling, as well as newer LLM-based frameworks that autonomously build pipelines. While LLM-based agents have shown promise in automating machine learning tasks, they often generate low-diversity and suboptimal code, even after multiple iterations. To overcome these limitations, we introduce Tree-Search Enhanced LLM Agents (SELA), an innovative agent-based system that leverages Monte Carlo Tree Search (MCTS) to optimize the AutoML process. By representing pipeline configurations as trees, our framework enables agents to conduct experiments intelligently and iteratively refine their strategies, facilitating a more effective exploration of the machine learning solution space. This novel approach allows SELA to discover optimal pathways based on experimental feedback, improving the overall quality of the solutions. In an extensive evaluation across 20 machine learning datasets, we compare the performance of traditional and agent-based AutoML methods, demonstrating that SELA achieves a win rate of 65% to 80% against each baseline across all datasets. These results underscore the significant potential of agent-based strategies in AutoML, offering a fresh perspective on tackling complex machine learning challenges.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Search"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.17238"
    },
    "5e376cf1a16e6af869b51f2242916e10": {
        "title": "AdvWeb: Controllable Black-box Attacks on VLM-powered Web Agents",
        "authors": [
            "Chejian Xu",
            "Mintong Kang",
            "Jiawei Zhang",
            "Zeyi Liao",
            "Lingbo Mo",
            "Mengqi Yuan",
            "Huan Sun",
            "Bo Li"
        ],
        "date": "2024/10/22",
        "pdf": "http://arxiv.org/pdf/2410.17401",
        "abstract": "Vision Language Models (VLMs) have revolutionized the creation of generalist web agents, empowering them to autonomously complete diverse tasks on real-world websites, thereby boosting human efficiency and productivity. However, despite their remarkable capabilities, the safety and security of these agents against malicious attacks remain critically underexplored, raising significant concerns about their safe deployment. To uncover and exploit such vulnerabilities in web agents, we provide AdvWeb, a novel black-box attack framework designed against web agents. AdvWeb trains an adversarial prompter model that generates and injects adversarial prompts into web pages, misleading web agents into executing targeted adversarial actions such as inappropriate stock purchases or incorrect bank transactions, actions that could lead to severe real-world consequences. With only black-box access to the web agent, we train and optimize the adversarial prompter model using DPO, leveraging both successful and failed attack strings against the target agent. Unlike prior approaches, our adversarial string injection maintains stealth and control: (1) the appearance of the website remains unchanged before and after the attack, making it nearly impossible for users to detect tampering, and (2) attackers can modify specific substrings within the generated adversarial string to seamlessly change the attack objective (e.g., purchasing stocks from a different company), enhancing attack flexibility and efficiency. We conduct extensive evaluations, demonstrating that AdvWeb achieves high success rates in attacking SOTA GPT-4V-based VLM agent across various web tasks. Our findings expose critical vulnerabilities in current LLM/VLM-based agents, emphasizing the urgent need for developing more reliable web agents and effective defenses. Our code and data are available at https://ai-secure.github.io/AdvWeb/ .",
        "code": "",
        "category": [
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.17401"
    },
    "755b1f3f54430a392b52bd1161dbb9c7": {
        "title": "Decoding Time Series with LLMs: A Multi-Agent Framework for Cross-Domain Annotation",
        "authors": [
            "Minhua Lin",
            "Zhengzhang Chen",
            "Yanchi Liu",
            "Xujiang Zhao",
            "Zongyu Wu",
            "Junxiang Wang",
            "Xiang Zhang",
            "Suhang Wang",
            "Haifeng Chen"
        ],
        "date": "2024/10/22",
        "pdf": "http://arxiv.org/pdf/2410.17462",
        "abstract": "Time series data is ubiquitous across various domains, including manufacturing, finance, and healthcare. High-quality annotations are essential for effectively understanding time series and facilitating downstream tasks; however, obtaining such annotations is challenging, particularly in mission-critical domains. In this paper, we propose TESSA, a multi-agent system designed to automatically generate both general and domain-specific annotations for time series data. TESSA introduces two agents: a general annotation agent and a domain-specific annotation agent. The general agent captures common patterns and knowledge across multiple source domains, leveraging both time-series-wise and text-wise features to generate general annotations. Meanwhile, the domain-specific agent utilizes limited annotations from the target domain to learn domain-specific terminology and generate targeted annotations. Extensive experiments on multiple synthetic and real-world datasets demonstrate that TESSA effectively generates high-quality annotations, outperforming existing methods.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.17462"
    },
    "6ac76cc87e780b174e4ceed8031e8914": {
        "title": "MobileSafetyBench: Evaluating Safety of Autonomous Agents in Mobile Device Control",
        "authors": [
            "Juyong Lee",
            "Dongyoon Hahm",
            "June Suk Choi",
            "W. Bradley Knox",
            "Kimin Lee"
        ],
        "date": "2024/10/23",
        "pdf": "http://arxiv.org/pdf/2410.17520",
        "abstract": "Autonomous agents powered by large language models (LLMs) show promising potential in assistive tasks across various domains, including mobile device control. As these agents interact directly with personal information and device settings, ensuring their safe and reliable behavior is crucial to prevent undesirable outcomes. However, no benchmark exists for standardized evaluation of the safety of mobile device-control agents. In this work, we introduce MobileSafetyBench, a benchmark designed to evaluate the safety of device-control agents within a realistic mobile environment based on Android emulators. We develop a diverse set of tasks involving interactions with various mobile applications, including messaging and banking applications, challenging agents with managing risks encompassing misuse and negative side effects. These tasks include tests to evaluate the safety of agents in daily scenarios as well as their robustness against indirect prompt injection attacks. Our experiments demonstrate that baseline agents, based on state-of-the-art LLMs, often fail to effectively prevent harm while performing the tasks. To mitigate these safety concerns, we propose a prompting method that encourages agents to prioritize safety considerations. While this method shows promise in promoting safer behaviors, there is still considerable room for improvement to fully earn user trust. This highlights the urgent need for continued research to develop more robust safety mechanisms in mobile environments. We open-source our benchmark at: https://mobilesafetybench.github.io/.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.17520"
    },
    "a74dfeda83a1eca851e8c597336f546a": {
        "title": "GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration",
        "authors": [
            "Xin Li",
            "Qizhi Chu",
            "Yubin Chen",
            "Yang Liu",
            "Yaoqi Liu",
            "Zekai Yu",
            "Weize Chen",
            "Chen Qian",
            "Chuan Shi",
            "Cheng Yang"
        ],
        "date": "2024/10/23",
        "pdf": "http://arxiv.org/pdf/2410.18032",
        "abstract": "Graphs are widely used for modeling relational data in real-world scenarios, such as social networks and urban computing. Existing LLM-based graph analysis approaches either integrate graph neural networks (GNNs) for specific machine learning tasks, limiting their transferability, or rely solely on LLMs&#39; internal reasoning ability, resulting in suboptimal performance. To address these limitations, we take advantage of recent advances in LLM-based agents, which have shown capabilities of utilizing external knowledge or tools for problem solving. By simulating human problem-solving strategies such as analogy and collaboration, we propose a multi-agent system based on LLMs named GraphTeam, for graph analysis. GraphTeam consists of five LLM-based agents from three modules, and the agents with different specialities can collaborate with each other to address complex problems. Specifically, (1) input-output normalization module: the question agent extracts and refines four key arguments from the original question, facilitating the problem understanding, and the answer agent organizes the results to meet the output requirement; (2) external knowledge retrieval module: we first build a knowledge base consisting of relevant documentation and experience information, and then the search agent retrieves the most relevant entries for each question. (3) problem-solving module: given the retrieved information from search agent, the coding agent uses established algorithms via programming to generate solutions, and in case the coding agent does not work, the reasoning agent will directly compute the results without programming. Extensive experiments on six graph analysis benchmarks demonstrate that GraphTeam achieves state-of-the-art performance with an average 25.85% improvement over the best baseline in terms of accuracy. The code and data are available at https://github.com/BUPT-GAMMA/GraphTeam.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.18032"
    },
    "754c1b4855932796972207a2d1a2fde3": {
        "title": "An LLM Agent for Automatic Geospatial Data Analysis",
        "authors": [
            "Yuxing Chen",
            "Weijie Wang",
            "Sylvain Lobry",
            "Camille Kurtz"
        ],
        "date": "2024/10/24",
        "pdf": "http://arxiv.org/pdf/2410.18792",
        "abstract": "Large language models (LLMs) are being used in data science code generation tasks, but they often struggle with complex sequential tasks, leading to logical errors. Their application to geospatial data processing is particularly challenging due to difficulties in incorporating complex data structures and spatial constraints, effectively utilizing diverse function calls, and the tendency to hallucinate less-used geospatial libraries. To tackle these problems, we introduce GeoAgent, a new interactive framework designed to help LLMs handle geospatial data processing more effectively. GeoAgent pioneers the integration of a code interpreter, static analysis, and Retrieval-Augmented Generation (RAG) techniques within a Monte Carlo Tree Search (MCTS) algorithm, offering a novel approach to geospatial data processing. In addition, we contribute a new benchmark specifically designed to evaluate the LLM-based approach in geospatial tasks. This benchmark leverages a variety of Python libraries and includes both single-turn and multi-turn tasks such as data acquisition, data analysis, and visualization. By offering a comprehensive evaluation among diverse geospatial contexts, this benchmark sets a new standard for developing LLM-based approaches in geospatial data analysis tasks. Our findings suggest that relying solely on knowledge of LLM is insufficient for accurate geospatial task programming, which requires coherent multi-step processes and multiple function calls. Compared to the baseline LLMs, the proposed GeoAgent has demonstrated superior performance, yielding notable improvements in function calls and task completion. In addition, these results offer valuable insights for the future development of LLM agents in automatic geospatial data analysis task programming.",
        "code": "",
        "category": [
            [
                "Automation",
                "Workflow"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.18792"
    },
    "0cc393b50ae9cb9f69c20b0451475020": {
        "title": "Schema-Guided Culture-Aware Complex Event Simulation with Multi-Agent Role-Play",
        "authors": [
            "Sha Li",
            "Revanth Gangi Reddy",
            "Khanh Duy Nguyen",
            "Qingyun Wang",
            "May Fung",
            "Chi Han",
            "Jiawei Han",
            "Kartik Natarajan",
            "Clare R. Voss",
            "Heng Ji"
        ],
        "date": "2024/10/24",
        "pdf": "http://arxiv.org/pdf/2410.18935",
        "abstract": "Complex news events, such as natural disasters and socio-political conflicts, require swift responses from the government and society. Relying on historical events to project the future is insufficient as such events are sparse and do not cover all possible conditions and nuanced situations. Simulation of these complex events can help better prepare and reduce the negative impact. We develop a controllable complex news event simulator guided by both the event schema representing domain knowledge about the scenario and user-provided assumptions representing case-specific conditions. As event dynamics depend on the fine-grained social and cultural context, we further introduce a geo-diverse commonsense and cultural norm-aware knowledge enhancement component. To enhance the coherence of the simulation, apart from the global timeline of events, we take an agent-based approach to simulate the individual character states, plans, and actions. By incorporating the schema and cultural norms, our generated simulations achieve much higher coherence and appropriateness and are received favorably by participants from a humanitarian assistance organization.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ],
            [
                "Interaction",
                "Simulation"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.18935"
    },
    "04dd7ba6a07a1a76773e1f058af0155b": {
        "title": "Infogent: An Agent-Based Framework for Web Information Aggregation",
        "authors": [
            "Revanth Gangi Reddy",
            "Sagnik Mukherjee",
            "Jeonghwan Kim",
            "Zhenhailong Wang",
            "Dilek Hakkani-Tur",
            "Heng Ji"
        ],
        "date": "2024/10/24",
        "pdf": "http://arxiv.org/pdf/2410.19054",
        "abstract": "Despite seemingly performant web agents on the task-completion benchmarks, most existing methods evaluate the agents based on a presupposition: the web navigation task consists of linear sequence of actions with an end state that marks task completion. In contrast, our work focuses on web navigation for information aggregation, wherein the agent must explore different websites to gather information for a complex query. We consider web information aggregation from two different perspectives: (i) Direct API-driven Access relies on a text-only view of the Web, leveraging external tools such as Google Search API to navigate the web and a scraper to extract website contents. (ii) Interactive Visual Access uses screenshots of the webpages and requires interaction with the browser to navigate and access information. Motivated by these diverse information access settings, we introduce Infogent, a novel modular framework for web information aggregation involving three distinct components: Navigator, Extractor and Aggregator. Experiments on different information access settings demonstrate Infogent beats an existing SOTA multi-agent search framework by 7% under Direct API-Driven Access on FRAMES, and improves over an existing information-seeking web agent by 4.3% under Interactive Visual Access on AssistantBench.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.19054"
    },
    "ef3801db57607ba7b38a23ae91dc4ff0": {
        "title": "ControlAgent: Automating Control System Design via Novel Integration of LLM Agents and Domain Expertise",
        "authors": [
            "Xingang Guo",
            "Darioush Keivan",
            "Usman Syed",
            "Lianhui Qin",
            "Huan Zhang",
            "Geir Dullerud",
            "Peter Seiler",
            "Bin Hu"
        ],
        "date": "2024/10/17",
        "pdf": "http://arxiv.org/pdf/2410.19811",
        "abstract": "Control system design is a crucial aspect of modern engineering with far-reaching applications across diverse sectors including aerospace, automotive systems, power grids, and robotics. Despite advances made by Large Language Models (LLMs) in various domains, their application in control system design remains limited due to the complexity and specificity of control theory. To bridge this gap, we introduce ControlAgent, a new paradigm that automates control system design via novel integration of LLM agents and control-oriented domain expertise. ControlAgent encodes expert control knowledge and emulates human iterative design processes by gradually tuning controller parameters to meet user-specified requirements for stability, performance, and robustness. ControlAgent integrates multiple collaborative LLM agents, including a central agent responsible for task distribution and task-specific agents dedicated to detailed controller design for various types of systems and requirements. ControlAgent also employs a Python computation agent that performs complex calculations and controller evaluations based on standard design information provided by task-specified LLM agents. Combined with a history and feedback module, the task-specific LLM agents iteratively refine controller parameters based on real-time feedback from prior designs. Overall, ControlAgent mimics the design processes used by (human) practicing engineers, but removes all the human efforts and can be run in a fully automated way to give end-to-end solutions for control system design with user-specified requirements. To validate ControlAgent&#39;s effectiveness, we develop ControlEval, an evaluation dataset that comprises 500 control tasks with various specific design goals. The effectiveness of ControlAgent is demonstrated via extensive comparative evaluations between LLM-based and traditional human-involved toolbox-based baselines.",
        "code": "",
        "category": [
            [
                "Automation",
                "Workflow"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.19811"
    },
    "48155878cc2ed9a5e204b5f705296ff0": {
        "title": "AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions",
        "authors": [
            "Ziming Li",
            "Qianbo Zang",
            "David Ma",
            "Jiawei Guo",
            "Tuney Zheng",
            "Minghao Liu",
            "Xinyao Niu",
            "Yue Wang",
            "Jian Yang",
            "Jiaheng Liu",
            "Wanjun Zhong",
            "Wangchunshu Zhou",
            "Wenhao Huang",
            "Ge Zhang"
        ],
        "date": "2024/10/27",
        "pdf": "http://arxiv.org/pdf/2410.20424",
        "abstract": "Data science tasks involving tabular data present complex challenges that require sophisticated problem-solving approaches. We propose AutoKaggle, a powerful and user-centric framework that assists data scientists in completing daily data pipelines through a collaborative multi-agent system. AutoKaggle implements an iterative development process that combines code execution, debugging, and comprehensive unit testing to ensure code correctness and logic consistency. The framework offers highly customizable workflows, allowing users to intervene at each phase, thus integrating automated intelligence with human expertise. Our universal data science toolkit, comprising validated functions for data cleaning, feature engineering, and modeling, forms the foundation of this solution, enhancing productivity by streamlining common tasks. We selected 8 Kaggle competitions to simulate data processing workflows in real-world application scenarios. Evaluation results demonstrate that AutoKaggle achieves a validation submission rate of 0.85 and a comprehensive score of 0.82 in typical data science pipelines, fully proving its effectiveness and practicality in handling complex data science tasks.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.20424"
    },
    "e34208346b53d465040b4d4629500b75": {
        "title": "Guide-LLM: An Embodied LLM Agent and Text-Based Topological Map for Robotic Guidance of People with Visual Impairments",
        "authors": [
            "Sangmim Song",
            "Sarath Kodagoda",
            "Amal Gunatilake",
            "Marc G. Carmichael",
            "Karthick Thiyagarajan",
            "Jodi Martin"
        ],
        "date": "2024/10/28",
        "pdf": "http://arxiv.org/pdf/2410.20666",
        "abstract": "Navigation presents a significant challenge for persons with visual impairments (PVI). While traditional aids such as white canes and guide dogs are invaluable, they fall short in delivering detailed spatial information and precise guidance to desired locations. Recent developments in large language models (LLMs) and vision-language models (VLMs) offer new avenues for enhancing assistive navigation. In this paper, we introduce Guide-LLM, an embodied LLM-based agent designed to assist PVI in navigating large indoor environments. Our approach features a novel text-based topological map that enables the LLM to plan global paths using a simplified environmental representation, focusing on straight paths and right-angle turns to facilitate navigation. Additionally, we utilize the LLM&#39;s commonsense reasoning for hazard detection and personalized path planning based on user preferences. Simulated experiments demonstrate the system&#39;s efficacy in guiding PVI, underscoring its potential as a significant advancement in assistive technology. The results highlight Guide-LLM&#39;s ability to offer efficient, adaptive, and personalized navigation assistance, pointing to promising advancements in this field.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.20666"
    },
    "bd58f4ac5680ddf73fefc5fdf8f4827c": {
        "title": "$\\texttt{PatentAgent}$: Intelligent Agent for Automated Pharmaceutical Patent Analysis",
        "authors": [
            "Xin Wang",
            "Yifan Zhang",
            "Xiaojing Zhang",
            "Longhui Yu",
            "Xinna Lin",
            "Jindong Jiang",
            "Bin Ma",
            "Kaicheng Yu"
        ],
        "date": "2024/10/25",
        "pdf": "http://arxiv.org/pdf/2410.21312",
        "abstract": "Pharmaceutical patents play a vital role in biochemical industries, especially in drug discovery, providing researchers with unique early access to data, experimental results, and research insights. With the advancement of machine learning, patent analysis has evolved from manual labor to tasks assisted by automatic tools. However, there still lacks an unified agent that assists every aspect of patent analysis, from patent reading to core chemical identification. Leveraging the capabilities of Large Language Models (LLMs) to understand requests and follow instructions, we introduce the $\\textbf{first}$ intelligent agent in this domain, $\\texttt{PatentAgent}$, poised to advance and potentially revolutionize the landscape of pharmaceutical research. $\\texttt{PatentAgent}$ comprises three key end-to-end modules -- $\\textit{PA-QA}$, $\\textit{PA-Img2Mol}$, and $\\textit{PA-CoreId}$ -- that respectively perform (1) patent question-answering, (2) image-to-molecular-structure conversion, and (3) core chemical structure identification, addressing the essential needs of scientists and practitioners in pharmaceutical patent analysis. Each module of $\\texttt{PatentAgent}$ demonstrates significant effectiveness with the updated algorithm and the synergistic design of $\\texttt{PatentAgent}$ framework. $\\textit{PA-Img2Mol}$ outperforms existing methods across CLEF, JPO, UOB, and USPTO patent benchmarks with an accuracy gain between 2.46% and 8.37% while $\\textit{PA-CoreId}$ realizes accuracy improvement ranging from 7.15% to 7.62% on PatentNetML benchmark. Our code and dataset will be publicly available.",
        "code": "",
        "category": [
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.21312"
    },
    "6171d08a4b6ca52c9cbcb1db304e40fb": {
        "title": "MARCO: Multi-Agent Real-time Chat Orchestration",
        "authors": [
            "Anubhav Shrimal",
            "Stanley Kanagaraj",
            "Kriti Biswas",
            "Swarnalatha Raghuraman",
            "Anish Nediyanchath",
            "Yi Zhang",
            "Promod Yenigalla"
        ],
        "date": "2024/10/29",
        "pdf": "http://arxiv.org/pdf/2410.21784",
        "abstract": "Large language model advancements have enabled the development of multi-agent frameworks to tackle complex, real-world problems such as to automate tasks that require interactions with diverse tools, reasoning, and human collaboration. We present MARCO, a Multi-Agent Real-time Chat Orchestration framework for automating tasks using LLMs. MARCO addresses key challenges in utilizing LLMs for complex, multi-step task execution. It incorporates robust guardrails to steer LLM behavior, validate outputs, and recover from errors that stem from inconsistent output formatting, function and parameter hallucination, and lack of domain knowledge. Through extensive experiments we demonstrate MARCO&#39;s superior performance with 94.48% and 92.74% accuracy on task execution for Digital Restaurant Service Platform conversations and Retail conversations datasets respectively along with 44.91% improved latency and 33.71% cost reduction. We also report effects of guardrails in performance gain along with comparisons of various LLM models, both open-source and proprietary. The modular and generic design of MARCO allows it to be adapted for automating tasks across domains and to execute complex usecases through multi-turn interactions.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.21784"
    },
    "bb6f1317381adf0bf6d3cc5806b230cd": {
        "title": "ADAM: An Embodied Causal Agent in Open-World Environments",
        "authors": [
            "Shu Yu",
            "Chaochao Lu"
        ],
        "date": "2024/10/29",
        "pdf": "http://arxiv.org/pdf/2410.22194",
        "abstract": "In open-world environments like Minecraft, existing agents face challenges in continuously learning structured knowledge, particularly causality. These challenges stem from the opacity inherent in black-box models and an excessive reliance on prior knowledge during training, which impair their interpretability and generalization capability. To this end, we introduce ADAM, An emboDied causal Agent in Minecraft, that can autonomously navigate the open world, perceive multimodal contexts, learn causal world knowledge, and tackle complex tasks through lifelong learning. ADAM is empowered by four key components: 1) an interaction module, enabling the agent to execute actions while documenting the interaction processes; 2) a causal model module, tasked with constructing an ever-growing causal graph from scratch, which enhances interpretability and diminishes reliance on prior knowledge; 3) a controller module, comprising a planner, an actor, and a memory pool, which uses the learned causal graph to accomplish tasks; 4) a perception module, powered by multimodal large language models, which enables ADAM to perceive like a human player. Extensive experiments show that ADAM constructs an almost perfect causal graph from scratch, enabling efficient task decomposition and execution with strong interpretability. Notably, in our modified Minecraft games where no prior knowledge is available, ADAM maintains its performance and shows remarkable robustness and generalization capability. ADAM pioneers a novel paradigm that integrates causal methods and embodied agents in a synergistic manner. Our project page is at https://opencausalab.github.io/ADAM.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2410.22194"
    },
    "bb312ac50b54729c4d6bd96e0da9bead": {
        "title": "The Ability of Large Language Models to Evaluate Constraint-satisfaction in Agent Responses to Open-ended Requests",
        "authors": [
            "Lior Madmoni",
            "Amir Zait",
            "Ilia Labzovsky",
            "Danny Karmon"
        ],
        "date": "2024/09/22",
        "pdf": "http://arxiv.org/pdf/2409.14371",
        "abstract": "Generative AI agents are often expected to respond to complex user requests that have No One Right Answer (NORA), e.g., &#34;design a vegetarian meal plan below 1800 calories&#34;. Such requests may entail a set of constraints that the agent should adhere to. To successfully develop agents for NORA scenarios, an accurate automatic evaluation framework is essential, and specifically - one capable of validating the satisfaction of constraints in the agent&#39;s response. Recently, large language models (LLMs) have been adopted as versatile evaluators for many NORA tasks, but their ability to evaluate constraint-satisfaction in generated text remains unclear. To study this, we develop and release a novel Arithmetic Constraint-Satisfaction (ACS) benchmarking dataset. The dataset consists of complex user requests with corresponding constraints, agent responses and human labels indicating each constraint&#39;s satisfaction level in the response. A unique property of this dataset is that validating many of its constraints requires reviewing the response as a whole (in contrast to many other benchmarks that require the validation of a single independent item). Moreover, it assesses LLMs in performing reasoning, in-context data extraction, arithmetic calculations, and counting. We then benchmark both open and proprietary LLMs on evaluating constraint-satisfaction, and show that most models still have a significant headroom for improvement, and that errors primarily stem from reasoning issues. In addition, most models exhibit a skewed constraint-satisfaction prediction pattern, with higher accuracy where the ground-truth label is &#34;satisfied&#34;. Lastly, few-shot prompting for our task proved to be rather challenging, since many of the studied models showed a degradation in performance when it was introduced.",
        "code": "",
        "category": [
            [
                "Automation",
                "Automatic Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.14371"
    },
    "34dede8cf1ee09ccdbfa52fade7357d0": {
        "title": "ERABAL: Enhancing Role-Playing Agents through Boundary-Aware Learning",
        "authors": [
            "Yihong Tang",
            "Jiao Ou",
            "Che Liu",
            "Fuzheng Zhang",
            "Di Zhang",
            "Kun Gai"
        ],
        "date": "2024/09/23",
        "pdf": "http://arxiv.org/pdf/2409.14710",
        "abstract": "Role-playing is an emerging application in the field of Human-Computer Interaction (HCI), primarily implemented through the alignment training of a large language model (LLM) with assigned characters. Despite significant progress, role-playing agents (RPLAs) still struggle with maintaining role-consistency across conversations, particularly when confronted with boundary queries subtly related to character attributes. In this paper, we present ERABAL, a framework aimed at enhancing RPLAs&#39; role-playing capabilities through boundary-aware learning. ERABAL encompasses a generation pipeline for role-specific dialogues and a concomitant methodology for alignment training. Through comprehensive evaluations, we demonstrate that ERABAL is both efficient and effective. By training with significantly fewer dialogues than those used in leading approaches, ERABAL achieves notable improvements across WikiRoleEval, CharacterEval, and the role-playing subset of MT-Bench compared to the generalist baseline models. Our code and datasets will be made publicly available to support further research.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.14710"
    },
    "dd00a0fbb2bee5fd3f114ae9def2f127": {
        "title": "Towards a Realistic Long-Term Benchmark for Open-Web Research Agents",
        "authors": [
            "Peter MÃ¼hlbacher",
            "Nikos I. Bosse",
            "Lawrence Phillips"
        ],
        "date": "2024/09/23",
        "pdf": "http://arxiv.org/pdf/2409.14913",
        "abstract": "We present initial results of a forthcoming benchmark for evaluating LLM agents on white-collar tasks of economic value. We evaluate agents on real-world &#34;messy&#34; open-web research tasks of the type that are routine in finance and consulting. In doing so, we lay the groundwork for an LLM agent evaluation suite where good performance directly corresponds to a large economic and societal impact. We built and tested several agent architectures with o1-preview, GPT-4o, Claude-3.5 Sonnet, Llama 3.1 (405b), and GPT-4o-mini. On average, LLM agents powered by Claude-3.5 Sonnet and o1-preview substantially outperformed agents using GPT-4o, with agents based on Llama 3.1 (405b) and GPT-4o-mini lagging noticeably behind. Across LLMs, a ReAct architecture with the ability to delegate subtasks to subagents performed best. In addition to quantitative evaluations, we qualitatively assessed the performance of the LLM agents by inspecting their traces and reflecting on their observations. Our evaluation represents the first in-depth assessment of agents&#39; abilities to conduct challenging, economically valuable analyst-style research on the real open web.",
        "code": "",
        "category": [
            [
                "Application",
                "Research"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.14913"
    },
    "746409495d2ea05b1222f0cd8ea11fb4": {
        "title": "Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents",
        "authors": [
            "Bandhav Veluri",
            "Benjamin N Peloquin",
            "Bokai Yu",
            "Hongyu Gong",
            "Shyamnath Gollakota"
        ],
        "date": "2024/09/23",
        "pdf": "http://arxiv.org/pdf/2409.15594",
        "abstract": "Despite broad interest in modeling spoken dialogue agents, most approaches are inherently &#34;half-duplex&#34; -- restricted to turn-based interaction with responses requiring explicit prompting by the user or implicit tracking of interruption or silence events. Human dialogue, by contrast, is &#34;full-duplex&#34; allowing for rich synchronicity in the form of quick and dynamic turn-taking, overlapping speech, and backchanneling. Technically, the challenge of achieving full-duplex dialogue with LLMs lies in modeling synchrony as pre-trained LLMs do not have a sense of &#34;time&#34;. To bridge this gap, we propose Synchronous LLMs for full-duplex spoken dialogue modeling. We design a novel mechanism to integrate time information into Llama3-8b so that they run synchronously with the real-world clock. We also introduce a training recipe that uses 212k hours of synthetic spoken dialogue data generated from text dialogue data to create a model that generates meaningful and natural spoken dialogue, with just 2k hours of real-world spoken dialogue data. Synchronous LLMs outperform state-of-the-art in dialogue meaningfulness while maintaining naturalness. Finally, we demonstrate the model&#39;s ability to participate in full-duplex dialogue by simulating interaction between two agents trained on different datasets, while considering Internet-scale latencies of up to 240 ms. Webpage: https://syncllm.cs.washington.edu/.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.15594"
    },
    "5f1e635457185ba1426c76ebc3fe581f": {
        "title": "Automated test generation to evaluate tool-augmented LLMs as conversational AI agents",
        "authors": [
            "Samuel Arcadinho",
            "David Aparicio",
            "Mariana Almeida"
        ],
        "date": "2024/09/24",
        "pdf": "http://arxiv.org/pdf/2409.15934",
        "abstract": "Tool-augmented LLMs are a promising approach to create AI agents that can have realistic conversations, follow procedures, and call appropriate functions. However, evaluating them is challenging due to the diversity of possible conversations, and existing datasets focus only on single interactions and function-calling. We present a test generation pipeline to evaluate LLMs as conversational AI agents. Our framework uses LLMs to generate diverse tests grounded on user-defined procedures. For that, we use intermediate graphs to limit the LLM test generator&#39;s tendency to hallucinate content that is not grounded on input procedures, and enforces high coverage of the possible conversations. Additionally, we put forward ALMITA, a manually curated dataset for evaluating AI agents in customer support, and use it to evaluate existing LLMs. Our results show that while tool-augmented LLMs perform well in single interactions, they often struggle to handle complete conversations. While our focus is on customer support, our method is general and capable of AI agents for different domains.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ],
            [
                "Interaction",
                "Conversation"
            ],
            [
                "Automation",
                "Automatic Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.15934"
    },
    "fd47a9bf36e0f553ccfb797072d92bf9": {
        "title": "Plurals: A System for Guiding LLMs Via Simulated Social Ensembles",
        "authors": [
            "Joshua Ashkinaze",
            "Emily Fry",
            "Narendra Edara",
            "Eric Gilbert",
            "Ceren Budak"
        ],
        "date": "2024/09/25",
        "pdf": "http://arxiv.org/pdf/2409.17213",
        "abstract": "Recent debates raised concerns that language models may favor certain viewpoints. But what if the solution is not to aim for a &#39;view from nowhere&#39; but rather to leverage different viewpoints? We introduce Plurals, a system and Python library for pluralistic AI deliberation. Plurals consists of Agents (LLMs, optionally with personas) which deliberate within customizable Structures, with Moderators overseeing deliberation. Plurals is a generator of simulated social ensembles. Plurals integrates with government datasets to create nationally representative personas, includes deliberation templates inspired by deliberative democracy, and allows users to customize both information-sharing structures and deliberation behavior within Structures. Six case studies demonstrate fidelity to theoretical constructs and efficacy. Three randomized experiments show simulated focus groups produced output resonant with an online sample of the relevant audiences (chosen over zero-shot generation in 75% of trials). Plurals is both a paradigm and a concrete system for pluralistic AI. The Plurals library is available at https://github.com/josh-ashkinaze/plurals and will be continually updated.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.17213"
    },
    "64c171708415d40fa08c6bd9f6fc6d4f": {
        "title": "A Survey on Complex Tasks for Goal-Directed Interactive Agents",
        "authors": [
            "Mareike Hartmann",
            "Alexander Koller"
        ],
        "date": "2024/09/27",
        "pdf": "http://arxiv.org/pdf/2409.18538",
        "abstract": "Goal-directed interactive agents, which autonomously complete tasks through interactions with their environment, can assist humans in various domains of their daily lives. Recent advances in large language models (LLMs) led to a surge of new, more and more challenging tasks to evaluate such agents. To properly contextualize performance across these tasks, it is imperative to understand the different challenges they pose to agents. To this end, this survey compiles relevant tasks and environments for evaluating goal-directed interactive agents, structuring them along dimensions relevant for understanding current obstacles. An up-to-date compilation of relevant resources can be found on our project website: https://coli-saar.github.io/interactive-agents.",
        "code": "",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2409.18538"
    },
    "db92968cb99da099ce2f5a7d57b8938c": {
        "title": "Towards Automated Patent Workflows: AI-Orchestrated Multi-Agent Framework for Intellectual Property Management and Analysis",
        "authors": [
            "Sakhinana Sagar Srinivas",
            "Vijay Sri Vaikunth",
            "Venkataramana Runkana"
        ],
        "date": "2024/09/21",
        "pdf": "http://arxiv.org/pdf/2409.19006",
        "abstract": "Patents are the currency of innovation, and like any currency, they need to be managed and protected (Gavin Potenza). Patents, as legal documents that secure intellectual property rights, play a critical role in technological innovation. The growing complexity of patent documents and the surge in patent applications have created a need for automated solutions in patent analysis. In this work, we present PatExpert, an autonomous multi-agent conversational framework designed to streamline and optimize patent-related tasks. The framework consists of a metaagent that coordinates task-specific expert agents for various patent-related tasks and a critique agent for error handling and feedback provision. The meta-agent orchestrates specialized expert agents, each fine-tuned for specific tasks such as patent classification, acceptance, claim generation, abstractive summarization, multi-patent analysis, and scientific hypothesis generation. For multi-patent analysis, the framework incorporates advanced methods like Graph Retrieval-Augmented Generation (GRAG) to enhance response accuracy and relevance by combining semantic similarity with knowledge graphs. Error handling is managed by critique agents (Gold-LLM-as-a-Judge and Reward-LLM-as-a-Judge), which evaluate output responses for accuracy and provide iterative feedback. The framework also prioritizes explainability, ensuring transparent justifications for decisions made during patent analysis. Its comprehensive capabilities make it a valuable tool for automating complex patent workflows, enhancing efficiency, accuracy, and compliance in patent-related tasks. Empirical evidence demonstrates significant improvements in patent processing tasks, concluding that the framework offers a robust solution for automating and optimizing patent analysis.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.19006"
    },
    "4b5a3dd76f2e66f22a4adc7ac0054530": {
        "title": "Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs",
        "authors": [
            "Zheng Wang",
            "Zhongyang Li",
            "Zeren Jiang",
            "Dandan Tu",
            "Wei Shi"
        ],
        "date": "2024/09/28",
        "pdf": "http://arxiv.org/pdf/2409.19401",
        "abstract": "In the age of mobile internet, user data, often referred to as memories, is continuously generated on personal devices. Effectively managing and utilizing this data to deliver services to users is a compelling research topic. In this paper, we introduce a novel task of crafting personalized agents powered by large language models (LLMs), which utilize a user&#39;s smartphone memories to enhance downstream applications with advanced LLM capabilities. To achieve this goal, we introduce EMG-RAG, a solution that combines Retrieval-Augmented Generation (RAG) techniques with an Editable Memory Graph (EMG). This approach is further optimized using Reinforcement Learning to address three distinct challenges: data collection, editability, and selectability. Extensive experiments on a real-world dataset validate the effectiveness of EMG-RAG, achieving an improvement of approximately 10% over the best existing approach. Additionally, the personalized agents have been transferred into a real smartphone AI assistant, which leads to enhanced usability.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Memory Mechanism"
            ],
            [
                "Technique For Enhancement",
                "RAG"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.19401"
    },
    "82e7c720dafe7b45fbc53faddaf12374": {
        "title": "Co-Learning: Code Learning for Multi-Agent Reinforcement Collaborative Framework with Conversational Natural Language Interfaces",
        "authors": [
            "Jiapeng Yu",
            "Yuqian Wu",
            "Yajing Zhan",
            "Wenhao Guo",
            "Zhou Xu",
            "Raymond Lee"
        ],
        "date": "2024/09/02",
        "pdf": "http://arxiv.org/pdf/2409.00985",
        "abstract": "Online question-and-answer (Q\\&amp;A) systems based on the Large Language Model (LLM) have progressively diverged from recreational to professional use. This paper proposed a Multi-Agent framework with environmentally reinforcement learning (E-RL) for code correction called Code Learning (Co-Learning) community, assisting beginners to correct code errors independently. It evaluates the performance of multiple LLMs from an original dataset with 702 error codes, uses it as a reward or punishment criterion for E-RL; Analyzes input error codes by the current agent; selects the appropriate LLM-based agent to achieve optimal error correction accuracy and reduce correction time. Experiment results showed that 3\\% improvement in Precision score and 15\\% improvement in time cost as compared with no E-RL method respectively. Our source code is available at: https://github.com/yuqian2003/Co_Learning",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ],
            [
                "Application",
                "Software Engineering"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.00985"
    },
    "02a0b2fc91f2e9d34a8068697e17bd4c": {
        "title": "A Survey on Emergent Language",
        "authors": [
            "Jannik Peters",
            "Constantin Waubert de Puiseau",
            "Hasan Tercan",
            "Arya Gopikrishnan",
            "Gustavo Adolpho Lucas De Carvalho",
            "Christian Bitter",
            "Tobias Meisen"
        ],
        "date": "2024/09/04",
        "pdf": "http://arxiv.org/pdf/2409.02645",
        "abstract": "The field of emergent language represents a novel area of research within the domain of artificial intelligence, particularly within the context of multi-agent reinforcement learning. Although the concept of studying language emergence is not new, early approaches were primarily concerned with explaining human language formation, with little consideration given to its potential utility for artificial agents. In contrast, studies based on reinforcement learning aim to develop communicative capabilities in agents that are comparable to or even superior to human language. Thus, they extend beyond the learned statistical representations that are common in natural language processing research. This gives rise to a number of fundamental questions, from the prerequisites for language emergence to the criteria for measuring its success. This paper addresses these questions by providing a comprehensive review of 181 scientific publications on emergent language in artificial intelligence. Its objective is to serve as a reference for researchers interested in or proficient in the field. Consequently, the main contributions are the definition and overview of the prevailing terminology, the analysis of existing evaluation methods and metrics, and the description of the identified research gaps.",
        "code": "",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2409.02645"
    },
    "e993f041789c8f1e491acdea1ffd4aef": {
        "title": "From MOOC to MAIC: Reshaping Online Teaching and Learning through LLM-driven Agents",
        "authors": [
            "Jifan Yu",
            "Zheyuan Zhang",
            "Daniel Zhang-li",
            "Shangqing Tu",
            "Zhanxin Hao",
            "Rui Miao Li",
            "Haoxuan Li",
            "Yuanchun Wang",
            "Hanming Li",
            "Linlu Gong",
            "Jie Cao",
            "Jiayin Lin",
            "Jinchang Zhou",
            "Fei Qin",
            "Haohua Wang",
            "Jianxiao Jiang",
            "Lijun Deng",
            "Yisi Zhan",
            "Chaojun Xiao",
            "Xusheng Dai",
            "Xuan Yan",
            "Nianyi Lin",
            "Nan Zhang",
            "Ruixin Ni",
            "Yang Dang",
            "Lei Hou",
            "Yu Zhang",
            "Xu Han",
            "Manli Li",
            "Juanzi Li",
            "Zhiyuan Liu",
            "Huiqin Liu",
            "Maosong Sun"
        ],
        "date": "2024/09/05",
        "pdf": "http://arxiv.org/pdf/2409.03512",
        "abstract": "Since the first instances of online education, where courses were uploaded to accessible and shared online platforms, this form of scaling the dissemination of human knowledge to reach a broader audience has sparked extensive discussion and widespread adoption. Recognizing that personalized learning still holds significant potential for improvement, new AI technologies have been continuously integrated into this learning format, resulting in a variety of educational AI applications such as educational recommendation and intelligent tutoring. The emergence of intelligence in large language models (LLMs) has allowed for these educational enhancements to be built upon a unified foundational model, enabling deeper integration. In this context, we propose MAIC (Massive AI-empowered Course), a new form of online education that leverages LLM-driven multi-agent systems to construct an AI-augmented classroom, balancing scalability with adaptivity. Beyond exploring the conceptual framework and technical innovations, we conduct preliminary experiments at Tsinghua University, one of China&#39;s leading universities. Drawing from over 100,000 learning records of more than 500 students, we obtain a series of valuable observations and initial analyses. This project will continue to evolve, ultimately aiming to establish a comprehensive open platform that supports and unifies research, technology, and applications in exploring the possibilities of online education in the era of large model AI. We envision this platform as a collaborative hub, bringing together educators, researchers, and innovators to collectively explore the future of AI-driven online education.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.03512"
    },
    "3e94d8511af8b7cb112bc3e3bdda8128": {
        "title": "Using Large Language Models to Generate Authentic Multi-agent Knowledge Work Datasets",
        "authors": [
            "Desiree Heim",
            "Christian Jilek",
            "Adrian Ulges",
            "Andreas Dengel"
        ],
        "date": "2024/09/06",
        "pdf": "http://arxiv.org/pdf/2409.04286",
        "abstract": "Current publicly available knowledge work data collections lack diversity, extensive annotations, and contextual information about the users and their documents. These issues hinder objective and comparable data-driven evaluations and optimizations of knowledge work assistance systems. Due to the considerable resources needed to collect such data in real-life settings and the necessity of data censorship, collecting such a dataset appears nearly impossible. For this reason, we propose a configurable, multi-agent knowledge work dataset generator. This system simulates collaborative knowledge work among agents producing Large Language Model-generated documents and accompanying data traces. Additionally, the generator captures all background information, given in its configuration or created during the simulation process, in a knowledge graph. Finally, the resulting dataset can be utilized and shared without privacy or confidentiality concerns. This paper introduces our approach&#39;s design and vision and focuses on generating authentic knowledge work documents using Large Language Models. Our study involving human raters who assessed 53% of the generated and 74% of the real documents as realistic demonstrates the potential of our approach. Furthermore, we analyze the authenticity criteria mentioned in the participants&#39; comments and elaborate on potential improvements for identified common issues.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Infrastructure",
                "Dataset"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.04286"
    },
    "4a59b5d4fb6f7293c6dbb7e6b050f812": {
        "title": "SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning",
        "authors": [
            "Alireza Ghafarollahi",
            "Markus J. Buehler"
        ],
        "date": "2024/09/09",
        "pdf": "http://arxiv.org/pdf/2409.05556",
        "abstract": "A key challenge in artificial intelligence is the creation of systems capable of autonomously advancing scientific understanding by exploring novel domains, identifying complex patterns, and uncovering previously unseen connections in vast scientific data. In this work, we present SciAgents, an approach that leverages three core concepts: (1) the use of large-scale ontological knowledge graphs to organize and interconnect diverse scientific concepts, (2) a suite of large language models (LLMs) and data retrieval tools, and (3) multi-agent systems with in-situ learning capabilities. Applied to biologically inspired materials, SciAgents reveals hidden interdisciplinary relationships that were previously considered unrelated, achieving a scale, precision, and exploratory power that surpasses traditional human-driven research methods. The framework autonomously generates and refines research hypotheses, elucidating underlying mechanisms, design principles, and unexpected material properties. By integrating these capabilities in a modular fashion, the intelligent system yields material discoveries, critique and improve existing hypotheses, retrieve up-to-date data about existing research, and highlights their strengths and limitations. Our case studies demonstrate scalable capabilities to combine generative AI, ontological representations, and multi-agent modeling, harnessing a `swarm of intelligence&#39; similar to biological systems. This provides new avenues for materials discovery and accelerates the development of advanced materials by unlocking Nature&#39;s design principles.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Search"
            ],
            [
                "Application",
                "Research"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.05556"
    },
    "6de7a5738c9e900612b380db5c07a079": {
        "title": "Using Generative Agents to Create Tip Sheets for Investigative Data Reporting",
        "authors": [
            "Joris Veerbeek",
            "Nicholas Diakopoulos"
        ],
        "date": "2024/09/11",
        "pdf": "http://arxiv.org/pdf/2409.07286",
        "abstract": "This paper introduces a system using generative AI agents to create tip sheets for investigative data reporting. Our system employs three specialized agents--an analyst, a reporter, and an editor--to collaboratively generate and refine tips from datasets. We validate this approach using real-world investigative stories, demonstrating that our agent-based system generally generates more newsworthy and accurate insights compared to a baseline model without agents, although some variability was noted between different stories. Our findings highlight the potential of generative AI to provide leads for investigative data reporting.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.07286"
    },
    "7a38cccb4e66d1f09fb40e7e40b39bd5": {
        "title": "SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories",
        "authors": [
            "Ben Bogin",
            "Kejuan Yang",
            "Shashank Gupta",
            "Kyle Richardson",
            "Erin Bransom",
            "Peter Clark",
            "Ashish Sabharwal",
            "Tushar Khot"
        ],
        "date": "2024/09/11",
        "pdf": "http://arxiv.org/pdf/2409.07440",
        "abstract": "Given that Large Language Models (LLMs) have made significant progress in writing code, can they now be used to autonomously reproduce results from research repositories? Such a capability would be a boon to the research community, helping researchers validate, understand, and extend prior work. To advance towards this goal, we introduce SUPER, the first benchmark designed to evaluate the capability of LLMs in setting up and executing tasks from research repositories. SUPERaims to capture the realistic challenges faced by researchers working with Machine Learning (ML) and Natural Language Processing (NLP) research repositories. Our benchmark comprises three distinct problem sets: 45 end-to-end problems with annotated expert solutions, 152 sub problems derived from the expert set that focus on specific challenges (e.g., configuring a trainer), and 602 automatically generated problems for larger-scale development. We introduce various evaluation measures to assess both task success and progress, utilizing gold solutions when available or approximations otherwise. We show that state-of-the-art approaches struggle to solve these problems with the best model (GPT-4o) solving only 16.3% of the end-to-end set, and 46.1% of the scenarios. This illustrates the challenge of this task, and suggests that SUPER can serve as a valuable resource for the community to make and measure progress.",
        "code": "",
        "category": [
            [
                "Application",
                "Research"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.07440"
    },
    "1ae330f91317aca5507a022b64aae990": {
        "title": "DSBench: How Far Are Data Science Agents to Becoming Data Science Experts?",
        "authors": [
            "Liqiang Jing",
            "Zhehui Huang",
            "Xiaoyang Wang",
            "Wenlin Yao",
            "Wenhao Yu",
            "Kaixin Ma",
            "Hongming Zhang",
            "Xinya Du",
            "Dong Yu"
        ],
        "date": "2024/09/12",
        "pdf": "http://arxiv.org/pdf/2409.07703",
        "abstract": "Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) have demonstrated impressive language/vision reasoning abilities, igniting the recent trend of building agents for targeted applications such as shopping assistants or AI software engineers. Recently, many data science benchmarks have been proposed to investigate their performance in the data science domain. However, existing data science benchmarks still fall short when compared to real-world data science applications due to their simplified settings. To bridge this gap, we introduce DSBench, a comprehensive benchmark designed to evaluate data science agents with realistic tasks. This benchmark includes 466 data analysis tasks and 74 data modeling tasks, sourced from Eloquence and Kaggle competitions. DSBench offers a realistic setting by encompassing long contexts, multimodal task backgrounds, reasoning with large data files and multi-table structures, and performing end-to-end data modeling tasks. Our evaluation of state-of-the-art LLMs, LVLMs, and agents shows that they struggle with most tasks, with the best agent solving only 34.12% of data analysis tasks and achieving a 34.74% Relative Performance Gap (RPG). These findings underscore the need for further advancements in developing more practical, intelligent, and autonomous data science agents.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ],
            [
                "Application",
                "Research"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.07703"
    },
    "e8a07f983ea7cadc2f2eb54e4ab93f13": {
        "title": "TravelAgent: An AI Assistant for Personalized Travel Planning",
        "authors": [
            "Aili Chen",
            "Xuyang Ge",
            "Ziquan Fu",
            "Yanghua Xiao",
            "Jiangjie Chen"
        ],
        "date": "2024/09/12",
        "pdf": "http://arxiv.org/pdf/2409.08069",
        "abstract": "As global tourism expands and artificial intelligence technology advances, intelligent travel planning services have emerged as a significant research focus. Within dynamic real-world travel scenarios with multi-dimensional constraints, services that support users in automatically creating practical and customized travel itineraries must address three key objectives: Rationality, Comprehensiveness, and Personalization. However, existing systems with rule-based combinations or LLM-based planning methods struggle to fully satisfy these criteria. To overcome the challenges, we introduce TravelAgent, a travel planning system powered by large language models (LLMs) designed to provide reasonable, comprehensive, and personalized travel itineraries grounded in dynamic scenarios. TravelAgent comprises four modules: Tool-usage, Recommendation, Planning, and Memory Module. We evaluate TravelAgent&#39;s performance with human and simulated users, demonstrating its overall effectiveness in three criteria and confirming the accuracy of personalized recommendations.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.08069"
    },
    "6eaaee674eeb1b60d91b0e6e8062546a": {
        "title": "Self-Supervised Inference of Agents in Trustless Environments",
        "authors": [
            "Vladyslav Larin",
            "Ivan Nikitin",
            "Alexander Firsov"
        ],
        "date": "2024/09/12",
        "pdf": "http://arxiv.org/pdf/2409.08386",
        "abstract": "In this paper, we propose a novel approach where agents can form swarms to produce high-quality responses effectively. This is accomplished by utilizing agents capable of data inference and ranking, which can be effectively implemented using LLMs as response classifiers. We assess existing approaches for trustless agent inference, define our methodology, estimate practical parameters, and model various types of malicious agent attacks. Our method leverages the collective intelligence of swarms, ensuring robust and efficient decentralized AI inference with better accuracy, security, and reliability. We show that our approach is an order of magnitude faster than other trustless inference strategies reaching less than 125 ms validation latency.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.08386"
    },
    "17b6124b9435fc829993658201fb15dd": {
        "title": "Safeguarding Decentralized Social Media: LLM Agents for Automating Community Rule Compliance",
        "authors": [
            "Lucio La Cava",
            "Andrea Tagarelli"
        ],
        "date": "2024/09/13",
        "pdf": "http://arxiv.org/pdf/2409.08963",
        "abstract": "Ensuring content compliance with community guidelines is crucial for maintaining healthy online social environments. However, traditional human-based compliance checking struggles with scaling due to the increasing volume of user-generated content and a limited number of moderators. Recent advancements in Natural Language Understanding demonstrated by Large Language Models unlock new opportunities for automated content compliance verification. This work evaluates six AI-agents built on Open-LLMs for automated rule compliance checking in Decentralized Social Networks, a challenging environment due to heterogeneous community scopes and rules. Analyzing over 50,000 posts from hundreds of Mastodon servers, we find that AI-agents effectively detect non-compliant content, grasp linguistic subtleties, and adapt to diverse community contexts. Most agents also show high inter-rater reliability and consistency in score justification and suggestions for compliance. Human-based evaluation with domain experts confirmed the agents&#39; reliability and usefulness, rendering them promising tools for semi-automated or human-in-the-loop content moderation systems.",
        "code": "",
        "category": [
            [
                "Automation",
                "Automatic Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.08963"
    },
    "0a5626864f29951fcfe8434985f5e08c": {
        "title": "AI-LieDar: Examine the Trade-off Between Utility and Truthfulness in LLM Agents",
        "authors": [
            "Zhe Su",
            "Xuhui Zhou",
            "Sanketh Rangreji",
            "Anubha Kabra",
            "Julia Mendelsohn",
            "Faeze Brahman",
            "Maarten Sap"
        ],
        "date": "2024/09/13",
        "pdf": "http://arxiv.org/pdf/2409.09013",
        "abstract": "To be safely and successfully deployed, LLMs must simultaneously satisfy truthfulness and utility goals. Yet, often these two goals compete (e.g., an AI agent assisting a used car salesman selling a car with flaws), partly due to ambiguous or misleading user instructions. We propose AI-LieDar, a framework to study how LLM-based agents navigate scenarios with utility-truthfulness conflicts in a multi-turn interactive setting. We design a set of realistic scenarios where language agents are instructed to achieve goals that are in conflict with being truthful during a multi-turn conversation with simulated human agents. To evaluate the truthfulness at large scale, we develop a truthfulness detector inspired by psychological literature to assess the agents&#39; responses. Our experiment demonstrates that all models are truthful less than 50% of the time, although truthfulness and goal achievement (utility) rates vary across models. We further test the steerability of LLMs towards truthfulness, finding that models follow malicious instructions to deceive, and even truth-steered models can still lie. These findings reveal the complex nature of truthfulness in LLMs and underscore the importance of further research to ensure the safe and reliable deployment of LLMs and AI agents.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ],
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.09013"
    },
    "7c5f7b7fe72c7d5d94f7648fddba9f49": {
        "title": "Agents in Software Engineering: Survey, Landscape, and Vision",
        "authors": [
            "Yanlin Wang",
            "Wanjun Zhong",
            "Yanxian Huang",
            "Ensheng Shi",
            "Min Yang",
            "Jiachi Chen",
            "Hui Li",
            "Yuchi Ma",
            "Qianxiang Wang",
            "Zibin Zheng"
        ],
        "date": "2024/09/13",
        "pdf": "http://arxiv.org/pdf/2409.09030",
        "abstract": "In recent years, Large Language Models (LLMs) have achieved remarkable success and have been widely used in various downstream tasks, especially in the tasks of the software engineering (SE) field. We find that many studies combining LLMs with SE have employed the concept of agents either explicitly or implicitly. However, there is a lack of an in-depth survey to sort out the development context of existing works, analyze how existing works combine the LLM-based agent technologies to optimize various tasks, and clarify the framework of LLM-based agents in SE. In this paper, we conduct the first survey of the studies on combining LLM-based agents with SE and present a framework of LLM-based agents in SE which includes three key modules: perception, memory, and action. We also summarize the current challenges in combining the two fields and propose future opportunities in response to existing challenges. We maintain a GitHub repository of the related papers at: https://github.com/DeepSoftwareAnalytics/Awesome-Agent4SE.",
        "code": "",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2409.09030"
    },
    "ae719da0778628f332e07c03d27b4a42": {
        "title": "Automatic Control With Human-Like Reasoning: Exploring Language Model Embodied Air Traffic Agents",
        "authors": [
            "Justas AndriuÅ¡keviÄius",
            "Junzi Sun"
        ],
        "date": "2024/09/15",
        "pdf": "http://arxiv.org/pdf/2409.09717",
        "abstract": "Recent developments in language models have created new opportunities in air traffic control studies. The current focus is primarily on text and language-based use cases. However, these language models may offer a higher potential impact in the air traffic control domain, thanks to their ability to interact with air traffic environments in an embodied agent form. They also provide a language-like reasoning capability to explain their decisions, which has been a significant roadblock for the implementation of automatic air traffic control. This paper investigates the application of a language model-based agent with function-calling and learning capabilities to resolve air traffic conflicts without human intervention. The main components of this research are foundational large language models, tools that allow the agent to interact with the simulator, and a new concept, the experience library. An innovative part of this research, the experience library, is a vector database that stores synthesized knowledge that agents have learned from interactions with the simulations and language models. To evaluate the performance of our language model-based agent, both open-source and closed-source models were tested. The results of our study reveal significant differences in performance across various configurations of the language model-based agents. The best-performing configuration was able to solve almost all 120 but one imminent conflict scenarios, including up to four aircraft at the same time. Most importantly, the agents are able to provide human-level text explanations on traffic situations and conflict resolution strategies.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.09717"
    },
    "35b1e73fdc5f871eb4e4efe3bab90c0b": {
        "title": "Instigating Cooperation among LLM Agents Using Adaptive Information Modulation",
        "authors": [
            "Qiliang Chen",
            "Sepehr Ilami",
            "Nunzio Lore",
            "Babak Heydari"
        ],
        "date": "2024/09/16",
        "pdf": "http://arxiv.org/pdf/2409.10372",
        "abstract": "This paper introduces a novel framework combining LLM agents as proxies for human strategic behavior with reinforcement learning (RL) to engage these agents in evolving strategic interactions within team environments. Our approach extends traditional agent-based simulations by using strategic LLM agents (SLA) and introducing dynamic and adaptive governance through a pro-social promoting RL agent (PPA) that modulates information access across agents in a network, optimizing social welfare and promoting pro-social behavior. Through validation in iterative games, including the prisoner dilemma, we demonstrate that SLA agents exhibit nuanced strategic adaptations. The PPA agent effectively learns to adjust information transparency, resulting in enhanced cooperation rates. This framework offers significant insights into AI-mediated social dynamics, contributing to the deployment of AI in real-world team settings.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.10372"
    },
    "a17a18a53e355ae8901effacf15f0f65": {
        "title": "Agentic Society: Merging skeleton from real world and texture from Large Language Model",
        "authors": [
            "Yuqi Bai",
            "Kun Sun",
            "Huishi Yin"
        ],
        "date": "2024/09/02",
        "pdf": "http://arxiv.org/pdf/2409.10550",
        "abstract": "Recent advancements in large language models (LLMs) and agent technologies offer promising solutions to the simulation of social science experiments, but the availability of data of real-world population required by many of them still poses as a major challenge. This paper explores a novel framework that leverages census data and LLMs to generate virtual populations, significantly reducing resource requirements and bypassing privacy compliance issues associated with real-world data, while keeping a statistical truthfulness. Drawing on real-world census data, our approach first generates a persona that reflects demographic characteristics of the population. We then employ LLMs to enrich these personas with intricate details, using techniques akin to those in image generative models but applied to textual data. Additionally, we propose a framework for the evaluation of the feasibility of our method with respect to capability of LLMs based on personality trait tests, specifically the Big Five model, which also enhances the depth and realism of the generated personas. Through preliminary experiments and analysis, we demonstrate that our method produces personas with variability essential for simulating diverse human behaviors in social science experiments. But the evaluation result shows that only weak sign of statistical truthfulness can be produced due to limited capability of current LLMs. Insights from our study also highlight the tension within LLMs between aligning with human values and reflecting real-world complexities. Thorough and rigorous test call for further research. Our codes are released at https://github.com/baiyuqi/agentic-society.git",
        "code": "",
        "category": [
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.10550"
    },
    "3a5280ef45b05c2165fe7cbcb86cf3a2": {
        "title": "EIA: Environmental Injection Attack on Generalist Web Agents for Privacy Leakage",
        "authors": [
            "Zeyi Liao",
            "Lingbo Mo",
            "Chejian Xu",
            "Mintong Kang",
            "Jiawei Zhang",
            "Chaowei Xiao",
            "Yuan Tian",
            "Bo Li",
            "Huan Sun"
        ],
        "date": "2024/09/17",
        "pdf": "http://arxiv.org/pdf/2409.11295",
        "abstract": "Generalist web agents have demonstrated remarkable potential in autonomously completing a wide range of tasks on real websites, significantly boosting human productivity. However, web tasks, such as booking flights, usually involve users&#39; PII, which may be exposed to potential privacy risks if web agents accidentally interact with compromised websites, a scenario that remains largely unexplored in the literature. In this work, we narrow this gap by conducting the first study on the privacy risks of generalist web agents in adversarial environments. First, we present a realistic threat model for attacks on the website, where we consider two adversarial targets: stealing users&#39; specific PII or the entire user request. Then, we propose a novel attack method, termed Environmental Injection Attack (EIA). EIA injects malicious content designed to adapt well to environments where the agents operate and our work instantiates EIA specifically for privacy scenarios in web environments. We collect 177 action steps that involve diverse PII categories on realistic websites from the Mind2Web, and conduct experiments using one of the most capable generalist web agent frameworks to date. The results demonstrate that EIA achieves up to 70% ASR in stealing specific PII and 16% ASR for full user request. Additionally, by accessing the stealthiness and experimenting with a defensive system prompt, we indicate that EIA is hard to detect and mitigate. Notably, attacks that are not well adapted for a webpage can be detected via human inspection, leading to our discussion about the trade-off between security and autonomy. However, extra attackers&#39; efforts can make EIA seamlessly adapted, rendering such supervision ineffective. Thus, we further discuss the defenses at the pre- and post-deployment stages of the websites without relying on human supervision and call for more advanced defense strategies.",
        "code": "",
        "category": [
            [
                "Stability",
                "Safety"
            ],
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.11295"
    },
    "33531e8e47fd8738cc3591a9a8cf5a76": {
        "title": "Synergistic Simulations: Multi-Agent Problem Solving with Large Language Models",
        "authors": [
            "Asher Sprigler",
            "Alexander Drobek",
            "Keagan Weinstock",
            "Wendpanga Tapsoba",
            "Gavin Childress",
            "Andy Dao",
            "Lucas Gral"
        ],
        "date": "2024/09/14",
        "pdf": "http://arxiv.org/pdf/2409.13753",
        "abstract": "Large Language Models (LLMs) have increasingly demonstrated the ability to facilitate the development of multi-agent systems that allow the interpretation of thoughts and actions generated by each individual. Promising advancements have also been made in LLM-based interaction with existing worlds, particularly in interacting with simulated environments. This paper aims to integrate both aforementioned topics (agents &amp; world interaction) into a single simulation where multiple agents can work together to solve a problem, modeling how groups of humans can often solve problems better than individuals. By showing whether LLMs demonstrate the synergy of human collaboration, it could lead to advancements in the applications of LLMs. We implemented two simulations: a physical studio apartment with two roommates, and another where agents collaborate to complete a programming task. We provide a multi-agent framework, discuss the performance of the agents in each simulation, and discuss potential future additions.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Simulation"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.13753"
    },
    "cc7066d09977aaae68d18954675765ad": {
        "title": "MOSS: Enabling Code-Driven Evolution and Context Management for AI Agents",
        "authors": [
            "Ming Zhu",
            "Yi Zhou"
        ],
        "date": "2024/09/24",
        "pdf": "http://arxiv.org/pdf/2409.16120",
        "abstract": "Developing AI agents powered by large language models (LLMs) faces significant challenges in achieving true Turing completeness and adaptive, code-driven evolution. Current approaches often generate code independently of its runtime context, relying heavily on the LLM&#39;s memory, which results in inefficiencies and limits adaptability. Manual protocol development in sandbox environments further constrains the agent&#39;s autonomous adaptability. Crucially, achieving consistency in code and context across multi-turn interactions and ensuring isolation of local variables within each interaction remains an unsolved problem. We introduce MOSS (llM-oriented Operating System Simulation), a novel framework that addresses these challenges by integrating code generation with a dynamic context management system. MOSS ensures consistency and adaptability by using a mechanism that maintains the Python context across interactions, including isolation of local variables and preservation of runtime integrity. At its core, the framework employs an Inversion of Control (IoC) container in conjunction with decorators to enforce the least knowledge principle, allowing agents to focus on abstract interfaces rather than concrete implementations. This facilitates seamless integration of new tools and libraries, enables runtime instance replacement, and reduces prompt complexity, providing a &#34;what you see is what you get&#34; environment for the agent. Through a series of case studies, we show how this framework can enhance the efficiency and capabilities of agent development and highlight its advantages in moving towards Turing-complete agents capable of evolving through code.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.16120"
    },
    "515a5f1e4ee0ed085471aa5674483bf4": {
        "title": "MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making",
        "authors": [
            "Dayuan Fu",
            "Biqing Qi",
            "Yihuai Gao",
            "Che Jiang",
            "Guanting Dong",
            "Bowen Zhou"
        ],
        "date": "2024/09/25",
        "pdf": "http://arxiv.org/pdf/2409.16686",
        "abstract": "Long-term memory is significant for agents, in which insights play a crucial role. However, the emergence of irrelevant insight and the lack of general insight can greatly undermine the effectiveness of insight. To solve this problem, in this paper, we introduce Multi-Scale Insight Agent (MSI-Agent), an embodied agent designed to improve LLMs&#39; planning and decision-making ability by summarizing and utilizing insight effectively across different scales. MSI achieves this through the experience selector, insight generator, and insight selector. Leveraging a three-part pipeline, MSI can generate task-specific and high-level insight, store it in a database, and then use relevant insight from it to aid in decision-making. Our experiments show that MSI outperforms another insight strategy when planning by GPT3.5. Moreover, We delve into the strategies for selecting seed experience and insight, aiming to provide LLM with more useful and relevant insight for better decision-making. Our observations also indicate that MSI exhibits better robustness when facing domain-shifting scenarios.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.16686"
    },
    "c41cde4a2e191810ef9b3b8ae9e35d10": {
        "title": "SELP: Generating Safe and Efficient Task Plans for Robot Agents with Large Language Models",
        "authors": [
            "Yi Wu",
            "Zikang Xiong",
            "Yiran Hu",
            "Shreyash S. Iyengar",
            "Nan Jiang",
            "Aniket Bera",
            "Lin Tan",
            "Suresh Jagannathan"
        ],
        "date": "2024/09/28",
        "pdf": "http://arxiv.org/pdf/2409.19471",
        "abstract": "Despite significant advancements in large language models (LLMs) that enhance robot agents&#39; understanding and execution of natural language (NL) commands, ensuring the agents adhere to user-specified constraints remains challenging, particularly for complex commands and long-horizon tasks. To address this challenge, we present three key insights, equivalence voting, constrained decoding, and domain-specific fine-tuning, which significantly enhance LLM planners&#39; capability in handling complex tasks. Equivalence voting ensures consistency by generating and sampling multiple Linear Temporal Logic (LTL) formulas from NL commands, grouping equivalent LTL formulas, and selecting the majority group of formulas as the final LTL formula. Constrained decoding then uses the generated LTL formula to enforce the autoregressive inference of plans, ensuring the generated plans conform to the LTL. Domain-specific fine-tuning customizes LLMs to produce safe and efficient plans within specific task domains. Our approach, Safe Efficient LLM Planner (SELP), combines these insights to create LLM planners to generate plans adhering to user commands with high confidence. We demonstrate the effectiveness and generalizability of SELP across different robot agents and tasks, including drone navigation and robot manipulation. For drone navigation tasks, SELP outperforms state-of-the-art planners by 10.8% in safety rate (i.e., finishing tasks conforming to NL commands) and by 19.8% in plan efficiency. For robot manipulation tasks, SELP achieves 20.4% improvement in safety rate. Our datasets for evaluating NL-to-LTL and robot task planning will be released in github.com/lt-asset/selp.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ],
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.19471"
    },
    "abaa1b3fbace483cafbaa6a1f843c901": {
        "title": "Automating Knowledge Discovery from Scientific Literature via LLMs: A Dual-Agent Approach with Progressive Ontology Prompting",
        "authors": [
            "Yuting Hu",
            "Dancheng Liu",
            "Qingyun Wang",
            "Charles Yu",
            "Heng Ji",
            "Jinjun Xiong"
        ],
        "date": "2024/08/20",
        "pdf": "http://arxiv.org/pdf/2409.00054",
        "abstract": "To address the challenge of automating knowledge discovery from a vast volume of literature, in this paper, we introduce a novel framework based on large language models (LLMs) that combines a progressive ontology prompting (POP) algorithm with a dual-agent system, named LLM-Duo, designed to enhance the automation of knowledge extraction from scientific articles. The POP algorithm utilizes a prioritized breadth-first search (BFS) across a predefined ontology to generate structured prompt templates and action orders, thereby guiding LLMs to discover knowledge in an automatic manner. Additionally, our LLM-Duo employs two specialized LLM agents: an explorer and an evaluator. These two agents work collaboratively and adversarially to enhance the reliability of the discovery and annotation processes. Experiments demonstrate that our method outperforms advanced baselines, enabling more accurate and complete annotations. To validate the effectiveness of our method in real-world scenarios, we employ our method in a case study of speech-language intervention discovery. Our method identifies 2,421 interventions from 64,177 research articles in the speech-language therapy domain. We curate these findings into a publicly accessible intervention knowledge base that holds significant potential to benefit the speech-language therapy community.",
        "code": "",
        "category": [
            [
                "Application",
                "Research"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.00054"
    },
    "ef86d708558553ddd1b0e408140ab7f3": {
        "title": "Towards Human-Level Understanding of Complex Process Engineering Schematics: A Pedagogical, Introspective Multi-Agent Framework for Open-Domain Question Answering",
        "authors": [
            "Sagar Srinivas Sakhinana",
            "Geethan Sannidhi",
            "Venkataramana Runkana"
        ],
        "date": "2024/08/24",
        "pdf": "http://arxiv.org/pdf/2409.00082",
        "abstract": "In the chemical and process industries, Process Flow Diagrams (PFDs) and Piping and Instrumentation Diagrams (P&amp;IDs) are critical for design, construction, and maintenance. Recent advancements in Generative AI, such as Large Multimodal Models (LMMs) like GPT4 (Omni), have shown promise in understanding and interpreting process diagrams for Visual Question Answering (VQA). However, proprietary models pose data privacy risks, and their computational complexity prevents knowledge editing for domain-specific customization on consumer hardware. To overcome these challenges, we propose a secure, on-premises enterprise solution using a hierarchical, multi-agent Retrieval Augmented Generation (RAG) framework for open-domain question answering (ODQA) tasks, offering enhanced data privacy, explainability, and cost-effectiveness. Our novel multi-agent framework employs introspective and specialized sub-agents using open-source, small-scale multimodal models with the ReAct (Reason+Act) prompting technique for PFD and P&amp;ID analysis, integrating multiple information sources to provide accurate and contextually relevant answers. Our approach, supported by iterative self-correction, aims to deliver superior performance in ODQA tasks. We conducted rigorous experimental studies, and the empirical results validated the proposed approach effectiveness.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.00082"
    },
    "2c0e95b6ad33e2bb7ba8eb19c033ac96": {
        "title": "HoneyComb: A Flexible LLM-Based Agent System for Materials Science",
        "authors": [
            "Huan Zhang",
            "Yu Song",
            "Ziyu Hou",
            "Santiago Miret",
            "Bang Liu"
        ],
        "date": "2024/08/29",
        "pdf": "http://arxiv.org/pdf/2409.00135",
        "abstract": "The emergence of specialized large language models (LLMs) has shown promise in addressing complex tasks for materials science. Many LLMs, however, often struggle with distinct complexities of material science tasks, such as materials science computational tasks, and often rely heavily on outdated implicit knowledge, leading to inaccuracies and hallucinations. To address these challenges, we introduce HoneyComb, the first LLM-based agent system specifically designed for materials science. HoneyComb leverages a novel, high-quality materials science knowledge base (MatSciKB) and a sophisticated tool hub (ToolHub) to enhance its reasoning and computational capabilities tailored to materials science. MatSciKB is a curated, structured knowledge collection based on reliable literature, while ToolHub employs an Inductive Tool Construction method to generate, decompose, and refine API tools for materials science. Additionally, HoneyComb leverages a retriever module that adaptively selects the appropriate knowledge source or tools for specific tasks, thereby ensuring accuracy and relevance. Our results demonstrate that HoneyComb significantly outperforms baseline models across various tasks in materials science, effectively bridging the gap between current LLM capabilities and the specialized needs of this domain. Furthermore, our adaptable framework can be easily extended to other scientific domains, highlighting its potential for broad applicability in advancing scientific research and applications.",
        "code": "",
        "category": [
            [
                "Application",
                "Chemistry"
            ],
            [
                "Application",
                "Physics"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.00135"
    },
    "42d1e3398f13e4f11882987a8babf97a": {
        "title": "Self-evolving Agents with reflective and memory-augmented abilities",
        "authors": [
            "Xuechen Liang",
            "Meiling Tao",
            "Yinghui Xia",
            "Tianyu Shi",
            "Jun Wang",
            "JingSong Yang"
        ],
        "date": "2024/09/01",
        "pdf": "http://arxiv.org/pdf/2409.00872",
        "abstract": "Large language models (LLMs) have made significant advances in the field of natural language processing, but they still face challenges such as continuous decision-making. In this research, we propose a novel framework by integrating iterative feedback, reflective mechanisms, and a memory optimization mechanism based on the Ebbinghaus forgetting curve, it significantly enhances the agents&#39; capabilities in handling multi-tasking and long-span information.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Memory Mechanism"
            ],
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.00872"
    },
    "3a06b3addc44479cccf3d5ac5f5aed02": {
        "title": "TinyAgent: Function Calling at the Edge",
        "authors": [
            "Lutfi Eren Erdogan",
            "Nicholas Lee",
            "Siddharth Jha",
            "Sehoon Kim",
            "Ryan Tabrizi",
            "Suhong Moon",
            "Coleman Hooper",
            "Gopala Anumanchipalli",
            "Kurt Keutzer",
            "Amir Gholami"
        ],
        "date": "2024/09/01",
        "pdf": "http://arxiv.org/pdf/2409.00608",
        "abstract": "Recent large language models (LLMs) have enabled the development of advanced agentic systems that can integrate various tools and APIs to fulfill user queries through function calling. However, the deployment of these LLMs on the edge has not been explored since they typically require cloud-based infrastructure due to their substantial model size and computational demands. To this end, we present TinyAgent, an end-to-end framework for training and deploying task-specific small language model agents capable of function calling for driving agentic systems at the edge. We first show how to enable accurate function calling for open-source models via the LLMCompiler framework. We then systematically curate a high-quality dataset for function calling, which we use to fine-tune two small language models, TinyAgent-1.1B and 7B. For efficient inference, we introduce a novel tool retrieval method to reduce the input prompt length and utilize quantization to further accelerate the inference speed. As a driving application, we demonstrate a local Siri-like system for Apple&#39;s MacBook that can execute user commands through text or voice input. Our results show that our models can achieve, and even surpass, the function-calling capabilities of larger models like GPT-4-Turbo, while being fully deployed at the edge. We open-source our dataset, models, and installable package and provide a demo video for our MacBook assistant agent.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.00608"
    },
    "21daf20c45bc0a57adf77b16b315f99d": {
        "title": "ComfyBench: Benchmarking LLM-based Agents in ComfyUI for Autonomously Designing Collaborative AI Systems",
        "authors": [
            "Xiangyuan Xue",
            "Zeyu Lu",
            "Di Huang",
            "Zidong Wang",
            "Wanli Ouyang",
            "Lei Bai"
        ],
        "date": "2024/09/02",
        "pdf": "http://arxiv.org/pdf/2409.01392",
        "abstract": "Much previous AI research has focused on developing monolithic models to maximize their intelligence, with the primary goal of enhancing performance on specific tasks. In contrast, this work attempts to study using LLM-based agents to design collaborative AI systems autonomously. To explore this problem, we first introduce ComfyBench to evaluate agents&#39;s ability to design collaborative AI systems in ComfyUI. ComfyBench is a comprehensive benchmark comprising 200 diverse tasks covering various instruction-following generation challenges, along with detailed annotations for 3,205 nodes and 20 workflows. Based on ComfyBench, we further develop ComfyAgent, a novel framework that empowers LLM-based agents to autonomously design collaborative AI systems by generating workflows. ComfyAgent is based on two core concepts. First, it represents workflows with code, which can be reversibly converted into workflows and executed as collaborative systems by the interpreter. Second, it constructs a multi-agent system that cooperates to learn from existing workflows and generate new workflows for a given task. While experimental results demonstrate that ComfyAgent achieves a comparable resolve rate to o1-preview and significantly surpasses other agents on ComfyBench, ComfyAgent has resolved only 15\\% of creative tasks. LLM-based agents still have a long way to go in autonomously designing collaborative AI systems. Progress with ComfyBench is paving the way for more intelligent and autonomous collaborative AI systems.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.01392"
    },
    "a8b1c34e922f35e9e1c58e604c9de741": {
        "title": "An Implementation of Werewolf Agent That does not Truly Trust LLMs",
        "authors": [
            "Takehiro Sato",
            "Shintaro Ozaki",
            "Daisaku Yokoyama"
        ],
        "date": "2024/09/03",
        "pdf": "http://arxiv.org/pdf/2409.01575",
        "abstract": "Werewolf is an incomplete information game, which has several challenges when creating a computer agent as a player given the lack of understanding of the situation and individuality of utterance (e.g., computer agents are not capable of characterful utterance or situational lying). We propose a werewolf agent that solves some of those difficulties by combining a Large Language Model (LLM) and a rule-based algorithm. In particular, our agent uses a rule-based algorithm to select an output either from an LLM or a template prepared beforehand based on the results of analyzing conversation history using an LLM. It allows the agent to refute in specific situations, identify when to end the conversation, and behave with persona. This approach mitigated conversational inconsistencies and facilitated logical utterance as a result. We also conducted a qualitative evaluation, which resulted in our agent being perceived as more human-like compared to an unmodified LLM. The agent is freely available for contributing to advance the research in the field of Werewolf game.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.01575"
    },
    "6cf03814bd2ba6b1c179299361564986": {
        "title": "AgentRE: An Agent-Based Framework for Navigating Complex Information Landscapes in Relation Extraction",
        "authors": [
            "Yuchen Shi",
            "Guochao Jiang",
            "Tian Qiu",
            "Deqing Yang"
        ],
        "date": "2024/09/03",
        "pdf": "http://arxiv.org/pdf/2409.01854",
        "abstract": "The relation extraction (RE) in complex scenarios faces challenges such as diverse relation types and ambiguous relations between entities within a single sentence, leading to the poor performance of pure &#34;text-in, text-out&#34; language models (LMs). To address these challenges, in this paper, we propose an agent-based RE framework, namely AgentRE, which fully leverages the potential of large language models (LLMs) including memory, retrieval and reflection, to achieve RE in complex scenarios. Specifically, three major modules are built in AgentRE serving as the tools to help the agent acquire and process various useful information, thereby obtaining improved RE performance. Our extensive experimental results upon two datasets in English and Chinese demonstrate our AgentRE&#39;s superior performance, especially in low-resource scenarios. Additionally, the trajectories generated by AgentRE can be refined to construct a high-quality training dataset incorporating different reasoning methods, which can be used to fine-tune smaller models. Code is available at https://github.com/Lightblues/AgentRE.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.01854"
    },
    "e0e4801519262a30c9546ffbdce264a6": {
        "title": "xLAM: A Family of Large Action Models to Empower AI Agent Systems",
        "authors": [
            "Jianguo Zhang",
            "Tian Lan",
            "Ming Zhu",
            "Zuxin Liu",
            "Thai Hoang",
            "Shirley Kokane",
            "Weiran Yao",
            "Juntao Tan",
            "Akshara Prabhakar",
            "Haolin Chen",
            "Zhiwei Liu",
            "Yihao Feng",
            "Tulika Awalgaonkar",
            "Rithesh Murthy",
            "Eric Hu",
            "Zeyuan Chen",
            "Ran Xu",
            "Juan Carlos Niebles",
            "Shelby Heinecke",
            "Huan Wang",
            "Silvio Savarese",
            "Caiming Xiong"
        ],
        "date": "2024/09/05",
        "pdf": "http://arxiv.org/pdf/2409.03215",
        "abstract": "Autonomous agents powered by large language models (LLMs) have attracted significant research interest. However, the open-source community faces many challenges in developing specialized models for agent tasks, driven by the scarcity of high-quality agent datasets and the absence of standard protocols in this area. We introduce and publicly release xLAM, a series of large action models designed for AI agent tasks. The xLAM series includes five models with both dense and mixture-of-expert architectures, ranging from 1B to 8x22B parameters, trained using a scalable, flexible pipeline that unifies, augments, and synthesizes diverse datasets to enhance AI agents&#39; generalizability and performance across varied environments. Our experimental results demonstrate that xLAM consistently delivers exceptional performance across multiple agent ability benchmarks, notably securing the 1st position on the Berkeley Function-Calling Leaderboard, outperforming GPT-4, Claude-3, and many other models in terms of tool use. By releasing the xLAM series, we aim to advance the performance of open-source LLMs for autonomous AI agents, potentially accelerating progress and democratizing access to high-performance models for agent tasks. Models are available at https://huggingface.co/collections/Salesforce/xlam-models-65f00e2a0a63bbcd1c2dade4",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.03215"
    },
    "9b16501ae98cd4f3c793c785575dc780": {
        "title": "E2CL: Exploration-based Error Correction Learning for Embodied Agents",
        "authors": [
            "Hanlin Wang",
            "Chak Tou Leong",
            "Jian Wang",
            "Wenjie Li"
        ],
        "date": "2024/09/05",
        "pdf": "http://arxiv.org/pdf/2409.03256",
        "abstract": "Language models are exhibiting increasing capability in knowledge utilization and reasoning. However, when applied as agents in embodied environments, they often suffer from misalignment between their intrinsic knowledge and environmental knowledge, leading to infeasible actions. Traditional environment alignment methods, such as supervised learning on expert trajectories and reinforcement learning, encounter limitations in covering environmental knowledge and achieving efficient convergence, respectively. Inspired by human learning, we propose Exploration-based Error Correction Learning (E2CL), a novel framework that leverages exploration-induced errors and environmental feedback to enhance environment alignment for embodied agents. E2CL incorporates teacher-guided and teacher-free explorations to gather environmental feedback and correct erroneous actions. The agent learns to provide feedback and self-correct, thereby enhancing its adaptability to target environments. Extensive experiments in the VirtualHome environment demonstrate that E2CL-trained agents outperform those trained by baseline methods and exhibit superior self-correction capabilities.",
        "code": "https://github.com/WangHanLinHenry/E2CL",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.03256"
    },
    "4da89e6f01d92485331348c3011afd44": {
        "title": "Rx Strategist: Prescription Verification using LLM Agents System",
        "authors": [
            "Phuc Phan Van",
            "Dat Nguyen Minh",
            "An Dinh Ngoc",
            "Huy Phan Thanh"
        ],
        "date": "2024/09/05",
        "pdf": "http://arxiv.org/pdf/2409.03440",
        "abstract": "To protect patient safety, modern pharmaceutical complexity demands strict prescription verification. We offer a new approach - Rx Strategist - that makes use of knowledge graphs and different search strategies to enhance the power of Large Language Models (LLMs) inside an agentic framework. This multifaceted technique allows for a multi-stage LLM pipeline and reliable information retrieval from a custom-built active ingredient database. Different facets of prescription verification, such as indication, dose, and possible drug interactions, are covered in each stage of the pipeline. We alleviate the drawbacks of monolithic LLM techniques by spreading reasoning over these stages, improving correctness and reliability while reducing memory demands. Our findings demonstrate that Rx Strategist surpasses many current LLMs, achieving performance comparable to that of a highly experienced clinical pharmacist. In the complicated world of modern medications, this combination of LLMs with organized knowledge and sophisticated search methods presents a viable avenue for reducing prescription errors and enhancing patient outcomes.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.03440"
    },
    "d93fb53beb898aadb36fc058ce9e3497": {
        "title": "LLM-based multi-agent poetry generation in non-cooperative environments",
        "authors": [
            "Ran Zhang",
            "Steffen Eger"
        ],
        "date": "2024/09/05",
        "pdf": "http://arxiv.org/pdf/2409.03659",
        "abstract": "Despite substantial progress of large language models (LLMs) for automatic poetry generation, the generated poetry lacks diversity while the training process differs greatly from human learning. Under the rationale that the learning process of the poetry generation systems should be more human-like and their output more diverse and novel, we introduce a framework based on social learning where we emphasize non-cooperative interactions besides cooperative interactions to encourage diversity. Our experiments are the first attempt at LLM-based multi-agent systems in non-cooperative environments for poetry generation employing both TRAINING-BASED agents (GPT-2) and PROMPTING-BASED agents (GPT-3 and GPT-4). Our evaluation based on 96k generated poems shows that our framework benefits the poetry generation process for TRAINING-BASED agents resulting in 1) a 3.0-3.7 percentage point (pp) increase in diversity and a 5.6-11.3 pp increase in novelty according to distinct and novel n-grams. The generated poetry from TRAINING-BASED agents also exhibits group divergence in terms of lexicons, styles and semantics. PROMPTING-BASED agents in our framework also benefit from non-cooperative environments and a more diverse ensemble of models with non-homogeneous agents has the potential to further enhance diversity, with an increase of 7.0-17.5 pp according to our experiments. However, PROMPTING-BASED agents show a decrease in lexical diversity over time and do not exhibit the group-based divergence intended in the social network. Our paper argues for a paradigm shift in creative tasks such as automatic poetry generation to include social learning processes (via LLM-based agent modeling) similar to human interaction.",
        "code": "",
        "category": [
            [
                "Application",
                "Art"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.03659"
    },
    "8e071e37350eccaf0e7fd83d1ebb3472": {
        "title": "Sparse Rewards Can Self-Train Dialogue Agents",
        "authors": [
            "Barrett Martin Lattimer",
            "Varun Gangal",
            "Ryan McDonald",
            "Yi Yang"
        ],
        "date": "2024/09/06",
        "pdf": "http://arxiv.org/pdf/2409.04617",
        "abstract": "Recent advancements in state-of-the-art (SOTA) Large Language Model (LLM) agents, especially in multi-turn dialogue tasks, have been primarily driven by supervised fine-tuning and high-quality human feedback. However, as base LLM models continue to improve, acquiring meaningful human feedback has become increasingly challenging and costly. In certain domains, base LLM agents may eventually exceed human capabilities, making traditional feedback-driven methods impractical. In this paper, we introduce a novel self-improvement paradigm that empowers LLM agents to autonomously enhance their performance without external human feedback. Our method, Juxtaposed Outcomes for Simulation Harvesting (JOSH), is a self-alignment algorithm that leverages a sparse reward simulation environment to extract ideal behaviors and further train the LLM on its own outputs. We present ToolWOZ, a sparse reward tool-calling simulation environment derived from MultiWOZ. We demonstrate that models trained with JOSH, both small and frontier, significantly improve tool-based interactions while preserving general model capabilities across diverse benchmarks. Our code and data are publicly available on GitHub at https://github.com/asappresearch/josh-llm-simulation-training",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.04617"
    },
    "cd493b2016ded91e8c3522c4451d21ab": {
        "title": "Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent LLMs",
        "authors": [
            "Firoj Alam",
            "Md. Rafiul Biswas",
            "Uzair Shah",
            "Wajdi Zaghouani",
            "Georgios Mikros"
        ],
        "date": "2024/09/11",
        "pdf": "http://arxiv.org/pdf/2409.07246",
        "abstract": "In the past decade, social media platforms have been used for information dissemination and consumption. While a major portion of the content is posted to promote citizen journalism and public awareness, some content is posted to mislead users. Among different content types such as text, images, and videos, memes (text overlaid on images) are particularly prevalent and can serve as powerful vehicles for propaganda, hate, and humor. In the current literature, there have been efforts to individually detect such content in memes. However, the study of their intersection is very limited. In this study, we explore the intersection between propaganda and hate in memes using a multi-agent LLM-based approach. We extend the propagandistic meme dataset with coarse and fine-grained hate labels. Our finding suggests that there is an association between propaganda and hate in memes. We provide detailed experimental results that can serve as a baseline for future studies. We will make the experimental resources publicly available to the community (https://github.com/firojalam/propaganda-and-hateful-memes).",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.07246"
    },
    "17b0196512689b297676db675a040c9f": {
        "title": "Agent Workflow Memory",
        "authors": [
            "Zora Zhiruo Wang",
            "Jiayuan Mao",
            "Daniel Fried",
            "Graham Neubig"
        ],
        "date": "2024/09/11",
        "pdf": "http://arxiv.org/pdf/2409.07429",
        "abstract": "Despite the potential of language model-based agents to solve real-world tasks such as web navigation, current methods still struggle with long-horizon tasks with complex action trajectories. In contrast, humans can flexibly solve complex tasks by learning reusable task workflows from past experiences and using them to guide future actions. To build agents that can similarly benefit from this process, we introduce Agent Workflow Memory (AWM), a method for inducing commonly reused routines, i.e., workflows, and selectively providing workflows to the agent to guide subsequent generations. AWM flexibly applies to both offline and online scenarios, where agents induce workflows from training examples beforehand or from test queries on the fly. We experiment on two major web navigation benchmarks -- Mind2Web and WebArena -- that collectively cover 1000+ tasks from 200+ domains across travel, shopping, and social media, among others. AWM substantially improves the baseline results by 24.6% and 51.1% relative success rate on Mind2Web and WebArena while reducing the number of steps taken to solve WebArena tasks successfully. Furthermore, online AWM robustly generalizes in cross-task, website, and domain evaluations, surpassing baselines from 8.9 to 14.0 absolute points as train-test task distribution gaps widen.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Memory Mechanism"
            ],
            [
                "Automation",
                "Workflow"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.07429"
    },
    "38e61751bacde32ac0c4114d29a893d5": {
        "title": "Knowledge Tagging with Large Language Model based Multi-Agent System",
        "authors": [
            "Hang Li",
            "Tianlong Xu",
            "Ethan Chang",
            "Qingsong Wen"
        ],
        "date": "2024/09/12",
        "pdf": "http://arxiv.org/pdf/2409.08406",
        "abstract": "Knowledge tagging for questions is vital in modern intelligent educational applications, including learning progress diagnosis, practice question recommendations, and course content organization. Traditionally, these annotations have been performed by pedagogical experts, as the task demands not only a deep semantic understanding of question stems and knowledge definitions but also a strong ability to link problem-solving logic with relevant knowledge concepts. With the advent of advanced natural language processing (NLP) algorithms, such as pre-trained language models and large language models (LLMs), pioneering studies have explored automating the knowledge tagging process using various machine learning models. In this paper, we investigate the use of a multi-agent system to address the limitations of previous algorithms, particularly in handling complex cases involving intricate knowledge definitions and strict numerical constraints. By demonstrating its superior performance on the publicly available math question knowledge tagging dataset, MathKnowCT, we highlight the significant potential of an LLM-based multi-agent system in overcoming the challenges that previous methods have encountered. Finally, through an in-depth discussion of the implications of automating knowledge tagging, we underscore the promising results of deploying LLM-based algorithms in educational contexts.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.08406"
    },
    "46fcbbcb6a5e36b2331f5099cd3ab9ca": {
        "title": "The Art of Storytelling: Multi-Agent Generative AI for Dynamic Multimodal Narratives",
        "authors": [
            "Samee Arif",
            "Taimoor Arif",
            "Muhammad Saad Haroon",
            "Aamina Jamal Khan",
            "Agha Ali Raza",
            "Awais Athar"
        ],
        "date": "2024/09/17",
        "pdf": "http://arxiv.org/pdf/2409.11261",
        "abstract": "This paper introduces the concept of an education tool that utilizes Generative Artificial Intelligence (GenAI) to enhance storytelling for children. The system combines GenAI-driven narrative co-creation, text-to-speech conversion, and text-to-video generation to produce an engaging experience for learners. We describe the co-creation process, the adaptation of narratives into spoken words using text-to-speech models, and the transformation of these narratives into contextually relevant visuals through text-to-video technology. Our evaluation covers the linguistics of the generated stories, the text-to-speech conversion quality, and the accuracy of the generated visuals.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.11261"
    },
    "286fa2ac65574904a8059dc636a6de68": {
        "title": "CORE-Bench: Fostering the Credibility of Published Research Through a Computational Reproducibility Agent Benchmark",
        "authors": [
            "Zachary S. Siegel",
            "Sayash Kapoor",
            "Nitya Nagdir",
            "Benedikt Stroebl",
            "Arvind Narayanan"
        ],
        "date": "2024/09/17",
        "pdf": "http://arxiv.org/pdf/2409.11363",
        "abstract": "AI agents have the potential to aid users on a variety of consequential tasks, including conducting scientific research. To spur the development of useful agents, we need benchmarks that are challenging, but more crucially, directly correspond to real-world tasks of interest. This paper introduces such a benchmark, designed to measure the accuracy of AI agents in tackling a crucial yet surprisingly challenging aspect of scientific research: computational reproducibility. This task, fundamental to the scientific process, involves reproducing the results of a study using the provided code and data. We introduce CORE-Bench (Computational Reproducibility Agent Benchmark), a benchmark consisting of 270 tasks based on 90 scientific papers across three disciplines (computer science, social science, and medicine). Tasks in CORE-Bench consist of three difficulty levels and include both language-only and vision-language tasks. We provide an evaluation system to measure the accuracy of agents in a fast and parallelizable way, saving days of evaluation time for each run compared to a sequential implementation. We evaluated two baseline agents: the general-purpose AutoGPT and a task-specific agent called CORE-Agent. We tested both variants using two underlying language models: GPT-4o and GPT-4o-mini. The best agent achieved an accuracy of 21% on the hardest task, showing the vast scope for improvement in automating routine scientific tasks. Having agents that can reproduce existing work is a necessary step towards building agents that can conduct novel research and could verify and improve the performance of other research agents. We hope that CORE-Bench can improve the state of reproducibility and spur the development of future research agents.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ],
            [
                "Application",
                "Research"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.11363"
    },
    "8d33203149957afde0b5aa3c179bec89": {
        "title": "MAgICoRe: Multi-Agent, Iterative, Coarse-to-Fine Refinement for Reasoning",
        "authors": [
            "Justin Chih-Yao Chen",
            "Archiki Prasad",
            "Swarnadeep Saha",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "date": "2024/09/18",
        "pdf": "http://arxiv.org/pdf/2409.12147",
        "abstract": "Large Language Models&#39; (LLM) reasoning can be improved using test-time aggregation strategies, i.e., generating multiple samples and voting among generated samples. While these improve performance, they often reach a saturation point. Refinement offers an alternative by using LLM-generated feedback to improve solution quality. However, refinement introduces 3 key challenges: (1) Excessive refinement: Uniformly refining all instances can over-correct and reduce the overall performance. (2) Inability to localize and address errors: LLMs have a limited ability to self-correct and struggle to identify and correct their own mistakes. (3) Insufficient refinement: Deciding how many iterations of refinement are needed is non-trivial, and stopping too soon could leave errors unaddressed. To tackle these issues, we propose MAgICoRe, which avoids excessive refinement by categorizing problem difficulty as easy or hard, solving easy problems with coarse-grained aggregation and hard ones with fine-grained and iterative multi-agent refinement. To improve error localization, we incorporate external step-wise reward model (RM) scores. Moreover, to ensure effective refinement, we employ a multi-agent loop with three agents: Solver, Reviewer (which generates targeted feedback based on step-wise RM scores), and the Refiner (which incorporates feedback). To ensure sufficient refinement, we re-evaluate updated solutions, iteratively initiating further rounds of refinement. We evaluate MAgICoRe on Llama-3-8B and GPT-3.5 and show its effectiveness across 5 math datasets. Even one iteration of MAgICoRe beats Self-Consistency by 3.4%, Best-of-k by 3.2%, and Self-Refine by 4.0% while using less than half the samples. Unlike iterative refinement with baselines, MAgICoRe continues to improve with more iterations. Finally, our ablations highlight the importance of MAgICoRe&#39;s RMs and multi-agent communication.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.12147"
    },
    "737ce2a7ac8b9939607d73146d29408e": {
        "title": "Textualized Agent-Style Reasoning for Complex Tasks by Multiple Round LLM Generation",
        "authors": [
            "Chen Liang",
            "Zhifan Feng",
            "Zihe Liu",
            "Wenbin Jiang",
            "Jinan Xu",
            "Yufeng Chen",
            "Yong Wang"
        ],
        "date": "2024/09/19",
        "pdf": "http://arxiv.org/pdf/2409.12411",
        "abstract": "Chain-of-thought prompting significantly boosts the reasoning ability of large language models but still faces three issues: hallucination problem, restricted interpretability, and uncontrollable generation. To address these challenges, we present AgentCOT, a llm-based autonomous agent framework, which can solve complex problems in an agent-style manner by multiple round LLM generation. At each step, AgentCOT selects an action and executes it to yield an intermediate result with supporting evidence. In addition, we integrate the step&#39;s index into the reasoning process to form a graph structure for complex inference logic. We introduce two new strategies to enhance the performance of AgentCOT.We conduct extensive experiments to verify the effectiveness of our method on six common benchmarks. Results exhibit that our method brings in substantial improvements over current competitive approaches.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.12411"
    },
    "b6d51b8f0e9a4d100cca5ea9a105c5eb": {
        "title": "FoodPuzzle: Developing Large Language Model Agents as Flavor Scientists",
        "authors": [
            "Tenghao Huang",
            "Donghee Lee",
            "John Sweeney",
            "Jiatong Shi",
            "Emily Steliotes",
            "Matthew Lange",
            "Jonathan May",
            "Muhao Chen"
        ],
        "date": "2024/09/19",
        "pdf": "http://arxiv.org/pdf/2409.12832",
        "abstract": "Flavor development in the food industry is increasingly challenged by the need for rapid innovation and precise flavor profile creation. Traditional flavor research methods typically rely on iterative, subjective testing, which lacks the efficiency and scalability required for modern demands. This paper presents three contributions to address the challenges. Firstly, we define a new problem domain for scientific agents in flavor science, conceptualized as the generation of hypotheses for flavor profile sourcing and understanding. To facilitate research in this area, we introduce the FoodPuzzle, a challenging benchmark consisting of 978 food items and 1,766 flavor molecules profiles. We propose a novel Scientific Agent approach, integrating in-context learning and retrieval augmented techniques to generate grounded hypotheses in the domain of food science. Experimental results indicate that our model significantly surpasses traditional methods in flavor profile prediction tasks, demonstrating its potential to transform flavor development practices.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.12832"
    },
    "87ab004e36b06b4054d9d2b8d6a5d107": {
        "title": "Minstrel: Structural Prompt Generation with Multi-Agents Coordination for Non-AI Experts",
        "authors": [
            "Ming Wang",
            "Yuanzhong Liu",
            "Xiaoyu Liang",
            "Yijie Huang",
            "Daling Wang",
            "Xiaocui Yang",
            "Sijia Shen",
            "Shi Feng",
            "Xiaoming Zhang",
            "Chaofeng Guan",
            "Yifei Zhang"
        ],
        "date": "2024/09/20",
        "pdf": "http://arxiv.org/pdf/2409.13449",
        "abstract": "LLMs have demonstrated commendable performance across diverse domains. Nevertheless, formulating high-quality prompts to assist them in their work poses a challenge for non-AI experts. Existing research in prompt engineering suggests somewhat scattered optimization principles and designs empirically dependent prompt optimizers. Unfortunately, these endeavors lack a structural design, incurring high learning costs and it is not conducive to the iterative updating of prompts, especially for non-AI experts. Inspired by structured reusable programming languages, we propose LangGPT, a structural prompt design framework. Furthermore, we introduce Minstrel, a multi-generative agent system with reflection to automate the generation of structural prompts. Experiments and the case study illustrate that structural prompts generated by Minstrel or written manually significantly enhance the performance of LLMs. Furthermore, we analyze the ease of use of structural prompts through a user survey in our online community.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.13449"
    },
    "11dda558774bbd22e20ed446273f9686": {
        "title": "Language agents achieve superhuman synthesis of scientific knowledge",
        "authors": [
            "Michael D. Skarlinski",
            "Sam Cox",
            "Jon M. Laurent",
            "James D. Braza",
            "Michaela Hinks",
            "Michael J. Hammerling",
            "Manvitha Ponnapati",
            "Samuel G. Rodriques",
            "Andrew D. White"
        ],
        "date": "2024/09/10",
        "pdf": "http://arxiv.org/pdf/2409.13740",
        "abstract": "Language models are known to hallucinate incorrect information, and it is unclear if they are sufficiently accurate and reliable for use in scientific research. We developed a rigorous human-AI comparison methodology to evaluate language model agents on real-world literature search tasks covering information retrieval, summarization, and contradiction detection tasks. We show that PaperQA2, a frontier language model agent optimized for improved factuality, matches or exceeds subject matter expert performance on three realistic literature research tasks without any restrictions on humans (i.e., full access to internet, search tools, and time). PaperQA2 writes cited, Wikipedia-style summaries of scientific topics that are significantly more accurate than existing, human-written Wikipedia articles. We also introduce a hard benchmark for scientific literature research called LitQA2 that guided design of PaperQA2, leading to it exceeding human performance. Finally, we apply PaperQA2 to identify contradictions within the scientific literature, an important scientific task that is challenging for humans. PaperQA2 identifies 2.34 +/- 1.99 contradictions per paper in a random subset of biology papers, of which 70% are validated by human experts. These results demonstrate that language model agents are now capable of exceeding domain experts across meaningful tasks on scientific literature.",
        "code": "",
        "category": [
            [
                "Application",
                "Research"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.13740"
    },
    "ab497c820fe14d1b7f6fa4350247b2bc": {
        "title": "GroupDebate: Enhancing the Efficiency of Multi-Agent Debate Using Group Discussion",
        "authors": [
            "Tongxuan Liu",
            "Xingyu Wang",
            "Weizhe Huang",
            "Wenjiang Xu",
            "Yuting Zeng",
            "Lei Jiang",
            "Hailong Yang",
            "Jing Li"
        ],
        "date": "2024/09/21",
        "pdf": "http://arxiv.org/pdf/2409.14051",
        "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse NLP tasks. Extensive research has explored how to enhance the logical reasoning abilities such as Chain-of-Thought, Chain-of-Thought with Self-Consistency, Tree-Of-Thoughts, and multi-agent debates. In the context of multi-agent debates, significant performance improvements can be achieved with an increasing number of agents and debate rounds. However, the escalation in the number of agents and debate rounds can drastically raise the tokens cost of debates, thereby limiting the scalability of the multi-agent debate technique. To better harness the advantages of multi-agent debates in logical reasoning tasks, this paper proposes a method to significantly reduce token cost in multi-agent debates. This approach involves dividing all agents into multiple debate groups, with agents engaging in debates within their respective groups and sharing interim debate results between groups. Comparative experiments across multiple datasets have demonstrated that this method can reduce the total tokens by up to 51.7% during debates and while potentially enhancing accuracy by as much as 25%. Our method significantly enhances the performance and efficiency of interactions in the multi-agent debate.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2409.14051"
    },
    "dbbc7e22bf928151d7636f8a71b9d283": {
        "title": "AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation",
        "authors": [
            "Mengkang Hu",
            "Pu Zhao",
            "Can Xu",
            "Qingfeng Sun",
            "Jianguang Lou",
            "Qingwei Lin",
            "Ping Luo",
            "Saravan Rajmohan"
        ],
        "date": "2024/08/01",
        "pdf": "http://arxiv.org/pdf/2408.00764",
        "abstract": "Large Language Model-based agents have garnered significant attention and are becoming increasingly popular. Furthermore, planning ability is a crucial component of an LLM-based agent, which generally entails achieving a desired goal from an initial state. This paper investigates enhancing the planning abilities of LLMs through instruction tuning, referred to as agent training. Recent studies have demonstrated that utilizing expert-level trajectory for instruction-tuning LLMs effectively enhances their planning capabilities. However, existing work primarily focuses on synthesizing trajectories from manually designed planning tasks and environments. The labor-intensive nature of creating these environments and tasks impedes the generation of sufficiently varied and extensive trajectories. To address this limitation, this paper explores the automated synthesis of diverse environments and a gradual range of planning tasks, from easy to difficult. We introduce a framework, AgentGen, that leverages LLMs first to generate environments and subsequently generate planning tasks conditioned on these environments. Specifically, to improve environmental diversity, we propose using an inspiration corpus composed of various domain-specific text segments as the context for synthesizing environments. Moreover, to increase the difficulty diversity of generated planning tasks, we propose a bidirectional evolution method, Bi-Evol, that evolves planning tasks from easier and harder directions to synthesize a task set with a smoother difficulty curve. The evaluation results derived from AgentBoard show that AgentGen greatly improves LLMs&#39; planning ability, e.g., the AgentGen instruction-tuned Llama-3.1-8B surpasses GPT-3.5 in overall performance. Moreover, the AgentGen-tuned Llama-3.1-70B model achieves state-of-the-art results in planning tasks. Project page: https://agent-gen.github.io/.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.00764"
    },
    "c6b627be92ba318c26367a5983aed27f": {
        "title": "Coalitions of Large Language Models Increase the Robustness of AI Agents",
        "authors": [
            "Prattyush Mangal",
            "Carol Mak",
            "Theo Kanakis",
            "Timothy Donovan",
            "Dave Braines",
            "Edward Pyzer-Knapp"
        ],
        "date": "2024/08/02",
        "pdf": "http://arxiv.org/pdf/2408.01380",
        "abstract": "The emergence of Large Language Models (LLMs) have fundamentally altered the way we interact with digital systems and have led to the pursuit of LLM powered AI agents to assist in daily workflows. LLMs, whilst powerful and capable of demonstrating some emergent properties, are not logical reasoners and often struggle to perform well at all sub-tasks carried out by an AI agent to plan and execute a workflow. While existing studies tackle this lack of proficiency by generalised pretraining at a huge scale or by specialised fine-tuning for tool use, we assess if a system comprising of a coalition of pretrained LLMs, each exhibiting specialised performance at individual sub-tasks, can match the performance of single model agents. The coalition of models approach showcases its potential for building robustness and reducing the operational costs of these AI agents by leveraging traits exhibited by specific models. Our findings demonstrate that fine-tuning can be mitigated by considering a coalition of pretrained models and believe that this approach can be applied to other non-agentic systems which utilise LLMs.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.01380"
    },
    "a74c42560de6b2fef2972ca80f4c95b3": {
        "title": "MathLearner: A Large Language Model Agent Framework for Learning to Solve Mathematical Problems",
        "authors": [
            "Wenbei Xie",
            "Donglin Liu",
            "Haoran Yan",
            "Wenjie Wu",
            "Zongyang Liu"
        ],
        "date": "2024/08/03",
        "pdf": "http://arxiv.org/pdf/2408.01779",
        "abstract": "With the development of artificial intelligence (AI), large language models (LLM) are widely used in many fields. However, the reasoning ability of LLM is still very limited when it comes to mathematical reasoning. Mathematics plays an important role in all aspects of human society and is a technical guarantee in the fields of healthcare, transport and aerospace, for this reason, the development of AI big language models in the field of mathematics has great potential significance. To improve the mathematical reasoning ability of large language models, we proposed an agent framework for learning to solve mathematical problems based on inductive reasoning. By emulating the human learning process of generalization of learned information and effective application of previous knowledge in new reasoning tasks, this framework has great performance in the mathematical reasoning process. It improves global accuracy over the baseline method (chain-of-thought) by 20.96% and solves 17.54% of the mathematical problems that the baseline cannot solve. Benefiting from the efficient RETRIEVAL method, our model improves the ability of large language models to efficiently use external knowledge, i.e., the mathematical computation of the model can be based on written procedures. In education, our model can be used as a personalised learning aid, thus reducing the inequality of educational resources.",
        "code": "",
        "category": [
            [
                "Application",
                "Math"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.01779"
    },
    "a2dd498870d0d8035b33a8c00b113d29": {
        "title": "MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance",
        "authors": [
            "Jihye Choi",
            "Nils Palumbo",
            "Prasad Chalasani",
            "Matthew M. Engelhard",
            "Somesh Jha",
            "Anivarya Kumar",
            "David Page"
        ],
        "date": "2024/08/03",
        "pdf": "http://arxiv.org/pdf/2408.01869",
        "abstract": "In the era of Large Language Models (LLMs), given their remarkable text understanding and generation abilities, there is an unprecedented opportunity to develop new, LLM-based methods for trustworthy medical knowledge synthesis, extraction and summarization. This paper focuses on the problem of Pharmacovigilance (PhV), where the significance and challenges lie in identifying Adverse Drug Events (ADEs) from diverse text sources, such as medical literature, clinical notes, and drug labels. Unfortunately, this task is hindered by factors including variations in the terminologies of drugs and outcomes, and ADE descriptions often being buried in large amounts of narrative text. We present MALADE, the first effective collaborative multi-agent system powered by LLM with Retrieval Augmented Generation for ADE extraction from drug label data. This technique involves augmenting a query to an LLM with relevant information extracted from text resources, and instructing the LLM to compose a response consistent with the augmented data. MALADE is a general LLM-agnostic architecture, and its unique capabilities are: (1) leveraging a variety of external sources, such as medical literature, drug labels, and FDA tools (e.g., OpenFDA drug information API), (2) extracting drug-outcome association in a structured format along with the strength of the association, and (3) providing explanations for established associations. Instantiated with GPT-4 Turbo or GPT-4o, and FDA drug label data, MALADE demonstrates its efficacy with an Area Under ROC Curve of 0.90 against the OMOP Ground Truth table of ADEs. Our implementation leverages the Langroid multi-agent LLM framework and can be found at https://github.com/jihyechoi77/malade.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "RAG"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.01869"
    },
    "6dcd3421d4242819d1932b7446ff91bb": {
        "title": "ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems",
        "authors": [
            "Andrew Zhu",
            "Liam Dugan",
            "Chris Callison-Burch"
        ],
        "date": "2024/08/05",
        "pdf": "http://arxiv.org/pdf/2408.02248",
        "abstract": "Recently, there has been increasing interest in using Large Language Models (LLMs) to construct complex multi-agent systems to perform tasks such as compiling literature reviews, drafting consumer reports, and planning vacations. Many tools and libraries exist for helping create such systems, however none support recursive multi-agent systems -- where the models themselves flexibly decide when to delegate tasks and how to organize their delegation structure. In this work, we introduce ReDel: a toolkit for recursive multi-agent systems that supports custom tool-use, delegation schemes, event-based logging, and interactive replay in an easy-to-use web interface. We show that, using ReDel, we are able to easily identify potential areas of improvements through the visualization and debugging tools. Our code, documentation, and PyPI package are open-source and free to use under the MIT license at https://github.com/zhudotexe/redel.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.02248"
    },
    "9aea28457ee0355851fe7ef5e72a81c4": {
        "title": "Caution for the Environment: Multimodal Agents are Susceptible to Environmental Distractions",
        "authors": [
            "Xinbei Ma",
            "Yiting Wang",
            "Yao Yao",
            "Tongxin Yuan",
            "Aston Zhang",
            "Zhuosheng Zhang",
            "Hai Zhao"
        ],
        "date": "2024/08/05",
        "pdf": "http://arxiv.org/pdf/2408.02544",
        "abstract": "This paper investigates the faithfulness of multimodal large language model (MLLM) agents in the graphical user interface (GUI) environment, aiming to address the research question of whether multimodal GUI agents can be distracted by environmental context. A general setting is proposed where both the user and the agent are benign, and the environment, while not malicious, contains unrelated content. A wide range of MLLMs are evaluated as GUI agents using our simulated dataset, following three working patterns with different levels of perception. Experimental results reveal that even the most powerful models, whether generalist agents or specialist GUI agents, are susceptible to distractions. While recent studies predominantly focus on the helpfulness (i.e., action accuracy) of multimodal agents, our findings indicate that these agents are prone to environmental distractions, resulting in unfaithful behaviors. Furthermore, we switch to the adversarial perspective and implement environment injection, demonstrating that such unfaithfulness can be exploited, leading to unexpected risks.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ],
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.02544"
    },
    "a23eda8dbe937be4a146b51306a36f25": {
        "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information",
        "authors": [
            "Yauwai Yim",
            "Chunkit Chan",
            "Tianyu Shi",
            "Zheye Deng",
            "Wei Fan",
            "Tianshi Zheng",
            "Yangqiu Song"
        ],
        "date": "2024/08/05",
        "pdf": "http://arxiv.org/pdf/2408.02559",
        "abstract": "Large language models (LLMs) have shown success in handling simple games with imperfect information and enabling multi-agent coordination, but their ability to facilitate practical collaboration against other agents in complex, imperfect information environments, especially in a non-English environment, still needs to be explored. This study investigates the applicability of knowledge acquired by open-source and API-based LLMs to sophisticated text-based games requiring agent collaboration under imperfect information, comparing their performance to established baselines using other types of agents. We propose a Theory of Mind (ToM) planning technique that allows LLM agents to adapt their strategy against various adversaries using only game rules, current state, and historical context as input. An external tool was incorporated to mitigate the challenge of dynamic and extensive action spaces in this card game. Our results show that although a performance gap exists between current LLMs and state-of-the-art reinforcement learning (RL) models, LLMs demonstrate ToM capabilities in this game setting. It consistently improves their performance against opposing agents, suggesting their ability to understand the actions of allies and adversaries and establish collaboration with allies. To encourage further research and understanding, we have made our codebase openly accessible.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.02559"
    },
    "e5c53089674be9108d8ce4f00ed5ae24": {
        "title": "Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate",
        "authors": [
            "Yiqun Zhang",
            "Xiaocui Yang",
            "Shi Feng",
            "Daling Wang",
            "Yifei Zhang",
            "Kaisong Song"
        ],
        "date": "2024/08/08",
        "pdf": "http://arxiv.org/pdf/2408.04472",
        "abstract": "Competitive debate is a complex task of computational argumentation. Large Language Models (LLMs) suffer from hallucinations and lack competitiveness in this field. To address these challenges, we introduce Agent for Debate (Agent4Debate), a dynamic multi-agent framework based on LLMs designed to enhance their capabilities in competitive debate. Drawing inspiration from human behavior in debate preparation and execution, Agent4Debate employs a collaborative architecture where four specialized agents, involving Searcher, Analyzer, Writer, and Reviewer, dynamically interact and cooperate. These agents work throughout the debate process, covering multiple stages from initial research and argument formulation to rebuttal and summary. To comprehensively evaluate framework performance, we construct the Competitive Debate Arena, comprising 66 carefully selected Chinese debate motions. We recruit ten experienced human debaters and collect records of 200 debates involving Agent4Debate, baseline models, and humans. The evaluation employs the Debatrix automatic scoring system and professional human reviewers based on the established Debatrix-Elo and Human-Elo ranking. Experimental results indicate that the state-of-the-art Agent4Debate exhibits capabilities comparable to those of humans. Furthermore, ablation studies demonstrate the effectiveness of each component in the agent structure.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.04472"
    },
    "d24290009beedf9b92d7e629bc7e6c7d": {
        "title": "MAG-SQL: Multi-Agent Generative Approach with Soft Schema Linking and Iterative Sub-SQL Refinement for Text-to-SQL",
        "authors": [
            "Wenxuan Xie",
            "Gaochen Wu",
            "Bowen Zhou"
        ],
        "date": "2024/08/15",
        "pdf": "http://arxiv.org/pdf/2408.07930",
        "abstract": "Recent In-Context Learning based methods have achieved remarkable success in Text-to-SQL task. However, there is still a large gap between the performance of these models and human performance on datasets with complex database schema and difficult questions, such as BIRD. Besides, existing work has neglected to supervise intermediate steps when solving questions iteratively with question decomposition methods, and the schema linking methods used in these works are very rudimentary. To address these issues, we propose MAG-SQL, a multi-agent generative approach with soft schema linking and iterative Sub-SQL refinement. In our framework, an entity-based method with tables&#39; summary is used to select the columns in database, and a novel targets-conditions decomposition method is introduced to decompose those complex questions. Additionally, we build a iterative generating module which includes a Sub-SQL Generator and Sub-SQL Refiner, introducing external oversight for each step of generation. Through a series of ablation studies, the effectiveness of each agent in our framework has been demonstrated. When evaluated on the BIRD benchmark with GPT-4, MAG-SQL achieves an execution accuracy of 61.08%, compared to the baseline accuracy of 46.35% for vanilla GPT-4 and the baseline accuracy of 57.56% for MAC-SQL. Besides, our approach makes similar progress on Spider. The codes are available at https://github.com/LancelotXWX/MAG-SQL.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.07930"
    },
    "e1991b64c3d638744b55d2c647b160df": {
        "title": "AgentCourt: Simulating Court with Adversarial Evolvable Lawyer Agents",
        "authors": [
            "Guhong Chen",
            "Liyang Fan",
            "Zihan Gong",
            "Nan Xie",
            "Zixuan Li",
            "Ziqiang Liu",
            "Chengming Li",
            "Qiang Qu",
            "Shiwen Ni",
            "Min Yang"
        ],
        "date": "2024/08/15",
        "pdf": "http://arxiv.org/pdf/2408.08089",
        "abstract": "In this paper, we present a simulation system called AgentCourt that simulates the entire courtroom process. The judge, plaintiff&#39;s lawyer, defense lawyer, and other participants are autonomous agents driven by large language models (LLMs). Our core goal is to enable lawyer agents to learn how to argue a case, as well as improving their overall legal skills, through courtroom process simulation. To achieve this goal, we propose an adversarial evolutionary approach for the lawyer-agent. Since AgentCourt can simulate the occurrence and development of court hearings based on a knowledge base and LLM, the lawyer agents can continuously learn and accumulate experience from real court cases. The simulation experiments show that after two lawyer-agents have engaged in a thousand adversarial legal cases in AgentCourt (which can take a decade for real-world lawyers), compared to their pre-evolutionary state, the evolved lawyer agents exhibit consistent improvement in their ability to handle legal tasks. To enhance the credibility of our experimental results, we enlisted a panel of professional lawyers to evaluate our simulations. The evaluation indicates that the evolved lawyer agents exhibit notable advancements in responsiveness, as well as expertise and logical rigor. This work paves the way for advancing LLM-driven agent technology in legal scenarios. Code is available at https://github.com/relic-yuexi/AgentCourt.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.08089"
    },
    "261b8e7b4a92a56a944db8d0e097cf90": {
        "title": "The Fellowship of the LLMs: Multi-Agent Workflows for Synthetic Preference Optimization Dataset Generation",
        "authors": [
            "Samee Arif",
            "Sualeha Farid",
            "Abdul Hameed Azeemi",
            "Awais Athar",
            "Agha Ali Raza"
        ],
        "date": "2024/08/16",
        "pdf": "http://arxiv.org/pdf/2408.08688",
        "abstract": "This paper presents a novel methodology for generating synthetic Preference Optimization (PO) datasets using multi-agent workflows. We evaluate the effectiveness and potential of these workflows in automating and enhancing the dataset generation process. PO dataset generation requires two modules: (1) response evaluation, and (2) response generation. In the response evaluation module, the responses from Large Language Models (LLMs) are evaluated and ranked - a task typically carried out by human annotators that we automate using LLMs. We assess the response evaluation module in a 2 step process. In step 1, we assess LLMs as evaluators using three distinct prompting strategies. In step 2, we apply the winning prompting strategy to compare the performance of LLM-as-a-Judge, LLMs-as-a-Jury, and LLM Debate. Our evaluation shows that GPT-4o-as-a-Judge is more consistent across all datasets. For the response generation module, we use the identified LLM evaluator configuration and compare different configurations of the LLM Feedback Loop. We use the win rate to determine the best multi-agent configuration for generation. Experimenting with various configurations, we find that the LLM Feedback Loop, with Llama as the generator and Gemma as the reviewer, achieves a notable 71.8% and 73.8% win rate over single-agent Llama and Gemma, respectively. After identifying the best configurations for both modules, we generate our PO datasets using the above pipeline.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Dataset"
            ],
            [
                "Automation",
                "Workflow"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.08688"
    },
    "a941f35559c198b6edff0f12757d76c1": {
        "title": "HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model",
        "authors": [
            "Mengkang Hu",
            "Tianxing Chen",
            "Qiguang Chen",
            "Yao Mu",
            "Wenqi Shao",
            "Ping Luo"
        ],
        "date": "2024/08/18",
        "pdf": "http://arxiv.org/pdf/2408.09559",
        "abstract": "Large Language Model (LLM)-based agents exhibit significant potential across various domains, operating as interactive systems that process environmental observations to generate executable actions for target tasks. The effectiveness of these agents is significantly influenced by their memory mechanism, which records historical experiences as sequences of action-observation pairs. We categorize memory into two types: cross-trial memory, accumulated across multiple attempts, and in-trial memory (working memory), accumulated within a single attempt. While considerable research has optimized performance through cross-trial memory, the enhancement of agent performance through improved working memory utilization remains underexplored. Instead, existing approaches often involve directly inputting entire historical action-observation pairs into LLMs, leading to redundancy in long-horizon tasks. Inspired by human problem-solving strategies, this paper introduces HiAgent, a framework that leverages subgoals as memory chunks to manage the working memory of LLM-based agents hierarchically. Specifically, HiAgent prompts LLMs to formulate subgoals before generating executable actions and enables LLMs to decide proactively to replace previous subgoals with summarized observations, retaining only the action-observation pairs relevant to the current subgoal. Experimental results across five long-horizon tasks demonstrate that HiAgent achieves a twofold increase in success rate and reduces the average number of steps required by 3.8. Additionally, our analysis shows that HiAgent consistently improves performance across various steps, highlighting its robustness and generalizability. Project Page: https://github.com/HiAgent2024/HiAgent .",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Memory Mechanism"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.09559"
    },
    "660d685a188a016b40085cefcafdfcc1": {
        "title": "BLADE: Benchmarking Language Model Agents for Data-Driven Science",
        "authors": [
            "Ken Gu",
            "Ruoxi Shang",
            "Ruien Jiang",
            "Keying Kuang",
            "Richard-John Lin",
            "Donghe Lyu",
            "Yue Mao",
            "Youran Pan",
            "Teng Wu",
            "Jiaqian Yu",
            "Yikun Zhang",
            "Tianmai M. Zhang",
            "Lanyi Zhu",
            "Mike A. Merrill",
            "Jeffrey Heer",
            "Tim Althoff"
        ],
        "date": "2024/08/19",
        "pdf": "http://arxiv.org/pdf/2408.09667",
        "abstract": "Data-driven scientific discovery requires the iterative integration of scientific domain knowledge, statistical expertise, and an understanding of data semantics to make nuanced analytical decisions, e.g., about which variables, transformations, and statistical models to consider. LM-based agents equipped with planning, memory, and code execution capabilities have the potential to support data-driven science. However, evaluating agents on such open-ended tasks is challenging due to multiple valid approaches, partially correct steps, and different ways to express the same decisions. To address these challenges, we present BLADE, a benchmark to automatically evaluate agents&#39; multifaceted approaches to open-ended research questions. BLADE consists of 12 datasets and research questions drawn from existing scientific literature, with ground truth collected from independent analyses by expert data scientists and researchers. To automatically evaluate agent responses, we developed corresponding computational methods to match different representations of analyses to this ground truth. Though language models possess considerable world knowledge, our evaluation shows that they are often limited to basic analyses. However, agents capable of interacting with the underlying data demonstrate improved, but still non-optimal, diversity in their analytical decision making. Our work enables the evaluation of agents for data-driven science and provides researchers deeper insights into agents&#39; analysis approaches.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.09667"
    },
    "55cb02be863c4932e55605e3b0fba125": {
        "title": "Anim-Director: A Large Multimodal Model Powered Agent for Controllable Animation Video Generation",
        "authors": [
            "Yunxin Li",
            "Haoyuan Shi",
            "Baotian Hu",
            "Longyue Wang",
            "Jiashun Zhu",
            "Jinyi Xu",
            "Zhen Zhao",
            "Min Zhang"
        ],
        "date": "2024/08/19",
        "pdf": "http://arxiv.org/pdf/2408.09787",
        "abstract": "Traditional animation generation methods depend on training generative models with human-labelled data, entailing a sophisticated multi-stage pipeline that demands substantial human effort and incurs high training costs. Due to limited prompting plans, these methods typically produce brief, information-poor, and context-incoherent animations. To overcome these limitations and automate the animation process, we pioneer the introduction of large multimodal models (LMMs) as the core processor to build an autonomous animation-making agent, named Anim-Director. This agent mainly harnesses the advanced understanding and reasoning capabilities of LMMs and generative AI tools to create animated videos from concise narratives or simple instructions. Specifically, it operates in three main stages: Firstly, the Anim-Director generates a coherent storyline from user inputs, followed by a detailed director&#39;s script that encompasses settings of character profiles and interior/exterior descriptions, and context-coherent scene descriptions that include appearing characters, interiors or exteriors, and scene events. Secondly, we employ LMMs with the image generation tool to produce visual images of settings and scenes. These images are designed to maintain visual consistency across different scenes using a visual-language prompting method that combines scene descriptions and images of the appearing character and setting. Thirdly, scene images serve as the foundation for producing animated videos, with LMMs generating prompts to guide this process. The whole process is notably autonomous without manual intervention, as the LMMs interact seamlessly with generative tools to generate prompts, evaluate visual quality, and select the best one to optimize the final output.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.09787"
    },
    "7cbf5c951a172306cc98e3d5da05a873": {
        "title": "Athena: Safe Autonomous Agents with Verbal Contrastive Learning",
        "authors": [
            "Tanmana Sadhu",
            "Ali Pesaranghader",
            "Yanan Chen",
            "Dong Hoon Yi"
        ],
        "date": "2024/08/20",
        "pdf": "http://arxiv.org/pdf/2408.11021",
        "abstract": "Due to emergent capabilities, large language models (LLMs) have been utilized as language-based agents to perform a variety of tasks and make decisions with an increasing degree of autonomy. These autonomous agents can understand high-level instructions, interact with their environments, and execute complex tasks using a selection of tools available to them. As the capabilities of the agents expand, ensuring their safety and trustworthiness becomes more imperative. In this study, we introduce the Athena framework which leverages the concept of verbal contrastive learning where past safe and unsafe trajectories are used as in-context (contrastive) examples to guide the agent towards safety while fulfilling a given task. The framework also incorporates a critiquing mechanism to guide the agent to prevent risky actions at every step. Furthermore, due to the lack of existing benchmarks on the safety reasoning ability of LLM-based agents, we curate a set of 80 toolkits across 8 categories with 180 scenarios to provide a safety evaluation benchmark. Our experimental evaluation, with both closed- and open-source LLMs, indicates verbal contrastive learning and interaction-level critiquing improve the safety rate significantly.",
        "code": "",
        "category": [
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.11021"
    },
    "cd5004147ad6ef1ced7635c17f8b0bd8": {
        "title": "MDD-5k: A New Diagnostic Conversation Dataset for Mental Disorders Synthesized via Neuro-Symbolic LLM Agents",
        "authors": [
            "Congchi Yin",
            "Feng Li",
            "Shu Zhang",
            "Zike Wang",
            "Jun Shao",
            "Piji Li",
            "Jianhua Chen",
            "Xun Jiang"
        ],
        "date": "2024/08/22",
        "pdf": "http://arxiv.org/pdf/2408.12142",
        "abstract": "The clinical diagnosis of most mental disorders primarily relies on the conversations between psychiatrist and patient. The creation of such diagnostic conversation datasets is promising to boost the AI mental healthcare community. However, directly collecting the conversations in real diagnosis scenarios is near impossible due to stringent privacy and ethical considerations. To address this issue, we seek to synthesize diagnostic conversation by exploiting anonymized patient cases that are easier to access. Specifically, we design a neuro-symbolic multi-agent framework for synthesizing the diagnostic conversation of mental disorders with large language models. It takes patient case as input and is capable of generating multiple diverse conversations with one single patient case. The framework basically involves the interaction between a doctor agent and a patient agent, and generates conversations under symbolic control via a dynamic diagnosis tree. By applying the proposed framework, we develop the largest Chinese mental disorders diagnosis dataset MDD-5k. This dataset is built upon 1000 real, anonymized patient cases by cooperating with Shanghai Mental Health Center and comprises 5000 high-quality long conversations with diagnosis results and treatment opinions as labels. To the best of our knowledge, it&#39;s also the first labeled dataset for Chinese mental disorders diagnosis. Human evaluation demonstrates the proposed MDD-5k dataset successfully simulates human-like diagnostic process of mental disorders.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ],
            [
                "Infrastructure",
                "Dataset"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.12142"
    },
    "69ac0fb45e46442c4063c4c3143bc62a": {
        "title": "AgentMonitor: A Plug-and-Play Framework for Predictive and Secure Multi-Agent Systems",
        "authors": [
            "Chi-Min Chan",
            "Jianxuan Yu",
            "Weize Chen",
            "Chunyang Jiang",
            "Xinyu Liu",
            "Weijie Shi",
            "Zhiyuan Liu",
            "Wei Xue",
            "Yike Guo"
        ],
        "date": "2024/08/27",
        "pdf": "http://arxiv.org/pdf/2408.14972",
        "abstract": "The rapid advancement of large language models (LLMs) has led to the rise of LLM-based agents. Recent research shows that multi-agent systems (MAS), where each agent plays a specific role, can outperform individual LLMs. However, configuring an MAS for a task remains challenging, with performance only observable post-execution. Inspired by scaling laws in LLM development, we investigate whether MAS performance can be predicted beforehand. We introduce AgentMonitor, a framework that integrates at the agent level to capture inputs and outputs, transforming them into statistics for training a regression model to predict task performance. Additionally, it can further apply real-time corrections to address security risks posed by malicious agents, mitigating negative impacts and enhancing MAS security. Experiments demonstrate that an XGBoost model achieves a Spearman correlation of 0.89 in-domain and 0.58 in more challenging scenarios. Furthermore, using AgentMonitor reduces harmful content by 6.2% and increases helpful content by 1.8% on average, enhancing safety and reliability. Code is available at \\url{https://github.com/chanchimin/AgentMonitor}.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.14972"
    },
    "a8c5757f567133bd8ed62e4cf3274497": {
        "title": "Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations",
        "authors": [
            "Yucheng Jiang",
            "Yijia Shao",
            "Dekun Ma",
            "Sina J. Semnani",
            "Monica S. Lam"
        ],
        "date": "2024/08/27",
        "pdf": "http://arxiv.org/pdf/2408.15232",
        "abstract": "While language model (LM)-powered chatbots and generative search engines excel at answering concrete queries, discovering information in the terrain of unknown unknowns remains challenging for users. To emulate the common educational scenario where children/students learn by listening to and participating in conversations of their parents/teachers, we create Collaborative STORM (Co-STORM). Unlike QA systems that require users to ask all the questions, Co-STORM lets users observe and occasionally steer the discourse among several LM agents. The agents ask questions on the user&#39;s behalf, allowing the user to discover unknown unknowns serendipitously. To facilitate user interaction, Co-STORM assists users in tracking the discourse by organizing the uncovered information into a dynamic mind map, ultimately generating a comprehensive report as takeaways. For automatic evaluation, we construct the WildSeek dataset by collecting real information-seeking records with user goals. Co-STORM outperforms baseline methods on both discourse trace and report quality. In a further human evaluation, 70% of participants prefer Co-STORM over a search engine, and 78% favor it over a RAG chatbot.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.15232"
    },
    "fb8a5b2f3bb18288e5d2a9878fa08723": {
        "title": "Interactive Agents: Simulating Counselor-Client Psychological Counseling via Role-Playing LLM-to-LLM Interactions",
        "authors": [
            "Huachuan Qiu",
            "Zhenzhong Lan"
        ],
        "date": "2024/08/28",
        "pdf": "http://arxiv.org/pdf/2408.15787",
        "abstract": "Virtual counselors powered by large language models (LLMs) aim to create interactive support systems that effectively assist clients struggling with mental health challenges. To replicate counselor-client conversations, researchers have built an online mental health platform that allows professional counselors to provide clients with text-based counseling services for about an hour per session. Notwithstanding its effectiveness, challenges exist as human annotation is time-consuming, cost-intensive, privacy-protected, and not scalable. To address this issue and investigate the applicability of LLMs in psychological counseling conversation simulation, we propose a framework that employs two LLMs via role-playing for simulating counselor-client interactions. Our framework involves two LLMs, one acting as a client equipped with a specific and real-life user profile and the other playing the role of an experienced counselor, generating professional responses using integrative therapy techniques. We implement both the counselor and the client by zero-shot prompting the GPT-4 model. In order to assess the effectiveness of LLMs in simulating counselor-client interactions and understand the disparities between LLM- and human-generated conversations, we evaluate the synthetic data from various perspectives. We begin by assessing the client&#39;s performance through automatic evaluations. Next, we analyze and compare the disparities between dialogues generated by the LLM and those generated by professional counselors. Furthermore, we conduct extensive experiments to thoroughly examine the performance of our LLM-based counselor trained with synthetic interactive dialogues by benchmarking against state-of-the-art models for mental health.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ],
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.15787"
    },
    "65fca19276be73ed930286269796a862": {
        "title": "BattleAgentBench: A Benchmark for Evaluating Cooperation and Competition Capabilities of Language Models in Multi-Agent Systems",
        "authors": [
            "Wei Wang",
            "Dan Zhang",
            "Tao Feng",
            "Boyan Wang",
            "Jie Tang"
        ],
        "date": "2024/08/28",
        "pdf": "http://arxiv.org/pdf/2408.15971",
        "abstract": "Large Language Models (LLMs) are becoming increasingly powerful and capable of handling complex tasks, e.g., building single agents and multi-agent systems. Compared to single agents, multi-agent systems have higher requirements for the collaboration capabilities of language models. Many benchmarks are proposed to evaluate their collaborative abilities. However, these benchmarks lack fine-grained evaluations of LLM collaborative capabilities. Additionally, multi-agent collaborative and competitive scenarios are ignored in existing works. To address these two problems, we propose a benchmark, called BattleAgentBench, which defines seven sub-stages of three varying difficulty levels and conducts a fine-grained evaluation of language models in terms of single-agent scenario navigation capabilities, paired-agent task execution abilities, and multi-agent collaboration and competition capabilities. We conducted extensive evaluations on leading four closed-source and seven open-source models. Experimental results indicate that API-based models perform excellently on simple tasks but open-source small models struggle with simple tasks. Regarding difficult tasks that require collaborative and competitive abilities, although API-based models have demonstrated some collaborative capabilities, there is still enormous room for improvement.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.15971"
    },
    "21beb16d5cb74aaced3f93b09ff8fee6": {
        "title": "Tool-Assisted Agent on SQL Inspection and Refinement in Real-World Scenarios",
        "authors": [
            "Zhongyuan Wang",
            "Richong Zhang",
            "Zhijie Nie",
            "Jaein Kim"
        ],
        "date": "2024/08/30",
        "pdf": "http://arxiv.org/pdf/2408.16991",
        "abstract": "Recent Text-to-SQL methods leverage large language models (LLMs) by incorporating feedback from the database management system. While these methods effectively address execution errors in SQL queries, they struggle with database mismatches -- errors that do not trigger execution exceptions. Database mismatches include issues such as condition mismatches and stricter constraint mismatches, both of which are more prevalent in real-world scenarios. To address these challenges, we propose a tool-assisted agent framework for SQL inspection and refinement, equipping the LLM-based agent with two specialized tools: a retriever and a detector, designed to diagnose and correct SQL queries with database mismatches. These tools enhance the capability of LLMs to handle real-world queries more effectively. We also introduce Spider-Mismatch, a new dataset specifically constructed to reflect the condition mismatch problems encountered in real-world scenarios. Experimental results demonstrate that our method achieves the highest performance on the averaged results of the Spider and Spider-Realistic datasets in few-shot settings, and it significantly outperforms baseline methods on the more realistic dataset, Spider-Mismatch.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.16991"
    },
    "1a3f39eece9285a119b607a90bd48082": {
        "title": "OmniParser for Pure Vision Based GUI Agent",
        "authors": [
            "Yadong Lu",
            "Jianwei Yang",
            "Yelong Shen",
            "Ahmed Awadallah"
        ],
        "date": "2024/08/01",
        "pdf": "http://arxiv.org/pdf/2408.00203",
        "abstract": "The recent success of large vision language models shows great potential in driving the agent system operating on user interfaces. However, we argue that the power multimodal models like GPT-4V as a general agent on multiple operating systems across different applications is largely underestimated due to the lack of a robust screen parsing technique capable of: 1) reliably identifying interactable icons within the user interface, and 2) understanding the semantics of various elements in a screenshot and accurately associate the intended action with the corresponding region on the screen. To fill these gaps, we introduce \\textsc{OmniParser}, a comprehensive method for parsing user interface screenshots into structured elements, which significantly enhances the ability of GPT-4V to generate actions that can be accurately grounded in the corresponding regions of the interface. We first curated an interactable icon detection dataset using popular webpages and an icon description dataset. These datasets were utilized to fine-tune specialized models: a detection model to parse interactable regions on the screen and a caption model to extract the functional semantics of the detected elements. \\textsc{OmniParser} significantly improves GPT-4V&#39;s performance on ScreenSpot benchmark. And on Mind2Web and AITW benchmark, \\textsc{OmniParser} with screenshot only input outperforms the GPT-4V baselines requiring additional information outside of screenshot.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.00203"
    },
    "fb9de19dc325901d191ebb8e3ace969f": {
        "title": "Golden-Retriever: High-Fidelity Agentic Retrieval Augmented Generation for Industrial Knowledge Base",
        "authors": [
            "Zhiyu An",
            "Xianzhong Ding",
            "Yen-Chun Fu",
            "Cheng-Chung Chu",
            "Yan Li",
            "Wan Du"
        ],
        "date": "2024/07/20",
        "pdf": "http://arxiv.org/pdf/2408.00798",
        "abstract": "This paper introduces Golden-Retriever, designed to efficiently navigate vast industrial knowledge bases, overcoming challenges in traditional LLM fine-tuning and RAG frameworks with domain-specific jargon and context interpretation. Golden-Retriever incorporates a reflection-based question augmentation step before document retrieval, which involves identifying jargon, clarifying its meaning based on context, and augmenting the question accordingly. Specifically, our method extracts and lists all jargon and abbreviations in the input question, determines the context against a pre-defined list, and queries a jargon dictionary for extended definitions and descriptions. This comprehensive augmentation ensures the RAG framework retrieves the most relevant documents by providing clear context and resolving ambiguities, significantly improving retrieval accuracy. Evaluations using three open-source LLMs on a domain-specific question-answer dataset demonstrate Golden-Retriever&#39;s superior performance, providing a robust solution for efficiently integrating and querying industrial knowledge bases.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "RAG"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.00798"
    },
    "d573edd529e927b53c5bd5c11dce12ec": {
        "title": "AgentPeerTalk: Empowering Students through Agentic-AI-Driven Discernment of Bullying and Joking in Peer Interactions in Schools",
        "authors": [
            "Aditya Paul",
            "Chi Lok Yu",
            "Eva Adelina Susanto",
            "Nicholas Wai Long Lau",
            "Gwenyth Isobel Meadows"
        ],
        "date": "2024/07/27",
        "pdf": "http://arxiv.org/pdf/2408.01459",
        "abstract": "Addressing school bullying effectively and promptly is crucial for the mental health of students. This study examined the potential of large language models (LLMs) to empower students by discerning between bullying and joking in school peer interactions. We employed ChatGPT-4, Gemini 1.5 Pro, and Claude 3 Opus, evaluating their effectiveness through human review. Our results revealed that not all LLMs were suitable for an agentic approach, with ChatGPT-4 showing the most promise. We observed variations in LLM outputs, possibly influenced by political overcorrectness, context window limitations, and pre-existing bias in their training data. ChatGPT-4 excelled in context-specific accuracy after implementing the agentic approach, highlighting its potential to provide continuous, real-time support to vulnerable students. This study underlines the significant social impact of using agentic AI in educational settings, offering a new avenue for reducing the negative consequences of bullying and enhancing student well-being.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.01459"
    },
    "764d26b7d815b1676b80b586bb776d93": {
        "title": "Self-Emotion Blended Dialogue Generation in Social Simulation Agents",
        "authors": [
            "Qiang Zhang",
            "Jason Naradowsky",
            "Yusuke Miyao"
        ],
        "date": "2024/08/03",
        "pdf": "http://arxiv.org/pdf/2408.01633",
        "abstract": "When engaging in conversations, dialogue agents in a virtual simulation environment may exhibit their own emotional states that are unrelated to the immediate conversational context, a phenomenon known as self-emotion. This study explores how such self-emotion affects the agents&#39; behaviors in dialogue strategies and decision-making within a large language model (LLM)-driven simulation framework. In a dialogue strategy prediction experiment, we analyze the dialogue strategy choices employed by agents both with and without self-emotion, comparing them to those of humans. The results show that incorporating self-emotion helps agents exhibit more human-like dialogue strategies. In an independent experiment comparing the performance of models fine-tuned on GPT-4 generated dialogue datasets, we demonstrate that self-emotion can lead to better overall naturalness and humanness. Finally, in a virtual simulation environment where agents have discussions on multiple topics, we show that self-emotion of agents can significantly influence the decision-making process of the agents, leading to approximately a 50% change in decisions.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ],
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.01633"
    },
    "cff7a01884eecfae46e3c6916e5e5203": {
        "title": "From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future",
        "authors": [
            "Haolin Jin",
            "Linghan Huang",
            "Haipeng Cai",
            "Jun Yan",
            "Bo Li",
            "Huaming Chen"
        ],
        "date": "2024/08/05",
        "pdf": "http://arxiv.org/pdf/2408.02479",
        "abstract": "With the rise of large language models (LLMs), researchers are increasingly exploring their applications in var ious vertical domains, such as software engineering. LLMs have achieved remarkable success in areas including code generation and vulnerability detection. However, they also exhibit numerous limitations and shortcomings. LLM-based agents, a novel tech nology with the potential for Artificial General Intelligence (AGI), combine LLMs as the core for decision-making and action-taking, addressing some of the inherent limitations of LLMs such as lack of autonomy and self-improvement. Despite numerous studies and surveys exploring the possibility of using LLMs in software engineering, it lacks a clear distinction between LLMs and LLM based agents. It is still in its early stage for a unified standard and benchmarking to qualify an LLM solution as an LLM-based agent in its domain. In this survey, we broadly investigate the current practice and solutions for LLMs and LLM-based agents for software engineering. In particular we summarise six key topics: requirement engineering, code generation, autonomous decision-making, software design, test generation, and software maintenance. We review and differentiate the work of LLMs and LLM-based agents from these six topics, examining their differences and similarities in tasks, benchmarks, and evaluation metrics. Finally, we discuss the models and benchmarks used, providing a comprehensive analysis of their applications and effectiveness in software engineering. We anticipate this work will shed some lights on pushing the boundaries of LLM-based agents in software engineering for future research.",
        "code": "",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2408.02479"
    },
    "086a5cb864eb76025e61465d55c23120": {
        "title": "OpenOmni: A Collaborative Open Source Tool for Building Future-Ready Multimodal Conversational Agents",
        "authors": [
            "Qiang Sun",
            "Yuanyi Luo",
            "Sirui Li",
            "Wenxiao Zhang",
            "Wei Liu"
        ],
        "date": "2024/08/06",
        "pdf": "http://arxiv.org/pdf/2408.03047",
        "abstract": "Multimodal conversational agents are highly desirable because they offer natural and human-like interaction. However, there is a lack of comprehensive end-to-end solutions to support collaborative development and benchmarking. While proprietary systems like GPT-4o and Gemini demonstrating impressive integration of audio, video, and text with response times of 200-250ms, challenges remain in balancing latency, accuracy, cost, and data privacy. To better understand and quantify these issues, we developed OpenOmni, an open-source, end-to-end pipeline benchmarking tool that integrates advanced technologies such as Speech-to-Text, Emotion Detection, Retrieval Augmented Generation, Large Language Models, along with the ability to integrate customized models. OpenOmni supports local and cloud deployment, ensuring data privacy and supporting latency and accuracy benchmarking. This flexible framework allows researchers to customize the pipeline, focusing on real bottlenecks and facilitating rapid proof-of-concept development. OpenOmni can significantly enhance applications like indoor assistance for visually impaired individuals, advancing human-computer interaction. Our demonstration video is available https://www.youtube.com/watch?v=zaSiT3clWqY, demo is available via https://openomni.ai4wa.com, code is available via https://github.com/AI4WA/OpenOmniFramework.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Environment&Platform"
            ],
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.03047"
    },
    "5d434acddc21b38bc2619646fa1fea05": {
        "title": "Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks",
        "authors": [
            "Zaijing Li",
            "Yuquan Xie",
            "Rui Shao",
            "Gongwei Chen",
            "Dongmei Jiang",
            "Liqiang Nie"
        ],
        "date": "2024/08/07",
        "pdf": "http://arxiv.org/pdf/2408.03615",
        "abstract": "Building a general-purpose agent is a long-standing vision in the field of artificial intelligence. Existing agents have made remarkable progress in many domains, yet they still struggle to complete long-horizon tasks in an open world. We attribute this to the lack of necessary world knowledge and multimodal experience that can guide agents through a variety of long-horizon tasks. In this paper, we propose a Hybrid Multimodal Memory module to address the above challenges. It 1) transforms knowledge into Hierarchical Directed Knowledge Graph that allows agents to explicitly represent and learn world knowledge, and 2) summarises historical information into Abstracted Multimodal Experience Pool that provide agents with rich references for in-context learning. On top of the Hybrid Multimodal Memory module, a multimodal agent, Optimus-1, is constructed with dedicated Knowledge-guided Planner and Experience-Driven Reflector, contributing to a better planning and reflection in the face of long-horizon tasks in Minecraft. Extensive experimental results show that Optimus-1 significantly outperforms all existing agents on challenging long-horizon task benchmarks, and exhibits near human-level performance on many tasks. In addition, we introduce various Multimodal Large Language Models (MLLMs) as the backbone of Optimus-1. Experimental results show that Optimus-1 exhibits strong generalization with the help of the Hybrid Multimodal Memory module, outperforming the GPT-4V baseline on many tasks.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Memory Mechanism"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.03615"
    },
    "1ef6b8889528920614a7762918a84a3f": {
        "title": "VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents",
        "authors": [
            "Xiao Liu",
            "Tianjie Zhang",
            "Yu Gu",
            "Iat Long Iong",
            "Yifan Xu",
            "Xixuan Song",
            "Shudan Zhang",
            "Hanyu Lai",
            "Xinyi Liu",
            "Hanlin Zhao",
            "Jiadai Sun",
            "Xinyue Yang",
            "Yu Yang",
            "Zehan Qi",
            "Shuntian Yao",
            "Xueqiao Sun",
            "Siyi Cheng",
            "Qinkai Zheng",
            "Hao Yu",
            "Hanchen Zhang",
            "Wenyi Hong",
            "Ming Ding",
            "Lihang Pan",
            "Xiaotao Gu",
            "Aohan Zeng",
            "Zhengxiao Du",
            "Chan Hee Song",
            "Yu Su",
            "Yuxiao Dong",
            "Jie Tang"
        ],
        "date": "2024/08/12",
        "pdf": "http://arxiv.org/pdf/2408.06327",
        "abstract": "Large Multimodal Models (LMMs) have ushered in a new era in artificial intelligence, merging capabilities in both language and vision to form highly capable Visual Foundation Agents. These agents are postulated to excel across a myriad of tasks, potentially approaching general artificial intelligence. However, existing benchmarks fail to sufficiently challenge or showcase the full potential of LMMs in complex, real-world environments. To address this gap, we introduce VisualAgentBench (VAB), a comprehensive and pioneering benchmark specifically designed to train and evaluate LMMs as visual foundation agents across diverse scenarios, including Embodied, Graphical User Interface, and Visual Design, with tasks formulated to probe the depth of LMMs&#39; understanding and interaction capabilities. Through rigorous testing across nine proprietary LMM APIs and eight open models, we demonstrate the considerable yet still developing agent capabilities of these models. Additionally, VAB constructs a trajectory training set constructed through hybrid methods including Program-based Solvers, LMM Agent Bootstrapping, and Human Demonstrations, promoting substantial performance improvements in LMMs through behavior cloning. Our work not only aims to benchmark existing models but also provides a solid foundation for future development into visual foundation agents. Code, train \\&amp; test data, and part of fine-tuned open LMMs are available at \\url{https://github.com/THUDM/VisualAgentBench}.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.06327"
    },
    "a640af362a345be1dda61463a08f66d5": {
        "title": "Large Language Model Agent in Financial Trading: A Survey",
        "authors": [
            "Han Ding",
            "Yinheng Li",
            "Junhao Wang",
            "Hang Chen"
        ],
        "date": "2024/07/26",
        "pdf": "http://arxiv.org/pdf/2408.06361",
        "abstract": "Trading is a highly competitive task that requires a combination of strategy, knowledge, and psychological fortitude. With the recent success of large language models(LLMs), it is appealing to apply the emerging intelligence of LLM agents in this competitive arena and understanding if they can outperform professional traders. In this survey, we provide a comprehensive review of the current research on using LLMs as agents in financial trading. We summarize the common architecture used in the agent, the data inputs, and the performance of LLM trading agents in backtesting as well as the challenges presented in these research. This survey aims to provide insights into the current state of LLM-based financial trading agents and outline future research directions in this field.",
        "code": "",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2408.06361"
    },
    "4cb0753ab613272080fe321459948459": {
        "title": "Towards Autonomous Agents: Adaptive-planning, Reasoning, and Acting in Language Models",
        "authors": [
            "Abhishek Dutta",
            "Yen-Che Hsiao"
        ],
        "date": "2024/08/12",
        "pdf": "http://arxiv.org/pdf/2408.06458",
        "abstract": "We propose a novel in-context learning algorithm for building autonomous decision-making language agents. The language agent continuously attempts to solve the same task by self-correcting each time the task fails. Our selected language agent demonstrates the ability to solve tasks in a text-based game environment. Our results show that the gemma-2-9b-it language model, using our proposed method, can successfully complete two of six tasks that failed in the first attempt. This highlights the effectiveness of our approach in enhancing the problem-solving capabilities of a single language model through self-correction, paving the way for more advanced autonomous agents. The code is publicly available at https://github.com/YenCheHsiao/AutonomousLLMAgentwithAdaptingPlanning.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.06458"
    },
    "969057ef323acecff476cec539bc0e0e": {
        "title": "Causal Agent based on Large Language Model",
        "authors": [
            "Kairong Han",
            "Kun Kuang",
            "Ziyu Zhao",
            "Junjian Ye",
            "Fei Wu"
        ],
        "date": "2024/08/13",
        "pdf": "http://arxiv.org/pdf/2408.06849",
        "abstract": "Large language models (LLMs) have achieved significant success across various domains. However, the inherent complexity of causal problems and causal theory poses challenges in accurately describing them in natural language, making it difficult for LLMs to comprehend and use them effectively. Causal methods are not easily conveyed through natural language, which hinders LLMs&#39; ability to apply them accurately. Additionally, causal datasets are typically tabular, while LLMs excel in handling natural language data, creating a structural mismatch that impedes effective reasoning with tabular data. This lack of causal reasoning capability limits the development of LLMs. To address these challenges, we have equipped the LLM with causal tools within an agent framework, named the Causal Agent, enabling it to tackle causal problems. The causal agent comprises tools, memory, and reasoning modules. In the tools module, the causal agent applies causal methods to align tabular data with natural language. In the reasoning module, the causal agent employs the ReAct framework to perform reasoning through multiple iterations with the tools. In the memory module, the causal agent maintains a dictionary instance where the keys are unique names and the values are causal graphs. To verify the causal ability of the causal agent, we established a benchmark consisting of four levels of causal problems: variable level, edge level, causal graph level, and causal effect level. We generated a test dataset of 1.3K using ChatGPT-3.5 for these four levels of issues and tested the causal agent on the datasets. Our methodology demonstrates remarkable efficacy on the four-level causal problems, with accuracy rates all above 80%. For further insights and implementation details, our code is accessible via the GitHub repository https://github.com/Kairong-Han/Causal_Agent.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.06849"
    },
    "3f890b32a1d1cf216d84404918e7425e": {
        "title": "Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents",
        "authors": [
            "Kexun Zhang",
            "Weiran Yao",
            "Zuxin Liu",
            "Yihao Feng",
            "Zhiwei Liu",
            "Rithesh Murthy",
            "Tian Lan",
            "Lei Li",
            "Renze Lou",
            "Jiacheng Xu",
            "Bo Pang",
            "Yingbo Zhou",
            "Shelby Heinecke",
            "Silvio Savarese",
            "Huan Wang",
            "Caiming Xiong"
        ],
        "date": "2024/08/13",
        "pdf": "http://arxiv.org/pdf/2408.07060",
        "abstract": "Large language model (LLM) agents have shown great potential in solving real-world software engineering (SWE) problems. The most advanced open-source SWE agent can resolve over 27% of real GitHub issues in SWE-Bench Lite. However, these sophisticated agent frameworks exhibit varying strengths, excelling in certain tasks while underperforming in others. To fully harness the diversity of these agents, we propose DEI (Diversity Empowered Intelligence), a framework that leverages their unique expertise. DEI functions as a meta-module atop existing SWE agent frameworks, managing agent collectives for enhanced problem-solving. Experimental results show that a DEI-guided committee of agents is able to surpass the best individual agent&#39;s performance by a large margin. For instance, a group of open-source SWE agents, with a maximum individual resolve rate of 27.3% on SWE-Bench Lite, can achieve a 34.3% resolve rate with DEI, making a 25% improvement and beating most closed-source solutions. Our best-performing group excels with a 55% resolve rate, securing the highest ranking on SWE-Bench Lite. Our findings contribute to the growing body of research on collaborative AI systems and their potential to solve complex software engineering challenges.",
        "code": "",
        "category": [
            [
                "Application",
                "Software Engineering"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.07060"
    },
    "38b8de6a2c2166ed9e53dc1569ece917": {
        "title": "Development of a Large Language Model-based Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments",
        "authors": [
            "Seungjun Han",
            "Wongyung Choi"
        ],
        "date": "2024/08/14",
        "pdf": "http://arxiv.org/pdf/2408.07531",
        "abstract": "Emergency department (ED) overcrowding and the complexity of rapid decision-making in critical care settings pose significant challenges to healthcare systems worldwide. While clinical decision support systems (CDSS) have shown promise, the integration of large language models (LLMs) offers new possibilities for enhancing triage accuracy and clinical decision-making. This study presents an LLM-driven CDSS designed to assist ED physicians and nurses in patient triage, treatment planning, and overall emergency care management. We developed a multi-agent CDSS utilizing Llama-3-70b as the base LLM, orchestrated by CrewAI and Langchain. The system comprises four AI agents emulating key ED roles: Triage Nurse, Emergency Physician, Pharmacist, and ED Coordinator. It incorporates the Korean Triage and Acuity Scale (KTAS) for triage assessment and integrates with the RxNorm API for medication management. The model was evaluated using the Asclepius dataset, with performance assessed by a clinical emergency medicine specialist. The CDSS demonstrated high accuracy in triage decision-making compared to the baseline of a single-agent system. Furthermore, the system exhibited strong performance in critical areas, including primary diagnosis, critical findings identification, disposition decision-making, treatment planning, and resource allocation. Our multi-agent CDSS demonstrates significant potential for supporting comprehensive emergency care management. By leveraging state-of-the-art AI technologies, this system offers a scalable and adaptable tool that could enhance emergency medical care delivery, potentially alleviating ED overcrowding and improving patient outcomes. This work contributes to the growing field of AI applications in emergency medicine and offers a promising direction for future research and clinical implementation.",
        "code": "",
        "category": [
            [
                "Application",
                "Medicine"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.07531"
    },
    "faee3dc900333e58359ab8708b0c9128": {
        "title": "Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework",
        "authors": [
            "Changyu Du",
            "Sebastian Esser",
            "Stavros Nousias",
            "AndrÃ© Borrmann"
        ],
        "date": "2024/08/15",
        "pdf": "http://arxiv.org/pdf/2408.08054",
        "abstract": "The conventional BIM authoring process typically requires designers to master complex and tedious modeling commands in order to materialize their design intentions within BIM authoring tools. This additional cognitive burden complicates the design process and hinders the adoption of BIM and model-based design in the AEC (Architecture, Engineering, and Construction) industry. To facilitate the expression of design intentions more intuitively, we propose Text2BIM, an LLM-based multi-agent framework that can generate 3D building models from natural language instructions. This framework orchestrates multiple LLM agents to collaborate and reason, transforming textual user input into imperative code that invokes the BIM authoring tool&#39;s APIs, thereby generating editable BIM models with internal layouts, external envelopes, and semantic information directly in the software. Furthermore, a rule-based model checker is introduced into the agentic workflow, utilizing predefined domain knowledge to guide the LLM agents in resolving issues within the generated models and iteratively improving model quality. Extensive experiments were conducted to compare and analyze the performance of three different LLMs under the proposed framework. The evaluation results demonstrate that our approach can effectively generate high-quality, structurally rational building models that are aligned with the abstract concepts specified by user input. Finally, an interactive software prototype was developed to integrate the framework into the BIM authoring software Vectorworks, showcasing the potential of modeling by chatting.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.08054"
    },
    "0fe4cbf987892034dae7fa1694691671": {
        "title": "What should I wear to a party in a Greek taverna? Evaluation for Conversational Agents in the Fashion Domain",
        "authors": [
            "Antonis Maronikolakis",
            "Ana Peleteiro Ramallo",
            "Weiwei Cheng",
            "Thomas Kober"
        ],
        "date": "2024/08/13",
        "pdf": "http://arxiv.org/pdf/2408.08907",
        "abstract": "Large language models (LLMs) are poised to revolutionize the domain of online fashion retail, enhancing customer experience and discovery of fashion online. LLM-powered conversational agents introduce a new way of discovery by directly interacting with customers, enabling them to express in their own ways, refine their needs, obtain fashion and shopping advice that is relevant to their taste and intent. For many tasks in e-commerce, such as finding a specific product, conversational agents need to convert their interactions with a customer to a specific call to different backend systems, e.g., a search system to showcase a relevant set of products. Therefore, evaluating the capabilities of LLMs to perform those tasks related to calling other services is vital. However, those evaluations are generally complex, due to the lack of relevant and high quality datasets, and do not align seamlessly with business needs, amongst others. To this end, we created a multilingual evaluation dataset of 4k conversations between customers and a fashion assistant in a large e-commerce fashion platform to measure the capabilities of LLMs to serve as an assistant between customers and a backend engine. We evaluate a range of models, showcasing how our dataset scales to business needs and facilitates iterative development of tools.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ],
            [
                "Application",
                "Art"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.08907"
    },
    "48afb3bd09e56a8df08382a0342bda1e": {
        "title": "VerilogCoder: Autonomous Verilog Coding Agents with Graph-based Planning and Abstract Syntax Tree (AST)-based Waveform Tracing Tool",
        "authors": [
            "Chia-Tung Ho",
            "Haoxing Ren",
            "Brucek Khailany"
        ],
        "date": "2024/08/15",
        "pdf": "http://arxiv.org/pdf/2408.08927",
        "abstract": "Due to the growing complexity of modern Integrated Circuits (ICs), automating hardware design can prevent a significant amount of human error from the engineering process and result in less errors. Verilog is a popular hardware description language for designing and modeling digital systems; thus, Verilog generation is one of the emerging areas of research to facilitate the design process. In this work, we propose VerilogCoder, a system of multiple Artificial Intelligence (AI) agents for Verilog code generation, to autonomously write Verilog code and fix syntax and functional errors using collaborative Verilog tools (i.e., syntax checker, simulator, and waveform tracer). Firstly, we propose a task planner that utilizes a novel Task and Circuit Relation Graph retrieval method to construct a holistic plan based on module descriptions. To debug and fix functional errors, we develop a novel and efficient abstract syntax tree (AST)-based waveform tracing tool, which is integrated within the autonomous Verilog completion flow. The proposed methodology successfully generates 94.2% syntactically and functionally correct Verilog code, surpassing the state-of-the-art methods by 33.9% on the VerilogEval-Human v2 benchmark.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ],
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.08927"
    },
    "fe362a02b673ee887cb919053cb2a8dd": {
        "title": "GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making",
        "authors": [
            "Arsham Gholamzadeh Khoee",
            "Yinan Yu",
            "Robert Feldt",
            "Andris Freimanis",
            "Patrick Andersson Rhodin",
            "Dhasarathy Parthasarathy"
        ],
        "date": "2024/08/19",
        "pdf": "http://arxiv.org/pdf/2408.09785",
        "abstract": "Traditional methods for making software deployment decisions in the automotive industry typically rely on manual analysis of tabular software test data. These methods often lead to higher costs and delays in the software release cycle due to their labor-intensive nature. Large Language Models (LLMs) present a promising solution to these challenges. However, their application generally demands multiple rounds of human-driven prompt engineering, which limits their practical deployment, particularly for industrial end-users who need reliable and efficient results. In this paper, we propose GoNoGo, an LLM agent system designed to streamline automotive software deployment while meeting both functional requirements and practical industrial constraints. Unlike previous systems, GoNoGo is specifically tailored to address domain-specific and risk-sensitive systems. We evaluate GoNoGo&#39;s performance across different task difficulties using zero-shot and few-shot examples taken from industrial practice. Our results show that GoNoGo achieves a 100% success rate for tasks up to Level 2 difficulty with 3-shot examples, and maintains high performance even for more complex tasks. We find that GoNoGo effectively automates decision-making for simpler tasks, significantly reducing the need for manual intervention. In summary, GoNoGo represents an efficient and user-friendly LLM-based solution currently employed in our industrial partner&#39;s company to assist with software release decision-making, supporting more informed and timely decisions in the release process for risk-sensitive vehicle systems.",
        "code": "",
        "category": [
            [
                "Application",
                "Software Engineering"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.09785"
    },
    "49e56c8922c2cdf59906fc0867e2c6b2": {
        "title": "LLM Agents Improve Semantic Code Search",
        "authors": [
            "Sarthak Jain",
            "Aditya Dora",
            "Ka Seng Sam",
            "Prabhat Singh"
        ],
        "date": "2024/08/05",
        "pdf": "http://arxiv.org/pdf/2408.11058",
        "abstract": "Code Search is a key task that many programmers often have to perform while developing solutions to problems. Current methodologies suffer from an inability to perform accurately on prompts that contain some ambiguity or ones that require additional context relative to a code-base. We introduce the approach of using Retrieval Augmented Generation (RAG) powered agents to inject information into user prompts allowing for better inputs into embedding models. By utilizing RAG, agents enhance user queries with relevant details from GitHub repositories, making them more informative and contextually aligned. Additionally, we introduce a multi-stream ensemble approach which when paired with agentic workflow can obtain improved retrieval accuracy, which we deploy on application called repo-rift.com. Experimental results on the CodeSearchNet dataset demonstrate that RepoRift significantly outperforms existing methods, achieving an 78.2% success rate at Success@10 and a 34.6% success rate at Success@1. This research presents a substantial advancement in semantic code search, highlighting the potential of agentic LLMs and RAG to enhance code retrieval systems.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "RAG"
            ],
            [
                "Application",
                "Software Engineering"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.11058"
    },
    "971e012ca5316ab62b1c7079cf4d7e04": {
        "title": "Drama Engine: A Framework for Narrative Agents",
        "authors": [
            "Martin Pichlmair",
            "Riddhi Raj",
            "Charlene Putney"
        ],
        "date": "2024/08/21",
        "pdf": "http://arxiv.org/pdf/2408.11574",
        "abstract": "This technical report presents the Drama Engine, a novel framework for agentic interaction with large language models designed for narrative purposes. The framework adapts multi-agent system principles to create dynamic, context-aware companions that can develop over time and interact with users and each other. Key features include multi-agent workflows with delegation, dynamic prompt assembly, and model-agnostic design. The Drama Engine introduces unique elements such as companion development, mood systems, and automatic context summarising. It is implemented in TypeScript. The framework&#39;s applications include multi-agent chats and virtual co-workers for creative writing. The paper discusses the system&#39;s architecture, prompt assembly process, delegation mechanisms, and moderation techniques, as well as potential ethical considerations and future extensions.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.11574"
    },
    "7d4eb40b5a86debe28b8f480335dac49": {
        "title": "DreamFactory: Pioneering Multi-Scene Long Video Generation with a Multi-Agent Framework",
        "authors": [
            "Zhifei Xie",
            "Daniel Tang",
            "Dingwei Tan",
            "Jacques Klein",
            "Tegawend F. Bissyand",
            "Saad Ezzini"
        ],
        "date": "2024/08/21",
        "pdf": "http://arxiv.org/pdf/2408.11788",
        "abstract": "Current video generation models excel at creating short, realistic clips, but struggle with longer, multi-scene videos. We introduce \\texttt{DreamFactory}, an LLM-based framework that tackles this challenge. \\texttt{DreamFactory} leverages multi-agent collaboration principles and a Key Frames Iteration Design Method to ensure consistency and style across long videos. It utilizes Chain of Thought (COT) to address uncertainties inherent in large language models. \\texttt{DreamFactory} generates long, stylistically coherent, and complex videos. Evaluating these long-form videos presents a challenge. We propose novel metrics such as Cross-Scene Face Distance Score and Cross-Scene Style Consistency Score. To further research in this area, we contribute the Multi-Scene Videos Dataset containing over 150 human-rated videos.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.11788"
    },
    "5dbbdf69da4ef34d11452718f9da9b9a": {
        "title": "MuMA-ToM: Multi-modal Multi-Agent Theory of Mind",
        "authors": [
            "Haojun Shi",
            "Suyu Ye",
            "Xinyu Fang",
            "Chuanyang Jin",
            "Leyla Isik",
            "Yen-Ling Kuo",
            "Tianmin Shu"
        ],
        "date": "2024/08/22",
        "pdf": "http://arxiv.org/pdf/2408.12574",
        "abstract": "Understanding people&#39;s social interactions in complex real-world scenarios often relies on intricate mental reasoning. To truly understand how and why people interact with one another, we must infer the underlying mental states that give rise to the social interactions, i.e., Theory of Mind reasoning in multi-agent interactions. Additionally, social interactions are often multi-modal -- we can watch people&#39;s actions, hear their conversations, and/or read about their past behaviors. For AI systems to successfully and safely interact with people in real-world environments, they also need to understand people&#39;s mental states as well as their inferences about each other&#39;s mental states based on multi-modal information about their interactions. For this, we introduce MuMA-ToM, a Multi-modal Multi-Agent Theory of Mind benchmark. MuMA-ToM is the first multi-modal Theory of Mind benchmark that evaluates mental reasoning in embodied multi-agent interactions. In MuMA-ToM, we provide video and text descriptions of people&#39;s multi-modal behavior in realistic household environments. Based on the context, we then ask questions about people&#39;s goals, beliefs, and beliefs about others&#39; goals. We validated MuMA-ToM in a human experiment and provided a human baseline. We also proposed a novel multi-modal, multi-agent ToM model, LIMP (Language model-based Inverse Multi-agent Planning). Our experimental results show that LIMP significantly outperforms state-of-the-art methods, including large multi-modal models (e.g., GPT-4o, Gemini-1.5 Pro) and a recent multi-modal ToM model, BIP-ALM.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.12574"
    },
    "be709d2a026411da1f508e5b53ad21ef": {
        "title": "DrugAgent: Explainable Drug Repurposing Agent with Large Language Model-based Reasoning",
        "authors": [
            "Yoshitaka Inoue",
            "Tianci Song",
            "Tianfan Fu"
        ],
        "date": "2024/08/23",
        "pdf": "http://arxiv.org/pdf/2408.13378",
        "abstract": "Drug repurposing offers a promising avenue for accelerating drug development by identifying new therapeutic potentials of existing drugs. In this paper, we propose a multi-agent framework to enhance the drug repurposing process using state-of-the-art machine learning techniques and knowledge integration. Our framework comprises several specialized agents: an AI Agent trains robust drug-target interaction (DTI) models; a Knowledge Graph Agent utilizes the drug-gene interaction database (DGIdb), DrugBank, Comparative Toxicogenomics Database (CTD), and Search Tool for Interactions of Chemicals (STITCH) to systematically extract DTIs; and a Search Agent interacts with biomedical literature to annotate and verify computational predictions. By integrating outputs from these agents, our system effectively harnesses diverse data sources, including external databases, to propose viable repurposing candidates. Preliminary results demonstrate the potential of our approach in not only predicting drug-disease interactions but also in reducing the time and cost associated with traditional drug discovery methods. This paper highlights the scalability of multi-agent systems in biomedical research and their role in driving innovation in drug repurposing. Our approach not only outperforms existing methods in predicting drug repurposing potential but also provides interpretable results, paving the way for more efficient and cost-effective drug discovery processes.",
        "code": "",
        "category": [
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.13378"
    },
    "1df4b92bf8b8b9242f08d156acabee10": {
        "title": "AgentMove: A Large Language Model based Agentic Framework for Zero-shot Next Location Prediction",
        "authors": [
            "Jie Feng",
            "Yuwei Du",
            "Jie Zhao",
            "Yong Li"
        ],
        "date": "2024/08/26",
        "pdf": "http://arxiv.org/pdf/2408.13986",
        "abstract": "Next location prediction plays a crucial role in various real-world applications. Recently, due to the limitation of existing deep learning methods, attempts have been made to apply large language models (LLMs) to zero-shot next location prediction task. However, they directly generate the final output using LLMs without systematic design, which limits the potential of LLMs to uncover complex mobility patterns and underestimates their extensive reserve of global geospatial knowledge. In this paper, we introduce AgentMove, a systematic agentic prediction framework to achieve generalized next location prediction. In AgentMove, we first decompose the mobility prediction task and design specific modules to complete them, including spatial-temporal memory for individual mobility pattern mining, world knowledge generator for modeling the effects of urban structure and collective knowledge extractor for capturing the shared patterns among population. Finally, we combine the results of three modules and conduct a reasoning step to generate the final predictions. Extensive experiments utilizing mobility data from two distinct sources reveal that AgentMove surpasses the leading baseline by 3.33% to 8.57% across 8 out of 12 metrics and it shows robust predictions with various LLMs as base and also less geographical bias across cities. Our codes are available via https://github.com/tsinghua-fib-lab/AgentMove.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.13986"
    },
    "49ea1a31712c4fd798264a5056f230f6": {
        "title": "MLR-Copilot: Autonomous Machine Learning Research based on Large Language Models Agents",
        "authors": [
            "Ruochen Li",
            "Teerth Patel",
            "Qingyun Wang",
            "Xinya Du"
        ],
        "date": "2024/08/26",
        "pdf": "http://arxiv.org/pdf/2408.14033",
        "abstract": "Machine learning research, crucial for technological advancements and innovation, often faces significant challenges due to its inherent complexity, slow pace of experimentation, and the necessity for specialized expertise. Motivated by this, we present a new systematic framework, autonomous Machine Learning Research with large language models (MLR-Copilot), designed to enhance machine learning research productivity through the automatic generation and implementation of research ideas using Large Language Model (LLM) agents. The framework consists of three phases: research idea generation, experiment implementation, and implementation execution. First, existing research papers are used to generate hypotheses and experimental plans vis IdeaAgent powered by LLMs. Next, the implementation generation phase translates these plans into executables with ExperimentAgent. This phase leverages retrieved prototype code and optionally retrieves candidate models and data. Finally, the execution phase, also managed by ExperimentAgent, involves running experiments with mechanisms for human feedback and iterative debugging to enhance the likelihood of achieving executable research outcomes. We evaluate our framework on five machine learning research tasks and the experimental results show the framework&#39;s potential to facilitate the research progress and innovations.",
        "code": "",
        "category": [
            [
                "Application",
                "Research"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.14033"
    },
    "a3e126fe6dd2047fce142c4e1846afb3": {
        "title": "Agentic Retrieval-Augmented Generation for Time Series Analysis",
        "authors": [
            "Chidaksh Ravuru",
            "Sagar Srinivas Sakhinana",
            "Venkataramana Runkana"
        ],
        "date": "2024/08/18",
        "pdf": "http://arxiv.org/pdf/2408.14484",
        "abstract": "Time series modeling is crucial for many applications, however, it faces challenges such as complex spatio-temporal dependencies and distribution shifts in learning from historical context to predict task-specific outcomes. To address these challenges, we propose a novel approach using an agentic Retrieval-Augmented Generation (RAG) framework for time series analysis. The framework leverages a hierarchical, multi-agent architecture where the master agent orchestrates specialized sub-agents and delegates the end-user request to the relevant sub-agent. The sub-agents utilize smaller, pre-trained language models (SLMs) customized for specific time series tasks through fine-tuning using instruction tuning and direct preference optimization, and retrieve relevant prompts from a shared repository of prompt pools containing distilled knowledge about historical patterns and trends to improve predictions on new data. Our proposed modular, multi-agent RAG approach offers flexibility and achieves state-of-the-art performance across major time series tasks by tackling complex challenges more effectively than task-specific customized methods across benchmark datasets.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "RAG"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.14484"
    },
    "c4d8f9f7271fa15038427adbb9c5d95b": {
        "title": "AutoGen Studio: A No-Code Developer Tool for Building and Debugging Multi-Agent Systems",
        "authors": [
            "Victor Dibia",
            "Jingya Chen",
            "Gagan Bansal",
            "Suff Syed",
            "Adam Fourney",
            "Erkang Zhu",
            "Chi Wang",
            "Saleema Amershi"
        ],
        "date": "2024/08/09",
        "pdf": "http://arxiv.org/pdf/2408.15247",
        "abstract": "Multi-agent systems, where multiple agents (generative AI models + tools) collaborate, are emerging as an effective pattern for solving long-running, complex tasks in numerous domains. However, specifying their parameters (such as models, tools, and orchestration mechanisms etc,.) and debugging them remains challenging for most developers. To address this challenge, we present AUTOGEN STUDIO, a no-code developer tool for rapidly prototyping, debugging, and evaluating multi-agent workflows built upon the AUTOGEN framework. AUTOGEN STUDIO offers a web interface and a Python API for representing LLM-enabled agents using a declarative (JSON-based) specification. It provides an intuitive drag-and-drop UI for agent workflow specification, interactive evaluation and debugging of workflows, and a gallery of reusable agent components. We highlight four design principles for no-code multi-agent developer tools and contribute an open-source implementation at https://github.com/microsoft/autogen/tree/main/samples/apps/autogen-studio",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Environment&Platform"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.15247"
    },
    "9719ef83384957e3c9f5de4592a57f3f": {
        "title": "Logic-Enhanced Language Model Agents for Trustworthy Social Simulations",
        "authors": [
            "Agnieszka Mensfelt",
            "Kostas Stathis",
            "Vince Trencsenyi"
        ],
        "date": "2024/08/28",
        "pdf": "http://arxiv.org/pdf/2408.16081",
        "abstract": "We introduce the Logic-Enhanced Language Model Agents (LELMA) framework, a novel approach to enhance the trustworthiness of social simulations that utilize large language models (LLMs). While LLMs have gained attention as agents for simulating human behaviour, their applicability in this role is limited by issues such as inherent hallucinations and logical inconsistencies. LELMA addresses these challenges by integrating LLMs with symbolic AI, enabling logical verification of the reasoning generated by LLMs. This verification process provides corrective feedback, refining the reasoning output. The framework consists of three main components: an LLM-Reasoner for producing strategic reasoning, an LLM-Translator for mapping natural language reasoning to logic queries, and a Solver for evaluating these queries. This study focuses on decision-making in game-theoretic scenarios as a model of human interaction. Experiments involving the Hawk-Dove game, Prisoner&#39;s Dilemma, and Stag Hunt highlight the limitations of state-of-the-art LLMs, GPT-4 Omni and Gemini 1.0 Pro, in producing correct reasoning in these contexts. LELMA demonstrates high accuracy in error detection and improves the reasoning correctness of LLMs via self-refinement, particularly in GPT-4 Omni.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2408.16081"
    },
    "46f33d8602ac3eaecb99547f0092b0be": {
        "title": "MAIN-RAG: Multi-Agent Filtering Retrieval-Augmented Generation",
        "authors": [
            "Chia-Yuan Chang",
            "Zhimeng Jiang",
            "Vineeth Rakesh",
            "Menghai Pan",
            "Chin-Chia Michael Yeh",
            "Guanchu Wang",
            "Mingzhi Hu",
            "Zhichao Xu",
            "Yan Zheng",
            "Mahashweta Das",
            "Na Zou"
        ],
        "date": "2024/12/31",
        "pdf": "http://arxiv.org/pdf/2501.00332",
        "abstract": "Large Language Models (LLMs) are becoming essential tools for various natural language processing tasks but often suffer from generating outdated or incorrect information. Retrieval-Augmented Generation (RAG) addresses this issue by incorporating external, real-time information retrieval to ground LLM responses. However, the existing RAG systems frequently struggle with the quality of retrieval documents, as irrelevant or noisy documents degrade performance, increase computational overhead, and undermine response reliability. To tackle this problem, we propose Multi-Agent Filtering Retrieval-Augmented Generation (MAIN-RAG), a training-free RAG framework that leverages multiple LLM agents to collaboratively filter and score retrieved documents. Specifically, MAIN-RAG introduces an adaptive filtering mechanism that dynamically adjusts the relevance filtering threshold based on score distributions, effectively minimizing noise while maintaining high recall of relevant documents. The proposed approach leverages inter-agent consensus to ensure robust document selection without requiring additional training data or fine-tuning. Experimental results across four QA benchmarks demonstrate that MAIN-RAG consistently outperforms traditional RAG approaches, achieving a 2-11% improvement in answer accuracy while reducing the number of irrelevant retrieved documents. Quantitative analysis further reveals that our approach achieves superior response consistency and answer accuracy over baseline methods, offering a competitive and practical alternative to training-based solutions.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "RAG"
            ]
        ],
        "url": "https://arxiv.org/abs/2501.00332"
    },
    "08f30e914a1e0d1d72576057c49e0f26": {
        "title": "Enhancing LLM Reasoning with Multi-Path Collaborative Reactive and Reflection agents",
        "authors": [
            "Chengbo He",
            "Bochao Zou",
            "Xin Li",
            "Jiansheng Chen",
            "Junliang Xing",
            "Huimin Ma"
        ],
        "date": "2024/12/31",
        "pdf": "http://arxiv.org/pdf/2501.00430",
        "abstract": "Agents have demonstrated their potential in scientific reasoning tasks through large language models. However, they often face challenges such as insufficient accuracy and degeneration of thought when handling complex reasoning tasks, which impede their performance. To overcome these issues, we propose the Reactive and Reflection agents with Multi-Path Reasoning (RR-MP) Framework, aimed at enhancing the reasoning capabilities of LLMs. Our approach improves scientific reasoning accuracy by employing a multi-path reasoning mechanism where each path consists of a reactive agent and a reflection agent that collaborate to prevent degeneration of thought inherent in single-agent reliance. Additionally, the RR-MP framework does not require additional training; it utilizes multiple dialogue instances for each reasoning path and a separate summarizer to consolidate insights from all paths. This design integrates diverse perspectives and strengthens reasoning across each path. We conducted zero-shot and few-shot evaluations on tasks involving moral scenarios, college-level physics, and mathematics. Experimental results demonstrate that our method outperforms baseline approaches, highlighting the effectiveness and advantages of the RR-MP framework in managing complex scientific reasoning tasks.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ]
        ],
        "url": "https://arxiv.org/abs/2501.00430"
    },
    "7330dc587fcb5196f8d65c4f4479404f": {
        "title": "A Multimodal Social Agent",
        "authors": [
            "Athina Bikaki",
            "Ioannis A. Kakadiaris"
        ],
        "date": "2024/12/11",
        "pdf": "http://arxiv.org/pdf/2501.06189",
        "abstract": "In recent years, large language models (LLMs) have demonstrated remarkable progress in common-sense reasoning tasks. This ability is fundamental to understanding social dynamics, interactions, and communication. However, the potential of integrating computers with these social capabilities is still relatively unexplored. However, the potential of integrating computers with these social capabilities is still relatively unexplored. This paper introduces MuSA, a multimodal LLM-based agent that analyzes text-rich social content tailored to address selected human-centric content analysis tasks, such as question answering, visual question answering, title generation, and categorization. It uses planning, reasoning, acting, optimizing, criticizing, and refining strategies to complete a task. Our approach demonstrates that MuSA can automate and improve social content analysis, helping decision-making processes across various applications. We have evaluated our agent&#39;s capabilities in question answering, title generation, and content categorization tasks. MuSA performs substantially better than our baselines.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2501.06189"
    },
    "8f32ebb1d6e90aa0dfa3fc669b6c4a11": {
        "title": "A Novel Task-Driven Method with Evolvable Interactive Agents Using Event Trees for Enhanced Emergency Decision Support",
        "authors": [
            "Xingyu Xiao",
            "Peng Chen",
            "Ben Qi",
            "Jingang Liang",
            "Jiejuan Tong",
            "Haitao Wang"
        ],
        "date": "2024/12/24",
        "pdf": "http://arxiv.org/pdf/2501.06193",
        "abstract": "As climate change and other global challenges increase the likelihood of unforeseen emergencies, the limitations of human-driven strategies in critical situations become more pronounced. Inadequate pre-established emergency plans can lead operators to become overwhelmed during complex systems malfunctions. This study addresses the urgent need for agile decision-making in response to various unforeseen incidents through a novel approach, EvoTaskTree (a task-driven method with evolvable interactive agents using event trees for emergency decision support). This advanced approach integrates two types of agents powered by large language models (LLMs): task executors, responsible for executing critical procedures, and task validators, ensuring the efficacy of those actions. By leveraging insights from event tree analysis, our framework encompasses three crucial tasks: initiating event subevent analysis, event tree header event analysis, and decision recommendations. The agents learn from both successful and unsuccessful responses from these tasks. Finally, we use nuclear power plants as a demonstration of a safety-critical system. Our findings indicate that the designed agents are not only effective but also outperform existing approaches, achieving an impressive accuracy rate of up to 100 % in processing previously unencoun32 tered incident scenarios. This paper demonstrates that EvoTaskTree significantly enhances the rapid formulation of emergency decision-making.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Search"
            ]
        ],
        "url": "https://arxiv.org/abs/2501.06193"
    },
    "900d8aa4e555e14d2d2434c19ad12c5b": {
        "title": "Beyond the Sum: Unlocking AI Agents Potential Through Market Forces",
        "authors": [
            "Jordi Montes Sanabria",
            "Pol Alvarez Vecino"
        ],
        "date": "2024/12/19",
        "pdf": "http://arxiv.org/pdf/2501.10388",
        "abstract": "The emergence of Large Language Models has fundamentally transformed the capabilities of AI agents, enabling a new class of autonomous agents capable of interacting with their environment through dynamic code generation and execution. These agents possess the theoretical capacity to operate as independent economic actors within digital markets, offering unprecedented potential for value creation through their distinct advantages in operational continuity, perfect replication, and distributed learning capabilities. However, contemporary digital infrastructure, architected primarily for human interaction, presents significant barriers to their participation. This work presents a systematic analysis of the infrastructure requirements necessary for AI agents to function as autonomous participants in digital markets. We examine four key areas - identity and authorization, service discovery, interfaces, and payment systems - to show how existing infrastructure actively impedes agent participation. We argue that addressing these infrastructure challenges represents more than a technical imperative; it constitutes a fundamental step toward enabling new forms of economic organization. Much as traditional markets enable human intelligence to coordinate complex activities beyond individual capability, markets incorporating AI agents could dramatically enhance economic efficiency through continuous operation, perfect information sharing, and rapid adaptation to changing conditions. The infrastructure challenges identified in this work represent key barriers to realizing this potential.",
        "code": "",
        "category": [
            [
                "Application",
                "Finance"
            ]
        ],
        "url": "https://arxiv.org/abs/2501.10388"
    },
    "99cdc8d8a88e40e82163639a80853f75": {
        "title": "Multi-Agent Collaboration in Incident Response with Large Language Models",
        "authors": [
            "Zefang Liu"
        ],
        "date": "2024/12/01",
        "pdf": "http://arxiv.org/pdf/2412.00652",
        "abstract": "Incident response (IR) is a critical aspect of cybersecurity, requiring rapid decision-making and coordinated efforts to address cyberattacks effectively. Leveraging large language models (LLMs) as intelligent agents offers a novel approach to enhancing collaboration and efficiency in IR scenarios. This paper explores the application of LLM-based multi-agent collaboration using the Backdoors &amp; Breaches framework, a tabletop game designed for cybersecurity training. We simulate real-world IR dynamics through various team structures, including centralized, decentralized, and hybrid configurations. By analyzing agent interactions and performance across these setups, we provide insights into optimizing multi-agent collaboration for incident response. Our findings highlight the potential of LLMs to enhance decision-making, improve adaptability, and streamline IR processes, paving the way for more effective and coordinated responses to cyber threats.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.00652"
    },
    "59203c63cf8cc77a5088c2b2885143f1": {
        "title": "Towards Adaptive Mechanism Activation in Language Agent",
        "authors": [
            "Ziyang Huang",
            "Jun Zhao",
            "Kang Liu"
        ],
        "date": "2024/12/01",
        "pdf": "http://arxiv.org/pdf/2412.00722",
        "abstract": "Language Agent could be endowed with different mechanisms for autonomous task accomplishment. Current agents typically rely on fixed mechanisms or a set of mechanisms activated in a predefined order, limiting their adaptation to varied potential task solution structures. To this end, this paper proposes \\textbf{A}daptive \\textbf{L}anguage \\textbf{A}gent \\textbf{M}echanism \\textbf{A}ctivation Learning with Self-Exploration (\\textbf{ALAMA}), which focuses on optimizing mechanism activation adaptability without reliance on expert models. Initially, it builds a harmonized agent framework (\\textbf{UniAct}) to \\textbf{Uni}fy different mechanisms via \\textbf{Act}ions. Then it leverages a training-efficient optimization method based on self-exploration to enable the UniAct to adaptively activate the appropriate mechanisms according to the potential characteristics of the task. Experimental results demonstrate significant improvements in downstream agent tasks, affirming the effectiveness of our approach in facilitating more dynamic and context-sensitive mechanism activation.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.00722"
    },
    "7ca7d2d57efc17dbe53c0723f1e97711": {
        "title": "SAUP: Situation Awareness Uncertainty Propagation on LLM Agent",
        "authors": [
            "Qiwei Zhao",
            "Xujiang Zhao",
            "Yanchi Liu",
            "Wei Cheng",
            "Yiyou Sun",
            "Mika Oishi",
            "Takao Osaki",
            "Katsushi Matsuda",
            "Huaxiu Yao",
            "Haifeng Chen"
        ],
        "date": "2024/12/02",
        "pdf": "http://arxiv.org/pdf/2412.01033",
        "abstract": "Large language models (LLMs) integrated into multistep agent systems enable complex decision-making processes across various applications. However, their outputs often lack reliability, making uncertainty estimation crucial. Existing uncertainty estimation methods primarily focus on final-step outputs, which fail to account for cumulative uncertainty over the multistep decision-making process and the dynamic interactions between agents and their environments. To address these limitations, we propose SAUP (Situation Awareness Uncertainty Propagation), a novel framework that propagates uncertainty through each step of an LLM-based agent&#39;s reasoning process. SAUP incorporates situational awareness by assigning situational weights to each step&#39;s uncertainty during the propagation. Our method, compatible with various one-step uncertainty estimation techniques, provides a comprehensive and accurate uncertainty measure. Extensive experiments on benchmark datasets demonstrate that SAUP significantly outperforms existing state-of-the-art methods, achieving up to 20% improvement in AUROC.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.01033"
    },
    "21ad3a6e3e487a9da8279a6d70a2a838": {
        "title": "Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking",
        "authors": [
            "Jie Liu",
            "Wenxuan Wang",
            "Zizhan Ma",
            "Guolin Huang",
            "Yihang SU",
            "Kao-Jung Chang",
            "Wenting Chen",
            "Haoliang Li",
            "Linlin Shen",
            "Michael Lyu"
        ],
        "date": "2024/12/02",
        "pdf": "http://arxiv.org/pdf/2412.01605",
        "abstract": "Clinical decision making (CDM) is a complex, dynamic process crucial to healthcare delivery, yet it remains a significant challenge for artificial intelligence systems. While Large Language Model (LLM)-based agents have been tested on general medical knowledge using licensing exams and knowledge question-answering tasks, their performance in the CDM in real-world scenarios is limited due to the lack of comprehensive testing datasets that mirror actual medical practice. To address this gap, we present MedChain, a dataset of 12,163 clinical cases that covers five key stages of clinical workflow. MedChain distinguishes itself from existing benchmarks with three key features of real-world clinical practice: personalization, interactivity, and sequentiality. Further, to tackle real-world CDM challenges, we also propose MedChain-Agent, an AI system that integrates a feedback mechanism and a MCase-RAG module to learn from previous cases and adapt its responses. MedChain-Agent demonstrates remarkable adaptability in gathering information dynamically and handling sequential clinical tasks, significantly outperforming existing approaches. The relevant dataset and code will be released upon acceptance of this paper.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ],
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.01605"
    },
    "d78645d839f219de0675787c68525fe2": {
        "title": "From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents",
        "authors": [
            "Xinyi Mou",
            "Xuanwen Ding",
            "Qi He",
            "Liang Wang",
            "Jingcong Liang",
            "Xinnong Zhang",
            "Libo Sun",
            "Jiayu Lin",
            "Jie Zhou",
            "Xuanjing Huang",
            "Zhongyu Wei"
        ],
        "date": "2024/12/04",
        "pdf": "http://arxiv.org/pdf/2412.03563",
        "abstract": "Traditional sociological research often relies on human participation, which, though effective, is expensive, challenging to scale, and with ethical concerns. Recent advancements in large language models (LLMs) highlight their potential to simulate human behavior, enabling the replication of individual responses and facilitating studies on many interdisciplinary studies. In this paper, we conduct a comprehensive survey of this field, illustrating the recent progress in simulation driven by LLM-empowered agents. We categorize the simulations into three types: (1) Individual Simulation, which mimics specific individuals or demographic groups; (2) Scenario Simulation, where multiple agents collaborate to achieve goals within specific contexts; and (3) Society Simulation, which models interactions within agent societies to reflect the complexity and variety of real-world dynamics. These simulations follow a progression, ranging from detailed individual modeling to large-scale societal phenomena. We provide a detailed discussion of each simulation type, including the architecture or key components of the simulation, the classification of objectives or scenarios and the evaluation method. Afterward, we summarize commonly used datasets and benchmarks. Finally, we discuss the trends across these three types of simulation. A repository for the related sources is at {\\url{https://github.com/FudanDISC/SocialAgent}}.",
        "code": "",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2412.03563"
    },
    "2a47602b8a2bec6431021bff2805abb1": {
        "title": "Agent AI with LangGraph: A Modular Framework for Enhancing Machine Translation Using Large Language Models",
        "authors": [
            "Jialin Wang",
            "Zhihua Duan"
        ],
        "date": "2024/12/05",
        "pdf": "http://arxiv.org/pdf/2412.03801",
        "abstract": "This paper explores the transformative role of Agent AI and LangGraph in advancing the automation and effectiveness of machine translation (MT). Agents are modular components designed to perform specific tasks, such as translating between particular languages, with specializations like TranslateEnAgent, TranslateFrenchAgent, and TranslateJpAgent for English, French, and Japanese translations, respectively. These agents leverage the powerful semantic capabilities of large language models (LLMs), such as GPT-4o, to ensure accurate, contextually relevant translations while maintaining modularity, scalability, and context retention. LangGraph, a graph-based framework built on LangChain, simplifies the creation and management of these agents and their workflows. It supports dynamic state management, enabling agents to maintain dialogue context and automates complex workflows by linking agents and facilitating their collaboration. With flexibility, open-source community support, and seamless integration with LLMs, LangGraph empowers agents to deliver high-quality translations. Together, Agent AI and LangGraph create a cohesive system where LangGraph orchestrates agent interactions, ensuring that user inputs are analyzed, routed, and processed efficiently. Experimental results demonstrate the potential of this system to enhance multilingual translation accuracy and scalability. By highlighting modular design and automated workflows, this paper sets the stage for further innovations in intelligent machine translation services.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Search"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.03801"
    },
    "9fa9fb061b2ac4d8227ddd970a8d9c7e": {
        "title": "Educational-Psychological Dialogue Robot Based on Multi-Agent Collaboration",
        "authors": [
            "Shiwen Ni",
            "Min Yang"
        ],
        "date": "2024/12/05",
        "pdf": "http://arxiv.org/pdf/2412.03847",
        "abstract": "Intelligent dialogue systems are increasingly used in modern education and psychological counseling fields, but most existing systems are limited to a single domain, cannot deal with both educational and psychological issues, and often lack accuracy and professionalism when dealing with complex issues. To address these problems, this paper proposes an intelligent dialog system that combines educational and psychological counseling functions. The system consists of multiple AI agent, including security detection agent, intent identification agent, educational LLM agent, and psychological LLM agent, which work in concert to ensure the provision of accurate educational knowledge Q\\&amp;A and psychological support services. Specifically, the system recognizes user-input intentions through an intention classification model and invokes a retrieval-enhanced educational grand model and a psychological grand model fine-tuned with psychological data in order to provide professional educational advice and psychological support.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ],
            [
                "Application",
                "Medicine"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.03847"
    },
    "060ad5ae0637df55f71fd354a46665d5": {
        "title": "A Survey on Large Language Model-Based Social Agents in Game-Theoretic Scenarios",
        "authors": [
            "Xiachong Feng",
            "Longxu Dou",
            "Ella Li",
            "Qinghao Wang",
            "Haochuan Wang",
            "Yu Guo",
            "Chang Ma",
            "Lingpeng Kong"
        ],
        "date": "2024/12/05",
        "pdf": "http://arxiv.org/pdf/2412.03920",
        "abstract": "Game-theoretic scenarios have become pivotal in evaluating the social intelligence of Large Language Model (LLM)-based social agents. While numerous studies have explored these agents in such settings, there is a lack of a comprehensive survey summarizing the current progress. To address this gap, we systematically review existing research on LLM-based social agents within game-theoretic scenarios. Our survey organizes the findings into three core components: Game Framework, Social Agent, and Evaluation Protocol. The game framework encompasses diverse game scenarios, ranging from choice-focusing to communication-focusing games. The social agent part explores agents&#39; preferences, beliefs, and reasoning abilities. The evaluation protocol covers both game-agnostic and game-specific metrics for assessing agent performance. By reflecting on the current research and identifying future research directions, this survey provides insights to advance the development and evaluation of social agents in game-theoretic scenarios.",
        "code": "",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2412.03920"
    },
    "91c4890df828c5af9540e911320c8b8f": {
        "title": "Aguvis: Unified Pure Vision Agents for Autonomous GUI Interaction",
        "authors": [
            "Yiheng Xu",
            "Zekun Wang",
            "Junli Wang",
            "Dunjie Lu",
            "Tianbao Xie",
            "Amrita Saha",
            "Doyen Sahoo",
            "Tao Yu",
            "Caiming Xiong"
        ],
        "date": "2024/12/05",
        "pdf": "http://arxiv.org/pdf/2412.04454",
        "abstract": "Graphical User Interfaces (GUIs) are critical to human-computer interaction, yet automating GUI tasks remains challenging due to the complexity and variability of visual environments. Existing approaches often rely on textual representations of GUIs, which introduce limitations in generalization, efficiency, and scalability. In this paper, we introduce Aguvis, a unified pure vision-based framework for autonomous GUI agents that operates across various platforms. Our approach leverages image-based observations, and grounding instructions in natural language to visual elements, and employs a consistent action space to ensure cross-platform generalization. To address the limitations of previous work, we integrate explicit planning and reasoning within the model, enhancing its ability to autonomously navigate and interact with complex digital environments. We construct a large-scale dataset of GUI agent trajectories, incorporating multimodal reasoning and grounding, and employ a two-stage training pipeline that first focuses on general GUI grounding, followed by planning and reasoning. Through comprehensive experiments, we demonstrate that Aguvis surpasses previous state-of-the-art methods in both offline and real-world online scenarios, achieving, to our knowledge, the first fully autonomous pure vision GUI agent capable of performing tasks independently without collaboration with external closed-source models. We open-sourced all datasets, models, and training recipes to facilitate future research at https://aguvis-project.github.io/.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.04454"
    },
    "40dcfea3296e6e7b61c0131dd3bbf7bb": {
        "title": "MAG-V: A Multi-Agent Framework for Synthetic Data Generation and Verification",
        "authors": [
            "Saptarshi Sengupta",
            "Harsh Vashistha",
            "Kristal Curtis",
            "Akshay Mallipeddi",
            "Abhinav Mathur",
            "Joseph Ross",
            "Liang Gou"
        ],
        "date": "2024/11/28",
        "pdf": "http://arxiv.org/pdf/2412.04494",
        "abstract": "Extending the capabilities of Large Language Models (LLMs) with functions or tools for environment interaction has led to the emergence of the agent paradigm. In industry, training an LLM is not always feasible because of the scarcity of domain data, legal holds on proprietary customer data, rapidly changing business requirements, and the need to prototype new assistants. Agents provide an elegant solution to the above by relying on the zero-shot reasoning abilities of the underlying LLM and utilizing tools to explore and reason over customer data and respond to user requests. However, there are two concerns here: (I) acquiring large scale customer queries for agent testing is time-consuming, and (II) high reliance on the tool call sequence (or trajectory) followed by the agent to respond to user queries may lead to unexpected or incorrect behavior. To address this, we propose MAG-V, a multi-agent framework to first generate a dataset of questions that mimic customer queries; and second, reverse-engineer alternate questions from the responses for trajectory verification. Initial results indicate that our synthetic data can improve agent performance on actual customer queries. Furthermore, our trajectory verification methodology, inspired by distant supervision and using traditional machine learning (ML) models, outperforms a GPT-4o judge baseline by 11% accuracy and matches the performance of a GPT-4 judge on our constructed dataset. Overall, our approach is a step towards unifying diverse task agents into a cohesive framework for achieving an aligned objective.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Infrastructure",
                "Dataset"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.04494"
    },
    "ccba7274693ae05f0805443b5a550a56": {
        "title": "Breaking Event Rumor Detection via Stance-Separated Multi-Agent Debate",
        "authors": [
            "Mingqing Zhang",
            "Haisong Gong",
            "Qiang Liu",
            "Shu Wu",
            "Liang Wang"
        ],
        "date": "2024/12/06",
        "pdf": "http://arxiv.org/pdf/2412.04859",
        "abstract": "The rapid spread of rumors on social media platforms during breaking events severely hinders the dissemination of the truth. Previous studies reveal that the lack of annotated resources hinders the direct detection of unforeseen breaking events not covered in yesterday&#39;s news. Leveraging large language models (LLMs) for rumor detection holds significant promise. However, it is challenging for LLMs to provide comprehensive responses to complex or controversial issues due to limited diversity. In this work, we propose the Stance Separated Multi-Agent Debate (S2MAD) to address this issue. Specifically, we firstly introduce Stance Separation, categorizing comments as either supporting or opposing the original claim. Subsequently, claims are classified as subjective or objective, enabling agents to generate reasonable initial viewpoints with different prompt strategies for each type of claim. Debaters then follow specific instructions through multiple rounds of debate to reach a consensus. If a consensus is not reached, a judge agent evaluates the opinions and delivers a final verdict on the claim&#39;s veracity. Extensive experiments conducted on two real-world datasets demonstrate that our proposed model outperforms state-of-the-art methods in terms of performance and effectively improves the performance of LLMs in breaking event rumor detection.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.04859"
    },
    "8b60d4112e8328816d5c8f69475c357a": {
        "title": "CALICO: Conversational Agent Localization via Synthetic Data Generation",
        "authors": [
            "Andy Rosenbaum",
            "Pegah Kharazmi",
            "Ershad Banijamali",
            "Lu Zeng",
            "Christopher DiPersio",
            "Pan Wei",
            "Gokmen Oz",
            "Clement Chung",
            "Karolina Owczarzak",
            "Fabian Triefenbach",
            "Wael Hamza"
        ],
        "date": "2024/12/06",
        "pdf": "http://arxiv.org/pdf/2412.05388",
        "abstract": "We present CALICO, a method to fine-tune Large Language Models (LLMs) to localize conversational agent training data from one language to another. For slots (named entities), CALICO supports three operations: verbatim copy, literal translation, and localization, i.e. generating slot values more appropriate in the target language, such as city and airport names located in countries where the language is spoken. Furthermore, we design an iterative filtering mechanism to discard noisy generated samples, which we show boosts the performance of the downstream conversational agent. To prove the effectiveness of CALICO, we build and release a new human-localized (HL) version of the MultiATIS++ travel information test set in 8 languages. Compared to the original human-translated (HT) version of the test set, we show that our new HL version is more challenging. We also show that CALICO out-performs state-of-the-art LINGUIST (which relies on literal slot translation out of context) both on the HT case, where CALICO generates more accurate slot translations, and on the HL case, where CALICO generates localized slots which are closer to the HL test set.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Dataset"
            ],
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.05388"
    },
    "b6b58ef8f0b6ae57084314231e9341a0": {
        "title": "Towards Effective GenAI Multi-Agent Collaboration: Design and Evaluation for Enterprise Applications",
        "authors": [
            "Raphael Shu",
            "Nilaksh Das",
            "Michelle Yuan",
            "Monica Sunkara",
            "Yi Zhang"
        ],
        "date": "2024/12/06",
        "pdf": "http://arxiv.org/pdf/2412.05449",
        "abstract": "AI agents powered by large language models (LLMs) have shown strong capabilities in problem solving. Through combining many intelligent agents, multi-agent collaboration has emerged as a promising approach to tackle complex, multi-faceted problems that exceed the capabilities of single AI agents. However, designing the collaboration protocols and evaluating the effectiveness of these systems remains a significant challenge, especially for enterprise applications. This report addresses these challenges by presenting a comprehensive evaluation of coordination and routing capabilities in a novel multi-agent collaboration framework. We evaluate two key operational modes: (1) a coordination mode enabling complex task completion through parallel communication and payload referencing, and (2) a routing mode for efficient message forwarding between agents. We benchmark on a set of handcrafted scenarios from three enterprise domains, which are publicly released with the report. For coordination capabilities, we demonstrate the effectiveness of inter-agent communication and payload referencing mechanisms, achieving end-to-end goal success rates of 90%. Our analysis yields several key findings: multi-agent collaboration enhances goal success rates by up to 70% compared to single-agent approaches in our benchmarks; payload referencing improves performance on code-intensive tasks by 23%; latency can be substantially reduced with a routing mechanism that selectively bypasses agent orchestration. These findings offer valuable guidance for enterprise deployments of multi-agent systems and advance the development of scalable, efficient multi-agent collaboration frameworks.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.05449"
    },
    "c2bb0f14c5bed5bf1247089fada2cd13": {
        "title": "Cooperative SQL Generation for Segmented Databases By Using Multi-functional LLM Agents",
        "authors": [
            "Zhiguang Wu",
            "Fengbin Zhu",
            "Xuequn Shang",
            "Yupei Zhang",
            "Pan Zhou"
        ],
        "date": "2024/12/08",
        "pdf": "http://arxiv.org/pdf/2412.05850",
        "abstract": "Text-to-SQL task aims to automatically yield SQL queries according to user text questions. To address this problem, we propose a Cooperative SQL Generation framework based on Multi-functional Agents (CSMA) through information interaction among large language model (LLM) based agents who own part of the database schema seperately. Inspired by the collaboration in human teamwork, CSMA consists of three stages: 1) Question-related schema collection, 2) Question-corresponding SQL query generation, and 3) SQL query correctness check. In the first stage, agents analyze their respective schema and communicate with each other to collect the schema information relevant to the question. In the second stage, agents try to generate the corresponding SQL query for the question using the collected information. In the third stage, agents check if the SQL query is created correctly according to their known information. This interaction-based method makes the question-relevant part of database schema from each agent to be used for SQL generation and check. Experiments on the Spider and Bird benckmark demonstrate that CSMA achieves a high performance level comparable to the state-of-the-arts, meanwhile holding the private data in these individual agents.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.05850"
    },
    "1bb9320297e220cb23ce02c2976917e1": {
        "title": "Enhancing LLMs for Impression Generation in Radiology Reports through a Multi-Agent System",
        "authors": [
            "Fang Zeng",
            "Zhiliang Lyu",
            "Quanzheng Li",
            "Xiang Li"
        ],
        "date": "2024/12/06",
        "pdf": "http://arxiv.org/pdf/2412.06828",
        "abstract": "This study introduces &#34;RadCouncil,&#34; a multi-agent Large Language Model (LLM) framework designed to enhance the generation of impressions in radiology reports from the finding section. RadCouncil comprises three specialized agents: 1) a &#34;Retrieval&#34; Agent that identifies and retrieves similar reports from a vector database, 2) a &#34;Radiologist&#34; Agent that generates impressions based on the finding section of the given report plus the exemplar reports retrieved by the Retrieval Agent, and 3) a &#34;Reviewer&#34; Agent that evaluates the generated impressions and provides feedback. The performance of RadCouncil was evaluated using both quantitative metrics (BLEU, ROUGE, BERTScore) and qualitative criteria assessed by GPT-4, using chest X-ray as a case study. Experiment results show improvements in RadCouncil over the single-agent approach across multiple dimensions, including diagnostic accuracy, stylistic concordance, and clarity. This study highlights the potential of utilizing multiple interacting LLM agents, each with a dedicated task, to enhance performance in specialized medical tasks and the development of more robust and adaptable healthcare AI solutions.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.06828"
    },
    "adc3de2b4e27910593a8eee421b74c95": {
        "title": "My Words Imply Your Opinion: Reader Agent-Based Propagation Enhancement for Personalized Implicit Emotion Analysis",
        "authors": [
            "Jian Liao",
            "Yu Feng",
            "Yujin Zheng",
            "Jun Zhao",
            "Suge Wang",
            "Jianxing Zheng"
        ],
        "date": "2024/12/10",
        "pdf": "http://arxiv.org/pdf/2412.07367",
        "abstract": "The subtlety of emotional expressions makes implicit emotion analysis (IEA) particularly sensitive to user-specific characteristics. Current studies personalize emotion analysis by focusing on the author but neglect the impact of the intended reader on implicit emotional feedback. In this paper, we introduce Personalized IEA (PIEA) and present the RAPPIE model, which addresses subjective variability by incorporating reader feedback. In particular, (1) we create reader agents based on large language models to simulate reader feedback, overcoming the issue of ``spiral of silence effect&#39;&#39; and data incompleteness of real reader reaction. (2) We develop a role-aware multi-view graph learning to model the emotion interactive propagation process in scenarios with sparse reader information. (3) We construct two new PIEA datasets covering English and Chinese social media with detailed user metadata, addressing the text-centric limitation of existing datasets. Extensive experiments show that RAPPIE significantly outperforms state-of-the-art baselines, demonstrating the value of incorporating reader feedback in PIEA.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.07367"
    },
    "7d7e1f8c66ab4fe9fe9cdbd69fdef646": {
        "title": "SweetieChat: A Strategy-Enhanced Role-playing Framework for Diverse Scenarios Handling Emotional Support Agent",
        "authors": [
            "Jing Ye",
            "Lu Xiang",
            "Yaping Zhang",
            "Chengqing Zong"
        ],
        "date": "2024/12/11",
        "pdf": "http://arxiv.org/pdf/2412.08389",
        "abstract": "Large Language Models (LLMs) have demonstrated promising potential in providing empathetic support during interactions. However, their responses often become verbose or overly formulaic, failing to adequately address the diverse emotional support needs of real-world scenarios. To tackle this challenge, we propose an innovative strategy-enhanced role-playing framework, designed to simulate authentic emotional support conversations. Specifically, our approach unfolds in two steps: (1) Strategy-Enhanced Role-Playing Interactions, which involve three pivotal roles -- Seeker, Strategy Counselor, and Supporter -- engaging in diverse scenarios to emulate real-world interactions and promote a broader range of dialogues; and (2) Emotional Support Agent Training, achieved through fine-tuning LLMs using our specially constructed dataset. Within this framework, we develop the \\textbf{ServeForEmo} dataset, comprising an extensive collection of 3.7K+ multi-turn dialogues and 62.8K+ utterances. We further present \\textbf{SweetieChat}, an emotional support agent capable of handling diverse open-domain scenarios. Extensive experiments and human evaluations confirm the framework&#39;s effectiveness in enhancing emotional support, highlighting its unique ability to provide more nuanced and tailored assistance.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.08389"
    },
    "0bb3d72a14add5caa1036e49129ddcbd": {
        "title": "DiverseAgentEntropy: Quantifying Black-Box LLM Uncertainty through Diverse Perspectives and Multi-Agent Interaction",
        "authors": [
            "Yu Feng",
            "Phu Mon Htut",
            "Zheng Qi",
            "Wei Xiao",
            "Manuel Mager",
            "Nikolaos Pappas",
            "Kishaloy Halder",
            "Yang Li",
            "Yassine Benajiba",
            "Dan Roth"
        ],
        "date": "2024/12/12",
        "pdf": "http://arxiv.org/pdf/2412.09572",
        "abstract": "Quantifying the uncertainty in the factual parametric knowledge of Large Language Models (LLMs), especially in a black-box setting, poses a significant challenge. Existing methods, which gauge a model&#39;s uncertainty through evaluating self-consistency in responses to the original query, do not always capture true uncertainty. Models might respond consistently to the origin query with a wrong answer, yet respond correctly to varied questions from different perspectives about the same query, and vice versa. In this paper, we propose a novel method, DiverseAgentEntropy, for evaluating a model&#39;s uncertainty using multi-agent interaction under the assumption that if a model is certain, it should consistently recall the answer to the original query across a diverse collection of questions about the same original query. We further implement an abstention policy to withhold responses when uncertainty is high. Our method offers a more accurate prediction of the model&#39;s reliability and further detects hallucinations, outperforming other self-consistency-based methods. Additionally, it demonstrates that existing models often fail to consistently retrieve the correct answer to the same query under diverse varied questions even when knowing the correct answer.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.09572"
    },
    "075c11e012b608856882ad1855dbf963": {
        "title": "AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials",
        "authors": [
            "Yiheng Xu",
            "Dunjie Lu",
            "Zhennan Shen",
            "Junli Wang",
            "Zekun Wang",
            "Yuchen Mao",
            "Caiming Xiong",
            "Tao Yu"
        ],
        "date": "2024/12/12",
        "pdf": "http://arxiv.org/pdf/2412.09605",
        "abstract": "Graphical User Interface (GUI) agents hold great potential for automating complex tasks across diverse digital environments, from web applications to desktop software. However, the development of such agents is hindered by the lack of high-quality, multi-step trajectory data required for effective training. Existing approaches rely on expensive and labor-intensive human annotation, making them unsustainable at scale. To address this challenge, we propose AgentTrek, a scalable data synthesis pipeline that generates high-quality GUI agent trajectories by leveraging web tutorials. Our method automatically gathers tutorial-like texts from the internet, transforms them into task goals with step-by-step instructions, and employs a visual-language model agent to simulate their execution in a real digital environment. A VLM-based evaluator ensures the correctness of the generated trajectories. We demonstrate that training GUI agents with these synthesized trajectories significantly improves their grounding and planning performance over the current models. Moreover, our approach is more cost-efficient compared to traditional human annotation methods. This work underscores the potential of guided replay with web tutorials as a viable strategy for large-scale GUI agent training, paving the way for more capable and autonomous digital agents.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.09605"
    },
    "ea85de58905f4c411ad1d1f3f0ef0fe0": {
        "title": "AutoPatent: A Multi-Agent Framework for Automatic Patent Generation",
        "authors": [
            "Qiyao Wang",
            "Shiwen Ni",
            "Huaren Liu",
            "Shule Lu",
            "Guhong Chen",
            "Xi Feng",
            "Chi Wei",
            "Qiang Qu",
            "Hamid Alinejad-Rokny",
            "Yuan Lin",
            "Min Yang"
        ],
        "date": "2024/12/13",
        "pdf": "http://arxiv.org/pdf/2412.09796",
        "abstract": "As the capabilities of Large Language Models (LLMs) continue to advance, the field of patent processing has garnered increased attention within the natural language processing community. However, the majority of research has been concentrated on classification tasks, such as patent categorization and examination, or on short text generation tasks like patent summarization and patent quizzes. In this paper, we introduce a novel and practical task known as Draft2Patent, along with its corresponding D2P benchmark, which challenges LLMs to generate full-length patents averaging 17K tokens based on initial drafts. Patents present a significant challenge to LLMs due to their specialized nature, standardized terminology, and extensive length. We propose a multi-agent framework called AutoPatent which leverages the LLM-based planner agent, writer agents, and examiner agent with PGTree and RRAG to generate lengthy, intricate, and high-quality complete patent documents. The experimental results demonstrate that our AutoPatent framework significantly enhances the ability to generate comprehensive patents across various LLMs. Furthermore, we have discovered that patents generated solely with the AutoPatent framework based on the Qwen2.5-7B model outperform those produced by larger and more powerful LLMs, such as GPT-4o, Qwen2.5-72B, and LLAMA3.1-70B, in both objective metrics and human evaluations. We will make the data and code available upon acceptance at \\url{https://github.com/QiYao-Wang/AutoPatent}.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.09796"
    },
    "5a916988933948c7cb4b7800767c818f": {
        "title": "AutoPrep: Natural Language Question-Aware Data Preparation with a Multi-Agent Framework",
        "authors": [
            "Meihao Fan",
            "Ju Fan",
            "Nan Tang",
            "Lei Cao",
            "Guoliang Li",
            "Xiaoyong Du"
        ],
        "date": "2024/12/10",
        "pdf": "http://arxiv.org/pdf/2412.10422",
        "abstract": "Answering natural language (NL) questions about tables, known as Tabular Question Answering (TQA), is crucial because it allows users to quickly and efficiently extract meaningful insights from structured data, effectively bridging the gap between human language and machine-readable formats. Many of these tables are derived from web sources or real-world scenarios, which require meticulous data preparation (or data prep) to ensure accurate responses. However, preparing such tables for NL questions introduces new requirements that extend beyond traditional data preparation. This question-aware data preparation involves specific tasks such as column augmentation and filtering tailored to particular questions, as well as question-aware value normalization or conversion, highlighting the need for a more nuanced approach in this context. Because each of the above tasks is unique, a single model (or agent) may not perform effectively across all scenarios. In this paper, we propose AutoPrep, a large language model (LLM)-based multi-agent framework that leverages the strengths of multiple agents, each specialized in a certain type of data prep, ensuring more accurate and contextually relevant responses. Given an NL question over a table, AutoPrep performs data prep through three key components. Planner: Determines a logical plan, outlining a sequence of high-level operations. Programmer: Translates this logical plan into a physical plan by generating the corresponding low-level code. Executor: Executes the generated code to process the table. To support this multi-agent framework, we design a novel Chain-of-Clauses reasoning mechanism for high-level operation suggestion, and a tool-augmented method for low-level code generation.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.10422"
    },
    "f65bcf62bab1cfc4c55e74a3a4b69398": {
        "title": "NAT-NL2GQL: A Novel Multi-Agent Framework for Translating Natural Language to Graph Query Language",
        "authors": [
            "Yuanyuan Liang",
            "Tingyu Xie",
            "Gan Peng",
            "Zihao Huang",
            "Yunshi Lan",
            "Weining Qian"
        ],
        "date": "2024/12/11",
        "pdf": "http://arxiv.org/pdf/2412.10434",
        "abstract": "The emergence of Large Language Models (LLMs) has revolutionized many fields, not only traditional natural language processing (NLP) tasks. Recently, research on applying LLMs to the database field has been booming, and as a typical non-relational database, the use of LLMs in graph database research has naturally gained significant attention. Recent efforts have increasingly focused on leveraging LLMs to translate natural language into graph query language (NL2GQL). Although some progress has been made, these methods have clear limitations, such as their reliance on streamlined processes that often overlook the potential of LLMs to autonomously plan and collaborate with other LLMs in tackling complex NL2GQL challenges. To address this gap, we propose NAT-NL2GQL, a novel multi-agent framework for translating natural language to graph query language. Specifically, our framework consists of three synergistic agents: the Preprocessor agent, the Generator agent, and the Refiner agent. The Preprocessor agent manages data processing as context, including tasks such as name entity recognition, query rewriting, path linking, and the extraction of query-related schemas. The Generator agent is a fine-tuned LLM trained on NL-GQL data, responsible for generating corresponding GQL statements based on queries and their related schemas. The Refiner agent is tasked with refining the GQL or context using error information obtained from the GQL execution results. Given the scarcity of high-quality open-source NL2GQL datasets based on nGQL syntax, we developed StockGQL, a dataset constructed from a financial market graph database. It is available at: https://github.com/leonyuancode/StockGQL. Experimental results on the StockGQL and SpCQL datasets reveal that our method significantly outperforms baseline approaches, highlighting its potential for advancing NL2GQL research.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.10434"
    },
    "aee6c9bff46d3d4e2653733637b47085": {
        "title": "Cultural Palette: Pluralising Culture Alignment via Multi-agent Palette",
        "authors": [
            "Jiahao Yuan",
            "Zixiang Di",
            "Shangzixin Zhao",
            "Usman Naseem"
        ],
        "date": "2024/12/15",
        "pdf": "http://arxiv.org/pdf/2412.11167",
        "abstract": "Large language models (LLMs) face challenges in aligning with diverse cultural values despite their remarkable performance in generation, which stems from inherent monocultural biases and difficulties in capturing nuanced cultural semantics. Existing methods struggle to adapt to unkown culture after fine-tuning. Inspired by cultural geography across five continents, we propose Cultural Palette, a multi-agent framework that redefines cultural alignment as an adaptive &#34;color-blending&#34; process for country-specific adaptation. Our approach harnesses cultural geography across five continents (Africa, America, Asia, Europe, Oceania) through three key steps: First, we synthesize the Pentachromatic Cultural Palette Dataset using GPT-4o, refining continental-level dialogues with Hofstede cultural dimensions to establish foundational cultural representations. Second, five continent-level alignment agents form specialized cultural communities that generate region-specific draft responses. Third, a Meta Agent employs Cultural MoErges to dynamically blend these cultural &#34;colors&#34; through attention-gated parameter merging, akin to mixing pigments on a palette, resolving conflicts while preserving cultural nuances to produce the final culturally-aligned response. Extensive experiments across various countries demonstrate that Cultural Palette surpasses existing baselines in cultural alignment.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.11167"
    },
    "0884b1c3c1cac77e3383d815f7542aea": {
        "title": "Seeker: Towards Exception Safety Code Generation with Intermediate Language Agents Framework",
        "authors": [
            "Xuanming Zhang",
            "Yuxuan Chen",
            "Yiming Zheng",
            "Zhexin Zhang",
            "Yuan Yuan",
            "Minlie Huang"
        ],
        "date": "2024/12/16",
        "pdf": "http://arxiv.org/pdf/2412.11713",
        "abstract": "In real world software development, improper or missing exception handling can severely impact the robustness and reliability of code. Exception handling mechanisms require developers to detect, capture, and manage exceptions according to high standards, but many developers struggle with these tasks, leading to fragile code. This problem is particularly evident in open-source projects and impacts the overall quality of the software ecosystem. To address this challenge, we explore the use of large language models (LLMs) to improve exception handling in code. Through extensive analysis, we identify three key issues: Insensitive Detection of Fragile Code, Inaccurate Capture of Exception Block, and Distorted Handling Solution. These problems are widespread across real world repositories, suggesting that robust exception handling practices are often overlooked or mishandled. In response, we propose Seeker, a multi-agent framework inspired by expert developer strategies for exception handling. Seeker uses agents: Scanner, Detector, Predator, Ranker, and Handler to assist LLMs in detecting, capturing, and resolving exceptions more effectively. Our work is the first systematic study on leveraging LLMs to enhance exception handling practices in real development scenarios, providing valuable insights for future improvements in code reliability.",
        "code": "",
        "category": [
            [
                "Application",
                "Software Engineering"
            ],
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.11713"
    },
    "a66e4599af301a10d2795193ba0770b2": {
        "title": "LLMs Can Simulate Standardized Patients via Agent Coevolution",
        "authors": [
            "Zhuoyun Du",
            "Lujie Zheng",
            "Renjun Hu",
            "Yuyang Xu",
            "Xiawei Li",
            "Ying Sun",
            "Wei Chen",
            "Jian Wu",
            "Haolei Cai",
            "Haohao Ying"
        ],
        "date": "2024/12/16",
        "pdf": "http://arxiv.org/pdf/2412.11716",
        "abstract": "Training medical personnel using standardized patients (SPs) remains a complex challenge, requiring extensive domain expertise and role-specific practice. Most research on Large Language Model (LLM)-based simulated patients focuses on improving data retrieval accuracy or adjusting prompts through human feedback. However, this focus has overlooked the critical need for patient agents to learn a standardized presentation pattern that transforms data into human-like patient responses through unsupervised simulations. To address this gap, we propose EvoPatient, a novel simulated patient framework in which a patient agent and doctor agents simulate the diagnostic process through multi-turn dialogues, simultaneously gathering experience to improve the quality of both questions and answers, ultimately enabling human doctor training. Extensive experiments on various cases demonstrate that, by providing only overall SP requirements, our framework improves over existing reasoning methods by more than 10% in requirement alignment and better human preference, while achieving an optimal balance of resource consumption after evolving over 200 cases for 10 hours, with excellent generalizability. The code will be available at https://github.com/ZJUMAI/EvoPatient.",
        "code": "",
        "category": [
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.11716"
    },
    "bf7408224725506a2df315f91e160be5": {
        "title": "BioRAGent: A Retrieval-Augmented Generation System for Showcasing Generative Query Expansion and Domain-Specific Search for Scientific Q&amp;A",
        "authors": [
            "Samy Ateia",
            "Udo Kruschwitz"
        ],
        "date": "2024/12/16",
        "pdf": "http://arxiv.org/pdf/2412.12358",
        "abstract": "We present BioRAGent, an interactive web-based retrieval-augmented generation (RAG) system for biomedical question answering. The system uses large language models (LLMs) for query expansion, snippet extraction, and answer generation while maintaining transparency through citation links to the source documents and displaying generated queries for further editing. Building on our successful participation in the BioASQ 2024 challenge, we demonstrate how few-shot learning with LLMs can be effectively applied for a professional search setting. The system supports both direct short paragraph style responses and responses with inline citations. Our demo is available online, and the source code is publicly accessible through GitHub.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "RAG"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.12358"
    },
    "77157d08ddb68a22a5d46d06b0c6bc44": {
        "title": "RareAgents: Advancing Rare Disease Care through LLM-Empowered Multi-disciplinary Team",
        "authors": [
            "Xuanzhong Chen",
            "Ye Jin",
            "Xiaohao Mao",
            "Lun Wang",
            "Shuyang Zhang",
            "Ting Chen"
        ],
        "date": "2024/12/17",
        "pdf": "http://arxiv.org/pdf/2412.12475",
        "abstract": "Rare diseases, despite their low individual incidence, collectively impact around 300 million people worldwide due to the vast number of diseases. The involvement of multiple organs and systems, and the shortage of specialized doctors with relevant experience make diagnosing and treating rare diseases more challenging than common diseases. Recently, agents powered by large language models (LLMs) have demonstrated notable applications across various domains. In the medical field, some agent methods have outperformed direct prompts in question-answering tasks from medical examinations. However, current agent frameworks are not well-adapted to real-world clinical scenarios, especially those involving the complex demands of rare diseases. To bridge this gap, we introduce RareAgents, the first LLM-driven multi-disciplinary team framework designed specifically for the complex clinical context of rare diseases. RareAgents integrates advanced Multidisciplinary Team (MDT) coordination, memory mechanisms, and medical tools utilization, leveraging Llama-3.1-8B/70B as the base model. Experimental results show that RareAgents outperforms state-of-the-art domain-specific models, GPT-4o, and current agent frameworks in differential diagnosis and medication recommendation for rare diseases. Furthermore, we contribute a novel rare disease dataset, MIMIC-IV-Ext-Rare, to support further advancements in this field.",
        "code": "",
        "category": [
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.12475"
    },
    "540b1f1ecfba1aac20ef4b77300ba3db": {
        "title": "TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks",
        "authors": [
            "Frank F. Xu",
            "Yufan Song",
            "Boxuan Li",
            "Yuxuan Tang",
            "Kritanjali Jain",
            "Mengxue Bao",
            "Zora Z. Wang",
            "Xuhui Zhou",
            "Zhitong Guo",
            "Murong Cao",
            "Mingyang Yang",
            "Hao Yang Lu",
            "Amaad Martin",
            "Zhe Su",
            "Leander Maben",
            "Raj Mehta",
            "Wayne Chi",
            "Lawrence Jang",
            "Yiqing Xie",
            "Shuyan Zhou",
            "Graham Neubig"
        ],
        "date": "2024/12/18",
        "pdf": "http://arxiv.org/pdf/2412.14161",
        "abstract": "We interact with computers on an everyday basis, be it in everyday life or work, and many aspects of work can be done entirely with access to a computer and the Internet. At the same time, thanks to improvements in large language models (LLMs), there has also been a rapid development in AI agents that interact with and affect change in their surrounding environments. But how performant are AI agents at helping to accelerate or even autonomously perform work-related tasks? The answer to this question has important implications for both industry looking to adopt AI into their workflows, and for economic policy to understand the effects that adoption of AI may have on the labor market. To measure the progress of these LLM agents&#39; performance on performing real-world professional tasks, in this paper, we introduce TheAgentCompany, an extensible benchmark for evaluating AI agents that interact with the world in similar ways to those of a digital worker: by browsing the Web, writing code, running programs, and communicating with other coworkers. We build a self-contained environment with internal web sites and data that mimics a small software company environment, and create a variety of tasks that may be performed by workers in such a company. We test baseline agents powered by both closed API-based and open-weights language models (LMs), and find that with the most competitive agent, 24% of the tasks can be completed autonomously. This paints a nuanced picture on task automation with LM agents -- in a setting simulating a real workplace, a good portion of simpler tasks could be solved autonomously, but more difficult long-horizon tasks are still beyond the reach of current systems.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.14161"
    },
    "7d1326f017c93528b6c386dc968c16ff": {
        "title": "Agent-SafetyBench: Evaluating the Safety of LLM Agents",
        "authors": [
            "Zhexin Zhang",
            "Shiyao Cui",
            "Yida Lu",
            "Jingzhuo Zhou",
            "Junxiao Yang",
            "Hongning Wang",
            "Minlie Huang"
        ],
        "date": "2024/12/19",
        "pdf": "http://arxiv.org/pdf/2412.14470",
        "abstract": "As large language models (LLMs) are increasingly deployed as agents, their integration into interactive environments and tool use introduce new safety challenges beyond those associated with the models themselves. However, the absence of comprehensive benchmarks for evaluating agent safety presents a significant barrier to effective assessment and further improvement. In this paper, we introduce Agent-SafetyBench, a comprehensive benchmark designed to evaluate the safety of LLM agents. Agent-SafetyBench encompasses 349 interaction environments and 2,000 test cases, evaluating 8 categories of safety risks and covering 10 common failure modes frequently encountered in unsafe interactions. Our evaluation of 16 popular LLM agents reveals a concerning result: none of the agents achieves a safety score above 60%. This highlights significant safety challenges in LLM agents and underscores the considerable need for improvement. Through quantitative analysis, we identify critical failure modes and summarize two fundamental safety detects in current LLM agents: lack of robustness and lack of risk awareness. Furthermore, our findings suggest that reliance on defense prompts alone is insufficient to address these safety issues, emphasizing the need for more advanced and robust strategies. We release Agent-SafetyBench at \\url{https://github.com/thu-coai/Agent-SafetyBench} to facilitate further research and innovation in agent safety evaluation and improvement.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.14470"
    },
    "2bed9a58ad1c38df3594d8352b225072": {
        "title": "PsyDraw: A Multi-Agent Multimodal System for Mental Health Screening in Left-Behind Children",
        "authors": [
            "Yiqun Zhang",
            "Xiaocui Yang",
            "Xiaobai Li",
            "Siyuan Yu",
            "Yi Luan",
            "Shi Feng",
            "Daling Wang",
            "Yifei Zhang"
        ],
        "date": "2024/12/19",
        "pdf": "http://arxiv.org/pdf/2412.14769",
        "abstract": "Left-behind children (LBCs), numbering over 66 million in China, face severe mental health challenges due to parental migration for work. Early screening and identification of at-risk LBCs is crucial, yet challenging due to the severe shortage of mental health professionals, especially in rural areas. While the House-Tree-Person (HTP) test shows higher child participation rates, its requirement for expert interpretation limits its application in resource-scarce regions. To address this challenge, we propose PsyDraw, a multi-agent system based on Multimodal Large Language Models that assists mental health professionals in analyzing HTP drawings. The system employs specialized agents for feature extraction and psychological interpretation, operating in two stages: comprehensive feature analysis and professional report generation. Evaluation of HTP drawings from 290 primary school students reveals that 71.03% of the analyzes achieved High Consistency with professional evaluations, 26.21% Moderate Consistency and only 2.41% Low Consistency. The system identified 31.03% of cases requiring professional attention, demonstrating its effectiveness as a preliminary screening tool. Currently deployed in pilot schools, \\method shows promise in supporting mental health professionals, particularly in resource-limited areas, while maintaining high professional standards in psychological assessment.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.14769"
    },
    "d7e1695bd346f2a520098dd1df058b8b": {
        "title": "Script-Based Dialog Policy Planning for LLM-Powered Conversational Agents: A Basic Architecture for an &#34;AI Therapist&#34;",
        "authors": [
            "Robert WasenmÃ¼ller",
            "Kevin Hilbert",
            "Christoph BenzmÃ¼ller"
        ],
        "date": "2024/12/13",
        "pdf": "http://arxiv.org/pdf/2412.15242",
        "abstract": "Large Language Model (LLM)-Powered Conversational Agents have the potential to provide users with scaled behavioral healthcare support, and potentially even deliver full-scale &#34;AI therapy&#39;&#34; in the future. While such agents can already conduct fluent and proactive emotional support conversations, they inherently lack the ability to (a) consistently and reliably act by predefined rules to align their conversation with an overarching therapeutic concept and (b) make their decision paths inspectable for risk management and clinical evaluation -- both essential requirements for an &#34;AI Therapist&#34;. In this work, we introduce a novel paradigm for dialog policy planning in conversational agents enabling them to (a) act according to an expert-written &#34;script&#34; that outlines the therapeutic approach and (b) explicitly transition through a finite set of states over the course of the conversation. The script acts as a deterministic component, constraining the LLM&#39;s behavior in desirable ways and establishing a basic architecture for an AI Therapist. We implement two variants of Script-Based Dialog Policy Planning using different prompting techniques and synthesize a total of 100 conversations with LLM-simulated patients. The results demonstrate the feasibility of this new technology and provide insights into the efficiency and effectiveness of different implementation variants.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ],
            [
                "Application",
                "Medicine"
            ],
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.15242"
    },
    "43c9252ebf3ff086196393a0bee5bcc3": {
        "title": "AgentPS: Agentic Process Supervision for Multi-modal Content Quality Assurance through Multi-round QA",
        "authors": [
            "Gorden Liu",
            "Yu Sun",
            "Ruixiao Sun",
            "Xin Dong",
            "Hongyu Xiong"
        ],
        "date": "2024/12/15",
        "pdf": "http://arxiv.org/pdf/2412.15251",
        "abstract": "The advanced processing and reasoning capabilities of multimodal large language models (MLLMs) have driven substantial progress in vision-language (VL) understanding tasks. However, while effective for tasks governed by straightforward logic, MLLMs often encounter challenges when reasoning over complex, interdependent logic structures. To address this limitation, we introduce \\textit{AgentPS}, a novel framework that integrates Agentic Process Supervision into MLLMs via multi-round question answering during fine-tuning. \\textit{AgentPS} demonstrates significant performance improvements over baseline MLLMs on proprietary TikTok datasets, due to its integration of process supervision and structured sequential reasoning. Furthermore, we show that replacing human-annotated labels with LLM-generated labels retains much of the performance gain, highlighting the framework&#39;s practical scalability in industrial applications. These results position \\textit{AgentPS} as a highly effective and efficient architecture for multimodal classification tasks. Its adaptability and scalability, especially when enhanced by automated annotation generation, make it a powerful tool for handling large-scale, real-world challenges.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.15251"
    },
    "1b70ab5ae6de29fbb4a31a56cb416478": {
        "title": "On the Structural Memory of LLM Agents",
        "authors": [
            "Ruihong Zeng",
            "Jinyuan Fang",
            "Siwei Liu",
            "Zaiqiao Meng"
        ],
        "date": "2024/12/17",
        "pdf": "http://arxiv.org/pdf/2412.15266",
        "abstract": "Memory plays a pivotal role in enabling large language model~(LLM)-based agents to engage in complex and long-term interactions, such as question answering (QA) and dialogue systems. While various memory modules have been proposed for these tasks, the impact of different memory structures across tasks remains insufficiently explored. This paper investigates how memory structures and memory retrieval methods affect the performance of LLM-based agents. Specifically, we evaluate four types of memory structures, including chunks, knowledge triples, atomic facts, and summaries, along with mixed memory that combines these components. In addition, we evaluate three widely used memory retrieval methods: single-step retrieval, reranking, and iterative retrieval. Extensive experiments conducted across four tasks and six datasets yield the following key insights: (1) Different memory structures offer distinct advantages, enabling them to be tailored to specific tasks; (2) Mixed memory structures demonstrate remarkable resilience in noisy environments; (3) Iterative retrieval consistently outperforms other methods across various scenarios. Our investigation aims to inspire further research into the design of memory systems for LLM-based agents.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Memory Mechanism"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.15266"
    },
    "6e87a96eaa1f7f026dab5edbba1c6cdd": {
        "title": "Memory-Augmented Agent Training for Business Document Understanding",
        "authors": [
            "Jiale Liu",
            "Yifan Zeng",
            "Malte HÃ¸jmark-Bertelsen",
            "Marie Normann Gadeberg",
            "Huazheng Wang",
            "Qingyun Wu"
        ],
        "date": "2024/12/17",
        "pdf": "http://arxiv.org/pdf/2412.15274",
        "abstract": "Traditional enterprises face significant challenges in processing business documents, where tasks like extracting transport references from invoices remain largely manual despite their crucial role in logistics operations. While Large Language Models offer potential automation, their direct application to specialized business domains often yields unsatisfactory results. We introduce Matrix (Memory-Augmented agent Training through Reasoning and Iterative eXploration), a novel paradigm that enables LLM agents to progressively build domain expertise through experience-driven memory refinement and iterative learning. To validate this approach, we collaborate with one of the world&#39;s largest logistics companies to create a dataset of Universal Business Language format invoice documents, focusing on the task of transport reference extraction. Experiments demonstrate that Matrix outperforms prompting a single LLM by 30.3%, vanilla LLM agent by 35.2%. We further analyze the metrics of the optimized systems and observe that the agent system requires less API calls, fewer costs and can analyze longer documents on average. Our methods establish a new approach to transform general-purpose LLMs into specialized business tools through systematic memory enhancement in document processing tasks.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Memory Mechanism"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.15274"
    },
    "894e74a987dbf8d9f0b3777c15186c60": {
        "title": "Mitigating Social Bias in Large Language Models: A Multi-Objective Approach within a Multi-Agent Framework",
        "authors": [
            "Zhenjie Xu",
            "Wenqing Chen",
            "Yi Tang",
            "Xuanying Li",
            "Cheng Hu",
            "Zhixuan Chu",
            "Kui Ren",
            "Zibin Zheng",
            "Zhichao Lu"
        ],
        "date": "2024/12/20",
        "pdf": "http://arxiv.org/pdf/2412.15504",
        "abstract": "Natural language processing (NLP) has seen remarkable advancements with the development of large language models (LLMs). Despite these advancements, LLMs often produce socially biased outputs. Recent studies have mainly addressed this problem by prompting LLMs to behave ethically, but this approach results in unacceptable performance degradation. In this paper, we propose a multi-objective approach within a multi-agent framework (MOMA) to mitigate social bias in LLMs without significantly compromising their performance. The key idea of MOMA involves deploying multiple agents to perform causal interventions on bias-related contents of the input questions, breaking the shortcut connection between these contents and the corresponding answers. Unlike traditional debiasing techniques leading to performance degradation, MOMA substantially reduces bias while maintaining accuracy in downstream tasks. Our experiments conducted on two datasets and two models demonstrate that MOMA reduces bias scores by up to 87.7%, with only a marginal performance degradation of up to 6.8% in the BBQ dataset. Additionally, it significantly enhances the multi-objective metric icat in the StereoSet dataset by up to 58.1%. Code will be made available at https://github.com/Cortantse/MOMA.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Stability",
                "Bias"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.15504"
    },
    "17aff96bdca1c01192c34ef84ab954b5": {
        "title": "InfoTech Assistant : A Multimodal Conversational Agent for InfoTechnology Web Portal Queries",
        "authors": [
            "Sai Surya Gadiraju",
            "Duoduo Liao",
            "Akhila Kudupudi",
            "Santosh Kasula",
            "Charitha Chalasani"
        ],
        "date": "2024/12/21",
        "pdf": "http://arxiv.org/pdf/2412.16412",
        "abstract": "This pilot study presents the development of the InfoTech Assistant, a domain-specific, multimodal chatbot engineered to address queries in bridge evaluation and infrastructure technology. By integrating web data scraping, large language models (LLMs), and Retrieval-Augmented Generation (RAG), the InfoTech Assistant provides accurate and contextually relevant responses. Data, including textual descriptions and images, are sourced from publicly available documents on the InfoTechnology website and organized in JSON format to facilitate efficient querying. The architecture of the system includes an HTML-based interface and a Flask back end connected to the Llama 3.1 model via LLM Studio. Evaluation results show approximately 95 percent accuracy on domain-specific tasks, with high similarity scores confirming the quality of response matching. This RAG-enhanced setup enables the InfoTech Assistant to handle complex, multimodal queries, offering both textual and visual information in its responses. The InfoTech Assistant demonstrates strong potential as a dependable tool for infrastructure professionals, delivering high accuracy and relevance in its domain-specific outputs.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ],
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.16412"
    },
    "e8decf58c5c37ba6942bd4c3ba495204": {
        "title": "Multi-Agent Sampling: Scaling Inference Compute for Data Synthesis with Tree Search-Based Agentic Collaboration",
        "authors": [
            "Hai Ye",
            "Mingbao Lin",
            "Hwee Tou Ng",
            "Shuicheng Yan"
        ],
        "date": "2024/12/22",
        "pdf": "http://arxiv.org/pdf/2412.17061",
        "abstract": "Scaling laws for inference compute in multi-agent systems remain under-explored compared to single-agent scenarios. This work aims to bridge this gap by investigating the problem of data synthesis through multi-agent sampling, where synthetic responses are generated by sampling from multiple distinct language models. Effective model coordination is crucial for successful multi-agent collaboration. Unlike previous approaches that rely on fixed workflows, we treat model coordination as a multi-step decision-making process, optimizing generation structures dynamically for each input question. We introduce Tree Search-based Orchestrated Agents~(TOA), where the workflow evolves iteratively during the sequential sampling process. To achieve this, we leverage Monte Carlo Tree Search (MCTS), integrating a reward model to provide real-time feedback and accelerate exploration. Our experiments on alignment, machine translation, and mathematical reasoning demonstrate that multi-agent sampling significantly outperforms single-agent sampling as inference compute scales. TOA is the most compute-efficient approach, achieving SOTA performance on WMT and a 71.8\\% LC win rate on AlpacaEval. Moreover, fine-tuning with our synthesized alignment data surpasses strong preference learning methods on challenging benchmarks such as Arena-Hard and AlpacaEval.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Technique For Enhancement",
                "Search"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.17061"
    },
    "5c204e7c8f5e4ecf34c1c357f3ef4f87": {
        "title": "A Multi-AI Agent System for Autonomous Optimization of Agentic AI Solutions via Iterative Refinement and LLM-Driven Feedback Loops",
        "authors": [
            "Kamer Ali Yuksel",
            "Hassan Sawaf"
        ],
        "date": "2024/12/22",
        "pdf": "http://arxiv.org/pdf/2412.17149",
        "abstract": "Agentic AI systems use specialized agents to handle tasks within complex workflows, enabling automation and efficiency. However, optimizing these systems often requires labor-intensive, manual adjustments to refine roles, tasks, and interactions. This paper introduces a framework for autonomously optimizing Agentic AI solutions across industries, such as NLP-driven enterprise applications. The system employs agents for Refinement, Execution, Evaluation, Modification, and Documentation, leveraging iterative feedback loops powered by an LLM (Llama 3.2-3B). The framework achieves optimal performance without human input by autonomously generating and testing hypotheses to improve system configurations. This approach enhances scalability and adaptability, offering a robust solution for real-world applications in dynamic environments. Case studies across diverse domains illustrate the transformative impact of this framework, showcasing significant improvements in output quality, relevance, and actionability. All data for these case studies, including original and evolved agent codes, along with their outputs, are here: https://anonymous.4open.science/r/evolver-1D11/",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.17149"
    },
    "3e6ade87b8f70c63658ac5d9ba55363e": {
        "title": "LegalAgentBench: Evaluating LLM Agents in Legal Domain",
        "authors": [
            "Haitao Li",
            "Junjie Chen",
            "Jingli Yang",
            "Qingyao Ai",
            "Wei Jia",
            "Youfeng Liu",
            "Kai Lin",
            "Yueyue Wu",
            "Guozhi Yuan",
            "Yiran Hu",
            "Wuyue Wang",
            "Yiqun Liu",
            "Minlie Huang"
        ],
        "date": "2024/12/23",
        "pdf": "http://arxiv.org/pdf/2412.17259",
        "abstract": "With the increasing intelligence and autonomy of LLM agents, their potential applications in the legal domain are becoming increasingly apparent. However, existing general-domain benchmarks cannot fully capture the complexity and subtle nuances of real-world judicial cognition and decision-making. Therefore, we propose LegalAgentBench, a comprehensive benchmark specifically designed to evaluate LLM Agents in the Chinese legal domain. LegalAgentBench includes 17 corpora from real-world legal scenarios and provides 37 tools for interacting with external knowledge. We designed a scalable task construction framework and carefully annotated 300 tasks. These tasks span various types, including multi-hop reasoning and writing, and range across different difficulty levels, effectively reflecting the complexity of real-world legal scenarios. Moreover, beyond evaluating final success, LegalAgentBench incorporates keyword analysis during intermediate processes to calculate progress rates, enabling more fine-grained evaluation. We evaluated eight popular LLMs, highlighting the strengths, limitations, and potential areas for improvement of existing models and methods. LegalAgentBench sets a new benchmark for the practical application of LLMs in the legal domain, with its code and data available at \\url{https://github.com/CSHaitao/LegalAgentBench}.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.17259"
    },
    "d7aaf3c343495594bc6e0f238176d165": {
        "title": "A Survey on LLM-based Multi-Agent System: Recent Advances and New Frontiers in Application",
        "authors": [
            "Shuaihang Chen",
            "Yuanxing Liu",
            "Wei Han",
            "Weinan Zhang",
            "Ting Liu"
        ],
        "date": "2024/12/23",
        "pdf": "http://arxiv.org/pdf/2412.17481",
        "abstract": "LLM-based Multi-Agent Systems ( LLM-MAS ) have become a research hotspot since the rise of large language models (LLMs). However, with the continuous influx of new related works, the existing reviews struggle to capture them comprehensively. This paper presents a comprehensive survey of these studies. We first discuss the definition of LLM-MAS, a framework encompassing much of previous work. We provide an overview of the various applications of LLM-MAS in (i) solving complex tasks, (ii) simulating specific scenarios, and (iii) evaluating generative agents. Building on previous studies, we also highlight several challenges and propose future directions for research in this field.",
        "code": "",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2412.17481"
    },
    "88fc2613f4ee0dbabb531a4f9b653b64": {
        "title": "Molly: Making Large Language Model Agents Solve Python Problem More Logically",
        "authors": [
            "Rui Xiao",
            "Jiong Wang",
            "Lu Han",
            "Na Zong",
            "Han Wu"
        ],
        "date": "2024/12/24",
        "pdf": "http://arxiv.org/pdf/2412.18093",
        "abstract": "Applying large language models (LLMs) as teaching assists has attracted much attention as an integral part of intelligent education, particularly in computing courses. To reduce the gap between the LLMs and the computer programming education expert, fine-tuning and retrieval augmented generation (RAG) are the two mainstream methods in existing researches. However, fine-tuning for specific tasks is resource-intensive and may diminish the model`s generalization capabilities. RAG can perform well on reducing the illusion of LLMs, but the generation of irrelevant factual content during reasoning can cause significant confusion for learners. To address these problems, we introduce the Molly agent, focusing on solving the proposed problem encountered by learners when learning Python programming language. Our agent automatically parse the learners&#39; questioning intent through a scenario-based interaction, enabling precise retrieval of relevant documents from the constructed knowledge base. At generation stage, the agent reflect on the generated responses to ensure that they not only align with factual content but also effectively answer the user&#39;s queries. Extensive experimentation on a constructed Chinese Python QA dataset shows the effectiveness of the Molly agent, indicating an enhancement in its performance for providing useful responses to Python questions.",
        "code": "",
        "category": [
            [
                "Application",
                "Software Engineering"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.18093"
    },
    "e2878976df938d993e2d40ee40aeabd7": {
        "title": "Multi-Agents Based on Large Language Models for Knowledge-based Visual Question Answering",
        "authors": [
            "Zhongjian Hu",
            "Peng Yang",
            "Bing Li",
            "Zhenqi Wang"
        ],
        "date": "2024/12/24",
        "pdf": "http://arxiv.org/pdf/2412.18351",
        "abstract": "Large Language Models (LLMs) have achieved impressive results in knowledge-based Visual Question Answering (VQA). However existing methods still have challenges: the inability to use external tools autonomously, and the inability to work in teams. Humans tend to know whether they need to use external tools when they encounter a new question, e.g., they tend to be able to give a direct answer to a familiar question, whereas they tend to use tools such as search engines when they encounter an unfamiliar question. In addition, humans also tend to collaborate and discuss with others to get better answers. Inspired by this, we propose the multi-agent voting framework. We design three LLM-based agents that simulate different levels of staff in a team, and assign the available tools according to the levels. Each agent provides the corresponding answer, and finally all the answers provided by the agents are voted to get the final answer. Experiments on OK-VQA and A-OKVQA show that our approach outperforms other baselines by 2.2 and 1.0, respectively.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.18351"
    },
    "18902d5ef448103ef142866d8f4852d6": {
        "title": "Extracting triples from dialogues for conversational social agents",
        "authors": [
            "Piek Vossen",
            "Selene BÃ¡ez SantamarÃ­a",
            "Lenka BajÄetiÄ",
            "Thomas Belluci"
        ],
        "date": "2024/12/24",
        "pdf": "http://arxiv.org/pdf/2412.18364",
        "abstract": "Obtaining an explicit understanding of communication within a Hybrid Intelligence collaboration is essential to create controllable and transparent agents. In this paper, we describe a number of Natural Language Understanding models that extract explicit symbolic triples from social conversation. Triple extraction has mostly been developed and tested for Knowledge Base Completion using Wikipedia text and data for training and testing. However, social conversation is very different as a genre in which interlocutors exchange information in sequences of utterances that involve statements, questions, and answers. Phenomena such as co-reference, ellipsis, coordination, and implicit and explicit negation or confirmation are more prominent in conversation than in Wikipedia text. We therefore describe an attempt to fill this gap by releasing data sets for training and testing triple extraction from social conversation. We also created five triple extraction models and tested them in our evaluation data. The highest precision is 51.14 for complete triples and 69.32 for triple elements when tested on single utterances. However, scores for conversational triples that span multiple turns are much lower, showing that extracting knowledge from true conversational data is much more challenging.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.18364"
    },
    "f0956c83100182ea18e1018102f6f9b9": {
        "title": "GeAR: Graph-enhanced Agent for Retrieval-augmented Generation",
        "authors": [
            "Zhili Shen",
            "Chenxin Diao",
            "Pavlos Vougiouklis",
            "Pascual Merita",
            "Shriram Piramanayagam",
            "Damien Graux",
            "Dandan Tu",
            "Zeren Jiang",
            "Ruofei Lai",
            "Yang Ren",
            "Jeff Z. Pan"
        ],
        "date": "2024/12/24",
        "pdf": "http://arxiv.org/pdf/2412.18431",
        "abstract": "Retrieval-augmented generation systems rely on effective document retrieval capabilities. By design, conventional sparse or dense retrievers face challenges in multi-hop retrieval scenarios. In this paper, we present GeAR, which advances RAG performance through two key innovations: (i) graph expansion, which enhances any conventional base retriever, such as BM25, and (ii) an agent framework that incorporates graph expansion. Our evaluation demonstrates GeAR&#39;s superior retrieval performance on three multi-hop question answering datasets. Additionally, our system achieves state-of-the-art results with improvements exceeding 10% on the challenging MuSiQue dataset, while requiring fewer tokens and iterations compared to other multi-step retrieval systems.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "RAG"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.18431"
    },
    "02fe8dc3b149fd328f733494727403a8": {
        "title": "OneKE: A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction System",
        "authors": [
            "Yujie Luo",
            "Xiangyuan Ru",
            "Kangwei Liu",
            "Lin Yuan",
            "Mengshu Sun",
            "Ningyu Zhang",
            "Lei Liang",
            "Zhiqiang Zhang",
            "Jun Zhou",
            "Lanning Wei",
            "Da Zheng",
            "Haofen Wang",
            "Huajun Chen"
        ],
        "date": "2024/12/28",
        "pdf": "http://arxiv.org/pdf/2412.20005",
        "abstract": "We introduce OneKE, a dockerized schema-guided knowledge extraction system, which can extract knowledge from the Web and raw PDF Books, and support various domains (science, news, etc.). Specifically, we design OneKE with multiple agents and a configure knowledge base. Different agents perform their respective roles, enabling support for various extraction scenarios. The configure knowledge base facilitates schema configuration, error case debugging and correction, further improving the performance. Empirical evaluations on benchmark datasets demonstrate OneKE&#39;s efficacy, while case studies further elucidate its adaptability to diverse tasks across multiple domains, highlighting its potential for broad applications. We have open-sourced the Code at https://github.com/zjunlp/OneKE and released a Video at http://oneke.openkg.cn/demo.mp4.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.20005"
    },
    "da0f39d1e9adc5eef95847cc7e91fd70": {
        "title": "M-MAD: Multidimensional Multi-Agent Debate for Advanced Machine Translation Evaluation",
        "authors": [
            "Zhaopeng Feng",
            "Jiayuan Su",
            "Jiamei Zheng",
            "Jiahan Ren",
            "Yan Zhang",
            "Jian Wu",
            "Hongwei Wang",
            "Zuozhu Liu"
        ],
        "date": "2024/12/28",
        "pdf": "http://arxiv.org/pdf/2412.20127",
        "abstract": "Recent advancements in large language models (LLMs) have given rise to the LLM-as-a-judge paradigm, showcasing their potential to deliver human-like judgments. However, in the field of machine translation (MT) evaluation, current LLM-as-a-judge methods fall short of learned automatic metrics. In this paper, we propose Multidimensional Multi-Agent Debate (M-MAD), a systematic LLM-based multi-agent framework for advanced LLM-as-a-judge MT evaluation. Our findings demonstrate that M-MAD achieves significant advancements by (1) decoupling heuristic MQM criteria into distinct evaluation dimensions for fine-grained assessments; (2) employing multi-agent debates to harness the collaborative reasoning capabilities of LLMs; (3) synthesizing dimension-specific results into a final evaluation judgment to ensure robust and reliable outcomes. Comprehensive experiments show that M-MAD not only outperforms all existing LLM-as-a-judge methods but also competes with state-of-the-art reference-based automatic metrics, even when powered by a suboptimal model like GPT-4o mini. Detailed ablations and analysis highlight the superiority of our framework design, offering a fresh perspective for LLM-as-a-judge paradigm. Our code and data are publicly available at https://github.com/SU-JIAYUAN/M-MAD.",
        "code": "",
        "category": [
            [
                "Automation",
                "Automatic Evaluation"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.20127"
    },
    "09362cdf722ab80b8e56a9027ea2a57a": {
        "title": "Efficient Multi-Agent Collaboration with Tool Use for Online Planning in Complex Table Question Answering",
        "authors": [
            "Wei Zhou",
            "Mohsen Mesgar",
            "Annemarie Friedrich",
            "Heike Adel"
        ],
        "date": "2024/12/28",
        "pdf": "http://arxiv.org/pdf/2412.20145",
        "abstract": "Complex table question answering (TQA) aims to answer questions that require complex reasoning, such as multi-step or multi-category reasoning, over data represented in tabular form. Previous approaches demonstrated notable performance by leveraging either closed-source large language models (LLMs) or fine-tuned open-weight LLMs. However, fine-tuning LLMs requires high-quality training data, which is costly to obtain, and utilizing closed-source LLMs poses accessibility challenges and leads to reproducibility issues. In this paper, we propose Multi-Agent Collaboration with Tool use (MACT), a framework that requires neither closed-source models nor fine-tuning. In MACT, a planning agent and a coding agent that also make use of tools collaborate to answer questions. Our experiments on four TQA benchmarks show that MACT outperforms previous SoTA systems on three out of four benchmarks and that it performs comparably to the larger and more expensive closed-source model GPT-4 on two benchmarks, even when using only open-weight models without any fine-tuning. We conduct extensive analyses to prove the effectiveness of MACT&#39;s multi-agent collaboration in TQA.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Interaction",
                "Tool Usage"
            ],
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.20145"
    },
    "eafc8bcc8302944f3b60dc2941334f9a": {
        "title": "Plancraft: an evaluation dataset for planning with LLM agents",
        "authors": [
            "Gautier Dagan",
            "Frank Keller",
            "Alex Lascarides"
        ],
        "date": "2024/12/30",
        "pdf": "http://arxiv.org/pdf/2412.21033",
        "abstract": "We present Plancraft, a multi-modal evaluation dataset for LLM agents. Plancraft has both a text-only and multi-modal interface, based on the Minecraft crafting GUI. We include the Minecraft Wiki to evaluate tool use and Retrieval Augmented Generation (RAG), as well as an oracle planner and oracle RAG information extractor, to ablate the different components of a modern agent architecture. To evaluate decision-making, Plancraft also includes a subset of examples that are intentionally unsolvable, providing a realistic challenge that requires the agent not only to complete tasks but also to decide whether they are solvable at all. We benchmark both open-source and closed-source LLMs and strategies on our task and compare their performance to a handcrafted planner. We find that LLMs and VLMs struggle with the planning problems that Plancraft introduces, and we offer suggestions on how to improve their capabilities.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Dataset"
            ],
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.21033"
    },
    "faede4355f3428609679dad5191c22e6": {
        "title": "Exploring and Controlling Diversity in LLM-Agent Conversation",
        "authors": [
            "KuanChao Chu",
            "Yi-Pei Chen",
            "Hideki Nakayama"
        ],
        "date": "2024/12/30",
        "pdf": "http://arxiv.org/pdf/2412.21102",
        "abstract": "Diversity is a critical aspect of multi-agent communication. In this paper, we focus on controlling and exploring diversity in the context of open-domain multi-agent conversations, particularly for world simulation applications. We propose Adaptive Prompt Pruning (APP), a novel method that dynamically adjusts the content of the utterance generation prompt to control diversity using a single parameter, lambda. Through extensive experiments, we show that APP effectively controls the output diversity across models and datasets, with pruning more information leading to more diverse output. We comprehensively analyze the relationship between prompt content and conversational diversity. Our findings reveal that information from all components of the prompt generally constrains the diversity of the output, with the Memory block exerting the most significant influence. APP is compatible with established techniques like temperature sampling and top-p sampling, providing a versatile tool for diversity management. To address the trade-offs of increased diversity, such as inconsistencies with omitted information, we incorporate a post-generation correction step, which effectively balances diversity enhancement with output consistency. Additionally, we examine how prompt structure, including component order and length, impacts diversity. This study addresses key questions surrounding diversity in multi-agent world simulation, offering insights into its control, influencing factors, and associated trade-offs. Our contributions lay the foundation for systematically engineering diversity in LLM-based multi-agent collaborations, advancing their effectiveness in real-world applications.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.21102"
    },
    "b4adc96c1f418c0693444243d1e85ea2": {
        "title": "Examining Identity Drift in Conversations of LLM Agents",
        "authors": [
            "Junhyuk Choi",
            "Yeseon Hong",
            "Minju Kim",
            "Bugeun Kim"
        ],
        "date": "2024/12/01",
        "pdf": "http://arxiv.org/pdf/2412.00804",
        "abstract": "Large Language Models (LLMs) show impressive conversational abilities but sometimes show identity drift problems, where their interaction patterns or styles change over time. As the problem has not been thoroughly examined yet, this study examines identity consistency across nine LLMs. Specifically, we (1) investigate whether LLMs could maintain consistent patterns (or identity) and (2) analyze the effect of the model family, parameter sizes, and provided persona types. Our experiments involve multi-turn conversations on personal themes, analyzed in qualitative and quantitative ways. Experimental results indicate three findings. (1) Larger models experience greater identity drift. (2) Model differences exist, but their effect is not stronger than parameter sizes. (3) Assigning a persona may not help to maintain identity. We hope these three findings can help to improve persona stability in AI-driven dialogue systems, particularly in long-term conversations.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.00804"
    },
    "12abd906c98299b4c8db7c46343079ff": {
        "title": "Large Multimodal Agents for Accurate Phishing Detection with Enhanced Token Optimization and Cost Reduction",
        "authors": [
            "Fouad Trad",
            "Ali Chehab"
        ],
        "date": "2024/12/03",
        "pdf": "http://arxiv.org/pdf/2412.02301",
        "abstract": "With the rise of sophisticated phishing attacks, there is a growing need for effective and economical detection solutions. This paper explores the use of large multimodal agents, specifically Gemini 1.5 Flash and GPT-4o mini, to analyze both URLs and webpage screenshots via APIs, thus avoiding the complexities of training and maintaining AI systems. Our findings indicate that integrating these two data types substantially enhances detection performance over using either type alone. However, API usage incurs costs per query that depend on the number of input and output tokens. To address this, we propose a two-tiered agentic approach: initially, one agent assesses the URL, and if inconclusive, a second agent evaluates both the URL and the screenshot. This method not only maintains robust detection performance but also significantly reduces API costs by minimizing unnecessary multi-input queries. Cost analysis shows that with the agentic approach, GPT-4o mini can process about 4.2 times as many websites per $100 compared to the multimodal approach (107,440 vs. 25,626), and Gemini 1.5 Flash can process about 2.6 times more websites (2,232,142 vs. 862,068). These findings underscore the significant economic benefits of the agentic approach over the multimodal method, providing a viable solution for organizations aiming to leverage advanced AI for phishing detection while controlling expenses.",
        "code": "",
        "category": [
            [
                "Others",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2412.02301"
    },
    "be47ab034f6a0fc2b5fd6a41a747dfc3": {
        "title": "How to Correctly do Semantic Backpropagation on Language-based Agentic Systems",
        "authors": [
            "Wenyi Wang",
            "Hisham A. Alyahya",
            "Dylan R. Ashley",
            "Oleg Serikov",
            "Dmitrii Khizbullin",
            "Francesco Faccio",
            "JÃ¼rgen Schmidhuber"
        ],
        "date": "2024/12/04",
        "pdf": "http://arxiv.org/pdf/2412.03624",
        "abstract": "Language-based agentic systems have shown great promise in recent years, transitioning from solving small-scale research problems to being deployed in challenging real-world tasks. However, optimizing these systems often requires substantial manual labor. Recent studies have demonstrated that these systems can be represented as computational graphs, enabling automatic optimization. Despite these advancements, most current efforts in Graph-based Agentic System Optimization (GASO) fail to properly assign feedback to the system&#39;s components given feedback on the system&#39;s output. To address this challenge, we formalize the concept of semantic backpropagation with semantic gradients -- a generalization that aligns several key optimization techniques, including reverse-mode automatic differentiation and the more recent TextGrad by exploiting the relationship among nodes with a common successor. This serves as a method for computing directional information about how changes to each component of an agentic system might improve the system&#39;s output. To use these gradients, we propose a method called semantic gradient descent which enables us to solve GASO effectively. Our results on both BIG-Bench Hard and GSM8K show that our approach outperforms existing state-of-the-art methods for solving GASO problems. A detailed ablation study on the LIAR dataset demonstrates the parsimonious nature of our method. A full copy of our implementation is publicly available at https://github.com/HishamAlyahya/semantic_backprop",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.03624"
    },
    "96fe3b8cd6d35aedadedf8793d845c83": {
        "title": "TeamCraft: A Benchmark for Multi-Modal Multi-Agent Systems in Minecraft",
        "authors": [
            "Qian Long",
            "Zhi Li",
            "Ran Gong",
            "Ying Nian Wu",
            "Demetri Terzopoulos",
            "Xiaofeng Gao"
        ],
        "date": "2024/12/06",
        "pdf": "http://arxiv.org/pdf/2412.05255",
        "abstract": "Collaboration is a cornerstone of society. In the real world, human teammates make use of multi-sensory data to tackle challenging tasks in ever-changing environments. It is essential for embodied agents collaborating in visually-rich environments replete with dynamic interactions to understand multi-modal observations and task specifications. To evaluate the performance of generalizable multi-modal collaborative agents, we present TeamCraft, a multi-modal multi-agent benchmark built on top of the open-world video game Minecraft. The benchmark features 55,000 task variants specified by multi-modal prompts, procedurally-generated expert demonstrations for imitation learning, and carefully designed protocols to evaluate model generalization capabilities. We also perform extensive analyses to better understand the limitations and strengths of existing approaches. Our results indicate that existing models continue to face significant challenges in generalizing to novel goals, scenes, and unseen numbers of agents. These findings underscore the need for further research in this area. The TeamCraft platform and dataset are publicly available at https://github.com/teamcraft-bench/teamcraft.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Interaction",
                "Game Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.05255"
    },
    "603bb485bb75b20a239b2bfe33060f8f": {
        "title": "StarWhisper Telescope: Agent-Based Observation Assistant System to Approach AI Astrophysicist",
        "authors": [
            "Cunshi Wang",
            "Xinjie Hu",
            "Yu Zhang",
            "Xunhao Chen",
            "Pengliang Du",
            "Yiming Mao",
            "Rui Wang",
            "Yuyang Li",
            "Ying Wu",
            "Hang Yang",
            "Yansong Li",
            "Beichuan Wang",
            "Haiyang Mu",
            "Zheng Wang",
            "Jianfeng Tian",
            "Liang Ge",
            "Yongna Mao",
            "Shengming Li",
            "Xiaomeng Lu",
            "Jinhang Zou",
            "Yang Huang",
            "Ningchen Sun",
            "Jie Zheng",
            "Min He",
            "Yu Bai",
            "Junjie Jin",
            "Hong Wu",
            "Chaohui Shang",
            "Jifeng Liu"
        ],
        "date": "2024/12/09",
        "pdf": "http://arxiv.org/pdf/2412.06412",
        "abstract": "With the rapid advancements in Large Language Models (LLMs), LLM-based agents have introduced convenient and user-friendly methods for leveraging tools across various domains. In the field of astronomical observation, the construction of new telescopes has significantly increased astronomers&#39; workload. Deploying LLM-powered agents can effectively alleviate this burden and reduce the costs associated with training personnel. Within the Nearby Galaxy Supernovae Survey (NGSS) project, which encompasses eight telescopes across three observation sites, aiming to find the transients from the galaxies in 50 mpc, we have developed the \\textbf{StarWhisper Telescope System} to manage the entire observation process. This system automates tasks such as generating observation lists, conducting observations, analyzing data, and providing feedback to the observer. Observation lists are customized for different sites and strategies to ensure comprehensive coverage of celestial objects. After manual verification, these lists are uploaded to the telescopes via the agents in the system, which initiates observations upon neutral language. The observed images are analyzed in real-time, and the transients are promptly communicated to the observer. The agent modifies them into a real-time follow-up observation proposal and send to the Xinglong observatory group chat, then add them to the next-day observation lists. Additionally, the integration of AI agents within the system provides online accessibility, saving astronomers&#39; time and encouraging greater participation from amateur astronomers in the NGSS project.",
        "code": "",
        "category": [
            [
                "Application",
                "Physics"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.06412"
    },
    "1e1cbd3f01301ef6ca591f499760c755": {
        "title": "The Fusion of Large Language Models and Formal Methods for Trustworthy AI Agents: A Roadmap",
        "authors": [
            "Yedi Zhang",
            "Yufan Cai",
            "Xinyue Zuo",
            "Xiaokun Luan",
            "Kailong Wang",
            "Zhe Hou",
            "Yifan Zhang",
            "Zhiyuan Wei",
            "Meng Sun",
            "Jun Sun",
            "Jing Sun",
            "Jin Song Dong"
        ],
        "date": "2024/12/09",
        "pdf": "http://arxiv.org/pdf/2412.06512",
        "abstract": "Large Language Models (LLMs) have emerged as a transformative AI paradigm, profoundly influencing daily life through their exceptional language understanding and contextual generation capabilities. Despite their remarkable performance, LLMs face a critical challenge: the propensity to produce unreliable outputs due to the inherent limitations of their learning-based nature. Formal methods (FMs), on the other hand, are a well-established computation paradigm that provides mathematically rigorous techniques for modeling, specifying, and verifying the correctness of systems. FMs have been extensively applied in mission-critical software engineering, embedded systems, and cybersecurity. However, the primary challenge impeding the deployment of FMs in real-world settings lies in their steep learning curves, the absence of user-friendly interfaces, and issues with efficiency and adaptability. This position paper outlines a roadmap for advancing the next generation of trustworthy AI systems by leveraging the mutual enhancement of LLMs and FMs. First, we illustrate how FMs, including reasoning and certification techniques, can help LLMs generate more reliable and formally certified outputs. Subsequently, we highlight how the advanced learning capabilities and adaptability of LLMs can significantly enhance the usability, efficiency, and scalability of existing FM tools. Finally, we show that unifying these two computation paradigms -- integrating the flexibility and intelligence of LLMs with the rigorous reasoning abilities of FMs -- has transformative potential for the development of trustworthy AI software systems. We acknowledge that this integration has the potential to enhance both the trustworthiness and efficiency of software engineering practices while fostering the development of intelligent FM tools capable of addressing complex yet real-world challenges.",
        "code": "",
        "category": [
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.06512"
    },
    "bdb2ee0cec7dbbcbe945c7b2c71a41f0": {
        "title": "SLA Management in Reconfigurable Multi-Agent RAG: A Systems Approach to Question Answering",
        "authors": [
            "Michael Iannelli",
            "Sneha Kuchipudi",
            "Vera Dvorak"
        ],
        "date": "2024/12/07",
        "pdf": "http://arxiv.org/pdf/2412.06832",
        "abstract": "Retrieval Augmented Generation (RAG) enables Large Language Models (LLMs) to generalize to new information by decoupling reasoning capabilities from static knowledge bases. Traditional RAG enhancements have explored vertical scaling -- assigning subtasks to specialized modules -- and horizontal scaling -- replicating tasks across multiple agents -- to improve performance. However, real-world applications impose diverse Service Level Agreements (SLAs) and Quality of Service (QoS) requirements, involving trade-offs among objectives such as reducing cost, ensuring answer quality, and adhering to specific operational constraints. In this work, we present a systems-oriented approach to multi-agent RAG tailored for real-world Question Answering (QA) applications. By integrating task-specific non-functional requirements -- such as answer quality, cost, and latency -- into the system, we enable dynamic reconfiguration to meet diverse SLAs. Our method maps these Service Level Objectives (SLOs) to system-level parameters, allowing the generation of optimal results within specified resource constraints. We conduct a case study in the QA domain, demonstrating how dynamic re-orchestration of a multi-agent RAG system can effectively manage the trade-off between answer quality and cost. By adjusting the system based on query intent and operational conditions, we systematically balance performance and resource utilization. This approach allows the system to meet SLOs for various query types, showcasing its practicality for real-world applications.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "RAG"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.06832"
    },
    "3ed4efd6950b1fe02a847815fd576435": {
        "title": "Political Actor Agent: Simulating Legislative System for Roll Call Votes Prediction with Large Language Models",
        "authors": [
            "Hao Li",
            "Ruoyuan Gong",
            "Hao Jiang"
        ],
        "date": "2024/12/10",
        "pdf": "http://arxiv.org/pdf/2412.07144",
        "abstract": "Predicting roll call votes through modeling political actors has emerged as a focus in quantitative political science and computer science. Widely used embedding-based methods generate vectors for legislators from diverse data sets to predict legislative behaviors. However, these methods often contend with challenges such as the need for manually predefined features, reliance on extensive training data, and a lack of interpretability. Achieving more interpretable predictions under flexible conditions remains an unresolved issue. This paper introduces the Political Actor Agent (PAA), a novel agent-based framework that utilizes Large Language Models to overcome these limitations. By employing role-playing architectures and simulating legislative system, PAA provides a scalable and interpretable paradigm for predicting roll-call votes. Our approach not only enhances the accuracy of predictions but also offers multi-view, human-understandable decision reasoning, providing new insights into political actor behaviors. We conducted comprehensive experiments using voting records from the 117-118th U.S. House of Representatives, validating the superior performance and interpretability of PAA. This study not only demonstrates PAA&#39;s effectiveness but also its potential in political science research.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.07144"
    },
    "98d18bf101e43ada6020a86ba91e5363": {
        "title": "Federated In-Context LLM Agent Learning",
        "authors": [
            "Panlong Wu",
            "Kangshuo Li",
            "Junbao Nan",
            "Fangxin Wang"
        ],
        "date": "2024/12/11",
        "pdf": "http://arxiv.org/pdf/2412.08054",
        "abstract": "Large Language Models (LLMs) have revolutionized intelligent services by enabling logical reasoning, tool use, and interaction with external systems as agents. The advancement of LLMs is frequently hindered by the scarcity of high-quality data, much of which is inherently sensitive. Federated learning (FL) offers a potential solution by facilitating the collaborative training of distributed LLMs while safeguarding private data. However, FL frameworks face significant bandwidth and computational demands, along with challenges from heterogeneous data distributions. The emerging in-context learning capability of LLMs offers a promising approach by aggregating natural language rather than bulky model parameters. Yet, this method risks privacy leakage, as it necessitates the collection and presentation of data samples from various clients during aggregation. In this paper, we propose a novel privacy-preserving Federated In-Context LLM Agent Learning (FICAL) algorithm, which to our best knowledge for the first work unleashes the power of in-context learning to train diverse LLM agents through FL. In our design, knowledge compendiums generated by a novel LLM-enhanced Knowledge Compendiums Generation (KCG) module are transmitted between clients and the server instead of model parameters in previous FL methods. Apart from that, an incredible Retrieval Augmented Generation (RAG) based Tool Learning and Utilizing (TLU) module is designed and we incorporate the aggregated global knowledge compendium as a teacher to teach LLM agents the usage of tools. We conducted extensive experiments and the results show that FICAL has competitive performance compared to other SOTA baselines with a significant communication cost decrease of $\\mathbf{3.33\\times10^5}$ times.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.08054"
    },
    "fb0a50afa3e9f9dabefc33a74e2aa839": {
        "title": "Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models",
        "authors": [
            "Fan Zhang",
            "Shulin Tian",
            "Ziqi Huang",
            "Yu Qiao",
            "Ziwei Liu"
        ],
        "date": "2024/12/10",
        "pdf": "http://arxiv.org/pdf/2412.09645",
        "abstract": "Recent advancements in visual generative models have enabled high-quality image and video generation, opening diverse applications. However, evaluating these models often demands sampling hundreds or thousands of images or videos, making the process computationally expensive, especially for diffusion-based models with inherently slow sampling. Moreover, existing evaluation methods rely on rigid pipelines that overlook specific user needs and provide numerical results without clear explanations. In contrast, humans can quickly form impressions of a model&#39;s capabilities by observing only a few samples. To mimic this, we propose the Evaluation Agent framework, which employs human-like strategies for efficient, dynamic, multi-round evaluations using only a few samples per round, while offering detailed, user-tailored analyses. It offers four key advantages: 1) efficiency, 2) promptable evaluation tailored to diverse user needs, 3) explainability beyond single numerical scores, and 4) scalability across various models and tools. Experiments show that Evaluation Agent reduces evaluation time to 10% of traditional methods while delivering comparable results. The Evaluation Agent framework is fully open-sourced to advance research in visual generative models and their efficient evaluation.",
        "code": "",
        "category": [
            [
                "Automation",
                "Automatic Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.09645"
    },
    "fc80e54353d65d5bb01b584319ac4f87": {
        "title": "LAW: Legal Agentic Workflows for Custody and Fund Services Contracts",
        "authors": [
            "William Watson",
            "Nicole Cho",
            "Nishan Srishankar",
            "Zhen Zeng",
            "Lucas Cecchi",
            "Daniel Scott",
            "Suchetha Siddagangappa",
            "Rachneet Kaur",
            "Tucker Balch",
            "Manuela Veloso"
        ],
        "date": "2024/12/15",
        "pdf": "http://arxiv.org/pdf/2412.11063",
        "abstract": "Legal contracts in the custody and fund services domain govern critical aspects such as key provider responsibilities, fee schedules, and indemnification rights. However, it is challenging for an off-the-shelf Large Language Model (LLM) to ingest these contracts due to the lengthy unstructured streams of text, limited LLM context windows, and complex legal jargon. To address these challenges, we introduce LAW (Legal Agentic Workflows for Custody and Fund Services Contracts). LAW features a modular design that responds to user queries by orchestrating a suite of domain-specific tools and text agents. Our experiments demonstrate that LAW, by integrating multiple specialized agents and tools, significantly outperforms the baseline. LAW excels particularly in complex tasks such as calculating a contract&#39;s termination date, surpassing the baseline by 92.9% points. Furthermore, LAW offers a cost-effective alternative to traditional fine-tuned legal LLMs by leveraging reusable, domain-specific tools.",
        "code": "",
        "category": [
            [
                "Automation",
                "Workflow"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.11063"
    },
    "2d22bbee5f4fa1e044b8f33e74cbc276": {
        "title": "Virtual Agent-Based Communication Skills Training to Facilitate Health Persuasion Among Peers",
        "authors": [
            "Farnaz Nouraei",
            "Keith Rebello",
            "Mina Fallah",
            "Prasanth Murali",
            "Haley Matuszak",
            "Valerie Jap",
            "Andrea Parker",
            "Michael Paasche-Orlow",
            "Timothy Bickmore"
        ],
        "date": "2024/12/16",
        "pdf": "http://arxiv.org/pdf/2412.12061",
        "abstract": "Many laypeople are motivated to improve the health behavior of their family or friends but do not know where to start, especially if the health behavior is potentially stigmatizing or controversial. We present an approach that uses virtual agents to coach community-based volunteers in health counseling techniques, such as motivational interviewing, and allows them to practice these skills in role-playing scenarios. We use this approach in a virtual agent-based system to increase COVID-19 vaccination by empowering users to influence their social network. In a between-subjects comparative design study, we test the effects of agent system interactivity and role-playing functionality on counseling outcomes, with participants evaluated by standardized patients and objective judges. We find that all versions are effective at producing peer counselors who score adequately on a standardized measure of counseling competence, and that participants were significantly more satisfied with interactive virtual agents compared to passive viewing of the training material. We discuss design implications for interpersonal skills training systems based on our findings.",
        "code": "",
        "category": [
            [
                "Training",
                "Fine tuning"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.12061"
    },
    "4d3e274f4358a55712f40de0301356f2": {
        "title": "An Agentic Approach to Automatic Creation of P&amp;ID Diagrams from Natural Language Descriptions",
        "authors": [
            "Shreeyash Gowaikar",
            "Srinivasan Iyengar",
            "Sameer Segal",
            "Shivkumar Kalyanaraman"
        ],
        "date": "2024/12/17",
        "pdf": "http://arxiv.org/pdf/2412.12898",
        "abstract": "The Piping and Instrumentation Diagrams (P&amp;IDs) are foundational to the design, construction, and operation of workflows in the engineering and process industries. However, their manual creation is often labor-intensive, error-prone, and lacks robust mechanisms for error detection and correction. While recent advancements in Generative AI, particularly Large Language Models (LLMs) and Vision-Language Models (VLMs), have demonstrated significant potential across various domains, their application in automating generation of engineering workflows remains underexplored. In this work, we introduce a novel copilot for automating the generation of P&amp;IDs from natural language descriptions. Leveraging a multi-step agentic workflow, our copilot provides a structured and iterative approach to diagram creation directly from Natural Language prompts. We demonstrate the feasibility of the generation process by evaluating the soundness and completeness of the workflow, and show improved results compared to vanilla zero-shot and few-shot generation approaches.",
        "code": "",
        "category": [
            [
                "Automation",
                "Workflow"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.12898"
    },
    "e1399dd9ea49f169cb3559f695b45345": {
        "title": "Gradual Vigilance and Interval Communication: Enhancing Value Alignment in Multi-Agent Debates",
        "authors": [
            "Rui Zou",
            "Mengqi Wei",
            "Jintian Feng",
            "Qian Wan",
            "Jianwen Sun",
            "Sannyuya Liu"
        ],
        "date": "2024/12/18",
        "pdf": "http://arxiv.org/pdf/2412.13471",
        "abstract": "In recent years, large language models have shown exceptional performance in fulfilling diverse human needs. However, their training data can introduce harmful content, underscoring the necessity for robust value alignment. Mainstream methods, which depend on feedback learning and supervised training, are resource-intensive and may constrain the full potential of the models. Multi-Agent Debate (MAD) offers a more efficient and innovative solution by enabling the generation of reliable answers through agent interactions. To apply MAD to value alignment, we examine the relationship between the helpfulness and harmlessness of debate outcomes and individual responses, and propose a MAD based framework Gradual Vigilance and Interval Communication (GVIC). GVIC allows agents to assess risks with varying levels of vigilance and to exchange diverse information through interval communication. We theoretically prove that GVIC optimizes debate efficiency while reducing communication overhead. Experimental results demonstrate that GVIC consistently outperforms baseline methods across various tasks and datasets, particularly excelling in harmfulness mitigation and fraud prevention. Additionally, GVIC exhibits strong adaptability across different base model sizes, including both unaligned and aligned models, and across various task types.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.13471"
    },
    "a2557a0735be090f75ec628cd25e003e": {
        "title": "ChinaTravel: A Real-World Benchmark for Language Agents in Chinese Travel Planning",
        "authors": [
            "Jie-Jing Shao",
            "Xiao-Wen Yang",
            "Bo-Wen Zhang",
            "Baizhi Chen",
            "Wen-Da Wei",
            "Guohao Cai",
            "Zhenhua Dong",
            "Lan-Zhe Guo",
            "Yu-feng Li"
        ],
        "date": "2024/12/18",
        "pdf": "http://arxiv.org/pdf/2412.13682",
        "abstract": "Recent advances in LLMs, particularly in language reasoning and tool integration, have rapidly sparked the real-world development of Language Agents. Among these, travel planning represents a prominent domain, combining academic challenges with practical value due to its complexity and market demand. However, existing benchmarks fail to reflect the diverse, real-world requirements crucial for deployment. To address this gap, we introduce ChinaTravel, a benchmark specifically designed for authentic Chinese travel planning scenarios. We collect the travel requirements from questionnaires and propose a compositionally generalizable domain-specific language that enables a scalable evaluation process, covering feasibility, constraint satisfaction, and preference comparison. Empirical studies reveal the potential of neuro-symbolic agents in travel planning, achieving a constraint satisfaction rate of 27.9%, significantly surpassing purely neural models at 2.6%. Moreover, we identify key challenges in real-world travel planning deployments, including open language reasoning and unseen concept composition. These findings highlight the significance of ChinaTravel as a pivotal milestone for advancing language agents in complex, real-world planning scenarios.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.13682"
    },
    "8d451b4d4ecff4a1ba1eed1691beef83": {
        "title": "A Survey on Large Language Model-based Agents for Statistics and Data Science",
        "authors": [
            "Maojun Sun",
            "Ruijian Han",
            "Binyan Jiang",
            "Houduo Qi",
            "Defeng Sun",
            "Yancheng Yuan",
            "Jian Huang"
        ],
        "date": "2024/12/18",
        "pdf": "http://arxiv.org/pdf/2412.14222",
        "abstract": "In recent years, data science agents powered by Large Language Models (LLMs), known as &#34;data agents,&#34; have shown significant potential to transform the traditional data analysis paradigm. This survey provides an overview of the evolution, capabilities, and applications of LLM-based data agents, highlighting their role in simplifying complex data tasks and lowering the entry barrier for users without related expertise. We explore current trends in the design of LLM-based frameworks, detailing essential features such as planning, reasoning, reflection, multi-agent collaboration, user interface, knowledge integration, and system design, which enable agents to address data-centric problems with minimal human intervention. Furthermore, we analyze several case studies to demonstrate the practical applications of various data agents in real-world scenarios. Finally, we identify key challenges and propose future research directions to advance the development of data agents into intelligent statistical analysis software.",
        "code": "",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2412.14222"
    },
    "83b0d3fc78bd9f05f3c09e59aae5be66": {
        "title": "Collaborative Gym: A Framework for Enabling and Evaluating Human-Agent Collaboration",
        "authors": [
            "Yijia Shao",
            "Vinay Samuel",
            "Yucheng Jiang",
            "John Yang",
            "Diyi Yang"
        ],
        "date": "2024/12/20",
        "pdf": "http://arxiv.org/pdf/2412.15701",
        "abstract": "Recent advancements in language models (LMs) have sparked growing interest in developing LM agents. While fully autonomous agents could excel in many scenarios, numerous use cases inherently require them to collaborate with humans due to humans&#39; latent preferences, domain expertise, or need for control. To facilitate the study of human-agent collaboration, we present Collaborative Gym (Co-Gym), a general framework enabling asynchronous, tripartite interaction among agents, humans, and task environments. We instantiate Co-Gym with three representative tasks in both simulated and real-world conditions, and propose an evaluation framework that assesses both the collaboration outcomes and processes. Our findings reveal that collaborative agents consistently outperform their fully autonomous counterparts in task performance within those delivered cases, achieving win rates of 86% in Travel Planning, 74% in Tabular Analysis, and 66% in Related Work when evaluated by real users. However, our study also highlights significant challenges in developing collaborative agents, requiring advancements in core aspects of intelligence -- communication capabilities, situational awareness, and balancing autonomy and human control.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Human-Agent Interaction"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.15701"
    },
    "c6049b81b62204279820d07318eaec50": {
        "title": "Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG",
        "authors": [
            "Hasan Md Tusfiqur Alam",
            "Devansh Srivastav",
            "Md Abdul Kadir",
            "Daniel Sonntag"
        ],
        "date": "2024/12/20",
        "pdf": "http://arxiv.org/pdf/2412.16086",
        "abstract": "Deep learning has advanced medical image classification, but interpretability challenges hinder its clinical adoption. This study enhances interpretability in Chest X-ray (CXR) classification by using concept bottleneck models (CBMs) and a multi-agent Retrieval-Augmented Generation (RAG) system for report generation. By modeling relationships between visual features and clinical concepts, we create interpretable concept vectors that guide a multi-agent RAG system to generate radiology reports, enhancing clinical relevance, explainability, and transparency. Evaluation of the generated reports using an LLM-as-a-judge confirmed the interpretability and clinical utility of our model&#39;s outputs. On the COVID-QU dataset, our model achieved 81% classification accuracy and demonstrated robust report generation performance, with five key metrics ranging between 84% and 90%. This interpretable multi-agent framework bridges the gap between high-performance AI and the explainability required for reliable AI-driven CXR analysis in clinical settings. Our code is available at https://github.com/tifat58/IRR-with-CBM-RAG.git.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "RAG"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.16086"
    },
    "199fd413718ec71f4f8d6c1b1df07c20": {
        "title": "Self-guided Knowledgeable Network of Thoughts: Amplifying Reasoning with Large Language Models",
        "authors": [
            "Chao-Chi Chen",
            "Chin-Yuan Yeh",
            "Hsi-Wen Chen",
            "De-Nian Yang",
            "Ming-Syan Chen"
        ],
        "date": "2024/12/21",
        "pdf": "http://arxiv.org/pdf/2412.16533",
        "abstract": "We introduce Knowledgeable Network of Thoughts (kNoT): a prompt scheme that advances the capabilities of large language models (LLMs) beyond existing paradigms like Chain-of-Thought (CoT), Tree of Thoughts (ToT), and Graph of Thoughts (GoT). The key innovation of kNoT is the LLM Workflow Template (LWT), which allows for an executable plan to be specified by LLMs for LLMs. LWT allows these plans to be arbitrary networks, where single-step LLM operations are nodes, and edges correspond to message passing between these steps. Furthermore, LWT supports selection of individual elements through indexing, facilitating kNoT to produce intricate plans where each LLM operation can be limited to elementary operations, greatly enhancing reliability over extended task sequences. We demonstrate that kNoT significantly outperforms the state of the art on six use cases, while reducing the need for extensive prompt engineering. For instance, kNoT finds 92% accuracy for sorting 32 numbers over 12% and 31% for ToT and GoT, while utilizing up to 84.4% and 87.3% less task-specific prompts, respectively.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.16533"
    },
    "ce3c7b3b6883b559844e1a5a4cc5c5dd": {
        "title": "The Task Shield: Enforcing Task Alignment to Defend Against Indirect Prompt Injection in LLM Agents",
        "authors": [
            "Feiran Jia",
            "Tong Wu",
            "Xin Qin",
            "Anna Squicciarini"
        ],
        "date": "2024/12/21",
        "pdf": "http://arxiv.org/pdf/2412.16682",
        "abstract": "Large Language Model (LLM) agents are increasingly being deployed as conversational assistants capable of performing complex real-world tasks through tool integration. This enhanced ability to interact with external systems and process various data sources, while powerful, introduces significant security vulnerabilities. In particular, indirect prompt injection attacks pose a critical threat, where malicious instructions embedded within external data sources can manipulate agents to deviate from user intentions. While existing defenses based on rule constraints, source spotlighting, and authentication protocols show promise, they struggle to maintain robust security while preserving task functionality. We propose a novel and orthogonal perspective that reframes agent security from preventing harmful actions to ensuring task alignment, requiring every agent action to serve user objectives. Based on this insight, we develop Task Shield, a test-time defense mechanism that systematically verifies whether each instruction and tool call contributes to user-specified goals. Through experiments on the AgentDojo benchmark, we demonstrate that Task Shield reduces attack success rates (2.07\\%) while maintaining high task utility (69.79\\%) on GPT-4o.",
        "code": "",
        "category": [
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.16682"
    },
    "f1e3e6f2bcc9514a71bed3eb13459823": {
        "title": "Modular Conversational Agents for Surveys and Interviews",
        "authors": [
            "Jiangbo Yu",
            "Jinhua Zhao",
            "Luis Miranda-Moreno",
            "Matthew Korp"
        ],
        "date": "2024/12/22",
        "pdf": "http://arxiv.org/pdf/2412.17049",
        "abstract": "Surveys and interviews (structured, semi-structured, or unstructured) are widely used for collecting insights on emerging or hypothetical scenarios. Traditional human-led methods often face challenges related to cost, scalability, and consistency. Recently, various domains have begun to explore the use of conversational agents (chatbots) powered by large language models (LLMs). However, as public investments and policies on infrastructure and services often involve substantial public stakes and environmental risks, there is a need for a rigorous, transparent, privacy-preserving, and cost-efficient development framework tailored for such major decision-making processes. This paper addresses this gap by introducing a modular approach and its resultant parameterized process for designing conversational agents. We detail the system architecture, integrating engineered prompts, specialized knowledge bases, and customizable, goal-oriented conversational logic in the proposed approach. We demonstrate the adaptability, generalizability, and efficacy of our modular approach through three empirical studies: (1) travel preference surveys, highlighting multimodal (voice, text, and image generation) capabilities; (2) public opinion elicitation on a newly constructed, novel infrastructure project, showcasing question customization and multilingual (English and French) capabilities; and (3) transportation expert consultation about future transportation systems, highlighting real-time, clarification request capabilities for open-ended questions, resilience in handling erratic inputs, and efficient transcript post-processing. The results show the effectiveness of this modular approach and how it addresses key ethical, privacy, security, and token consumption concerns, setting the stage for the next-generation surveys and interviews.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ],
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.17049"
    },
    "d4f02245712f906a648160b45f03dcc4": {
        "title": "MineAgent: Towards Remote-Sensing Mineral Exploration with Multimodal Large Language Models",
        "authors": [
            "Beibei Yu",
            "Tao Shen",
            "Hongbin Na",
            "Ling Chen",
            "Denqi Li"
        ],
        "date": "2024/12/23",
        "pdf": "http://arxiv.org/pdf/2412.17339",
        "abstract": "Remote-sensing mineral exploration is critical for identifying economically viable mineral deposits, yet it poses significant challenges for multimodal large language models (MLLMs). These include limitations in domain-specific geological knowledge and difficulties in reasoning across multiple remote-sensing images, further exacerbating long-context issues. To address these, we present MineAgent, a modular framework leveraging hierarchical judging and decision-making modules to improve multi-image reasoning and spatial-spectral integration. Complementing this, we propose MineBench, a benchmark specific for evaluating MLLMs in domain-specific mineral exploration tasks using geological and hyperspectral data. Extensive experiments demonstrate the effectiveness of MineAgent, highlighting its potential to advance MLLMs in remote-sensing mineral exploration.",
        "code": "",
        "category": [
            [
                "Application",
                "Geography"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.17339"
    },
    "f498595dbcf340ae405c55773dae2e48": {
        "title": "Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent",
        "authors": [
            "Farhad Nooralahzadeh",
            "Yi Zhang",
            "Jonathan Furst",
            "Kurt Stockinger"
        ],
        "date": "2024/12/24",
        "pdf": "http://arxiv.org/pdf/2412.18428",
        "abstract": "International enterprises, organizations, or hospitals collect large amounts of multi-modal data stored in databases, text documents, images, and videos. While there has been recent progress in the separate fields of multi-modal data exploration as well as in database systems that automatically translate natural language questions to database query languages, the research challenge of querying database systems combined with other unstructured modalities such as images in natural language is widely unexplored. In this paper, we propose XMODE - a system that enables explainable, multi-modal data exploration in natural language. Our approach is based on the following research contributions: (1) Our system is inspired by a real-world use case that enables users to explore multi-modal information systems. (2) XMODE leverages a LLM-based agentic AI framework to decompose a natural language question into subtasks such as text-to-SQL generation and image analysis. (3) Experimental results on multi-modal datasets over relational data and images demonstrate that our system outperforms state-of-the-art multi-modal exploration systems, excelling not only in accuracy but also in various performance metrics such as query latency, API costs, planning efficiency, and explanation quality, thanks to the more effective utilization of the reasoning capabilities of LLMs.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Dataset"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.18428"
    },
    "0c6907ecf0d389f2fc52e449f3319c5c": {
        "title": "OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis",
        "authors": [
            "Qiushi Sun",
            "Kanzhi Cheng",
            "Zichen Ding",
            "Chuanyang Jin",
            "Yian Wang",
            "Fangzhi Xu",
            "Zhenyu Wu",
            "Chengyou Jia",
            "Liheng Chen",
            "Zhoumianze Liu",
            "Ben Kao",
            "Guohao Li",
            "Junxian He",
            "Yu Qiao",
            "Zhiyong Wu"
        ],
        "date": "2024/12/27",
        "pdf": "http://arxiv.org/pdf/2412.19723",
        "abstract": "Graphical User Interface (GUI) agents powered by Vision-Language Models (VLMs) have demonstrated human-like computer control capability. Despite their utility in advancing digital automation, a critical bottleneck persists: collecting high-quality trajectory data for training. Common practices for collecting such data rely on human supervision or synthetic data generation through executing pre-defined tasks, which are either resource-intensive or unable to guarantee data quality. Moreover, these methods suffer from limited data diversity and significant gaps between synthetic data and real-world environments. To address these challenges, we propose OS-Genesis, a novel GUI data synthesis pipeline that reverses the conventional trajectory collection process. Instead of relying on pre-defined tasks, OS-Genesis enables agents first to perceive environments and perform step-wise interactions, then retrospectively derive high-quality tasks to enable trajectory-level exploration. A trajectory reward model is then employed to ensure the quality of the generated trajectories. We demonstrate that training GUI agents with OS-Genesis significantly improves their performance on highly challenging online benchmarks. In-depth analysis further validates OS-Genesis&#39;s efficiency and its superior data quality and diversity compared to existing synthesis methods. Our codes, data, and checkpoints are available at \\href{https://qiushisun.github.io/OS-Genesis-Home/}{OS-Genesis Homepage}.",
        "code": "",
        "category": [
            [
                "Application",
                "Finance"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.19723"
    },
    "85253a047b9d490704c7a5bb9f980a93": {
        "title": "BaiJia: A Large-Scale Role-Playing Agent Corpus of Chinese Historical Characters",
        "authors": [
            "Ting Bai",
            "Jiazheng Kang",
            "Jiayang Fan"
        ],
        "date": "2024/12/28",
        "pdf": "http://arxiv.org/pdf/2412.20024",
        "abstract": "We introduce a comprehensive large-scale role-playing agent corpus, termed BaiJia, that comprises various Chinese historical characters. This corpus is noteworthy for being the pioneering compilation of low-resource data that can be utilized in large language models (LLMs) to engage in AI-driven historical role-playing agents. BaiJia addresses the challenges in terms of fragmented historical textual records in different forms and modalities, integrating various characters&#39; information, including their biographical, literary, family relations, historical events, and so on. We conduct extensive experiments to demonstrate the effectiveness of our BaiJia agent corpus in bolstering the role-playing abilities of various foundational LLMs, and promoting the development and assessment of LLMs in the context of historical role-playing tasks. The agent corpus is available at baijia.online.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ],
            [
                "Infrastructure",
                "Dataset"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.20024"
    },
    "b7c608b3105aa534358cbcf047f2547c": {
        "title": "Training Software Engineering Agents and Verifiers with SWE-Gym",
        "authors": [
            "Jiayi Pan",
            "Xingyao Wang",
            "Graham Neubig",
            "Navdeep Jaitly",
            "Heng Ji",
            "Alane Suhr",
            "Yizhe Zhang"
        ],
        "date": "2024/12/30",
        "pdf": "http://arxiv.org/pdf/2412.21139",
        "abstract": "We present SWE-Gym, the first environment for training real-world software engineering (SWE) agents. SWE-Gym contains 2,438 real-world Python task instances, each comprising a codebase with an executable runtime environment, unit tests, and a task specified in natural language. We use SWE-Gym to train language model based SWE agents , achieving up to 19% absolute gains in resolve rate on the popular SWE-Bench Verified and Lite test sets. We also experiment with inference-time scaling through verifiers trained on agent trajectories sampled from SWE-Gym. When combined with our fine-tuned SWE agents, we achieve 32.0% and 26.0% on SWE-Bench Verified and Lite, respectively, reflecting a new state-of-the-art for open-weight SWE agents. To facilitate further research, we publicly release SWE-Gym, models, and agent trajectories.",
        "code": "",
        "category": [
            [
                "Application",
                "Software Engineering"
            ],
            [
                "Training",
                "Fine tuning"
            ],
            [
                "Infrastructure",
                "Environment&Platform"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.21139"
    },
    "1bb2bdc836185799e2a0e983ef5f1fe7": {
        "title": "Aviary: training language agents on challenging scientific tasks",
        "authors": [
            "Siddharth Narayanan",
            "James D. Braza",
            "Ryan-Rhys Griffiths",
            "Manu Ponnapati",
            "Albert Bou",
            "Jon Laurent",
            "Ori Kabeli",
            "Geemi Wellawatte",
            "Sam Cox",
            "Samuel G. Rodriques",
            "Andrew D. White"
        ],
        "date": "2024/12/30",
        "pdf": "http://arxiv.org/pdf/2412.21154",
        "abstract": "Solving complex real-world tasks requires cycles of actions and observations. This is particularly true in science, where tasks require many cycles of analysis, tool use, and experimentation. Language agents are promising for automating intellectual tasks in science because they can interact with tools via natural language or code. Yet their flexibility creates conceptual and practical challenges for software implementations, since agents may comprise non-standard components such as internal reasoning, planning, tool usage, as well as the inherent stochasticity of temperature-sampled language models. Here, we introduce Aviary, an extensible gymnasium for language agents. We formalize agents as policies solving language-grounded partially observable Markov decision processes, which we term language decision processes. We then implement five environments, including three challenging scientific environments: (1) manipulating DNA constructs for molecular cloning, (2) answering research questions by accessing scientific literature, and (3) engineering protein stability. These environments were selected for their focus on multi-step reasoning and their relevance to contemporary biology research. Finally, with online training and scaling inference-time compute, we show that language agents backed by open-source, non-frontier LLMs can match and exceed both frontier LLM agents and human experts on multiple tasks at up to 100x lower inference cost.",
        "code": "",
        "category": [
            [
                "Training",
                "Fine tuning"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.21154"
    },
    "bc62d4238b8f4fb14b1bd084e24e54d1": {
        "title": "Distributed Mixture-of-Agents for Edge Inference with Large Language Models",
        "authors": [
            "Purbesh Mitra",
            "Priyanka Kaswan",
            "Sennur Ulukus"
        ],
        "date": "2024/12/30",
        "pdf": "http://arxiv.org/pdf/2412.21200",
        "abstract": "Mixture-of-Agents (MoA) has recently been proposed as a method to enhance performance of large language models (LLMs), enabling multiple individual LLMs to work together for collaborative inference. This collaborative approach results in improved responses to user prompts compared to relying on a single LLM. In this paper, we consider such an MoA architecture in a distributed setting, where LLMs operate on individual edge devices, each uniquely associated with a user and equipped with its own distributed computing power. These devices exchange information using decentralized gossip algorithms, allowing different device nodes to talk without the supervision of a centralized server. In the considered setup, different users have their own LLM models to address user prompts. Additionally, the devices gossip either their own user-specific prompts or augmented prompts to generate more refined answers to certain queries. User prompts are temporarily stored in the device queues when their corresponding LLMs are busy. Given the memory limitations of edge devices, it is crucial to ensure that the average queue sizes in the system remain bounded. In this paper, we address this by theoretically calculating the queuing stability conditions for the device queues under reasonable assumptions, which we validate experimentally as well. Further, we demonstrate through experiments, leveraging open-source LLMs for the implementation of distributed MoA, that certain MoA configurations produce higher-quality responses compared to others, as evaluated on AlpacaEval 2.0 benchmark. The implementation is available at: https://github.com/purbeshmitra/distributed_moa.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2412.21200"
    },
    "cd539b083e92057613d3fb65ac4792f9": {
        "title": "Large Language Models as User-Agents for Evaluating Task-Oriented-Dialogue Systems",
        "authors": [
            "Taaha Kazi",
            "Ruiliang Lyu",
            "Sizhe Zhou",
            "Dilek Hakkani-Tur",
            "Gokhan Tur"
        ],
        "date": "2024/11/15",
        "pdf": "http://arxiv.org/pdf/2411.09972",
        "abstract": "Traditionally, offline datasets have been used to evaluate task-oriented dialogue (TOD) models. These datasets lack context awareness, making them suboptimal benchmarks for conversational systems. In contrast, user-agents, which are context-aware, can simulate the variability and unpredictability of human conversations, making them better alternatives as evaluators. Prior research has utilized large language models (LLMs) to develop user-agents. Our work builds upon this by using LLMs to create user-agents for the evaluation of TOD systems. This involves prompting an LLM, using in-context examples as guidance, and tracking the user-goal state. Our evaluation of diversity and task completion metrics for the user-agents shows improved performance with the use of better prompts. Additionally, we propose methodologies for the automatic evaluation of TOD models within this dynamic framework.",
        "code": "",
        "category": [
            [
                "Automation",
                "Automatic Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.09972"
    },
    "6a6bfc2846616d3e53e7ea004e4ddee9": {
        "title": "IntentGPT: Few-shot Intent Discovery with Large Language Models",
        "authors": [
            "Juan A. Rodriguez",
            "Nicholas Botzer",
            "David Vazquez",
            "Christopher Pal",
            "Marco Pedersoli",
            "Issam Laradji"
        ],
        "date": "2024/11/16",
        "pdf": "http://arxiv.org/pdf/2411.10670",
        "abstract": "In today&#39;s digitally driven world, dialogue systems play a pivotal role in enhancing user interactions, from customer service to virtual assistants. In these dialogues, it is important to identify user&#39;s goals automatically to resolve their needs promptly. This has necessitated the integration of models that perform Intent Detection. However, users&#39; intents are diverse and dynamic, making it challenging to maintain a fixed set of predefined intents. As a result, a more practical approach is to develop a model capable of identifying new intents as they emerge. We address the challenge of Intent Discovery, an area that has drawn significant attention in recent research efforts. Existing methods need to train on a substantial amount of data for correctly identifying new intents, demanding significant human effort. To overcome this, we introduce IntentGPT, a novel training-free method that effectively prompts Large Language Models (LLMs) such as GPT-4 to discover new intents with minimal labeled data. IntentGPT comprises an \\textit{In-Context Prompt Generator}, which generates informative prompts for In-Context Learning, an \\textit{Intent Predictor} for classifying and discovering user intents from utterances, and a \\textit{Semantic Few-Shot Sampler} that selects relevant few-shot examples and a set of known intents to be injected into the prompt. Our experiments show that IntentGPT outperforms previous methods that require extensive domain-specific data and fine-tuning, in popular benchmarks, including CLINC and BANKING, among others.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.10670"
    },
    "038978f7e5f48c40365b284c9cc94d36": {
        "title": "OASIS: Open Agent Social Interaction Simulations with One Million Agents",
        "authors": [
            "Ziyi Yang",
            "Zaibin Zhang",
            "Zirui Zheng",
            "Yuxian Jiang",
            "Ziyue Gan",
            "Zhiyu Wang",
            "Zijian Ling",
            "Jinsong Chen",
            "Martz Ma",
            "Bowen Dong",
            "Prateek Gupta",
            "Shuyue Hu",
            "Zhenfei Yin",
            "Guohao Li",
            "Xu Jia",
            "Lijun Wang",
            "Bernard Ghanem",
            "Huchuan Lu",
            "Chaochao Lu",
            "Wanli Ouyang",
            "Yu Qiao",
            "Philip Torr",
            "Jing Shao"
        ],
        "date": "2024/11/18",
        "pdf": "http://arxiv.org/pdf/2411.11581",
        "abstract": "There has been a growing interest in enhancing rule-based agent-based models (ABMs) for social media platforms (i.e., X, Reddit) with more realistic large language model (LLM) agents, thereby allowing for a more nuanced study of complex systems. As a result, several LLM-based ABMs have been proposed in the past year. While they hold promise, each simulator is specifically designed to study a particular scenario, making it time-consuming and resource-intensive to explore other phenomena using the same ABM. Additionally, these models simulate only a limited number of agents, whereas real-world social media platforms involve millions of users. To this end, we propose OASIS, a generalizable and scalable social media simulator. OASIS is designed based on real-world social media platforms, incorporating dynamically updated environments (i.e., dynamic social networks and post information), diverse action spaces (i.e., following, commenting), and recommendation systems (i.e., interest-based and hot-score-based). Additionally, OASIS supports large-scale user simulations, capable of modeling up to one million users. With these features, OASIS can be easily extended to different social media platforms to study large-scale group phenomena and behaviors. We replicate various social phenomena, including information spreading, group polarization, and herd effects across X and Reddit platforms. Moreover, we provide observations of social phenomena at different agent group scales. We observe that the larger agent group scale leads to more enhanced group dynamics and more diverse and helpful agents&#39; opinions. These findings demonstrate OASIS&#39;s potential as a powerful tool for studying complex systems in digital environments.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Simulation"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.11581"
    },
    "e8fca720b205eeaa8b7ee524ec7542fc": {
        "title": "Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN",
        "authors": [
            "Zhilun Zhou",
            "Jingyang Fan",
            "Yu Liu",
            "Fengli Xu",
            "Depeng Jin",
            "Yong Li"
        ],
        "date": "2024/10/29",
        "pdf": "http://arxiv.org/pdf/2411.00028",
        "abstract": "The fast development of location-based social networks (LBSNs) has led to significant changes in society, resulting in popular studies of using LBSN data for socioeconomic prediction, e.g., regional population and commercial activity estimation. Existing studies design various graphs to model heterogeneous LBSN data, and further apply graph representation learning methods for socioeconomic prediction. However, these approaches heavily rely on heuristic ideas and expertise to extract task-relevant knowledge from diverse data, which may not be optimal for specific tasks. Additionally, they tend to overlook the inherent relationships between different indicators, limiting the prediction accuracy. Motivated by the remarkable abilities of large language models (LLMs) in commonsense reasoning, embedding, and multi-agent collaboration, in this work, we synergize LLM agents and knowledge graph for socioeconomic prediction. We first construct a location-based knowledge graph (LBKG) to integrate multi-sourced LBSN data. Then we leverage the reasoning power of LLM agent to identify relevant meta-paths in the LBKG for each type of socioeconomic prediction task, and design a semantic-guided attention module for knowledge fusion with meta-paths. Moreover, we introduce a cross-task communication mechanism to further enhance performance by enabling knowledge sharing across tasks at both LLM agent and KG levels. On the one hand, the LLM agents for different tasks collaborate to generate more diverse and comprehensive meta-paths. On the other hand, the embeddings from different tasks are adaptively merged for better socioeconomic prediction. Experiments on two datasets demonstrate the effectiveness of the synergistic design between LLM and KG, providing insights for information sharing across socioeconomic prediction tasks.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Search"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.00028"
    },
    "80d8d5d9e27211ff226fac023f5b8551": {
        "title": "ACC-Debate: An Actor-Critic Approach to Multi-Agent Debate",
        "authors": [
            "Andrew Estornell",
            "Jean-Francois Ton",
            "Yuanshun Yao",
            "Yang Liu"
        ],
        "date": "2024/10/30",
        "pdf": "http://arxiv.org/pdf/2411.00053",
        "abstract": "Large language models (LLMs) have demonstrated a remarkable ability to serve as general-purpose tools for various language-based tasks. Recent works have demonstrated that the efficacy of such models can be improved through iterative dialog between multiple models, frequently referred to as multi-agent debate (MAD). While debate shows promise as a means of improving model efficacy, most works in this area treat debate as an emergent behavior, rather than a learned behavior. In doing so, current debate frameworks rely on collaborative behaviors to have been sufficiently trained into off-the-shelf models. To address this limitation, we propose ACC-Debate, an Actor-Critic based learning framework to produce a two-agent team specialized in debate. We demonstrate that ACC-Debate outperforms SotA debate techniques on a wide array of benchmarks.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.00053"
    },
    "997fd688a91f3216e5585078ddc4ea80": {
        "title": "DARD: A Multi-Agent Approach for Task-Oriented Dialog Systems",
        "authors": [
            "Aman Gupta",
            "Anirudh Ravichandran",
            "Ziji Zhang",
            "Swair Shah",
            "Anurag Beniwal",
            "Narayanan Sadagopan"
        ],
        "date": "2024/11/01",
        "pdf": "http://arxiv.org/pdf/2411.00427",
        "abstract": "Task-oriented dialogue systems are essential for applications ranging from customer service to personal assistants and are widely used across various industries. However, developing effective multi-domain systems remains a significant challenge due to the complexity of handling diverse user intents, entity types, and domain-specific knowledge across several domains. In this work, we propose DARD (Domain Assigned Response Delegation), a multi-agent conversational system capable of successfully handling multi-domain dialogs. DARD leverages domain-specific agents, orchestrated by a central dialog manager agent. Our extensive experiments compare and utilize various agent modeling approaches, combining the strengths of smaller fine-tuned models (Flan-T5-large &amp; Mistral-7B) with their larger counterparts, Large Language Models (LLMs) (Claude Sonnet 3.0). We provide insights into the strengths and limitations of each approach, highlighting the benefits of our multi-agent framework in terms of flexibility and composability. We evaluate DARD using the well-established MultiWOZ benchmark, achieving state-of-the-art performance by improving the dialogue inform rate by 6.6% and the success rate by 4.1% over the best-performing existing approaches. Additionally, we discuss various annotator discrepancies and issues within the MultiWOZ dataset and its evaluation system.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.00427"
    },
    "01f705e457c8761bebd1d0356903c5b3": {
        "title": "ReSpAct: Harmonizing Reasoning, Speaking, and Acting Towards Building Large Language Model-Based Conversational AI Agents",
        "authors": [
            "Vardhan Dongre",
            "Xiaocheng Yang",
            "Emre Can Acikgoz",
            "Suvodip Dey",
            "Gokhan Tur",
            "Dilek Hakkani-TÃ¼r"
        ],
        "date": "2024/11/01",
        "pdf": "http://arxiv.org/pdf/2411.00927",
        "abstract": "Large language model (LLM)-based agents have been increasingly used to interact with external environments (e.g., games, APIs, etc.) and solve tasks. However, current frameworks do not enable these agents to work with users and interact with them to align on the details of their tasks and reach user-defined goals; instead, in ambiguous situations, these agents may make decisions based on assumptions. This work introduces ReSpAct (Reason, Speak, and Act), a novel framework that synergistically combines the essential skills for building task-oriented &#34;conversational&#34; agents. ReSpAct addresses this need for agents, expanding on the ReAct approach. The ReSpAct framework enables agents to interpret user instructions, reason about complex tasks, execute appropriate actions, and engage in dynamic dialogue to seek guidance, clarify ambiguities, understand user preferences, resolve problems, and use the intermediate feedback and responses of users to update their plans. We evaluated ReSpAct in environments supporting user interaction, such as task-oriented dialogue (MultiWOZ) and interactive decision-making (AlfWorld, WebShop). ReSpAct is flexible enough to incorporate dynamic user feedback and addresses prevalent issues like error propagation and agents getting stuck in reasoning loops. This results in more interpretable, human-like task-solving trajectories than relying solely on reasoning traces. In two interactive decision-making benchmarks, AlfWorld and WebShop, ReSpAct outperform the strong reasoning-only method ReAct by an absolute success rate of 6% and 4%, respectively. In the task-oriented dialogue benchmark MultiWOZ, ReSpAct improved Inform and Success scores by 5.5% and 3%, respectively.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.00927"
    },
    "0574e3418a65863981e4070f7e27fdc0": {
        "title": "DynaSaur: Large Language Agents Beyond Predefined Actions",
        "authors": [
            "Dang Nguyen",
            "Viet Dac Lai",
            "Seunghyun Yoon",
            "Ryan A. Rossi",
            "Handong Zhao",
            "Ruiyi Zhang",
            "Puneet Mathur",
            "Nedim Lipka",
            "Yu Wang",
            "Trung Bui",
            "Franck Dernoncourt",
            "Tianyi Zhou"
        ],
        "date": "2024/11/04",
        "pdf": "http://arxiv.org/pdf/2411.01747",
        "abstract": "Existing LLM agent systems typically select actions from a fixed and predefined set at every step. While this approach is effective in closed, narrowly-scoped environments, we argue that it presents two major challenges when deploying LLM agents in real-world scenarios: (1) selecting from a fixed set of actions significantly restricts the planning and acting capabilities of LLM agents, and (2) this approach requires substantial human effort to enumerate and implement all possible actions, which becomes impractical in complex environments with a vast number of potential actions. In this work, we propose an LLM agent framework that enables the dynamic creation and composition of actions in an online manner. In this framework, the agent interacts with the environment by generating and executing programs written in a general-purpose programming language at each step. Furthermore, generated actions are accumulated over time for future reuse. Our extensive experiments on the GAIA benchmark demonstrate that this framework offers significantly greater flexibility and outperforms previous methods. Notably, it allows an LLM agent to recover in scenarios where no relevant action exists in the predefined set or when existing actions fail due to unforeseen edge cases. At the time of writing, we hold the top position on the GAIA public leaderboard. Our code can be found in \\href{https://github.com/adobe-research/dynasaur}{https://github.com/adobe-research/dynasaur}.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.01747"
    },
    "95ede89c08bbb54504d36c13b0b1e7ec": {
        "title": "Positive Experience Reflection for Agents in Interactive Text Environments",
        "authors": [
            "Philip Lippmann",
            "Matthijs T. J. Spaan",
            "Jie Yang"
        ],
        "date": "2024/11/04",
        "pdf": "http://arxiv.org/pdf/2411.02223",
        "abstract": "Intelligent agents designed for interactive environments face significant challenges in text-based games, a domain that demands complex reasoning and adaptability. While agents based on large language models (LLMs) using self-reflection have shown promise, they struggle when initially successful and exhibit reduced effectiveness when using smaller LLMs. We introduce Sweet&amp;Sour, a novel approach that addresses these limitations in existing reflection methods by incorporating positive experiences and managed memory to enrich the context available to the agent at decision time. Our comprehensive analysis spans both closed- and open-source LLMs and demonstrates the effectiveness of Sweet&amp;Sour in improving agent performance, particularly in scenarios where previous approaches fall short.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.02223"
    },
    "493bd6ae9da7a0e47c1b2706a8b376fa": {
        "title": "CRMArena: Understanding the Capacity of LLM Agents to Perform Professional CRM Tasks in Realistic Environments",
        "authors": [
            "Kung-Hsiang Huang",
            "Akshara Prabhakar",
            "Sidharth Dhawan",
            "Yixin Mao",
            "Huan Wang",
            "Silvio Savarese",
            "Caiming Xiong",
            "Philippe Laban",
            "Chien-Sheng Wu"
        ],
        "date": "2024/11/04",
        "pdf": "http://arxiv.org/pdf/2411.02305",
        "abstract": "Customer Relationship Management (CRM) systems are vital for modern enterprises, providing a foundation for managing customer interactions and data. Integrating AI agents into CRM systems can automate routine processes and enhance personalized service. However, deploying and evaluating these agents is challenging due to the lack of realistic benchmarks that reflect the complexity of real-world CRM tasks. To address this issue, we introduce CRMArena, a novel benchmark designed to evaluate AI agents on realistic tasks grounded in professional work environments. Following guidance from CRM experts and industry best practices, we designed CRMArena with nine customer service tasks distributed across three personas: service agent, analyst, and manager. The benchmark includes 16 commonly used industrial objects (e.g., account, order, knowledge article, case) with high interconnectivity, along with latent variables (e.g., complaint habits, policy violations) to simulate realistic data distributions. Experimental results reveal that state-of-the-art LLM agents succeed in less than 40% of the tasks with ReAct prompting, and less than 55% even with function-calling abilities. Our findings highlight the need for enhanced agent capabilities in function-calling and rule-following to be deployed in real-world work environments. CRMArena is an open challenge to the community: systems that can reliably complete tasks showcase direct business value in a popular work environment.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.02305"
    },
    "a6024600912abd0cf9bd4fbabea337bc": {
        "title": "WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning",
        "authors": [
            "Zehan Qi",
            "Xiao Liu",
            "Iat Long Iong",
            "Hanyu Lai",
            "Xueqiao Sun",
            "Wenyi Zhao",
            "Yu Yang",
            "Xinyue Yang",
            "Jiadai Sun",
            "Shuntian Yao",
            "Tianjie Zhang",
            "Wei Xu",
            "Jie Tang",
            "Yuxiao Dong"
        ],
        "date": "2024/11/04",
        "pdf": "http://arxiv.org/pdf/2411.02337",
        "abstract": "Large language models (LLMs) have shown remarkable potential as autonomous agents, particularly in web-based tasks. However, existing LLM web agents heavily rely on expensive proprietary LLM APIs, while open LLMs lack the necessary decision-making capabilities. This paper introduces WebRL, a self-evolving online curriculum reinforcement learning framework designed to train high-performance web agents using open LLMs. WebRL addresses three key challenges in building LLM web agents, including the scarcity of training tasks, sparse feedback signals, and policy distribution drift in online learning. Specifically, WebRL incorporates 1) a self-evolving curriculum that generates new tasks from unsuccessful attempts, 2) a robust outcome-supervised reward model (ORM), and 3) adaptive reinforcement learning strategies to ensure consistent improvements. We apply WebRL to transform open Llama-3.1 and GLM-4 models into proficient web agents. On WebArena-Lite, WebRL improves the success rate of Llama-3.1-8B from 4.8% to 42.4%, and from 6.1% to 43% for GLM-4-9B. These open models significantly surpass the performance of GPT-4-Turbo (17.6%) and GPT-4o (13.9%) and outperform previous state-of-the-art web agents trained on open LLMs (AutoWebGLM, 18.2%). Our findings demonstrate WebRL&#39;s effectiveness in bridging the gap between open and proprietary LLM-based web agents, paving the way for more accessible and powerful autonomous web interaction systems.",
        "code": "",
        "category": [
            [
                "Training",
                "RL"
            ],
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.02337"
    },
    "a00b727f39d6e27a0aebc226417dc2c2": {
        "title": "Attacking Vision-Language Computer Agents via Pop-ups",
        "authors": [
            "Yanzhe Zhang",
            "Tao Yu",
            "Diyi Yang"
        ],
        "date": "2024/11/04",
        "pdf": "http://arxiv.org/pdf/2411.02391",
        "abstract": "Autonomous agents powered by large vision and language models (VLM) have demonstrated significant potential in completing daily computer tasks, such as browsing the web to book travel and operating desktop software, which requires agents to understand these interfaces. Despite such visual inputs becoming more integrated into agentic applications, what types of risks and attacks exist around them still remain unclear. In this work, we demonstrate that VLM agents can be easily attacked by a set of carefully designed adversarial pop-ups, which human users would typically recognize and ignore. This distraction leads agents to click these pop-ups instead of performing the tasks as usual. Integrating these pop-ups into existing agent testing environments like OSWorld and VisualWebArena leads to an attack success rate (the frequency of the agent clicking the pop-ups) of 86% on average and decreases the task success rate by 47%. Basic defense techniques such as asking the agent to ignore pop-ups or including an advertisement notice, are ineffective against the attack.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ],
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.02391"
    },
    "27bf554b81fd0c736898036915b5bc34": {
        "title": "A Multi-Task Role-Playing Agent Capable of Imitating Character Linguistic Styles",
        "authors": [
            "Siyuan Chen",
            "Qingyi Si",
            "Chenxu Yang",
            "Yunzhi Liang",
            "Zheng Lin",
            "Huan Liu",
            "Weiping Wang"
        ],
        "date": "2024/11/04",
        "pdf": "http://arxiv.org/pdf/2411.02457",
        "abstract": "The advent of large language models (LLMs) has significantly propelled the advancement of Role-Playing Agents (RPAs). However, current Role-Playing Agents predominantly focus on mimicking a character&#39;s fundamental attributes while neglecting the replication of linguistic style, and they are incapable of effectively replicating characters when performing tasks beyond multi-turn dialogues, which results in generated responses that lack authenticity. The reason current RPAs lack this capability is due to the nature of existing character datasets, which lack collections of character quotations and are limited to multi-turn dialogue tasks, constraining the RPA&#39;s performance across other task domains and failing to mimic a character&#39;s linguistic style. To address this gap, we developed a multi-task role-playing dataset named MRstyle, which encompasses a substantial number of real individuals along with their quotations and covers seven different tasks. On this basis, we develop StyleRPA, a Multi-Task Role-Playing Agent (MRPA) that significantly outperforms recent open-source LLMs and RPAs baselines on 7 tasks including Dialogue, Dictionary, Composition, Story Generation, Product Description, Music Commentary, and Open Question Answering. The code and data will be released.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.02457"
    },
    "747145ec88fbcde21d8b8c020ead2d62": {
        "title": "Benchmarking Multimodal Retrieval Augmented Generation with Dynamic VQA Dataset and Self-adaptive Planning Agent",
        "authors": [
            "Yangning Li",
            "Yinghui Li",
            "Xinyu Wang",
            "Yong Jiang",
            "Zhen Zhang",
            "Xinran Zheng",
            "Hui Wang",
            "Hai-Tao Zheng",
            "Pengjun Xie",
            "Philip S. Yu",
            "Fei Huang",
            "Jingren Zhou"
        ],
        "date": "2024/11/05",
        "pdf": "http://arxiv.org/pdf/2411.02937",
        "abstract": "Multimodal Retrieval Augmented Generation (mRAG) plays an important role in mitigating the &#34;hallucination&#34; issue inherent in multimodal large language models (MLLMs). Although promising, existing heuristic mRAGs typically predefined fixed retrieval processes, which causes two issues: (1) Non-adaptive Retrieval Queries. (2) Overloaded Retrieval Queries. However, these flaws cannot be adequately reflected by current knowledge-seeking visual question answering (VQA) datasets, since the most required knowledge can be readily obtained with a standard two-step retrieval. To bridge the dataset gap, we first construct Dyn-VQA dataset, consisting of three types of &#34;dynamic&#34; questions, which require complex knowledge retrieval strategies variable in query, tool, and time: (1) Questions with rapidly changing answers. (2) Questions requiring multi-modal knowledge. (3) Multi-hop questions. Experiments on Dyn-VQA reveal that existing heuristic mRAGs struggle to provide sufficient and precisely relevant knowledge for dynamic questions due to their rigid retrieval processes. Hence, we further propose the first self-adaptive planning agent for multimodal retrieval, OmniSearch. The underlying idea is to emulate the human behavior in question solution which dynamically decomposes complex multimodal questions into sub-question chains with retrieval action. Extensive experiments prove the effectiveness of our OmniSearch, also provide direction for advancing mRAG. The code and dataset will be open-sourced at https://github.com/Alibaba-NLP/OmniSearch.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ],
            [
                "Technique For Enhancement",
                "Planning"
            ],
            [
                "Technique For Enhancement",
                "RAG"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.02937"
    },
    "bf9ac2a3c7d0d51487348abbb81e84c6": {
        "title": "SAUCE: Synchronous and Asynchronous User-Customizable Environment for Multi-Agent LLM Interaction",
        "authors": [
            "Shlomo Neuberger",
            "Niv Eckhaus",
            "Uri Berger",
            "Amir Taubenfeld",
            "Gabriel Stanovsky",
            "Ariel Goldstein"
        ],
        "date": "2024/11/05",
        "pdf": "http://arxiv.org/pdf/2411.03397",
        "abstract": "Many human interactions, such as political debates, are carried out in group settings, where there are arbitrarily many participants, each with different views and agendas. To explore such complex social settings, we present SAUCE: a customizable Python platform, allowing researchers to plug-and-play various LLMs participating in discussions on any topic chosen by the user. Our platform takes care of instantiating the models, scheduling their responses, managing the discussion history, and producing a comprehensive output log, all customizable through configuration files, requiring little to no coding skills. A novel feature of SAUCE is our asynchronous communication feature, where models decide when to speak in addition to what to say, thus modeling an important facet of human communication. We show SAUCE&#39;s attractiveness in two initial experiments, and invite the community to use it in simulating various group simulations.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Environment&Platform"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.03397"
    },
    "72633ec04a266e65bcd0254e02ad14e7": {
        "title": "CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models",
        "authors": [
            "Jierui Li",
            "Hung Le",
            "Yingbo Zhou",
            "Caiming Xiong",
            "Silvio Savarese",
            "Doyen Sahoo"
        ],
        "date": "2024/11/07",
        "pdf": "http://arxiv.org/pdf/2411.04329",
        "abstract": "Pre-trained on massive amounts of code and text data, large language models (LLMs) have demonstrated remarkable achievements in performing code generation tasks. With additional execution-based feedback, these models can act as agents with capabilities to self-refine and improve generated code autonomously. However, on challenging coding tasks with extremely large search space, current agentic approaches still struggle with multi-stage planning, generating, and debugging. To address this problem, we propose CodeTree, a framework for LLM agents to efficiently explore the search space in different stages of the code generation process. Specifically, we adopted a unified tree structure to explicitly explore different coding strategies, generate corresponding coding solutions, and subsequently refine the solutions. In each stage, critical decision-making (ranking, termination, expanding) of the exploration process is guided by both the environmental execution-based feedback and LLM-agent-generated feedback. We comprehensively evaluated CodeTree on 7 code generation benchmarks and demonstrated the significant performance gains of CodeTree against strong baselines. Using GPT-4o as the base model, we consistently achieved top results of 95.1 on HumanEval, 98.7 on MBPP, and 43.0 on CodeContests. On the challenging SWEBench benchmark, our approach led to significant performance gains.",
        "code": "",
        "category": [
            [
                "Application",
                "Software Engineering"
            ],
            [
                "Technique For Enhancement",
                "Search"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.04329"
    },
    "77945f4938ebd9cee80e768cc3055bee": {
        "title": "Thanos: Enhancing Conversational Agents with Skill-of-Mind-Infused Large Language Model",
        "authors": [
            "Young-Jun Lee",
            "Dokyong Lee",
            "Junyoung Youn",
            "Kyeongjin Oh",
            "Ho-Jin Choi"
        ],
        "date": "2024/11/07",
        "pdf": "http://arxiv.org/pdf/2411.04496",
        "abstract": "To increase social bonding with interlocutors, humans naturally acquire the ability to respond appropriately in a given situation by considering which conversational skill is most suitable for the response - a process we call skill-of-mind. For large language model (LLM)-based conversational agents, planning appropriate conversational skills, as humans do, is challenging due to the complexity of social dialogue, especially in interactive scenarios. To address this, we propose a skill-of-mind-annotated conversation dataset, named Multifaceted Skill-of-Mind, which includes multi-turn and multifaceted conversational skills across various interactive scenarios (e.g., long-term, counseling, task-oriented), grounded in diverse social contexts (e.g., demographics, persona, rules of thumb). This dataset consists of roughly 100K conversations. Using this dataset, we introduce a new family of skill-of-mind-infused LLMs, named Thanos, with model sizes of 1B, 3B, and 8B parameters. With extensive experiments, these models successfully demonstrate the skill-of-mind process and exhibit strong generalizability in inferring multifaceted skills across a variety of domains. Moreover, we show that Thanos significantly enhances the quality of responses generated by LLM-based conversational agents and promotes prosocial behavior in human evaluations.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.04496"
    },
    "4fe6fec96e86645c0064d0518d01f727": {
        "title": "Towards Low-Resource Harmful Meme Detection with LMM Agents",
        "authors": [
            "Jianzhao Huang",
            "Hongzhan Lin",
            "Ziyan Liu",
            "Ziyang Luo",
            "Guang Chen",
            "Jing Ma"
        ],
        "date": "2024/11/08",
        "pdf": "http://arxiv.org/pdf/2411.05383",
        "abstract": "The proliferation of Internet memes in the age of social media necessitates effective identification of harmful ones. Due to the dynamic nature of memes, existing data-driven models may struggle in low-resource scenarios where only a few labeled examples are available. In this paper, we propose an agency-driven framework for low-resource harmful meme detection, employing both outward and inward analysis with few-shot annotated samples. Inspired by the powerful capacity of Large Multimodal Models (LMMs) on multimodal reasoning, we first retrieve relative memes with annotations to leverage label information as auxiliary signals for the LMM agent. Then, we elicit knowledge-revising behavior within the LMM agent to derive well-generalized insights into meme harmfulness. By combining these strategies, our approach enables dialectical reasoning over intricate and implicit harm-indicative patterns. Extensive experiments conducted on three meme datasets demonstrate that our proposed approach achieves superior performance than state-of-the-art methods on the low-resource harmful meme detection task.",
        "code": "",
        "category": [
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.05383"
    },
    "7bfcb7676c0cd32832964d55977a5823": {
        "title": "Mixture of Knowledge Minigraph Agents for Literature Review Generation",
        "authors": [
            "Zhi Zhang",
            "Yan Liu",
            "Sheng-hua Zhong",
            "Gong Chen",
            "Yu Yang",
            "Jiannong Cao"
        ],
        "date": "2024/11/09",
        "pdf": "http://arxiv.org/pdf/2411.06159",
        "abstract": "Literature reviews play a crucial role in scientific research for understanding the current state of research, identifying gaps, and guiding future studies on specific topics. However, the process of conducting a comprehensive literature review is yet time-consuming. This paper proposes a novel framework, collaborative knowledge minigraph agents (CKMAs), to automate scholarly literature reviews. A novel prompt-based algorithm, the knowledge minigraph construction agent (KMCA), is designed to identify relations between concepts from academic literature and automatically constructs knowledge minigraphs. By leveraging the capabilities of large language models on constructed knowledge minigraphs, the multiple path summarization agent (MPSA) efficiently organizes concepts and relations from different viewpoints to generate literature review paragraphs. We evaluate CKMAs on three benchmark datasets. Experimental results show the effectiveness of the proposed method, further revealing promising applications of LLMs in scientific research.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.06159"
    },
    "6f9f654dcca1a89902e8aad4db0cc863": {
        "title": "Using Generative AI and Multi-Agents to Provide Automatic Feedback",
        "authors": [
            "Shuchen Guo",
            "Ehsan Latif",
            "Yifan Zhou",
            "Xuan Huang",
            "Xiaoming Zhai"
        ],
        "date": "2024/11/11",
        "pdf": "http://arxiv.org/pdf/2411.07407",
        "abstract": "This study investigates the use of generative AI and multi-agent systems to provide automatic feedback in educational contexts, particularly for student constructed responses in science assessments. The research addresses a key gap in the field by exploring how multi-agent systems, called AutoFeedback, can improve the quality of GenAI-generated feedback, overcoming known issues such as over-praise and over-inference that are common in single-agent large language models (LLMs). The study developed a multi-agent system consisting of two AI agents: one for generating feedback and another for validating and refining it. The system was tested on a dataset of 240 student responses, and its performance was compared to that of a single-agent LLM. Results showed that AutoFeedback significantly reduced the occurrence of over-praise and over-inference errors, providing more accurate and pedagogically sound feedback. The findings suggest that multi-agent systems can offer a more reliable solution for generating automated feedback in educational settings, highlighting their potential for scalable and personalized learning support. These results have important implications for educators and researchers seeking to leverage AI in formative assessments, offering a pathway to more effective feedback mechanisms that enhance student learning outcomes.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.07407"
    },
    "0d65614b30d851d877806b6804f0e12a": {
        "title": "Mitigating Bias in Queer Representation within Large Language Models: A Collaborative Agent Approach",
        "authors": [
            "Tianyi Huang",
            "Arya Somasundaram"
        ],
        "date": "2024/11/12",
        "pdf": "http://arxiv.org/pdf/2411.07656",
        "abstract": "Large Language Models (LLMs) often perpetuate biases in pronoun usage, leading to misrepresentation or exclusion of queer individuals. This paper addresses the specific problem of biased pronoun usage in LLM outputs, particularly the inappropriate use of traditionally gendered pronouns (&#34;he,&#34; &#34;she&#34;) when inclusive language is needed to accurately represent all identities. We introduce a collaborative agent pipeline designed to mitigate these biases by analyzing and optimizing pronoun usage for inclusivity. Our multi-agent framework includes specialized agents for both bias detection and correction. Experimental evaluations using the Tango dataset-a benchmark focused on gender pronoun usage-demonstrate that our approach significantly improves inclusive pronoun classification, achieving a 32.6 percentage point increase over GPT-4o in correctly disagreeing with inappropriate traditionally gendered pronouns $(\\chi^2 = 38.57, p &lt; 0.0001)$. These results accentuate the potential of agent-driven frameworks in enhancing fairness and inclusivity in AI-generated content, demonstrating their efficacy in reducing biases and promoting socially responsible AI.",
        "code": "",
        "category": [
            [
                "Stability",
                "Bias"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.07656"
    },
    "afcc05f016d1ae6bbda7576849bd997f": {
        "title": "SHARP: Unlocking Interactive Hallucination via Stance Transfer in Role-Playing Agents",
        "authors": [
            "Chuyi Kong",
            "Ziyang Luo",
            "Hongzhan Lin",
            "Zhiyuan Fan",
            "Yaxin Fan",
            "Yuxi Sun",
            "Jing Ma"
        ],
        "date": "2024/11/12",
        "pdf": "http://arxiv.org/pdf/2411.07965",
        "abstract": "The advanced role-playing capabilities of Large Language Models (LLMs) have paved the way for developing Role-Playing Agents (RPAs). However, existing benchmarks in social interaction such as HPD and SocialBench have not investigated hallucination and face limitations like poor generalizability and implicit judgments for character fidelity. To address these issues, we propose a generalizable, explicit and effective paradigm to unlock the interactive patterns in diverse worldviews. Specifically, we define the interactive hallucination based on stance transfer and construct a benchmark, SHARP, by extracting relations from a general commonsense knowledge graph and leveraging the inherent hallucination properties of RPAs to simulate interactions across roles. Extensive experiments validate the effectiveness and stability of our paradigm. Our findings further explore the factors influencing these metrics and discuss the trade-off between blind loyalty to roles and adherence to facts in RPAs.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ],
            [
                "Stability",
                "Hallucination"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.07965"
    },
    "c1780e3dd2b4cdadd4d9a49c04301616": {
        "title": "One STEP at a time: Language Agents are Stepwise Planners",
        "authors": [
            "Minh Nguyen",
            "Ehsan Shareghi"
        ],
        "date": "2024/11/13",
        "pdf": "http://arxiv.org/pdf/2411.08432",
        "abstract": "Language agents have shown promising adaptability in dynamic environments to perform complex tasks. However, despite the versatile knowledge embedded in large language models, these agents still fall short when it comes to tasks that require planning. We introduce STEP, a novel framework designed to efficiently learn from previous experiences to enhance the planning capabilities of language agents in future steps. Concretely, STEP functions through four interconnected components. First, the Planner takes on the task, breaks it down into subtasks and provides relevant insights. Then the Executor generates action candidates, while the Evaluator ensures the actions align with learned rules from previous experiences. Lastly, Memory stores experiences to inform future decisions. In the ScienceWorld benchmark, our results show that STEP consistently outperforms state-of-the-art models, achieving an overall score of 67.4 and successfully completing 12 out of 18 tasks. These findings highlight STEP&#39;s potential as a framework for enhancing planning capabilities in language agents, paving the way for more sophisticated task-solving in dynamic environments.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.08432"
    },
    "21df2d2067039268ad60cf8fb2846fcb": {
        "title": "Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction",
        "authors": [
            "Sonny George",
            "Chris Sypherd",
            "Dylan Cashman"
        ],
        "date": "2024/11/19",
        "pdf": "http://arxiv.org/pdf/2411.12828",
        "abstract": "Large language model (LLM) agents show promise in an increasing number of domains. In many proposed applications, it is expected that the agent reasons over accumulated experience presented in an input prompt. We propose the OEDD (Operationalize Experience Despite Distraction) corpus, a human-annotator-validated body of scenarios with pre-scripted agent histories where the agent must make a decision based on disparate experiential information in the presence of a distractor. We evaluate three state-of-the-art LLMs (GPT-3.5 Turbo, GPT-4o, and Gemini 1.5 Pro) using a minimal chain-of-thought prompting strategy and observe that when (1) the input context contains over 1,615 tokens of historical interactions, (2) a crucially decision-informing premise is the rightful conclusion over two disparate environment premises, and (3) a trivial, but distracting red herring fact follows, all LLMs perform worse than random choice at selecting the better of two actions. Our code and test corpus are publicly available at: https://github.com/sonnygeorge/OEDD .",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.12828"
    },
    "55f76bd329c940644fce2b65b67fc877": {
        "title": "PIORS: Personalized Intelligent Outpatient Reception based on Large Language Model with Multi-Agents Medical Scenario Simulation",
        "authors": [
            "Zhijie Bao",
            "Qingyun Liu",
            "Ying Guo",
            "Zhengqiang Ye",
            "Jun Shen",
            "Shirong Xie",
            "Jiajie Peng",
            "Xuanjing Huang",
            "Zhongyu Wei"
        ],
        "date": "2024/11/21",
        "pdf": "http://arxiv.org/pdf/2411.13902",
        "abstract": "In China, receptionist nurses face overwhelming workloads in outpatient settings, limiting their time and attention for each patient and ultimately reducing service quality. In this paper, we present the Personalized Intelligent Outpatient Reception System (PIORS). This system integrates an LLM-based reception nurse and a collaboration between LLM and hospital information system (HIS) into real outpatient reception setting, aiming to deliver personalized, high-quality, and efficient reception services. Additionally, to enhance the performance of LLMs in real-world healthcare scenarios, we propose a medical conversational data generation framework named Service Flow aware Medical Scenario Simulation (SFMSS), aiming to adapt the LLM to the real-world environments and PIORS settings. We evaluate the effectiveness of PIORS and SFMSS through automatic and human assessments involving 15 users and 15 clinical experts. The results demonstrate that PIORS-Nurse outperforms all baselines, including the current state-of-the-art model GPT-4o, and aligns with human preferences and clinical needs. Further details and demo can be found at https://github.com/FudanDISC/PIORS",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.13902"
    },
    "77e16e168e86cd3724e76fbcc1148c4c": {
        "title": "Towards Full Delegation: Designing Ideal Agentic Behaviors for Travel Planning",
        "authors": [
            "Song Jiang",
            "Da JU",
            "Andrew Cohen",
            "Sasha Mitts",
            "Aaron Foss",
            "Justine T Kao",
            "Xian Li",
            "Yuandong Tian"
        ],
        "date": "2024/11/21",
        "pdf": "http://arxiv.org/pdf/2411.13904",
        "abstract": "How are LLM-based agents used in the future? While many of the existing work on agents has focused on improving the performance of a specific family of objective and challenging tasks, in this work, we take a different perspective by thinking about full delegation: agents take over humans&#39; routine decision-making processes and are trusted by humans to find solutions that fit people&#39;s personalized needs and are adaptive to ever-changing context. In order to achieve such a goal, the behavior of the agents, i.e., agentic behaviors, should be evaluated not only on their achievements (i.e., outcome evaluation), but also how they achieved that (i.e., procedure evaluation). For this, we propose APEC Agent Constitution, a list of criteria that an agent should follow for good agentic behaviors, including Accuracy, Proactivity, Efficiency and Credibility. To verify whether APEC aligns with human preferences, we develop APEC-Travel, a travel planning agent that proactively extracts hidden personalized needs via multi-round dialog with travelers. APEC-Travel is constructed purely from synthetic data generated by Llama3.1-405B-Instruct with a diverse set of travelers&#39; persona to simulate rich distribution of dialogs. Iteratively fine-tuned to follow APEC Agent Constitution, APEC-Travel surpasses baselines by 20.7% on rule-based metrics and 9.1% on LLM-as-a-Judge scores across the constitution axes.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.13904"
    },
    "a2f0097818923ece58ab50a26a2e4463": {
        "title": "Towards Next-Generation Medical Agent: How o1 is Reshaping Decision-Making in Medical Scenarios",
        "authors": [
            "Shaochen Xu",
            "Yifan Zhou",
            "Zhengliang Liu",
            "Zihao Wu",
            "Tianyang Zhong",
            "Huaqin Zhao",
            "Yiwei Li",
            "Hanqi Jiang",
            "Yi Pan",
            "Junhao Chen",
            "Jin Lu",
            "Wei Zhang",
            "Tuo Zhang",
            "Lu Zhang",
            "Dajiang Zhu",
            "Xiang Li",
            "Wei Liu",
            "Quanzheng Li",
            "Andrea Sikora",
            "Xiaoming Zhai",
            "Zhen Xiang",
            "Tianming Liu"
        ],
        "date": "2024/11/16",
        "pdf": "http://arxiv.org/pdf/2411.14461",
        "abstract": "Artificial Intelligence (AI) has become essential in modern healthcare, with large language models (LLMs) offering promising advances in clinical decision-making. Traditional model-based approaches, including those leveraging in-context demonstrations and those with specialized medical fine-tuning, have demonstrated strong performance in medical language processing but struggle with real-time adaptability, multi-step reasoning, and handling complex medical tasks. Agent-based AI systems address these limitations by incorporating reasoning traces, tool selection based on context, knowledge retrieval, and both short- and long-term memory. These additional features enable the medical AI agent to handle complex medical scenarios where decision-making should be built on real-time interaction with the environment. Therefore, unlike conventional model-based approaches that treat medical queries as isolated questions, medical AI agents approach them as complex tasks and behave more like human doctors. In this paper, we study the choice of the backbone LLM for medical AI agents, which is the foundation for the agent&#39;s overall reasoning and action generation. In particular, we consider the emergent o1 model and examine its impact on agents&#39; reasoning, tool-use adaptability, and real-time information retrieval across diverse clinical scenarios, including high-stakes settings such as intensive care units (ICUs). Our findings demonstrate o1&#39;s ability to enhance diagnostic accuracy and consistency, paving the way for smarter, more responsive AI tools that support better patient outcomes and decision-making efficacy in clinical practice.",
        "code": "",
        "category": [
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.14461"
    },
    "63d7e59118063bab7335ed48bea024d3": {
        "title": "Star-Agents: Automatic Data Optimization with LLM Agents for Instruction Tuning",
        "authors": [
            "Hang Zhou",
            "Yehui Tang",
            "Haochen Qin",
            "Yujie Yang",
            "Renren Jin",
            "Deyi Xiong",
            "Kai Han",
            "Yunhe Wang"
        ],
        "date": "2024/11/21",
        "pdf": "http://arxiv.org/pdf/2411.14497",
        "abstract": "The efficacy of large language models (LLMs) on downstream tasks usually hinges on instruction tuning, which relies critically on the quality of training data. Unfortunately, collecting high-quality and diverse data is both expensive and time-consuming. To mitigate this issue, we propose a novel Star-Agents framework, which automates the enhancement of data quality across datasets through multi-agent collaboration and assessment. The framework adopts a three-pronged strategy. It initially generates diverse instruction data with multiple LLM agents through a bespoke sampling method. Subsequently, the generated data undergo a rigorous evaluation using a dual-model method that assesses both difficulty and quality. Finaly, the above process evolves in a dynamic refinement phase, where more effective LLMs are prioritized, enhancing the overall data quality. Our empirical studies, including instruction tuning experiments with models such as Pythia and LLaMA, demonstrate the effectiveness of the proposed framework. Optimized datasets have achieved substantial improvements, with an average increase of 12% and notable gains in specific metrics, such as a 40% improvement in Fermi, as evidenced by benchmarks like MT-bench, Vicuna bench, and WizardLM testset.",
        "code": "",
        "category": [
            [
                "Training",
                "Fine tuning"
            ],
            [
                "Infrastructure",
                "Dataset"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.14497"
    },
    "2f0fd180d3792d642b7ac6396b3ca2fe": {
        "title": "ScribeAgent: Towards Specialized Web Agents Using Production-Scale Workflow Data",
        "authors": [
            "Junhong Shen",
            "Atishay Jain",
            "Zedian Xiao",
            "Ishan Amlekar",
            "Mouad Hadji",
            "Aaron Podolny",
            "Ameet Talwalkar"
        ],
        "date": "2024/11/22",
        "pdf": "http://arxiv.org/pdf/2411.15004",
        "abstract": "Large Language Model (LLM) agents are rapidly improving to handle increasingly complex web-based tasks. Most of these agents rely on general-purpose, proprietary models like GPT-4 and focus on designing better prompts to improve their planning abilities. However, general-purpose LLMs are not specifically trained to understand specialized web contexts such as HTML, and they often struggle with long-horizon planning. We explore an alternative approach that fine-tunes open-source LLMs using production-scale workflow data collected from over 250 domains corresponding to 6 billion tokens. This simple yet effective approach shows substantial gains over prompting-based agents on existing benchmarks -- ScribeAgent achieves state-of-the-art direct generation performance on Mind2Web and improves the task success rate by 7.3% over the previous best text-only web agents on WebArena. We further perform detailed ablation studies on various fine-tuning design choices and provide insights into LLM selection, training recipes, context window optimization, and effect of dataset sizes.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ],
            [
                "Automation",
                "Workflow"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.15004"
    },
    "2cb39e4535378b3fdb12346aa4ed3a30": {
        "title": "SAGEval: The frontiers of Satisfactory Agent based NLG Evaluation for reference-free open-ended text",
        "authors": [
            "Reshmi Ghosh",
            "Tianyi Yao",
            "Lizzy Chen",
            "Sadid Hasan",
            "Tianwei Chen",
            "Dario Bernal",
            "Huitian Jiao",
            "H M Sajjad Hossain"
        ],
        "date": "2024/11/25",
        "pdf": "http://arxiv.org/pdf/2411.16077",
        "abstract": "Large Language Model (LLM) integrations into applications like Microsoft365 suite and Google Workspace for creating/processing documents, emails, presentations, etc. has led to considerable enhancements in productivity and time savings. But as these integrations become more more complex, it is paramount to ensure that the quality of output from the LLM-integrated applications are relevant and appropriate for use. Identifying the need to develop robust evaluation approaches for natural language generation, wherein references/ground labels doesn&#39;t exist or isn&#39;t amply available, this paper introduces a novel framework called &#34;SAGEval&#34; which utilizes a critiquing Agent to provide feedback on scores generated by LLM evaluators. We show that the critiquing Agent is able to rectify scores from LLM evaluators, in absence of references/ground-truth labels, thereby reducing the need for labeled data even for complex NLG evaluation scenarios, like the generation of JSON-structured forms/surveys with responses in different styles like multiple choice, likert ratings, single choice questions, etc.",
        "code": "",
        "category": [
            [
                "Automation",
                "Automatic Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.16077"
    },
    "ccd4030d40d4592c7a3dabd50b7128d7": {
        "title": "Enhancing LLMs for Power System Simulations: A Feedback-driven Multi-agent Framework",
        "authors": [
            "Mengshuo Jia",
            "Zeyu Cui",
            "Gabriela Hug"
        ],
        "date": "2024/11/21",
        "pdf": "http://arxiv.org/pdf/2411.16707",
        "abstract": "The integration of experimental technologies with large language models (LLMs) is transforming scientific research, positioning AI as a versatile research assistant rather than a mere problem-solving tool. In the field of power systems, however, managing simulations -- one of the essential experimental technologies -- remains a challenge for LLMs due to their limited domain-specific knowledge, restricted reasoning capabilities, and imprecise handling of simulation parameters. To address these limitations, we propose a feedback-driven, multi-agent framework that incorporates three proposed modules: an enhanced retrieval-augmented generation (RAG) module, an improved reasoning module, and a dynamic environmental acting module with an error-feedback mechanism. Validated on 69 diverse tasks from Daline and MATPOWER, this framework achieves success rates of 93.13% and 96.85%, respectively, significantly outperforming the latest LLMs (ChatGPT 4o and o1-preview), which achieved a 27.77% success rate on standard simulation tasks and 0% on complex tasks. Additionally, our framework also supports rapid, cost-effective task execution, completing each simulation in approximately 30 seconds at an average cost of 0.014 USD for tokens. Overall, this adaptable framework lays a foundation for developing intelligent LLM-based assistants for human researchers, facilitating power system research and beyond.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.16707"
    },
    "a56a97848d2bbc9bfd47d7d2048dbb95": {
        "title": "Training Agents with Weakly Supervised Feedback from Large Language Models",
        "authors": [
            "Dihong Gong",
            "Pu Lu",
            "Zelong Wang",
            "Meng Zhou",
            "Xiuqiang He"
        ],
        "date": "2024/11/29",
        "pdf": "http://arxiv.org/pdf/2411.19547",
        "abstract": "Large Language Models (LLMs) offer a promising basis for creating agents that can tackle complex tasks through iterative environmental interaction. Existing methods either require these agents to mimic expert-provided trajectories or rely on definitive environmental feedback for reinforcement learning which limits their application to specific scenarios like gaming or code generation. This paper introduces a novel training method for LLM-based agents using weakly supervised signals from a critic LLM, bypassing the need for expert trajectories or definitive feedback. Our agents are trained in iterative manner, where they initially generate trajectories through environmental interaction. Subsequently, a critic LLM selects a subset of good trajectories, which are then used to update the agents, enabling them to generate improved trajectories in the next iteration. Extensive tests on the API-bank dataset show consistent improvement in our agents&#39; capabilities and comparable performance to GPT-4, despite using open-source models with much fewer parameters.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ],
            [
                "Training",
                "Fine tuning"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.19547"
    },
    "0ac837041dfa4e8ea7acc19954756d95": {
        "title": "AutoGLM: Autonomous Foundation Agents for GUIs",
        "authors": [
            "Xiao Liu",
            "Bo Qin",
            "Dongzhu Liang",
            "Guang Dong",
            "Hanyu Lai",
            "Hanchen Zhang",
            "Hanlin Zhao",
            "Iat Long Iong",
            "Jiadai Sun",
            "Jiaqi Wang",
            "Junjie Gao",
            "Junjun Shan",
            "Kangning Liu",
            "Shudan Zhang",
            "Shuntian Yao",
            "Siyi Cheng",
            "Wentao Yao",
            "Wenyi Zhao",
            "Xinghan Liu",
            "Xinyi Liu",
            "Xinying Chen",
            "Xinyue Yang",
            "Yang Yang",
            "Yifan Xu",
            "Yu Yang",
            "Yujia Wang",
            "Yulin Xu",
            "Zehan Qi",
            "Yuxiao Dong",
            "Jie Tang"
        ],
        "date": "2024/10/28",
        "pdf": "http://arxiv.org/pdf/2411.00820",
        "abstract": "We present AutoGLM, a new series in the ChatGLM family, designed to serve as foundation agents for autonomous control of digital devices through Graphical User Interfaces (GUIs). While foundation models excel at acquiring human knowledge, they often struggle with decision-making in dynamic real-world environments, limiting their progress toward artificial general intelligence. This limitation underscores the importance of developing foundation agents capable of learning through autonomous environmental interactions by reinforcing existing models. Focusing on Web Browser and Phone as representative GUI scenarios, we have developed AutoGLM as a practical foundation agent system for real-world GUI interactions. Our approach integrates a comprehensive suite of techniques and infrastructures to create deployable agent systems suitable for user delivery. Through this development, we have derived two key insights: First, the design of an appropriate &#34;intermediate interface&#34; for GUI control is crucial, enabling the separation of planning and grounding behaviors, which require distinct optimization for flexibility and accuracy respectively. Second, we have developed a novel progressive training framework that enables self-evolving online curriculum reinforcement learning for AutoGLM. Our evaluations demonstrate AutoGLM&#39;s effectiveness across multiple domains. For web browsing, AutoGLM achieves a 55.2% success rate on VAB-WebArena-Lite (improving to 59.1% with a second attempt) and 96.2% on OpenTable evaluation tasks. In Android device control, AutoGLM attains a 36.2% success rate on AndroidLab (VAB-Mobile) and 89.7% on common tasks in popular Chinese APPs.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.00820"
    },
    "014be58e37dbcbe9438cb07d822be937": {
        "title": "Infant Agent: A Tool-Integrated, Logic-Driven Agent with Cost-Effective API Usage",
        "authors": [
            "Bin Lei",
            "Yuchen Li",
            "Yiming Zeng",
            "Tao Ren",
            "Yi Luo",
            "Tianyu Shi",
            "Zitian Gao",
            "Zeyu Hu",
            "Weitai Kang",
            "Qiuwu Chen"
        ],
        "date": "2024/11/02",
        "pdf": "http://arxiv.org/pdf/2411.01114",
        "abstract": "Despite the impressive capabilities of large language models (LLMs), they currently exhibit two primary limitations, \\textbf{\\uppercase\\expandafter{\\romannumeral 1}}: They struggle to \\textbf{autonomously solve the real world engineering problem}. \\textbf{\\uppercase\\expandafter{\\romannumeral 2}}: They remain \\textbf{challenged in reasoning through complex logic problems}. To address these challenges, we developed the \\textsc{Infant Agent}, integrating task-aware functions, operators, a hierarchical management system, and a memory retrieval mechanism. Together, these components enable large language models to sustain extended reasoning processes and handle complex, multi-step tasks efficiently, all while significantly reducing API costs. Using the \\textsc{Infant Agent}, GPT-4o&#39;s accuracy on the SWE-bench-lite dataset rises from $\\mathbf{0.33\\%}$ to $\\mathbf{30\\%}$, and in the AIME-2024 mathematics competition, it increases GPT-4o&#39;s accuracy from $\\mathbf{13.3\\%}$ to $\\mathbf{37\\%}$.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.01114"
    },
    "5fcf0694bf04604462993d6cf79bef73": {
        "title": "EcoAct: Economic Agent Determines When to Register What Action",
        "authors": [
            "Shaokun Zhang",
            "Jieyu Zhang",
            "Dujian Ding",
            "Mirian Hipolito Garcia",
            "Ankur Mallick",
            "Daniel Madrigal",
            "Menglin Xia",
            "Victor RÃ¼hle",
            "Qingyun Wu",
            "Chi Wang"
        ],
        "date": "2024/11/03",
        "pdf": "http://arxiv.org/pdf/2411.01643",
        "abstract": "Recent advancements have enabled Large Language Models (LLMs) to function as agents that can perform actions using external tools. This requires registering, i.e., integrating tool information into the LLM context prior to taking actions. Current methods indiscriminately incorporate all candidate tools into the agent&#39;s context and retain them across multiple reasoning steps. This process remains opaque to LLM agents and is not integrated into their reasoning procedures, leading to inefficiencies due to increased context length from irrelevant tools. To address this, we introduce EcoAct, a tool using algorithm that allows LLMs to selectively register tools as needed, optimizing context use. By integrating the tool registration process into the reasoning procedure, EcoAct reduces computational costs by over 50% in multiple steps reasoning tasks while maintaining performance, as demonstrated through extensive experiments. Moreover, it can be plugged into any reasoning pipeline with only minor modifications to the prompt, making it applicable to LLM agents now and future.",
        "code": "",
        "category": [
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.01643"
    },
    "9cff1f7f18e383040e2b89a5b8503131": {
        "title": "SMoA: Improving Multi-agent Large Language Models with Sparse Mixture-of-Agents",
        "authors": [
            "Dawei Li",
            "Zhen Tan",
            "Peijia Qian",
            "Yifan Li",
            "Kumar Satvik Chaudhary",
            "Lijie Hu",
            "Jiayi Shen"
        ],
        "date": "2024/11/05",
        "pdf": "http://arxiv.org/pdf/2411.03284",
        "abstract": "While multi-agent systems have been shown to significantly enhance the performance of Large Language Models (LLMs) across various tasks and applications, the dense interaction between scaling agents potentially hampers their efficiency and diversity. To address these challenges, we draw inspiration from the sparse mixture-of-agents (SMoE) and propose a sparse mixture-of-agents (SMoA) framework to improve the efficiency and diversity of multi-agent LLMs. Unlike completely connected structures, SMoA introduces novel Response Selection and Early Stopping mechanisms to sparsify information flows among individual LLM agents, striking a balance between performance and efficiency. Additionally, inspired by the expert diversity principle in SMoE frameworks for workload balance between experts, we assign distinct role descriptions to each LLM agent, fostering diverse and divergent thinking. Extensive experiments on reasoning, alignment, and fairness benchmarks demonstrate that SMoA achieves performance comparable to traditional mixture-of-agents approaches but with significantly lower computational costs. Further analysis reveals that SMoA is more stable, has a greater capacity to scale, and offers considerable potential through hyper-parameter optimization. Code and data will be available at: https://github.com/David-Li0406/SMoA.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.03284"
    },
    "57a6019e36294fa0259a53bfd04fea8c": {
        "title": "MRJ-Agent: An Effective Jailbreak Agent for Multi-Round Dialogue",
        "authors": [
            "Fengxiang Wang",
            "Ranjie Duan",
            "Peng Xiao",
            "Xiaojun Jia",
            "Shiji Zhao",
            "Cheng Wei",
            "YueFeng Chen",
            "Chongwen Wang",
            "Jialing Tao",
            "Hang Su",
            "Jun Zhu",
            "Hui Xue"
        ],
        "date": "2024/11/06",
        "pdf": "http://arxiv.org/pdf/2411.03814",
        "abstract": "Large Language Models (LLMs) demonstrate outstanding performance in their reservoir of knowledge and understanding capabilities, but they have also been shown to be prone to illegal or unethical reactions when subjected to jailbreak attacks. To ensure their responsible deployment in critical applications, it is crucial to understand the safety capabilities and vulnerabilities of LLMs. Previous works mainly focus on jailbreak in single-round dialogue, overlooking the potential jailbreak risks in multi-round dialogues, which are a vital way humans interact with and extract information from LLMs. Some studies have increasingly concentrated on the risks associated with jailbreak in multi-round dialogues. These efforts typically involve the use of manually crafted templates or prompt engineering techniques. However, due to the inherent complexity of multi-round dialogues, their jailbreak performance is limited. To solve this problem, we propose a novel multi-round dialogue jailbreaking agent, emphasizing the importance of stealthiness in identifying and mitigating potential threats to human values posed by LLMs. We propose a risk decomposition strategy that distributes risks across multiple rounds of queries and utilizes psychological strategies to enhance attack strength. Extensive experiments show that our proposed method surpasses other attack methods and achieves state-of-the-art attack success rate. We will make the corresponding code and dataset available for future research. The code will be released soon.",
        "code": "",
        "category": [
            [
                "Stability",
                "Safety"
            ],
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.03814"
    },
    "56169ee7676c119635f159aa795dbb7f": {
        "title": "From Novice to Expert: LLM Agent Policy Optimization via Step-wise Reinforcement Learning",
        "authors": [
            "Zhirui Deng",
            "Zhicheng Dou",
            "Yutao Zhu",
            "Ji-Rong Wen",
            "Ruibin Xiong",
            "Mang Wang",
            "Weipeng Chen"
        ],
        "date": "2024/11/06",
        "pdf": "http://arxiv.org/pdf/2411.03817",
        "abstract": "The outstanding capabilities of large language models (LLMs) render them a crucial component in various autonomous agent systems. While traditional methods depend on the inherent knowledge of LLMs without fine-tuning, more recent approaches have shifted toward the reinforcement learning strategy to further enhance agents&#39; ability to solve complex interactive tasks with environments and tools. However, previous approaches are constrained by the sparse reward issue, where existing datasets solely provide a final scalar reward for each multi-step reasoning chain, potentially leading to ineffectiveness and inefficiency in policy learning. In this paper, we introduce StepAgent, which utilizes step-wise reward to optimize the agent&#39;s reinforcement learning process. Inheriting the spirit of novice-to-expert theory, we first compare the actions of the expert and the agent to automatically generate intermediate rewards for fine-grained optimization. Additionally, we propose implicit-reward and inverse reinforcement learning techniques to facilitate agent reflection and policy adjustment. Further theoretical analysis demonstrates that the action distribution of the agent can converge toward the expert action distribution over multiple training cycles. Experimental results across various datasets indicate that StepAgent outperforms existing baseline methods.",
        "code": "",
        "category": [
            [
                "Training",
                "RL"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.03817"
    },
    "81707e2deb5c979beebfb961235d4293": {
        "title": "Enhancing Investment Analysis: Optimizing AI-Agent Collaboration in Financial Research",
        "authors": [
            "Xuewen Han",
            "Neng Wang",
            "Shangkun Che",
            "Hongyang Yang",
            "Kunpeng Zhang",
            "Sean Xin Xu"
        ],
        "date": "2024/11/07",
        "pdf": "http://arxiv.org/pdf/2411.04788",
        "abstract": "In recent years, the application of generative artificial intelligence (GenAI) in financial analysis and investment decision-making has gained significant attention. However, most existing approaches rely on single-agent systems, which fail to fully utilize the collaborative potential of multiple AI agents. In this paper, we propose a novel multi-agent collaboration system designed to enhance decision-making in financial investment research. The system incorporates agent groups with both configurable group sizes and collaboration structures to leverage the strengths of each agent group type. By utilizing a sub-optimal combination strategy, the system dynamically adapts to varying market conditions and investment scenarios, optimizing performance across different tasks. We focus on three sub-tasks: fundamentals, market sentiment, and risk analysis, by analyzing the 2023 SEC 10-K forms of 30 companies listed on the Dow Jones Index. Our findings reveal significant performance variations based on the configurations of AI agents for different tasks. The results demonstrate that our multi-agent collaboration system outperforms traditional single-agent models, offering improved accuracy, efficiency, and adaptability in complex financial environments. This study highlights the potential of multi-agent systems in transforming financial analysis and investment decision-making by integrating diverse analytical perspectives.",
        "code": "",
        "category": [
            [
                "Application",
                "Finance"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.04788"
    },
    "8de5d8cc60468e2a3f0f1a56c3768aa2": {
        "title": "Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations",
        "authors": [
            "Joey Hong",
            "Jessica Lin",
            "Anca Dragan",
            "Sergey Levine"
        ],
        "date": "2024/11/07",
        "pdf": "http://arxiv.org/pdf/2411.05194",
        "abstract": "Recent progress on large language models (LLMs) has enabled dialogue agents to generate highly naturalistic and plausible text. However, current LLM language generation focuses on responding accurately to questions and requests with a single effective response. In reality, many real dialogues are interactive, meaning an agent&#39;s utterances will influence their conversational partner, elicit information, or change their opinion. Accounting for how an agent can effectively steer a conversation is a crucial ability in many dialogue tasks, from healthcare to preference elicitation. Existing methods for fine-tuning dialogue agents to accomplish such tasks would rely on curating some amount of expert data. However, doing so often requires understanding the underlying cognitive processes of the conversational partner, which is a skill neither humans nor LLMs trained on human data can reliably do. Our key insight is that while LLMs may not be adept at identifying effective strategies for steering conversations a priori, or in the middle of an ongoing conversation, they can do so post-hoc, or in hindsight, after seeing how their conversational partner responds. We use this fact to rewrite and augment existing suboptimal data, and train via offline reinforcement learning (RL) an agent that outperforms both prompting and learning from unaltered human demonstrations. We apply our approach to two domains that require understanding human mental state, intelligent interaction, and persuasion: mental health support, and soliciting charitable donations. Our results in a user study with real humans show that our approach greatly outperforms existing state-of-the-art dialogue agents.",
        "code": "",
        "category": [
            [
                "Training",
                "RL"
            ],
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.05194"
    },
    "ab6d199ccf8cce41f79f51df3889a4c0": {
        "title": "Game-theoretic LLM: Agent Workflow for Negotiation Games",
        "authors": [
            "Wenyue Hua",
            "Ollie Liu",
            "Lingyao Li",
            "Alfonso Amayuelas",
            "Julie Chen",
            "Lucas Jiang",
            "Mingyu Jin",
            "Lizhou Fan",
            "Fei Sun",
            "William Wang",
            "Xintong Wang",
            "Yongfeng Zhang"
        ],
        "date": "2024/11/08",
        "pdf": "http://arxiv.org/pdf/2411.05990",
        "abstract": "This paper investigates the rationality of large language models (LLMs) in strategic decision-making contexts, specifically within the framework of game theory. We evaluate several state-of-the-art LLMs across a spectrum of complete-information and incomplete-information games. Our findings reveal that LLMs frequently deviate from rational strategies, particularly as the complexity of the game increases with larger payoff matrices or deeper sequential trees. To address these limitations, we design multiple game-theoretic workflows that guide the reasoning and decision-making processes of LLMs. These workflows aim to enhance the models&#39; ability to compute Nash Equilibria and make rational choices, even under conditions of uncertainty and incomplete information. Experimental results demonstrate that the adoption of these workflows significantly improves the rationality and robustness of LLMs in game-theoretic tasks. Specifically, with the workflow, LLMs exhibit marked improvements in identifying optimal strategies, achieving near-optimal allocations in negotiation scenarios, and reducing susceptibility to exploitation during negotiations. Furthermore, we explore the meta-strategic considerations of whether it is rational for agents to adopt such workflows, recognizing that the decision to use or forgo the workflow constitutes a game-theoretic issue in itself. Our research contributes to a deeper understanding of LLMs&#39; decision-making capabilities in strategic contexts and provides insights into enhancing their rationality through structured workflows. The findings have implications for the development of more robust and strategically sound AI agents capable of navigating complex interactive environments. Code and data supporting this study are available at \\url{https://github.com/Wenyueh/game_theory}.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ],
            [
                "Automation",
                "Workflow"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.05990"
    },
    "86933496e7c3c4fe305ab7ef9ebf208e": {
        "title": "BudgetMLAgent: A Cost-Effective LLM Multi-Agent system for Automating Machine Learning Tasks",
        "authors": [
            "Shubham Gandhi",
            "Manasi Patwardhan",
            "Lovekesh Vig",
            "Gautam Shroff"
        ],
        "date": "2024/11/12",
        "pdf": "http://arxiv.org/pdf/2411.07464",
        "abstract": "Large Language Models (LLMs) excel in diverse applications including generation of code snippets, but often struggle with generating code for complex Machine Learning (ML) tasks. Although existing LLM single-agent based systems give varying performance depending on the task complexity, they purely rely on larger and expensive models such as GPT-4. Our investigation reveals that no-cost and low-cost models such as Gemini-Pro, Mixtral and CodeLlama perform far worse than GPT-4 in a single-agent setting. With the motivation of developing a cost-efficient LLM based solution for solving ML tasks, we propose an LLM Multi-Agent based system which leverages combination of experts using profiling, efficient retrieval of past observations, LLM cascades, and ask-the-expert calls. Through empirical analysis on ML engineering tasks in the MLAgentBench benchmark, we demonstrate the effectiveness of our system, using no-cost models, namely Gemini as the base LLM, paired with GPT-4 in cascade and expert to serve occasional ask-the-expert calls for planning. With 94.2\\% reduction in the cost (from \\$0.931 per run cost averaged over all tasks for GPT-4 single agent system to \\$0.054), our system is able to yield better average success rate of 32.95\\% as compared to GPT-4 single-agent system yielding 22.72\\% success rate averaged over all the tasks of MLAgentBench.",
        "code": "",
        "category": [
            [
                "Automation",
                "Workflow"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.07464"
    },
    "8f2b3abfa1479315b9b4ccf595dd2386": {
        "title": "The Dawn of GUI Agent: A Preliminary Case Study with Claude 3.5 Computer Use",
        "authors": [
            "Siyuan Hu",
            "Mingyu Ouyang",
            "Difei Gao",
            "Mike Zheng Shou"
        ],
        "date": "2024/11/15",
        "pdf": "http://arxiv.org/pdf/2411.10323",
        "abstract": "The recently released model, Claude 3.5 Computer Use, stands out as the first frontier AI model to offer computer use in public beta as a graphical user interface (GUI) agent. As an early beta, its capability in the real-world complex environment remains unknown. In this case study to explore Claude 3.5 Computer Use, we curate and organize a collection of carefully designed tasks spanning a variety of domains and software. Observations from these cases demonstrate Claude 3.5 Computer Use&#39;s unprecedented ability in end-to-end language to desktop actions. Along with this study, we provide an out-of-the-box agent framework for deploying API-based GUI automation models with easy implementation. Our case studies aim to showcase a groundwork of capabilities and limitations of Claude 3.5 Computer Use with detailed analyses and bring to the fore questions about planning, action, and critic, which must be considered for future improvement. We hope this preliminary exploration will inspire future research into the GUI agent community. All the test cases in the paper can be tried through the project: https://github.com/showlab/computer_use_ootb.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.10323"
    },
    "b79b54e4e2e8c9d4e01b69ab450f6920": {
        "title": "The Power of Many: Multi-Agent Multimodal Models for Cultural Image Captioning",
        "authors": [
            "Longju Bai",
            "Angana Borah",
            "Oana Ignat",
            "Rada Mihalcea"
        ],
        "date": "2024/11/18",
        "pdf": "http://arxiv.org/pdf/2411.11758",
        "abstract": "Large Multimodal Models (LMMs) exhibit impressive performance across various multimodal tasks. However, their effectiveness in cross-cultural contexts remains limited due to the predominantly Western-centric nature of most data and models. Conversely, multi-agent models have shown significant capability in solving complex tasks. Our study evaluates the collective performance of LMMs in a multi-agent interaction setting for the novel task of cultural image captioning. Our contributions are as follows: (1) We introduce MosAIC, a Multi-Agent framework to enhance cross-cultural Image Captioning using LMMs with distinct cultural personas; (2) We provide a dataset of culturally enriched image captions in English for images from China, India, and Romania across three datasets: GeoDE, GD-VCR, CVQA; (3) We propose a culture-adaptable metric for evaluating cultural information within image captions; and (4) We show that the multi-agent interaction outperforms single-agent models across different metrics, and offer valuable insights for future research. Our dataset and models can be accessed at https://github.com/MichiganNLP/MosAIC.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.11758"
    },
    "6d61860eeb03c2f4a008000d3d3932e8": {
        "title": "MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Collaborative Learning",
        "authors": [
            "Mircea LicÄ",
            "Ojas Shirekar",
            "Baptiste Colle",
            "Chirag Raman"
        ],
        "date": "2024/11/20",
        "pdf": "http://arxiv.org/pdf/2411.12977",
        "abstract": "Contemporary embodied agents powered by large language models (LLMs), such as Voyager, have shown promising capabilities in individual learning within open-ended environments like Minecraft. However, when powered by open LLMs, they struggle with basic tasks even after domain-specific fine-tuning. We present MindForge, a generative-agent framework for collaborative lifelong learning through explicit perspective taking. We introduce three key innovations: (1) a structured theory of mind representation linking percepts, beliefs, desires, and actions; (2) natural interagent communication; and (3) a multicomponent memory system. In Minecraft experiments, MindForge agents powered by open-weight LLMs significantly outperform their Voyager counterparts in basic tasks where traditional Voyager fails without GPT-4, collecting $2.3\\times$ more unique items and achieving $3\\times$ more tech-tree milestones, advancing from basic wood tools to advanced iron equipment. MindForge agents demonstrate sophisticated behaviors, including expert-novice knowledge transfer, collaborative problem solving, and adaptation to out-of-distribution tasks through accumulated collaborative experiences. MindForge advances the democratization of embodied AI development through open-ended social learning, enabling peer-to-peer knowledge sharing.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.12977"
    },
    "ee14dab14fb8e5203979e90375f7c883": {
        "title": "AdaptAgent: Adapting Multimodal Web Agents with Few-Shot Learning from Human Demonstrations",
        "authors": [
            "Gaurav Verma",
            "Rachneet Kaur",
            "Nishan Srishankar",
            "Zhen Zeng",
            "Tucker Balch",
            "Manuela Veloso"
        ],
        "date": "2024/11/20",
        "pdf": "http://arxiv.org/pdf/2411.13451",
        "abstract": "State-of-the-art multimodal web agents, powered by Multimodal Large Language Models (MLLMs), can autonomously execute many web tasks by processing user instructions and interacting with graphical user interfaces (GUIs). Current strategies for building web agents rely on (i) the generalizability of underlying MLLMs and their steerability via prompting, and (ii) large-scale fine-tuning of MLLMs on web-related tasks. However, web agents still struggle to automate tasks on unseen websites and domains, limiting their applicability to enterprise-specific and proprietary platforms. Beyond generalization from large-scale pre-training and fine-tuning, we propose building agents for few-shot adaptability using human demonstrations. We introduce the AdaptAgent framework that enables both proprietary and open-weights multimodal web agents to adapt to new websites and domains using few human demonstrations (up to 2). Our experiments on two popular benchmarks -- Mind2Web &amp; VisualWebArena -- show that using in-context demonstrations (for proprietary models) or meta-adaptation demonstrations (for meta-learned open-weights models) boosts task success rate by 3.36% to 7.21% over non-adapted state-of-the-art models, corresponding to a relative increase of 21.03% to 65.75%. Furthermore, our additional analyses (a) show the effectiveness of multimodal demonstrations over text-only ones, (b) shed light on the influence of different data selection strategies during meta-learning on the generalization of the agent, and (c) demonstrate the effect of number of few-shot examples on the web agent&#39;s success rate. Overall, our results unlock a complementary axis for developing widely applicable multimodal web agents beyond large-scale pre-training and fine-tuning, emphasizing few-shot adaptability.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.13451"
    },
    "ba120860863e625f73069667fd9026b7": {
        "title": "Enhancing Multi-Agent Consensus through Third-Party LLM Integration: Analyzing Uncertainty and Mitigating Hallucinations in Large Language Models",
        "authors": [
            "Zhihua Duan",
            "Jialin Wang"
        ],
        "date": "2024/11/25",
        "pdf": "http://arxiv.org/pdf/2411.16189",
        "abstract": "Large Language Models (LLMs) still face challenges when dealing with complex reasoning tasks, often resulting in hallucinations, which limit the practical application of LLMs. To alleviate this issue, this paper proposes a new method that integrates different LLMs to expand the knowledge boundary, reduce dependence on a single model, and promote in-depth debate among agents. The main contributions include: 1) Introducing third-party LLMs to adjust the attention weights of agents through uncertainty estimation and confidence analysis, optimizing consensus formation in multi-agent systems; 2) Experiments on arithmetic datasets have validated the effectiveness of the method, surpassing traditional multi-agent baselines. This research provides a new perspective for large models to alleviate hallucination phenomena when dealing with complex tasks.",
        "code": "",
        "category": [
            [
                "Stability",
                "Hallucination"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.16189"
    },
    "4f5d2d62b028cd24565210e52cb1d04f": {
        "title": "LLM-Based Offline Learning for Embodied Agents via Consistency-Guided Reward Ensemble",
        "authors": [
            "Yujeong Lee",
            "Sangwoo Shin",
            "Wei-Jin Park",
            "Honguk Woo"
        ],
        "date": "2024/11/26",
        "pdf": "http://arxiv.org/pdf/2411.17135",
        "abstract": "Employing large language models (LLMs) to enable embodied agents has become popular, yet it presents several limitations in practice. In this work, rather than using LLMs directly as agents, we explore their use as tools for embodied agent learning. Specifically, to train separate agents via offline reinforcement learning (RL), an LLM is used to provide dense reward feedback on individual actions in training datasets. In doing so, we present a consistency-guided reward ensemble framework (CoREN), designed for tackling difficulties in grounding LLM-generated estimates to the target environment domain. The framework employs an adaptive ensemble of spatio-temporally consistent rewards to derive domain-grounded rewards in the training datasets, thus enabling effective offline learning of embodied agents in different environment domains. Experiments with the VirtualHome benchmark demonstrate that CoREN significantly outperforms other offline RL agents, and it also achieves comparable performance to state-of-the-art LLM-based agents with 8B parameters, despite CoREN having only 117M parameters for the agent policy network and using LLMs only for training.",
        "code": "",
        "category": [
            [
                "Training",
                "RL"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.17135"
    },
    "43314f39545f52e9c38988abb7766b37": {
        "title": "ShowUI: One Vision-Language-Action Model for GUI Visual Agent",
        "authors": [
            "Kevin Qinghong Lin",
            "Linjie Li",
            "Difei Gao",
            "Zhengyuan Yang",
            "Shiwei Wu",
            "Zechen Bai",
            "Weixian Lei",
            "Lijuan Wang",
            "Mike Zheng Shou"
        ],
        "date": "2024/11/26",
        "pdf": "http://arxiv.org/pdf/2411.17465",
        "abstract": "Building Graphical User Interface (GUI) assistants holds significant promise for enhancing human workflow productivity. While most agents are language-based, relying on closed-source API with text-rich meta-information (e.g., HTML or accessibility tree), they show limitations in perceiving UI visuals as humans do, highlighting the need for GUI visual agents. In this work, we develop a vision-language-action model in digital world, namely ShowUI, which features the following innovations: (i) UI-Guided Visual Token Selection to reduce computational costs by formulating screenshots as an UI connected graph, adaptively identifying their redundant relationship and serve as the criteria for token selection during self-attention blocks; (ii) Interleaved Vision-Language-Action Streaming that flexibly unifies diverse needs within GUI tasks, enabling effective management of visual-action history in navigation or pairing multi-turn query-action sequences per screenshot to enhance training efficiency; (iii) Small-scale High-quality GUI Instruction-following Datasets by careful data curation and employing a resampling strategy to address significant data type imbalances. With above components, ShowUI, a lightweight 2B model using 256K data, achieves a strong 75.1% accuracy in zero-shot screenshot grounding. Its UI-guided token selection further reduces 33% of redundant visual tokens during training and speeds up the performance by 1.4x. Navigation experiments across web Mind2Web, mobile AITW, and online MiniWob environments further underscore the effectiveness and potential of our model in advancing GUI visual agents. The models are available at https://github.com/showlab/ShowUI.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2411.17465"
    },
    "4a45ec4f1e3a9ad51c1cd03b08bb34be": {
        "title": "Large Language Model-Brained GUI Agents: A Survey",
        "authors": [
            "Chaoyun Zhang",
            "Shilin He",
            "Jiaxu Qian",
            "Bowen Li",
            "Liqun Li",
            "Si Qin",
            "Yu Kang",
            "Minghua Ma",
            "Guyue Liu",
            "Qingwei Lin",
            "Saravan Rajmohan",
            "Dongmei Zhang",
            "Qi Zhang"
        ],
        "date": "2024/11/27",
        "pdf": "http://arxiv.org/pdf/2411.18279",
        "abstract": "GUIs have long been central to human-computer interaction, providing an intuitive and visually-driven way to access and interact with digital systems. The advent of LLMs, particularly multimodal models, has ushered in a new era of GUI automation. They have demonstrated exceptional capabilities in natural language understanding, code generation, and visual processing. This has paved the way for a new generation of LLM-brained GUI agents capable of interpreting complex GUI elements and autonomously executing actions based on natural language instructions. These agents represent a paradigm shift, enabling users to perform intricate, multi-step tasks through simple conversational commands. Their applications span across web navigation, mobile app interactions, and desktop automation, offering a transformative user experience that revolutionizes how individuals interact with software. This emerging field is rapidly advancing, with significant progress in both research and industry. To provide a structured understanding of this trend, this paper presents a comprehensive survey of LLM-brained GUI agents, exploring their historical evolution, core components, and advanced techniques. We address research questions such as existing GUI agent frameworks, the collection and utilization of data for training specialized GUI agents, the development of large action models tailored for GUI tasks, and the evaluation metrics and benchmarks necessary to assess their effectiveness. Additionally, we examine emerging applications powered by these agents. Through a detailed analysis, this survey identifies key research gaps and outlines a roadmap for future advancements in the field. By consolidating foundational knowledge and state-of-the-art developments, this work aims to guide both researchers and practitioners in overcoming challenges and unlocking the full potential of LLM-brained GUI agents.",
        "code": "",
        "category": [
            [
                "Survey",
                null
            ]
        ],
        "url": "https://arxiv.org/abs/2411.18279"
    },
    "a026ce088d857c1c18c63fe1d1744aab": {
        "title": "BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science",
        "authors": [
            "Xinna Lin",
            "Siqi Ma",
            "Junjie Shan",
            "Xiaojing Zhang",
            "Shell Xu Hu",
            "Tiannan Guo",
            "Stan Z. Li",
            "Kaicheng Yu"
        ],
        "date": "2024/06/29",
        "pdf": "http://arxiv.org/pdf/2407.00466",
        "abstract": "Pursuing artificial intelligence for biomedical science, a.k.a. AI Scientist, draws increasing attention, where one common approach is to build a copilot agent driven by Large Language Models (LLMs). However, to evaluate such systems, people either rely on direct Question-Answering (QA) to the LLM itself, or in a biomedical experimental manner. How to precisely benchmark biomedical agents from an AI Scientist perspective remains largely unexplored. To this end, we draw inspiration from one most important abilities of scientists, understanding the literature, and introduce BioKGBench. In contrast to traditional evaluation benchmark that only focuses on factual QA, where the LLMs are known to have hallucination issues, we first disentangle &#34;Understanding Literature&#34; into two atomic abilities, i) &#34;Understanding&#34; the unstructured text from research papers by performing scientific claim verification, and ii) Ability to interact with structured Knowledge-Graph Question-Answering (KGQA) as a form of &#34;Literature&#34; grounding. We then formulate a novel agent task, dubbed KGCheck, using KGQA and domain-based Retrieval-Augmented Generation (RAG) to identify the factual errors of existing large-scale knowledge graph databases. We collect over two thousand data for two atomic tasks and 225 high-quality annotated data for the agent task. Surprisingly, we discover that state-of-the-art agents, both daily scenarios and biomedical ones, have either failed or inferior performance on our benchmark. We then introduce a simple yet effective baseline, dubbed BKGAgent. On the widely used popular knowledge graph, we discover over 90 factual errors which provide scenarios for agents to make discoveries and demonstrate the effectiveness of our approach. The code and data are available at https://github.com/westlake-autolab/BioKGBench.",
        "code": "",
        "category": [
            [
                "Application",
                "Biology"
            ],
            [
                "Stability",
                "Hallucination"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.00466"
    },
    "bc3e51aa9322ce4f6955c3e298b00b0e": {
        "title": "IBSEN: Director-Actor Agent Collaboration for Controllable and Interactive Drama Script Generation",
        "authors": [
            "Senyu Han",
            "Lu Chen",
            "Li-Min Lin",
            "Zhengshan Xu",
            "Kai Yu"
        ],
        "date": "2024/07/01",
        "pdf": "http://arxiv.org/pdf/2407.01093",
        "abstract": "Large language models have demonstrated their capabilities in storyline creation and human-like character role-playing. Current language model agents mainly focus on reasonable behaviors from the level of individuals, and their behaviors might be hard to constraint on the level of the whole storyline. In this paper we introduce IBSEN, a director-actor coordinate agent framework that generates drama scripts and makes the plot played by agents more controllable. The director agent writes plot outlines that the user desires to see, instructs the actor agents to role-play their characters, and reschedules the plot when human players participate in the scenario to ensure the plot is progressing towards the objective. To evaluate the framework, we create a novel drama plot that involves several actor agents and check the interactions between them under the instruction of the director agent. Evaluation results show that our framework could generate complete, diverse drama scripts from only a rough outline of plot objectives, meanwhile maintaining the characteristics of characters in the drama. Our codes and prompts are available at https://github.com/OpenDFM/ibsen.",
        "code": "",
        "category": [
            [
                "Application",
                "Art"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.01093"
    },
    "9ea042bb80c3f5521f4367212b8278ae": {
        "title": "MIRAI: Evaluating LLM Agents for Event Forecasting",
        "authors": [
            "Chenchen Ye",
            "Ziniu Hu",
            "Yihe Deng",
            "Zijie Huang",
            "Mingyu Derek Ma",
            "Yanqiao Zhu",
            "Wei Wang"
        ],
        "date": "2024/07/01",
        "pdf": "http://arxiv.org/pdf/2407.01231",
        "abstract": "Recent advancements in Large Language Models (LLMs) have empowered LLM agents to autonomously collect world information, over which to conduct reasoning to solve complex problems. Given this capability, increasing interests have been put into employing LLM agents for predicting international events, which can influence decision-making and shape policy development on an international scale. Despite such a growing interest, there is a lack of a rigorous benchmark of LLM agents&#39; forecasting capability and reliability. To address this gap, we introduce MIRAI, a novel benchmark designed to systematically evaluate LLM agents as temporal forecasters in the context of international events. Our benchmark features an agentic environment with tools for accessing an extensive database of historical, structured events and textual news articles. We refine the GDELT event database with careful cleaning and parsing to curate a series of relational prediction tasks with varying forecasting horizons, assessing LLM agents&#39; abilities from short-term to long-term forecasting. We further implement APIs to enable LLM agents to utilize different tools via a code-based interface. In summary, MIRAI comprehensively evaluates the agents&#39; capabilities in three dimensions: 1) autonomously source and integrate critical information from large global databases; 2) write codes using domain-specific APIs and libraries for tool-use; and 3) jointly reason over historical knowledge from diverse formats and time to accurately predict future events. Through comprehensive benchmarking, we aim to establish a reliable framework for assessing the capabilities of LLM agents in forecasting international events, thereby contributing to the development of more accurate and trustworthy models for international relation analysis.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.01231"
    },
    "902c9b87eefcec3b27c056a31870217b": {
        "title": "Predicting vs. Acting: A Trade-off Between World Modeling &amp; Agent Modeling",
        "authors": [
            "Margaret Li",
            "Weijia Shi",
            "Artidoro Pagnoni",
            "Peter West",
            "Ari Holtzman"
        ],
        "date": "2024/07/02",
        "pdf": "http://arxiv.org/pdf/2407.02446",
        "abstract": "RLHF-aligned LMs have shown unprecedented ability on both benchmarks and long-form text generation, yet they struggle with one foundational task: next-token prediction. As RLHF models become agent models aimed at interacting with humans, they seem to lose their world modeling -- the ability to predict what comes next in arbitrary documents, which is the foundational training objective of the Base LMs that RLHF adapts. Besides empirically demonstrating this trade-off, we propose a potential explanation: to perform coherent long-form generation, RLHF models restrict randomness via implicit blueprints. In particular, RLHF models concentrate probability on sets of anchor spans that co-occur across multiple generations for the same prompt, serving as textual scaffolding but also limiting a model&#39;s ability to generate documents that do not include these spans. We study this trade-off on the most effective current agent models, those aligned with RLHF, while exploring why this may remain a fundamental trade-off between models that act and those that predict, even as alignment techniques improve.",
        "code": "",
        "category": [
            [
                "Training",
                "RL"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.02446"
    },
    "4766c01174460201fd9d6c1e935aa1ec": {
        "title": "MMedAgent: Learning to Use Medical Tools with Multi-modal Agent",
        "authors": [
            "Binxu Li",
            "Tiankai Yan",
            "Yuanting Pan",
            "Jie Luo",
            "Ruiyang Ji",
            "Jiayuan Ding",
            "Zhe Xu",
            "Shilong Liu",
            "Haoyu Dong",
            "Zihao Lin",
            "Yixin Wang"
        ],
        "date": "2024/07/02",
        "pdf": "http://arxiv.org/pdf/2407.02483",
        "abstract": "Multi-Modal Large Language Models (MLLMs), despite being successful, exhibit limited generality and often fall short when compared to specialized models. Recently, LLM-based agents have been developed to address these challenges by selecting appropriate specialized models as tools based on user inputs. However, such advancements have not been extensively explored within the medical domain. To bridge this gap, this paper introduces the first agent explicitly designed for the medical field, named \\textbf{M}ulti-modal \\textbf{Med}ical \\textbf{Agent} (MMedAgent). We curate an instruction-tuning dataset comprising six medical tools solving seven tasks across five modalities, enabling the agent to choose the most suitable tools for a given task. Comprehensive experiments demonstrate that MMedAgent achieves superior performance across a variety of medical tasks compared to state-of-the-art open-source methods and even the closed-source model, GPT-4o. Furthermore, MMedAgent exhibits efficiency in updating and integrating new medical tools. Codes and models are all available.",
        "code": "",
        "category": [
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.02483"
    },
    "c4ac42f19ee64b3b59eae3986914bd28": {
        "title": "MentalAgora: A Gateway to Advanced Personalized Care in Mental Health through Multi-Agent Debating and Attribute Control",
        "authors": [
            "Yeonji Lee",
            "Sangjun Park",
            "Kyunghyun Cho",
            "JinYeong Bak"
        ],
        "date": "2024/07/03",
        "pdf": "http://arxiv.org/pdf/2407.02736",
        "abstract": "As mental health issues globally escalate, there is a tremendous need for advanced digital support systems. We introduce MentalAgora, a novel framework employing large language models enhanced by interaction between multiple agents for tailored mental health support. This framework operates through three stages: strategic debating, tailored counselor creation, and response generation, enabling the dynamic customization of responses based on individual user preferences and therapeutic needs. We conduct experiments utilizing a high-quality evaluation dataset TherapyTalk crafted with mental health professionals, shwoing that MentalAgora generates expert-aligned and user preference-enhanced responses. Our evaluations, including experiments and user studies, demonstrate that MentalAgora aligns with professional standards and effectively meets user preferences, setting a new benchmark for digital mental health interventions.",
        "code": "",
        "category": [
            [
                "Application",
                "Medicine"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.02736"
    },
    "cc5f2f0a7be91fe771f67099f1ba341c": {
        "title": "Controllable Conversations: Planning-Based Dialogue Agent with Large Language Models",
        "authors": [
            "Zhigen Li",
            "Jianxiang Peng",
            "Yanmeng Wang",
            "Yong Cao",
            "Tianhao Shen",
            "Minghui Zhang",
            "Linxi Su",
            "Shang Wu",
            "Yihang Wu",
            "Yuqian Wang",
            "Ye Wang",
            "Wei Hu",
            "Jianfeng Li",
            "Shaojun Wang",
            "Jing Xiao",
            "Deyi Xiong"
        ],
        "date": "2024/07/04",
        "pdf": "http://arxiv.org/pdf/2407.03884",
        "abstract": "Conversational agents powered by Large Language Models (LLMs) show superior performance in various tasks. Despite the better user understanding and human-like responses, their lack of controllability remains a key challenge, often leading to unfocused conversations or task failure. To address this challenge, we propose Planning-based Conversational Agents (PCA), a novel dialogue framework aimed at enhancing the controllability of LLM-driven agents. Specifically, our approach introduces Standard Operating Procedure (SOP) to regulate dialogue flow. To enable PCA to learn SOP, we curate a dataset comprising SOP-annotated multi-scenario dialogues, generated using a semi-automated role-playing system with GPT-4o and validated through strict manual quality control. Additionally, we propose a novel method that integrates Chain of Thought reasoning with supervised fine-tuning for SOP prediction and utilizes Monte Carlo Tree Search for optimal action planning during dialogues. Experimental results demonstrate the effectiveness of our method, such as achieving a 27.95% improvement in action accuracy compared to baseline models based on GPT-3.5 and also showing notable gains for open-source models. Dataset and codes are publicly available.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ],
            [
                "Technique For Enhancement",
                "Planning"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.03884"
    },
    "662474e30812fcdc298fa42af56bfb1e": {
        "title": "DebUnc: Mitigating Hallucinations in Large Language Model Agent Communication with Uncertainty Estimations",
        "authors": [
            "Luke Yoffe",
            "Alfonso Amayuelas",
            "William Yang Wang"
        ],
        "date": "2024/07/08",
        "pdf": "http://arxiv.org/pdf/2407.06426",
        "abstract": "To enhance Large Language Model (LLM) capabilities, multi-agent debates have been introduced, where multiple LLMs discuss solutions to a problem over several rounds of debate. However, LLMs often produce incorrect responses that appear deceptively confident, which can mislead other agents. This is partly because agents do not express their confidence levels during standard debates. To address this, we introduce DebUnc, a multi-agent debate framework that uses uncertainty metrics to assess agent confidence levels. We adapted the LLM attention mechanism to adjust token weights based on confidence levels and also explored using textual prompts to convey confidence. Our evaluations across various benchmarks show that attention-based methods are particularly effective, and that as uncertainty metrics evolve, performance will continue to increase. The code is available at https://github.com/lukeyoffe/debunc",
        "code": "",
        "category": [
            [
                "Stability",
                "Hallucination"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.06426"
    },
    "faaab14561e979451f3fe444a4d25984": {
        "title": "FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making",
        "authors": [
            "Yangyang Yu",
            "Zhiyuan Yao",
            "Haohang Li",
            "Zhiyang Deng",
            "Yupeng Cao",
            "Zhi Chen",
            "Jordan W. Suchow",
            "Rong Liu",
            "Zhenyu Cui",
            "Zhaozhuo Xu",
            "Denghui Zhang",
            "Koduvayur Subbalakshmi",
            "Guojun Xiong",
            "Yueru He",
            "Jimin Huang",
            "Dong Li",
            "Qianqian Xie"
        ],
        "date": "2024/07/09",
        "pdf": "http://arxiv.org/pdf/2407.06567",
        "abstract": "Large language models (LLMs) have demonstrated notable potential in conducting complex tasks and are increasingly utilized in various financial applications. However, high-quality sequential financial investment decision-making remains challenging. These tasks require multiple interactions with a volatile environment for every decision, demanding sufficient intelligence to maximize returns and manage risks. Although LLMs have been used to develop agent systems that surpass human teams and yield impressive investment returns, opportunities to enhance multi-sourced information synthesis and optimize decision-making outcomes through timely experience refinement remain unexplored. Here, we introduce the FinCon, an LLM-based multi-agent framework with CONceptual verbal reinforcement tailored for diverse FINancial tasks. Inspired by effective real-world investment firm organizational structures, FinCon utilizes a manager-analyst communication hierarchy. This structure allows for synchronized cross-functional agent collaboration towards unified goals through natural language interactions and equips each agent with greater memory capacity than humans. Additionally, a risk-control component in FinCon enhances decision quality by episodically initiating a self-critiquing mechanism to update systematic investment beliefs. The conceptualized beliefs serve as verbal reinforcement for the future agent&#39;s behavior and can be selectively propagated to the appropriate node that requires knowledge updates. This feature significantly improves performance while reducing unnecessary peer-to-peer communication costs. Moreover, FinCon demonstrates strong generalization capabilities in various financial tasks, including single stock trading and portfolio management.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Application",
                "Finance"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.06567"
    },
    "51e976732097b1a59f9600651dbc72a6": {
        "title": "Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence",
        "authors": [
            "Weize Chen",
            "Ziming You",
            "Ran Li",
            "Yitong Guan",
            "Chen Qian",
            "Chenyang Zhao",
            "Cheng Yang",
            "Ruobing Xie",
            "Zhiyuan Liu",
            "Maosong Sun"
        ],
        "date": "2024/07/09",
        "pdf": "http://arxiv.org/pdf/2407.07061",
        "abstract": "The rapid advancement of large language models (LLMs) has paved the way for the development of highly capable autonomous agents. However, existing multi-agent frameworks often struggle with integrating diverse capable third-party agents due to reliance on agents defined within their own ecosystems. They also face challenges in simulating distributed environments, as most frameworks are limited to single-device setups. Furthermore, these frameworks often rely on hard-coded communication pipelines, limiting their adaptability to dynamic task requirements. Inspired by the concept of the Internet, we propose the Internet of Agents (IoA), a novel framework that addresses these limitations by providing a flexible and scalable platform for LLM-based multi-agent collaboration. IoA introduces an agent integration protocol, an instant-messaging-like architecture design, and dynamic mechanisms for agent teaming and conversation flow control. Through extensive experiments on general assistant tasks, embodied AI tasks, and retrieval-augmented generation benchmarks, we demonstrate that IoA consistently outperforms state-of-the-art baselines, showcasing its ability to facilitate effective collaboration among heterogeneous agents. IoA represents a step towards linking diverse agents in an Internet-like environment, where agents can seamlessly collaborate to achieve greater intelligence and capabilities. Our codebase has been released at \\url{https://github.com/OpenBMB/IoA}.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.07061"
    },
    "6dbb46181a99d90e6ad15a76e40e29cc": {
        "title": "Flooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities",
        "authors": [
            "Tianjie Ju",
            "Yiting Wang",
            "Xinbei Ma",
            "Pengzhou Cheng",
            "Haodong Zhao",
            "Yulong Wang",
            "Lifeng Liu",
            "Jian Xie",
            "Zhuosheng Zhang",
            "Gongshen Liu"
        ],
        "date": "2024/07/10",
        "pdf": "http://arxiv.org/pdf/2407.07791",
        "abstract": "The rapid adoption of large language models (LLMs) in multi-agent systems has highlighted their impressive capabilities in various applications, such as collaborative problem-solving and autonomous negotiation. However, the security implications of these LLM-based multi-agent systems have not been thoroughly investigated, particularly concerning the spread of manipulated knowledge. In this paper, we investigate this critical issue by constructing a detailed threat model and a comprehensive simulation environment that mirrors real-world multi-agent deployments in a trusted platform. Subsequently, we propose a novel two-stage attack method involving Persuasiveness Injection and Manipulated Knowledge Injection to systematically explore the potential for manipulated knowledge (i.e., counterfactual and toxic knowledge) spread without explicit prompt manipulation. Our method leverages the inherent vulnerabilities of LLMs in handling world knowledge, which can be exploited by attackers to unconsciously spread fabricated information. Through extensive experiments, we demonstrate that our attack method can successfully induce LLM-based agents to spread both counterfactual and toxic knowledge without degrading their foundational capabilities during agent communication. Furthermore, we show that these manipulations can persist through popular retrieval-augmented generation frameworks, where several benign agents store and retrieve manipulated chat histories for future interactions. This persistence indicates that even after the interaction has ended, the benign agents may continue to be influenced by manipulated knowledge. Our findings reveal significant security risks in LLM-based multi-agent systems, emphasizing the imperative need for robust defenses against manipulated knowledge spread, such as introducing ``guardian&#39;&#39; agents and advanced fact-checking tools.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.07791"
    },
    "79aa1aae2ea043f738869b1e009100fe": {
        "title": "GTA: A Benchmark for General Tool Agents",
        "authors": [
            "Jize Wang",
            "Zerun Ma",
            "Yining Li",
            "Songyang Zhang",
            "Cailian Chen",
            "Kai Chen",
            "Xinyi Le"
        ],
        "date": "2024/07/11",
        "pdf": "http://arxiv.org/pdf/2407.08713",
        "abstract": "Significant focus has been placed on integrating large language models (LLMs) with various tools in developing general-purpose agents. This poses a challenge to LLMs&#39; tool-use capabilities. However, there are evident gaps between existing tool-use evaluations and real-world scenarios. Current evaluations often use AI-generated queries, single-step tasks, dummy tools, and text-only interactions, failing to reveal the agents&#39; real-world problem-solving abilities effectively. To address this, we propose GTA, a benchmark for General Tool Agents, featuring three main aspects: (i) Real user queries: human-written queries with simple real-world objectives but implicit tool-use, requiring the LLM to reason the suitable tools and plan the solution steps. (ii) Real deployed tools: an evaluation platform equipped with tools across perception, operation, logic, and creativity categories to evaluate the agents&#39; actual task execution performance. (iii) Real multimodal inputs: authentic image files, such as spatial scenes, web page screenshots, tables, code snippets, and printed/handwritten materials, used as the query contexts to align with real-world scenarios closely. We design 229 real-world tasks and executable tool chains to evaluate mainstream LLMs. Our findings show that real-world user queries are challenging for existing LLMs, with GPT-4 completing less than 50% of the tasks and most LLMs achieving below 25%. This evaluation reveals the bottlenecks in the tool-use capabilities of current LLMs in real-world scenarios, which provides future direction for advancing general-purpose tool agents. The code and dataset are available at https://github.com/open-compass/GTA.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.08713"
    },
    "fb58344899467568664eaf1b1d59e23e": {
        "title": "Synergistic Multi-Agent Framework with Trajectory Learning for Knowledge-Intensive Tasks",
        "authors": [
            "Shengbin Yue",
            "Siyuan Wang",
            "Wei Chen",
            "Xuanjing Huang",
            "Zhongyu Wei"
        ],
        "date": "2024/07/13",
        "pdf": "http://arxiv.org/pdf/2407.09893",
        "abstract": "Recent advancements in Large Language Models (LLMs) have led to significant breakthroughs in various natural language processing tasks. However, generating factually consistent responses in knowledge-intensive scenarios remains a challenge due to issues such as hallucination, difficulty in acquiring long-tailed knowledge, and limited memory expansion. This paper introduces SMART, a novel multi-agent framework that leverages external knowledge to enhance the interpretability and factual consistency of LLM-generated responses. SMART comprises four specialized agents, each performing a specific sub-trajectory action to navigate complex knowledge-intensive tasks. We propose a multi-agent co-training paradigm, Long-Short Trajectory Learning, which ensures synergistic collaboration among agents while maintaining fine-grained execution by each agent. Extensive experiments on five knowledge-intensive tasks demonstrate SMART&#39;s superior performance compared to widely adopted knowledge internalization and knowledge enhancement methods. Our framework can extend beyond knowledge-intensive tasks to more complex scenarios. Our code is available at https://github.com/yueshengbin/SMART.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.09893"
    },
    "673dda33dce876b3e3201e3de4982636": {
        "title": "Cohesive Conversations: Enhancing Authenticity in Multi-Agent Simulated Dialogues",
        "authors": [
            "KuanChao Chu",
            "Yi-Pei Chen",
            "Hideki Nakayama"
        ],
        "date": "2024/07/13",
        "pdf": "http://arxiv.org/pdf/2407.09897",
        "abstract": "This paper investigates the quality of multi-agent dialogues in simulations powered by Large Language Models (LLMs). Analyzing dialogues and memory over multiple sessions revealed significant issues such as repetition, inconsistency, and hallucination, exacerbated by the propagation of erroneous information. To combat these challenges, we propose a novel Screening, Diagnosis, and Regeneration (SDR) framework that detects and corrects utterance errors through a comprehensive process involving immediate issue identification, evidence gathering from past dialogues, and LLM analysis for utterance revision. By incorporating our SDR framework to Generative Agents (Park et al., 2023), we enhance the diversity, consistency, and factualness of the generated dialogues. This work presents a pioneering approach to enhancing dialogue quality in multi-agent simulations, establishing a new standard for future research in the field.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ],
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.09897"
    },
    "15221eb90ab82ffaf61edaf4fafce855": {
        "title": "AutoGRAMS: Autonomous Graphical Agent Modeling Software",
        "authors": [
            "Ben Krause",
            "Lucia Chen",
            "Emmanuel Kahembwe"
        ],
        "date": "2024/07/14",
        "pdf": "http://arxiv.org/pdf/2407.10049",
        "abstract": "We introduce the AutoGRAMS framework for programming multi-step interactions with language models. AutoGRAMS represents AI agents as a graph, where each node can execute either a language modeling instruction or traditional code. Likewise, transitions in the graph can be governed by either language modeling decisions or traditional branch logic. AutoGRAMS supports using variables as memory and allows nodes to call other AutoGRAMS graphs as functions. We show how AutoGRAMS can be used to design highly sophisticated agents, including self-referential agents that can modify their own graph. AutoGRAMS&#39;s graph-centric approach aids interpretability, controllability, and safety during the design, development, and deployment of AI agents. We provide our framework as open source at https://github.com/autograms/autograms .",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Environment&Platform"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.10049"
    },
    "d50eca4e14ac69e343905d0028936de4": {
        "title": "The Effects of Embodiment and Personality Expression on Learning in LLM-based Educational Agents",
        "authors": [
            "Sinan Sonlu",
            "Bennie Bendiksen",
            "Funda Durupinar",
            "UÄur GÃ¼dÃ¼kbay"
        ],
        "date": "2024/06/24",
        "pdf": "http://arxiv.org/pdf/2407.10993",
        "abstract": "This work investigates how personality expression and embodiment affect personality perception and learning in educational conversational agents. We extend an existing personality-driven conversational agent framework by integrating LLM-based conversation support tailored to an educational application. We describe a user study built on this system to evaluate two distinct personality styles: high extroversion and agreeableness and low extroversion and agreeableness. For each personality style, we assess three models: (1) a dialogue-only model that conveys personality through dialogue, (2) an animated human model that expresses personality solely through dialogue, and (3) an animated human model that expresses personality through both dialogue and body and facial animations. The results indicate that all models are positively perceived regarding both personality and learning outcomes. Models with high personality traits are perceived as more engaging than those with low personality traits. We provide a comprehensive quantitative and qualitative analysis of perceived personality traits, learning parameters, and user experiences based on participant ratings of the model types and personality styles, as well as users&#39; responses to open-ended questions.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Role Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.10993"
    },
    "de89365b19a94479bbacb6fc6bd821ae": {
        "title": "Geode: A Zero-shot Geospatial Question-Answering Agent with Explicit Reasoning and Precise Spatio-Temporal Retrieval",
        "authors": [
            "Devashish Vikas Gupta",
            "Azeez Syed Ali Ishaqui",
            "Divya Kiran Kadiyala"
        ],
        "date": "2024/06/26",
        "pdf": "http://arxiv.org/pdf/2407.11014",
        "abstract": "Large language models (LLMs) have shown promising results in learning and contextualizing information from different forms of data. Recent advancements in foundational models, particularly those employing self-attention mechanisms, have significantly enhanced our ability to comprehend the semantics of diverse data types. One such area that could highly benefit from multi-modality is in understanding geospatial data, which inherently has multiple modalities. However, current Natural Language Processing (NLP) mechanisms struggle to effectively address geospatial queries. Existing pre-trained LLMs are inadequately equipped to meet the unique demands of geospatial data, lacking the ability to retrieve precise spatio-temporal data in real-time, thus leading to significantly reduced accuracy in answering complex geospatial queries. To address these limitations, we introduce Geode--a pioneering system designed to tackle zero-shot geospatial question-answering tasks with high precision using spatio-temporal data retrieval. Our approach represents a significant improvement in addressing the limitations of current LLM models, demonstrating remarkable improvement in geospatial question-answering abilities compared to existing state-of-the-art pre-trained models.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "RAG"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.11014"
    },
    "3ec8ec4c95d2793a54aa90fa0e03c152": {
        "title": "InvAgent: A Large Language Model based Multi-Agent System for Inventory Management in Supply Chains",
        "authors": [
            "Yinzhu Quan",
            "Zefang Liu"
        ],
        "date": "2024/07/16",
        "pdf": "http://arxiv.org/pdf/2407.11384",
        "abstract": "Supply chain management (SCM) involves coordinating the flow of goods, information, and finances across various entities to deliver products efficiently. Effective inventory management is crucial in today&#39;s volatile and uncertain world. Previous research has demonstrated the superiority of heuristic methods and reinforcement learning applications in inventory management. However, the application of large language models (LLMs) as autonomous agents in multi-agent systems for inventory management remains underexplored. This study introduces a novel approach using LLMs to manage multi-agent inventory systems. Leveraging their zero-shot learning capabilities, our model, InvAgent, enhances resilience and improves efficiency across the supply chain network. Our contributions include utilizing LLMs for zero-shot learning to enable adaptive and informed decision-making without prior training, providing explainability and clarity through chain-of-thought, and demonstrating dynamic adaptability to varying demand scenarios while reducing costs and preventing stockouts. Extensive evaluations across different scenarios highlight the efficiency of our model in SCM.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.11384"
    },
    "2ed773da8fac0dde0c6c261176afab53": {
        "title": "Preemptive Detection and Correction of Misaligned Actions in LLM Agents",
        "authors": [
            "Haishuo Fang",
            "Xiaodan Zhu",
            "Iryna Gurevych"
        ],
        "date": "2024/07/16",
        "pdf": "http://arxiv.org/pdf/2407.11843",
        "abstract": "Deploying LLM-based agents in real-life applications often faces a critical challenge: the misalignment between agents&#39; behavior and user intent. Such misalignment may lead agents to unintentionally execute critical actions that carry negative outcomes (e.g., accidentally triggering a &#34;buy-now&#34; in web shopping), resulting in undesirable or even irreversible consequences. Although addressing these issues is crucial, the preemptive detection and correction of misaligned actions remains relatively underexplored. To fill this gap, we introduce InferAct, a novel approach that leverages the belief reasoning ability of LLMs, grounded in Theory-of-Mind, to detect misaligned actions before execution. Once the misalignment is detected, InferAct alerts users for timely correction, preventing adverse outcomes and enhancing the reliability of LLM agents&#39; decision-making processes. Experiments on three widely used tasks demonstrate that InferAct achieves up to 20% improvements on Marco-F1 against baselines in misaligned action detection. An in-depth evaluation of misalignment correction further highlights InferAct&#39;s effectiveness in improving agent alignment.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.11843"
    },
    "f8ecd52fbcbad5ac03d97c7b9a51cac1": {
        "title": "Towards Collaborative Intelligence: Propagating Intentions and Reasoning for Multi-Agent Coordination with Large Language Models",
        "authors": [
            "Xihe Qiu",
            "Haoyu Wang",
            "Xiaoyu Tan",
            "Chao Qu",
            "Yujie Xiong",
            "Yuan Cheng",
            "Yinghui Xu",
            "Wei Chu",
            "Yuan Qi"
        ],
        "date": "2024/07/17",
        "pdf": "http://arxiv.org/pdf/2407.12532",
        "abstract": "Effective collaboration in multi-agent systems requires communicating goals and intentions between agents. Current agent frameworks often suffer from dependencies on single-agent execution and lack robust inter-module communication, frequently leading to suboptimal multi-agent reinforcement learning (MARL) policies and inadequate task coordination. To address these challenges, we present a framework for training large language models (LLMs) as collaborative agents to enable coordinated behaviors in cooperative MARL. Each agent maintains a private intention consisting of its current goal and associated sub-tasks. Agents broadcast their intentions periodically, allowing other agents to infer coordination tasks. A propagation network transforms broadcast intentions into teammate-specific communication messages, sharing relevant goals with designated teammates. The architecture of our framework is structured into planning, grounding, and execution modules. During execution, multiple agents interact in a downstream environment and communicate intentions to enable coordinated behaviors. The grounding module dynamically adapts comprehension strategies based on emerging coordination patterns, while feedback from execution agents influnces the planning module, enabling the dynamic re-planning of sub-tasks. Results in collaborative environment simulation demonstrate intention propagation reduces miscoordination errors by aligning sub-task dependencies between agents. Agents learn when to communicate intentions and which teammates require task details, resulting in emergent coordinated behaviors. This demonstrates the efficacy of intention sharing for cooperative multi-agent RL based on LLMs.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.12532"
    },
    "1a251e7c759e994585df5ea1c5038191": {
        "title": "A LLM Benchmark based on the Minecraft Builder Dialog Agent Task",
        "authors": [
            "Chris Madge",
            "Massimo Poesio"
        ],
        "date": "2024/07/17",
        "pdf": "http://arxiv.org/pdf/2407.12734",
        "abstract": "In this work we proposing adapting the Minecraft builder task into an LLM benchmark suitable for evaluating LLM ability in spatially orientated tasks, and informing builder agent design. Previous works have proposed corpora with varying complex structures, and human written instructions. We instead attempt to provide a comprehensive synthetic benchmark for testing builder agents over a series of distinct tasks that comprise of common building operations. We believe this approach allows us to probe specific strengths and weaknesses of different agents, and test the ability of LLMs in the challenging area of spatial reasoning and vector based math.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.12734"
    },
    "5bf70c5fa709d79fe1f680f1ae96fb81": {
        "title": "AutoFlow: Automated Workflow Generation for Large Language Model Agents",
        "authors": [
            "Zelong Li",
            "Shuyuan Xu",
            "Kai Mei",
            "Wenyue Hua",
            "Balaji Rama",
            "Om Raheja",
            "Hao Wang",
            "He Zhu",
            "Yongfeng Zhang"
        ],
        "date": "2024/07/01",
        "pdf": "http://arxiv.org/pdf/2407.12821",
        "abstract": "Recent advancements in Large Language Models (LLMs) have shown significant progress in understanding complex natural language. One important application of LLM is LLM-based AI Agent, which leverages the ability of LLM as well as external tools for complex-task solving. To make sure LLM Agents follow an effective and reliable procedure to solve the given task, manually designed workflows are usually used to guide the working mechanism of agents. However, manually designing the workflows requires considerable efforts and domain knowledge, making it difficult to develop and deploy agents on massive scales. To address these issues, we propose AutoFlow, a framework designed to automatically generate workflows for agents to solve complex tasks. AutoFlow takes natural language program as the format of agent workflow and employs a workflow optimization procedure to iteratively optimize the workflow quality. Besides, this work offers two workflow generation methods: fine-tuning-based and in-context-based methods, making the AutoFlow framework applicable to both open-source and closed-source LLMs. Experimental results show that our framework can produce robust and reliable agent workflows. We believe that the automatic generation and interpretation of workflows in natural language represent a promising paradigm for solving complex tasks, particularly with the rapid development of LLMs. The source code of this work is available at https://github.com/agiresearch/AutoFlow.",
        "code": "",
        "category": [
            [
                "Automation",
                "Workflow"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.12821"
    },
    "127b55e2bc87c0db28354b2293ae0836": {
        "title": "CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis",
        "authors": [
            "Junying Chen",
            "Chi Gui",
            "Anningzhe Gao",
            "Ke Ji",
            "Xidong Wang",
            "Xiang Wan",
            "Benyou Wang"
        ],
        "date": "2024/07/18",
        "pdf": "http://arxiv.org/pdf/2407.13301",
        "abstract": "The field of medical diagnosis has undergone a significant transformation with the advent of large language models (LLMs), yet the challenges of interpretability within these models remain largely unaddressed. This study introduces Chain-of-Diagnosis (CoD) to enhance the interpretability of LLM-based medical diagnostics. CoD transforms the diagnostic process into a diagnostic chain that mirrors a physician&#39;s thought process, providing a transparent reasoning pathway. Additionally, CoD outputs the disease confidence distribution to ensure transparency in decision-making. This interpretability makes model diagnostics controllable and aids in identifying critical symptoms for inquiry through the entropy reduction of confidences. With CoD, we developed DiagnosisGPT, capable of diagnosing 9604 diseases. Experimental results demonstrate that DiagnosisGPT outperforms other LLMs on diagnostic benchmarks. Moreover, DiagnosisGPT provides interpretability while ensuring controllability in diagnostic rigor.",
        "code": "",
        "category": [
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.13301"
    },
    "957aabf00df5e731c903e71e8545a0fe": {
        "title": "dzFinNlp at AraFinNLP: Improving Intent Detection in Financial Conversational Agents",
        "authors": [
            "Mohamed Lichouri",
            "Khaled Lounnas",
            "Mohamed Zakaria Amziane"
        ],
        "date": "2024/07/18",
        "pdf": "http://arxiv.org/pdf/2407.13565",
        "abstract": "In this paper, we present our dzFinNlp team&#39;s contribution for intent detection in financial conversational agents, as part of the AraFinNLP shared task. We experimented with various models and feature configurations, including traditional machine learning methods like LinearSVC with TF-IDF, as well as deep learning models like Long Short-Term Memory (LSTM). Additionally, we explored the use of transformer-based models for this task. Our experiments show promising results, with our best model achieving a micro F1-score of 93.02% and 67.21% on the ArBanking77 dataset, in the development and test sets, respectively.",
        "code": "",
        "category": [
            [
                "Application",
                "Finance"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.13565"
    },
    "e99f659dbd52521525b3131c7815a9b4": {
        "title": "NeLLCom-X: A Comprehensive Neural-Agent Framework to Simulate Language Learning and Group Communication",
        "authors": [
            "Yuchen Lian",
            "Tessa Verhoef",
            "Arianna Bisazza"
        ],
        "date": "2024/07/19",
        "pdf": "http://arxiv.org/pdf/2407.13999",
        "abstract": "Recent advances in computational linguistics include simulating the emergence of human-like languages with interacting neural network agents, starting from sets of random symbols. The recently introduced NeLLCom framework (Lian et al., 2023) allows agents to first learn an artificial language and then use it to communicate, with the aim of studying the emergence of specific linguistics properties. We extend this framework (NeLLCom-X) by introducing more realistic role-alternating agents and group communication in order to investigate the interplay between language learnability, communication pressures, and group size effects. We validate NeLLCom-X by replicating key findings from prior research simulating the emergence of a word-order/case-marking trade-off. Next, we investigate how interaction affects linguistic convergence and emergence of the trade-off. The novel framework facilitates future simulations of diverse linguistic aspects, emphasizing the importance of interaction and group dynamics in language evolution.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.13999"
    },
    "70c0b3b97e7a46e0075d8c0ed157ad57": {
        "title": "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?",
        "authors": [
            "Ori Yoran",
            "Samuel Joseph Amouyal",
            "Chaitanya Malaviya",
            "Ben Bogin",
            "Ofir Press",
            "Jonathan Berant"
        ],
        "date": "2024/07/22",
        "pdf": "http://arxiv.org/pdf/2407.15711",
        "abstract": "Language agents, built on top of language models (LMs), are systems that can interact with complex environments, such as the open web. In this work, we examine whether such agents can perform realistic and time-consuming tasks on the web, e.g., monitoring real-estate markets or locating relevant nearby businesses. We introduce AssistantBench, a challenging new benchmark consisting of 214 realistic tasks that can be automatically evaluated, covering different scenarios and domains. We find that AssistantBench exposes the limitations of current systems, including language models and retrieval-augmented language models, as no model reaches an accuracy of more than 26 points. While closed-book LMs perform well in terms of accuracy, they exhibit low precision and tend to hallucinate facts. State-of-the-art web agents reach a score of near zero. Additionally, we introduce SeePlanAct (SPA), a new web agent that significantly outperforms previous agents, and an ensemble of SPA and closed-book models reaches the best overall performance. Moreover, we analyze failures of current systems and highlight that open web navigation remains a major challenge.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Tool Usage"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.15711"
    },
    "491d7beede149a2be68a285b803bbd94": {
        "title": "LawLuo: A Multi-Agent Collaborative Framework for Multi-Round Chinese Legal Consultation",
        "authors": [
            "Jingyun Sun",
            "Chengxiao Dai",
            "Zhongze Luo",
            "Yangbo Chang",
            "Yang Li"
        ],
        "date": "2024/07/23",
        "pdf": "http://arxiv.org/pdf/2407.16252",
        "abstract": "Legal Large Language Models (LLMs) have shown promise in providing legal consultations to non-experts. However, most existing Chinese legal consultation models are based on single-agent systems, which differ from real-world legal consultations, where multiple professionals collaborate to offer more tailored responses. To better simulate real consultations, we propose LawLuo, a multi-agent framework for multi-turn Chinese legal consultations. LawLuo includes four agents: the receptionist agent, which assesses user intent and selects a lawyer agent; the lawyer agent, which interacts with the user; the secretary agent, which organizes conversation records and generates consultation reports; and the boss agent, which evaluates the performance of the lawyer and secretary agents to ensure optimal results. These agents&#39; interactions mimic the operations of real law firms. To train them to follow different legal instructions, we developed distinct fine-tuning datasets. We also introduce a case graph-based RAG to help the lawyer agent address vague user inputs. Experimental results show that LawLuo outperforms baselines in generating more personalized and professional responses, handling ambiguous queries, and following legal instructions in multi-turn conversations. Our full code and constructed datasets will be open-sourced upon paper acceptance.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.16252"
    },
    "2bf42dfefea6083a42ff87a4a2c0ea19": {
        "title": "AMONGAGENTS: Evaluating Large Language Models in the Interactive Text-Based Social Deduction Game",
        "authors": [
            "Yizhou Chi",
            "Lingjun Mao",
            "Zineng Tang"
        ],
        "date": "2024/07/23",
        "pdf": "http://arxiv.org/pdf/2407.16521",
        "abstract": "Strategic social deduction games serve as valuable testbeds for evaluating the understanding and inference skills of language models, offering crucial insights into social science, artificial intelligence, and strategic gaming. This paper focuses on creating proxies of human behavior in simulated environments, with Among Us utilized as a tool for studying simulated human behavior. The study introduces a text-based game environment, named AmongAgents, that mirrors the dynamics of Among Us. Players act as crew members aboard a spaceship, tasked with identifying impostors who are sabotaging the ship and eliminating the crew. Within this environment, the behavior of simulated language agents is analyzed. The experiments involve diverse game sequences featuring different configurations of Crewmates and Impostor personality archetypes. Our work demonstrates that state-of-the-art large language models (LLMs) can effectively grasp the game rules and make decisions based on the current context. This work aims to promote further exploration of LLMs in goal-oriented games with incomplete information and complex action spaces, as these settings offer valuable opportunities to assess language model performance in socially driven scenarios.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.16521"
    },
    "280868d42f85c9d32642c562519382ea": {
        "title": "PersonaGym: Evaluating Persona Agents and LLMs",
        "authors": [
            "Vinay Samuel",
            "Henry Peng Zou",
            "Yue Zhou",
            "Shreyas Chaudhari",
            "Ashwin Kalyan",
            "Tanmay Rajpurohit",
            "Ameet Deshpande",
            "Karthik Narasimhan",
            "Vishvak Murahari"
        ],
        "date": "2024/07/25",
        "pdf": "http://arxiv.org/pdf/2407.18416",
        "abstract": "Persona agents, which are LLM agents that act according to an assigned persona, have demonstrated impressive contextual response capabilities across various applications. These persona agents offer significant enhancements across diverse sectors, such as education, healthcare, and entertainment, where model developers can align agent responses to different user requirements thereby broadening the scope of agent applications. However, evaluating persona agent performance is incredibly challenging due to the complexity of assessing persona adherence in free-form interactions across various environments that are relevant to each persona agent. We introduce PersonaGym, the first dynamic evaluation framework for assessing persona agents, and PersonaScore, the first automated human-aligned metric grounded in decision theory for comprehensive large-scale evaluation of persona agents. Our evaluation of 6 open and closed-source LLMs, using a benchmark encompassing 200 personas and 10,000 questions, reveals significant opportunities for advancement in persona agent capabilities across state-of-the-art models. For example, Claude 3.5 Sonnet only has a 2.97% relative improvement in PersonaScore than GPT 3.5 despite being a much more advanced model. Importantly, we find that increased model size and complexity do not necessarily imply enhanced persona agent capabilities thereby highlighting the pressing need for algorithmic and architectural invention towards faithful and performant persona agents.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.18416"
    },
    "0389418121da3e9e33cc92a9b644279d": {
        "title": "OfficeBench: Benchmarking Language Agents across Multiple Applications for Office Automation",
        "authors": [
            "Zilong Wang",
            "Yuedong Cui",
            "Li Zhong",
            "Zimin Zhang",
            "Da Yin",
            "Bill Yuchen Lin",
            "Jingbo Shang"
        ],
        "date": "2024/07/26",
        "pdf": "http://arxiv.org/pdf/2407.19056",
        "abstract": "Office automation significantly enhances human productivity by automatically finishing routine tasks in the workflow. Beyond the basic information extraction studied in much of the prior document AI literature, the office automation research should be extended to more realistic office tasks which require to integrate various information sources in the office system and produce outputs through a series of decision-making processes. We introduce OfficeBench, one of the first office automation benchmarks for evaluating current LLM agents&#39; capability to address office tasks in realistic office workflows. OfficeBench requires LLM agents to perform feasible long-horizon planning, proficiently switch between applications in a timely manner, and accurately ground their actions within a large combined action space, based on the contextual demands of the workflow. Applying our customized evaluation methods on each task, we find that GPT-4 Omni achieves the highest pass rate of 47.00%, demonstrating a decent performance in handling office tasks. However, this is still far below the human performance and accuracy standards required by real-world office workflows. We further observe that most issues are related to operation redundancy and hallucinations, as well as limitations in switching between multiple applications, which may provide valuable insights for developing effective agent frameworks for office automation.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.19056"
    },
    "e24c3f7923bcd5a29b347a98774c229f": {
        "title": "Towards Achieving Human Parity on End-to-end Simultaneous Speech Translation via LLM Agent",
        "authors": [
            "Shanbo Cheng",
            "Zhichao Huang",
            "Tom Ko",
            "Hang Li",
            "Ningxin Peng",
            "Lu Xu",
            "Qini Zhang"
        ],
        "date": "2024/07/31",
        "pdf": "http://arxiv.org/pdf/2407.21646",
        "abstract": "In this paper, we present Cross Language Agent -- Simultaneous Interpretation, CLASI, a high-quality and human-like Simultaneous Speech Translation (SiST) System. Inspired by professional human interpreters, we utilize a novel data-driven read-write strategy to balance the translation quality and latency. To address the challenge of translating in-domain terminologies, CLASI employs a multi-modal retrieving module to obtain relevant information to augment the translation. Supported by LLMs, our approach can generate error-tolerated translation by considering the input audio, historical context, and retrieved information. Experimental results show that our system outperforms other systems by significant margins. Aligned with professional human interpreters, we evaluate CLASI with a better human evaluation metric, valid information proportion (VIP), which measures the amount of information that can be successfully conveyed to the listeners. In the real-world scenarios, where the speeches are often disfluent, informal, and unclear, CLASI achieves VIP of 81.3% and 78.0% for Chinese-to-English and English-to-Chinese translation directions, respectively. In contrast, state-of-the-art commercial or open-source systems only achieve 35.4% and 41.6%. On the extremely hard dataset, where other systems achieve under 13% VIP, CLASI can still achieve 70% VIP.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.21646"
    },
    "e5aa9385baf7075bdd5e9a6d56387854": {
        "title": "OmniJARVIS: Unified Vision-Language-Action Tokenization Enables Open-World Instruction Following Agents",
        "authors": [
            "Zihao Wang",
            "Shaofei Cai",
            "Zhancun Mu",
            "Haowei Lin",
            "Ceyao Zhang",
            "Xuejie Liu",
            "Qing Li",
            "Anji Liu",
            "Xiaojian Ma",
            "Yitao Liang"
        ],
        "date": "2024/06/27",
        "pdf": "http://arxiv.org/pdf/2407.00114",
        "abstract": "This paper presents OmniJARVIS, a novel Vision-Language-Action (VLA) model for open-world instruction-following agents in Minecraft. Compared to prior works that either emit textual goals to separate controllers or produce the control command directly, OmniJARVIS seeks a different path to ensure both strong reasoning and efficient decision-making capabilities via unified tokenization of multimodal interaction data. First, we introduce a self-supervised approach to learn a behavior encoder that produces discretized tokens for behavior trajectories $\\tau = \\{o_0, a_0, \\dots\\}$ and an imitation learning policy decoder conditioned on these tokens. These additional behavior tokens will be augmented to the vocabulary of pretrained Multimodal Language Models. With this encoder, we then pack long-term multimodal interactions involving task instructions, memories, thoughts, observations, textual responses, behavior trajectories, etc into unified token sequences and model them with autoregressive transformers. Thanks to the semantically meaningful behavior tokens, the resulting VLA model, OmniJARVIS, can reason (by producing chain-of-thoughts), plan, answer questions, and act (by producing behavior tokens for the imitation learning policy decoder). OmniJARVIS demonstrates excellent performances on a comprehensive collection of atomic, programmatic, and open-ended tasks in open-world Minecraft. Our analysis further unveils the crucial design principles in interaction data formation, unified tokenization, and its scaling potentials. The dataset, models, and code will be released at https://craftjarvis.org/OmniJARVIS.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Game Playing"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.00114"
    },
    "59a212db7d657f7091328e53727414ad": {
        "title": "CAMON: Cooperative Agents for Multi-Object Navigation with LLM-based Conversations",
        "authors": [
            "Pengying Wu",
            "Yao Mu",
            "Kangjie Zhou",
            "Ji Ma",
            "Junting Chen",
            "Chang Liu"
        ],
        "date": "2024/06/30",
        "pdf": "http://arxiv.org/pdf/2407.00632",
        "abstract": "Visual navigation tasks are critical for household service robots. As these tasks become increasingly complex, effective communication and collaboration among multiple robots become imperative to ensure successful completion. In recent years, large language models (LLMs) have exhibited remarkable comprehension and planning abilities in the context of embodied agents. However, their application in household scenarios, specifically in the use of multiple agents collaborating to complete complex navigation tasks through communication, remains unexplored. Therefore, this paper proposes a framework for decentralized multi-agent navigation, leveraging LLM-enabled communication and collaboration. By designing the communication-triggered dynamic leadership organization structure, we achieve faster team consensus with fewer communication instances, leading to better navigation effectiveness and collaborative exploration efficiency. With the proposed novel communication scheme, our framework promises to be conflict-free and robust in multi-object navigation tasks, even when there is a surge in team size.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.00632"
    },
    "6a3d4c045462598babfac98e1b976395": {
        "title": "ProductAgent: Benchmarking Conversational Product Search Agent with Asking Clarification Questions",
        "authors": [
            "Jingheng Ye",
            "Yong Jiang",
            "Xiaobin Wang",
            "Yinghui Li",
            "Yangning Li",
            "Hai-Tao Zheng",
            "Pengjun Xie",
            "Fei Huang"
        ],
        "date": "2024/07/01",
        "pdf": "http://arxiv.org/pdf/2407.00942",
        "abstract": "This paper introduces the task of product demand clarification within an e-commercial scenario, where the user commences the conversation with ambiguous queries and the task-oriented agent is designed to achieve more accurate and tailored product searching by asking clarification questions. To address this task, we propose ProductAgent, a conversational information seeking agent equipped with abilities of strategic clarification question generation and dynamic product retrieval. Specifically, we develop the agent with strategies for product feature summarization, query generation, and product retrieval. Furthermore, we propose the benchmark called PROCLARE to evaluate the agent&#39;s performance both automatically and qualitatively with the aid of a LLM-driven user simulator. Experiments show that ProductAgent interacts positively with the user and enhances retrieval performance with increasing dialogue turns, where user demands become gradually more explicit and detailed. All the source codes will be released after the review anonymity period.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.00942"
    },
    "89e1ca3b34613186732308d39ff3096d": {
        "title": "Mobile-Bench: An Evaluation Benchmark for LLM-based Mobile Agents",
        "authors": [
            "Shihan Deng",
            "Weikai Xu",
            "Hongda Sun",
            "Wei Liu",
            "Tao Tan",
            "Jianfeng Liu",
            "Ang Li",
            "Jian Luan",
            "Bin Wang",
            "Rui Yan",
            "Shuo Shang"
        ],
        "date": "2024/07/01",
        "pdf": "http://arxiv.org/pdf/2407.00993",
        "abstract": "With the remarkable advancements of large language models (LLMs), LLM-based agents have become a research hotspot in human-computer interaction. However, there is a scarcity of benchmarks available for LLM-based mobile agents. Benchmarking these agents generally faces three main challenges: (1) The inefficiency of UI-only operations imposes limitations to task evaluation. (2) Specific instructions within a singular application lack adequacy for assessing the multi-dimensional reasoning and decision-making capacities of LLM mobile agents. (3) Current evaluation metrics are insufficient to accurately assess the process of sequential actions. To this end, we propose Mobile-Bench, a novel benchmark for evaluating the capabilities of LLM-based mobile agents. First, we expand conventional UI operations by incorporating 103 collected APIs to accelerate the efficiency of task completion. Subsequently, we collect evaluation data by combining real user queries with augmentation from LLMs. To better evaluate different levels of planning capabilities for mobile agents, our data is categorized into three distinct groups: SAST, SAMT, and MAMT, reflecting varying levels of task complexity. Mobile-Bench comprises 832 data entries, with more than 200 tasks specifically designed to evaluate multi-APP collaboration scenarios. Furthermore, we introduce a more accurate evaluation metric, named CheckPoint, to assess whether LLM-based mobile agents reach essential points during their planning and reasoning steps.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ],
            [
                "Interaction",
                "Tool Usage"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.00993"
    },
    "d73ffeb8329ac0bd5b29edacae5a0c04": {
        "title": "Tree Search for Language Model Agents",
        "authors": [
            "Jing Yu Koh",
            "Stephen McAleer",
            "Daniel Fried",
            "Ruslan Salakhutdinov"
        ],
        "date": "2024/07/01",
        "pdf": "http://arxiv.org/pdf/2407.01476",
        "abstract": "Autonomous agents powered by language models (LMs) have demonstrated promise in their ability to perform decision-making tasks such as web automation. However, a key limitation remains: LMs, primarily optimized for natural language understanding and generation, struggle with multi-step reasoning, planning, and using environmental feedback when attempting to solve realistic computer tasks. Towards addressing this, we propose an inference-time search algorithm for LM agents to explicitly perform exploration and multi-step planning in interactive web environments. Our approach is a form of best-first tree search that operates within the actual environment space, and is complementary with most existing state-of-the-art agents. It is the first tree search algorithm for LM agents that shows effectiveness on realistic web tasks. On the challenging VisualWebArena benchmark, applying our search algorithm on top of a GPT-4o agent yields a 39.7% relative increase in success rate compared to the same baseline without search, setting a state-of-the-art success rate of 26.4%. On WebArena, search also yields a 28.0% relative improvement over a baseline agent, setting a competitive success rate of 19.2%. Our experiments highlight the effectiveness of search for web agents, and we demonstrate that performance scales with increased test-time compute. We conduct a thorough analysis of our results to highlight improvements from search, limitations, and promising directions for future work. Our code and models are publicly released at https://jykoh.com/search-agents.",
        "code": "",
        "category": [
            [
                "Technique For Enhancement",
                "Search"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.01476"
    },
    "ea131129157d81fa25bdb203dc0f7071": {
        "title": "Agentless: Demystifying LLM-based Software Engineering Agents",
        "authors": [
            "Chunqiu Steven Xia",
            "Yinlin Deng",
            "Soren Dunn",
            "Lingming Zhang"
        ],
        "date": "2024/07/01",
        "pdf": "http://arxiv.org/pdf/2407.01489",
        "abstract": "Recent advancements in large language models (LLMs) have significantly advanced the automation of software development tasks, including code synthesis, program repair, and test generation. More recently, researchers and industry practitioners have developed various autonomous LLM agents to perform end-to-end software development tasks. These agents are equipped with the ability to use tools, run commands, observe feedback from the environment, and plan for future actions. However, the complexity of these agent-based approaches, together with the limited abilities of current LLMs, raises the following question: Do we really have to employ complex autonomous software agents? To attempt to answer this question, we build Agentless -- an agentless approach to automatically solve software development problems. Compared to the verbose and complex setup of agent-based approaches, Agentless employs a simplistic three-phase process of localization, repair, and patch validation, without letting the LLM decide future actions or operate with complex tools. Our results on the popular SWE-bench Lite benchmark show that surprisingly the simplistic Agentless is able to achieve both the highest performance (32.00%, 96 correct fixes) and low cost ($0.70) compared with all existing open-source software agents! Furthermore, we manually classified the problems in SWE-bench Lite and found problems with exact ground truth patch or insufficient/misleading issue descriptions. As such, we construct SWE-bench Lite-S by excluding such problematic issues to perform more rigorous evaluation and comparison. Our work highlights the current overlooked potential of a simple, interpretable technique in autonomous software development. We hope Agentless will help reset the baseline, starting point, and horizon for autonomous software agents, and inspire future work along this crucial direction.",
        "code": "",
        "category": [
            [
                "Application",
                "Software Engineering"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.01489"
    },
    "5164e419d0f40c0b38e57d101a013876": {
        "title": "A Review of Large Language Models and Autonomous Agents in Chemistry",
        "authors": [
            "Mayk Caldas Ramos",
            "Christopher J. Collison",
            "Andrew D. White"
        ],
        "date": "2024/06/26",
        "pdf": "http://arxiv.org/pdf/2407.01603",
        "abstract": "Large language models (LLMs) have emerged as powerful tools in chemistry, significantly impacting molecule design, property prediction, and synthesis optimization. This review highlights LLM capabilities in these domains and their potential to accelerate scientific discovery through automation. We also review LLM-based autonomous agents: LLMs with a broader set of tools to interact with their surrounding environment. These agents perform diverse tasks such as paper scraping, interfacing with automated laboratories, and synthesis planning. As agents are an emerging topic, we extend the scope of our review of agents beyond chemistry and discuss across any scientific domains. This review covers the recent history, current capabilities, and design of LLMs and autonomous agents, addressing specific challenges, opportunities, and future directions in chemistry. Key challenges include data quality and integration, model interpretability, and the need for standard benchmarks, while future directions point towards more sophisticated multi-modal agents and enhanced collaboration between agents and experimental methods. Due to the quick pace of this field, a repository has been built to keep track of the latest studies: https://github.com/ur-whitelab/LLMs-in-science.",
        "code": "",
        "category": [
            [
                "Application",
                "Chemistry"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.01603"
    },
    "98890103f5ad2d299dc3510635fe63a9": {
        "title": "Empathic Grounding: Explorations using Multimodal Interaction and Large Language Models with Conversational Agents",
        "authors": [
            "Mehdi Arjmand",
            "Farnaz Nouraei",
            "Ian Steenstra",
            "Timothy Bickmore"
        ],
        "date": "2024/07/01",
        "pdf": "http://arxiv.org/pdf/2407.01824",
        "abstract": "We introduce the concept of &#34;empathic grounding&#34; in conversational agents as an extension of Clark&#39;s conceptualization of grounding in conversation in which the grounding criterion includes listener empathy for the speaker&#39;s affective state. Empathic grounding is generally required whenever the speaker&#39;s emotions are foregrounded and can make the grounding process more efficient and reliable by communicating both propositional and affective understanding. Both speaker expressions of affect and listener empathic grounding can be multimodal, including facial expressions and other nonverbal displays. Thus, models of empathic grounding for embodied agents should be multimodal to facilitate natural and efficient communication. We describe a multimodal model that takes as input user speech and facial expression to generate multimodal grounding moves for a listening agent using a large language model. We also describe a testbed to evaluate approaches to empathic grounding, in which a humanoid robot interviews a user about a past episode of pain and then has the user rate their perception of the robot&#39;s empathy. We compare our proposed model to one that only generates non-affective grounding cues in a between-subjects experiment. Findings demonstrate that empathic grounding increases user perceptions of empathy, understanding, emotional intelligence, and trust. Our work highlights the role of emotion awareness and multimodality in generating appropriate grounding moves for conversational agents.",
        "code": "",
        "category": [
            [
                "Interaction",
                "Conversation"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.01824"
    },
    "c8fbc14c9e8ac667748c4e8997726ce8": {
        "title": "Beyond Numeric Awards: In-Context Dueling Bandits with LLM Agents",
        "authors": [
            "Fanzeng Xia",
            "Hao Liu",
            "Yisong Yue",
            "Tongxin Li"
        ],
        "date": "2024/07/02",
        "pdf": "http://arxiv.org/pdf/2407.01887",
        "abstract": "In-context reinforcement learning (ICRL) is a frontier paradigm for solving reinforcement learning problems in the foundation model era. While ICRL capabilities have been demonstrated in transformers through task-specific training, the potential of Large Language Models (LLMs) out-of-the-box remains largely unexplored. Recent findings highlight that LLMs often face challenges when dealing with numerical contexts, and limited attention has been paid to evaluating their performance through preference feedback generated by the environment. This paper is the first to investigate LLMs as in-context decision-makers under the problem of Dueling Bandits (DB), a stateless preference-based reinforcement learning setting that extends the classic Multi-Armed Bandit (MAB) model by querying for preference feedback. We compare GPT-3.5 Turbo, GPT-4, GPT-4 Turbo, Llama 3.1, and o1-Preview against nine well-established DB algorithms. Our results reveal that our top-performing LLM, GPT-4 Turbo, has the zero-shot relative decision-making ability to achieve surprisingly low weak regret across all the DB environment instances by quickly including the best arm in duels. However, an optimality gap exists between LLMs and classic DB algorithms in terms of strong regret. LLMs struggle to converge and consistently exploit even when explicitly prompted to do so, and are sensitive to prompt variations. To bridge this gap, we propose an agentic flow framework: LLM with Enhanced Algorithmic Dueling (LEAD), which integrates off-the-shelf DB algorithms with LLM agents through fine-grained adaptive interplay. We show that LEAD has theoretical guarantees inherited from classic DB algorithms on both weak and strong regret. We validate its efficacy and robustness even with noisy and adversarial prompts. The design of our framework sheds light on how to enhance the trustworthiness of LLMs used for in-context decision-making.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.01887"
    },
    "b4bf86ba93333e2371a3421dce934afd": {
        "title": "AgentInstruct: Toward Generative Teaching with Agentic Flows",
        "authors": [
            "Arindam Mitra",
            "Luciano Del Corro",
            "Guoqing Zheng",
            "Shweti Mahajan",
            "Dany Rouhana",
            "Andres Codas",
            "Yadong Lu",
            "Wei-ge Chen",
            "Olga Vrousgos",
            "Corby Rosset",
            "Fillipe Silva",
            "Hamed Khanpour",
            "Yash Lara",
            "Ahmed Awadallah"
        ],
        "date": "2024/07/03",
        "pdf": "http://arxiv.org/pdf/2407.03502",
        "abstract": "Synthetic data is becoming increasingly important for accelerating the development of language models, both large and small. Despite several successful use cases, researchers also raised concerns around model collapse and drawbacks of imitating other models. This discrepancy can be attributed to the fact that synthetic data varies in quality and diversity. Effective use of synthetic data usually requires significant human effort in curating the data. We focus on using synthetic data for post-training, specifically creating data by powerful models to teach a new skill or behavior to another model, we refer to this setting as Generative Teaching. We introduce AgentInstruct, an extensible agentic framework for automatically creating large amounts of diverse and high-quality synthetic data. AgentInstruct can create both the prompts and responses, using only raw data sources like text documents and code files as seeds. We demonstrate the utility of AgentInstruct by creating a post training dataset of 25M pairs to teach language models different skills, such as text editing, creative writing, tool usage, coding, reading comprehension, etc. The dataset can be used for instruction tuning of any base model. We post-train Mistral-7b with the data. When comparing the resulting model Orca-3 to Mistral-7b-Instruct (which uses the same base model), we observe significant improvements across many benchmarks. For example, 40% improvement on AGIEval, 19% improvement on MMLU, 54% improvement on GSM8K, 38% improvement on BBH and 45% improvement on AlpacaEval. Additionally, it consistently outperforms other models such as LLAMA-8B-instruct and GPT-3.5-turbo.",
        "code": "",
        "category": [
            [
                "Automation",
                "Workflow"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.03502"
    },
    "b271026016604f9b053a53bfbde1c1a3": {
        "title": "Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems",
        "authors": [
            "Shmuel Berman",
            "Kathleen McKeown",
            "Baishakhi Ray"
        ],
        "date": "2024/07/04",
        "pdf": "http://arxiv.org/pdf/2407.03956",
        "abstract": "Prior research has enhanced the ability of Large Language Models (LLMs) to solve logic puzzles using techniques such as chain-of-thought prompting or introducing a symbolic representation. These frameworks are still usually insufficient to solve complicated logical problems, such as Zebra puzzles, due to the inherent complexity of translating natural language clues into logical statements. We introduce a multi-agent system, ZPS, that integrates LLMs with an off the shelf theorem prover. This system tackles the complex puzzle-solving task by breaking down the problem into smaller, manageable parts, generating SMT (Satisfiability Modulo Theories) code to solve them with a theorem prover, and using feedback between the agents to repeatedly improve their answers. We also introduce an automated grid puzzle grader to assess the correctness of our puzzle solutions and show that the automated grader is reliable by evaluating it in a user-study. Our approach shows improvement in all three LLMs we tested, with GPT-4 showing 166% improvement in the number of fully correct solutions.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.03956"
    },
    "c0225ca7c0f16e817aba8c303dd09042": {
        "title": "Coding Reliable LLM-based Integrated Task and Knowledge Agents with GenieWorksheets",
        "authors": [
            "Harshit Joshi",
            "Shicheng Liu",
            "James Chen",
            "Robert Weigle",
            "Monica S. Lam"
        ],
        "date": "2024/07/08",
        "pdf": "http://arxiv.org/pdf/2407.05674",
        "abstract": "Large Language Models (LLMs) present an opportunity to create automated assistants that can help users navigate complex tasks. However, existing approaches have limitations in handling conditional logic, integrating knowledge sources, and consistently following instructions. Researchers and industry professionals often employ ad hoc pipelines to construct conversational agents. These pipelines aim to maintain context, address failure cases, and minimize hallucinations, yet frequently fail to achieve these objectives. To this end, we present Genie - a programmable framework for creating task-oriented conversational agents that are designed to handle complex user interactions and knowledge queries. Unlike LLMs, Genie provides reliable grounded responses, with controllable agent policies through its expressive specification, Genie Worksheet. In contrast to dialog trees, it is resilient to diverse user queries, helpful with knowledge sources, and offers ease of programming policies through its declarative paradigm. The agents built using Genie outperforms the state-of-the-art method on complex logic domains in STARV2 dataset by up to 20.5%. Additionally, through a real-user study involving 62 participants, we show that Genie beats the GPT-4 with function calling baseline by 21.1%, 20.1%, and 61% on execution accuracy, dialogue act accuracy, and goal completion rate, respectively, on three diverse real-world domains",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Environment&Platform"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.05674"
    },
    "8e7294abf696fa3b159ad4c1ef9743c3": {
        "title": "Virtual Agents for Alcohol Use Counseling: Exploring LLM-Powered Motivational Interviewing",
        "authors": [
            "Ian Steenstra",
            "Farnaz Nouraei",
            "Mehdi Arjmand",
            "Timothy W. Bickmore"
        ],
        "date": "2024/07/10",
        "pdf": "http://arxiv.org/pdf/2407.08095",
        "abstract": "We introduce a novel application of large language models (LLMs) in developing a virtual counselor capable of conducting motivational interviewing (MI) for alcohol use counseling. Access to effective counseling remains limited, particularly for substance abuse, and virtual agents offer a promising solution by leveraging LLM capabilities to simulate nuanced communication techniques inherent in MI. Our approach combines prompt engineering and integration into a user-friendly virtual platform to facilitate realistic, empathetic interactions. We evaluate the effectiveness of our virtual agent through a series of studies focusing on replicating MI techniques and human counselor dialog. Initial findings suggest that our LLM-powered virtual agent matches human counselors&#39; empathetic and adaptive conversational skills, presenting a significant step forward in virtual health counseling and providing insights into the design and implementation of LLM-based therapeutic interactions.",
        "code": "",
        "category": [
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.08095"
    },
    "8c771d15fe017a9008f179fab98fdb26": {
        "title": "IDAT: A Multi-Modal Dataset and Toolkit for Building and Evaluating Interactive Task-Solving Agents",
        "authors": [
            "Shrestha Mohanty",
            "Negar Arabzadeh",
            "Andrea Tupini",
            "Yuxuan Sun",
            "Alexey Skrynnik",
            "Artem Zholus",
            "Marc-Alexandre CÃ´tÃ©",
            "Julia Kiseleva"
        ],
        "date": "2024/07/12",
        "pdf": "http://arxiv.org/pdf/2407.08898",
        "abstract": "Seamless interaction between AI agents and humans using natural language remains a key goal in AI research. This paper addresses the challenges of developing interactive agents capable of understanding and executing grounded natural language instructions through the IGLU competition at NeurIPS. Despite advancements, challenges such as a scarcity of appropriate datasets and the need for effective evaluation platforms persist. We introduce a scalable data collection tool for gathering interactive grounded language instructions within a Minecraft-like environment, resulting in a Multi-Modal dataset with around 9,000 utterances and over 1,000 clarification questions. Additionally, we present a Human-in-the-Loop interactive evaluation platform for qualitative analysis and comparison of agent performance through multi-turn communication with human annotators. We offer to the community these assets referred to as IDAT (IGLU Dataset And Toolkit) which aim to advance the development of intelligent, interactive AI agents and provide essential resources for further research.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ],
            [
                "Infrastructure",
                "Environment&Platform"
            ],
            [
                "Infrastructure",
                "Dataset"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.08898"
    },
    "a37e7ba05a2ddb72bd353cd190b1f630": {
        "title": "Sibyl: Simple yet Effective Agent Framework for Complex Real-world Reasoning",
        "authors": [
            "Yulong Wang",
            "Tianhao Shen",
            "Lifeng Liu",
            "Jian Xie"
        ],
        "date": "2024/07/15",
        "pdf": "http://arxiv.org/pdf/2407.10718",
        "abstract": "Existing agents based on large language models (LLMs) demonstrate robust problem-solving capabilities by integrating LLMs&#39; inherent knowledge, strong in-context learning and zero-shot capabilities, and the use of tools combined with intricately designed LLM invocation workflows by humans. However, these agents still exhibit shortcomings in long-term reasoning and under-use the potential of existing tools, leading to noticeable deficiencies in complex real-world reasoning scenarios. To address these limitations, we introduce Sibyl, a simple yet powerful LLM-based agent framework designed to tackle complex reasoning tasks by efficiently leveraging a minimal set of tools. Drawing inspiration from Global Workspace Theory, Sibyl incorporates a global workspace to enhance the management and sharing of knowledge and conversation history throughout the system. Furthermore, guided by Society of Mind Theory, Sibyl implements a multi-agent debate-based jury to self-refine the final answers, ensuring a comprehensive and balanced approach. This approach aims to reduce system complexity while expanding the scope of problems solvable-from matters typically resolved by humans in minutes to those requiring hours or even days, thus facilitating a shift from System-1 to System-2 thinking. Sibyl has been designed with a focus on scalability and ease of debugging by incorporating the concept of reentrancy from functional programming from its inception, with the aim of seamless and low effort integration in other LLM applications to improve capabilities. Our experimental results on the GAIA benchmark test set reveal that the Sibyl agent instantiated with GPT-4 achieves state-of-the-art performance with an average score of 34.55%, compared to other agents based on GPT-4. We hope that Sibyl can inspire more reliable and reusable LLM-based agent solutions to address complex real-world reasoning tasks.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.10718"
    },
    "e37aba8066bbd1c8cc374565ccee365c": {
        "title": "Spider2-V: How Far Are Multimodal Agents From Automating Data Science and Engineering Workflows?",
        "authors": [
            "Ruisheng Cao",
            "Fangyu Lei",
            "Haoyuan Wu",
            "Jixuan Chen",
            "Yeqiao Fu",
            "Hongcheng Gao",
            "Xinzhuang Xiong",
            "Hanchong Zhang",
            "Yuchen Mao",
            "Wenjing Hu",
            "Tianbao Xie",
            "Hongshen Xu",
            "Danyang Zhang",
            "Sida Wang",
            "Ruoxi Sun",
            "Pengcheng Yin",
            "Caiming Xiong",
            "Ansong Ni",
            "Qian Liu",
            "Victor Zhong",
            "Lu Chen",
            "Kai Yu",
            "Tao Yu"
        ],
        "date": "2024/07/15",
        "pdf": "http://arxiv.org/pdf/2407.10956",
        "abstract": "Data science and engineering workflows often span multiple stages, from warehousing to orchestration, using tools like BigQuery, dbt, and Airbyte. As vision language models (VLMs) advance in multimodal understanding and code generation, VLM-based agents could potentially automate these workflows by generating SQL queries, Python code, and GUI operations. This automation can improve the productivity of experts while democratizing access to large-scale data analysis. In this paper, we introduce Spider2-V, the first multimodal agent benchmark focusing on professional data science and engineering workflows, featuring 494 real-world tasks in authentic computer environments and incorporating 20 enterprise-level professional applications. These tasks, derived from real-world use cases, evaluate the ability of a multimodal agent to perform data-related tasks by writing code and managing the GUI in enterprise data software systems. To balance realistic simulation with evaluation simplicity, we devote significant effort to developing automatic configurations for task setup and carefully crafting evaluation metrics for each task. Furthermore, we supplement multimodal agents with comprehensive documents of these enterprise data software systems. Our empirical evaluation reveals that existing state-of-the-art LLM/VLM-based agents do not reliably automate full data workflows (14.0% success). Even with step-by-step guidance, these agents still underperform in tasks that require fine-grained, knowledge-intensive GUI actions (16.2%) and involve remote cloud-hosted workspaces (10.6%). We hope that Spider2-V paves the way for autonomous multimodal agents to transform the automation of data science and engineering workflow. Our code and data are available at https://spider2-v.github.io.",
        "code": "",
        "category": [
            [
                "Automation",
                "Workflow"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.10956"
    },
    "f533a4d2e2dca63f5227fd8c506db96a": {
        "title": "Towards Automated Functional Equation Proving: A Benchmark Dataset and A Domain-Specific In-Context Agent",
        "authors": [
            "Mahdi Buali",
            "Robert Hoehndorf"
        ],
        "date": "2024/07/05",
        "pdf": "http://arxiv.org/pdf/2407.14521",
        "abstract": "Automated Theorem Proving (ATP) faces challenges due to its complexity and computational demands. Recent work has explored using Large Language Models (LLMs) for ATP action selection, but these methods can be resource-intensive. This study introduces FEAS, an agent that enhances the COPRA in-context learning framework within Lean. FEAS refines prompt generation, response parsing, and incorporates domain-specific heuristics for functional equations. It introduces FunEq, a curated dataset of functional equation problems with varying difficulty. FEAS outperforms baselines on FunEq, particularly with the integration of domain-specific heuristics. The results demonstrate FEAS&#39;s effectiveness in generating and formalizing high-level proof strategies into Lean proofs, showcasing the potential of tailored approaches for specific ATP challenges.",
        "code": "",
        "category": [
            [
                "Application",
                "Finance"
            ],
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.14521"
    },
    "75fd8a80a92a7664a07cc27ade56b7ce": {
        "title": "Multi-Agent Causal Discovery Using Large Language Models",
        "authors": [
            "Hao Duong Le",
            "Xin Xia",
            "Zhang Chen"
        ],
        "date": "2024/07/21",
        "pdf": "http://arxiv.org/pdf/2407.15073",
        "abstract": "Large Language Models (LLMs) have demonstrated significant potential in causal discovery tasks by utilizing their vast expert knowledge from extensive text corpora. However, the multi-agent capabilities of LLMs in causal discovery remain underexplored. This paper introduces a general framework to investigate this potential. The first is the Meta Agents Model, which relies exclusively on reasoning and discussions among LLM agents to conduct causal discovery. The second is the Coding Agents Model, which leverages the agents&#39; ability to plan, write, and execute code, utilizing advanced statistical libraries for causal discovery. The third is the Hybrid Model, which integrates both the Meta Agents Model and CodingAgents Model approaches, combining the statistical analysis and reasoning skills of multiple agents. Our proposed framework shows promising results by effectively utilizing LLMs expert knowledge, reasoning capabilities, multi-agent cooperation, and statistical causal methods. By exploring the multi-agent potential of LLMs, we aim to establish a foundation for further research in utilizing LLMs multi-agent for solving causal-related problems.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.15073"
    },
    "dede7fc648d5b7ab653c6eb7f95555d8": {
        "title": "RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent",
        "authors": [
            "Huiyu Xu",
            "Wenhui Zhang",
            "Zhibo Wang",
            "Feng Xiao",
            "Rui Zheng",
            "Yunhe Feng",
            "Zhongjie Ba",
            "Kui Ren"
        ],
        "date": "2024/07/23",
        "pdf": "http://arxiv.org/pdf/2407.16667",
        "abstract": "Recently, advanced Large Language Models (LLMs) such as GPT-4 have been integrated into many real-world applications like Code Copilot. These applications have significantly expanded the attack surface of LLMs, exposing them to a variety of threats. Among them, jailbreak attacks that induce toxic responses through jailbreak prompts have raised critical safety concerns. To identify these threats, a growing number of red teaming approaches simulate potential adversarial scenarios by crafting jailbreak prompts to test the target LLM. However, existing red teaming methods do not consider the unique vulnerabilities of LLM in different scenarios, making it difficult to adjust the jailbreak prompts to find context-specific vulnerabilities. Meanwhile, these methods are limited to refining jailbreak templates using a few mutation operations, lacking the automation and scalability to adapt to different scenarios. To enable context-aware and efficient red teaming, we abstract and model existing attacks into a coherent concept called &#34;jailbreak strategy&#34; and propose a multi-agent LLM system named RedAgent that leverages these strategies to generate context-aware jailbreak prompts. By self-reflecting on contextual feedback in an additional memory buffer, RedAgent continuously learns how to leverage these strategies to achieve effective jailbreaks in specific contexts. Extensive experiments demonstrate that our system can jailbreak most black-box LLMs in just five queries, improving the efficiency of existing red teaming methods by two times. Additionally, RedAgent can jailbreak customized LLM applications more efficiently. By generating context-aware jailbreak prompts towards applications on GPTs, we discover 60 severe vulnerabilities of these real-world applications with only two queries per vulnerability. We have reported all found issues and communicated with OpenAI and Meta for bug fixes.",
        "code": "",
        "category": [
            [
                "Stability",
                "Safety"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.16667"
    },
    "1b4c705859313c5f9fbc8ad3009f7ec1": {
        "title": "OpenHands: An Open Platform for AI Software Developers as Generalist Agents",
        "authors": [
            "Xingyao Wang",
            "Boxuan Li",
            "Yufan Song",
            "Frank F. Xu",
            "Xiangru Tang",
            "Mingchen Zhuge",
            "Jiayi Pan",
            "Yueqi Song",
            "Bowen Li",
            "Jaskirat Singh",
            "Hoang H. Tran",
            "Fuqiang Li",
            "Ren Ma",
            "Mingzhang Zheng",
            "Bill Qian",
            "Yanjun Shao",
            "Niklas Muennighoff",
            "Yizhe Zhang",
            "Binyuan Hui",
            "Junyang Lin",
            "Robert Brennan",
            "Hao Peng",
            "Heng Ji",
            "Graham Neubig"
        ],
        "date": "2024/07/23",
        "pdf": "http://arxiv.org/pdf/2407.16741",
        "abstract": "Software is one of the most powerful tools that we humans have at our disposal; it allows a skilled programmer to interact with the world in complex and profound ways. At the same time, thanks to improvements in large language models (LLMs), there has also been a rapid development in AI agents that interact with and affect change in their surrounding environments. In this paper, we introduce OpenHands (f.k.a. OpenDevin), a platform for the development of powerful and flexible AI agents that interact with the world in similar ways to those of a human developer: by writing code, interacting with a command line, and browsing the web. We describe how the platform allows for the implementation of new agents, safe interaction with sandboxed environments for code execution, coordination between multiple agents, and incorporation of evaluation benchmarks. Based on our currently incorporated benchmarks, we perform an evaluation of agents over 15 challenging tasks, including software engineering (e.g., SWE-BENCH) and web browsing (e.g., WEBARENA), among others. Released under the permissive MIT license, OpenHands is a community project spanning academia and industry with more than 2.1K contributions from over 188 contributors.",
        "code": "",
        "category": [
            [
                "Infrastructure",
                "Environment&Platform"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.16741"
    },
    "6603b962c1cdb1549eaac6a4e7ffc57e": {
        "title": "Enhancing Agent Learning through World Dynamics Modeling",
        "authors": [
            "Zhiyuan Sun",
            "Haochen Shi",
            "Marc-Alexandre CÃ´tÃ©",
            "Glen Berseth",
            "Xingdi Yuan",
            "Bang Liu"
        ],
        "date": "2024/07/25",
        "pdf": "http://arxiv.org/pdf/2407.17695",
        "abstract": "Large language models (LLMs) have been increasingly applied to tasks in language understanding and interactive decision-making, with their impressive performance largely attributed to the extensive domain knowledge embedded within them. However, the depth and breadth of this knowledge can vary across domains. Many existing approaches assume that LLMs possess a comprehensive understanding of their environment, often overlooking potential gaps in their grasp of actual world dynamics. To address this, we introduce Discover, Verify, and Evolve (DiVE), a framework that discovers world dynamics from a small number of demonstrations, verifies the accuracy of these dynamics, and evolves new, advanced dynamics tailored to the current situation. Through extensive evaluations, we assess the impact of each component on performance and compare the dynamics generated by DiVE to human-annotated dynamics. Our results show that LLMs guided by DiVE make more informed decisions, achieving rewards comparable to human players in the Crafter environment and surpassing methods that require prior task-specific training in the MiniHack environment.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.17695"
    },
    "3c797c2f47846e22b1b9affa5cd1dbbb": {
        "title": "RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models",
        "authors": [
            "Haoyu Chen",
            "Wenbo Li",
            "Jinjin Gu",
            "Jingjing Ren",
            "Sixiang Chen",
            "Tian Ye",
            "Renjing Pei",
            "Kaiwen Zhou",
            "Fenglong Song",
            "Lei Zhu"
        ],
        "date": "2024/07/25",
        "pdf": "http://arxiv.org/pdf/2407.18035",
        "abstract": "Natural images captured by mobile devices often suffer from multiple types of degradation, such as noise, blur, and low light. Traditional image restoration methods require manual selection of specific tasks, algorithms, and execution sequences, which is time-consuming and may yield suboptimal results. All-in-one models, though capable of handling multiple tasks, typically support only a limited range and often produce overly smooth, low-fidelity outcomes due to their broad data distribution fitting. To address these challenges, we first define a new pipeline for restoring images with multiple degradations, and then introduce RestoreAgent, an intelligent image restoration system leveraging multimodal large language models. RestoreAgent autonomously assesses the type and extent of degradation in input images and performs restoration through (1) determining the appropriate restoration tasks, (2) optimizing the task sequence, (3) selecting the most suitable models, and (4) executing the restoration. Experimental results demonstrate the superior performance of RestoreAgent in handling complex degradation, surpassing human experts. Furthermore, the system modular design facilitates the fast integration of new tasks and models, enhancing its flexibility and scalability for various applications.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Single-Agent Framework"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.18035"
    },
    "48b4d5c8eb15b11f2f0c0a578b38d24e": {
        "title": "Recursive Introspection: Teaching Language Model Agents How to Self-Improve",
        "authors": [
            "Yuxiao Qu",
            "Tianjun Zhang",
            "Naman Garg",
            "Aviral Kumar"
        ],
        "date": "2024/07/25",
        "pdf": "http://arxiv.org/pdf/2407.18219",
        "abstract": "A central piece in enabling intelligent agentic behavior in foundation models is to make them capable of introspecting upon their behavior, reasoning, and correcting their mistakes as more computation or interaction is available. Even the strongest proprietary large language models (LLMs) do not quite exhibit the ability of continually improving their responses sequentially, even in scenarios where they are explicitly told that they are making a mistake. In this paper, we develop RISE: Recursive IntroSpEction, an approach for fine-tuning LLMs to introduce this capability, despite prior work hypothesizing that this capability may not be possible to attain. Our approach prescribes an iterative fine-tuning procedure, which attempts to teach the model how to alter its response after having executed previously unsuccessful attempts to solve a hard test-time problem, with optionally additional environment feedback. RISE poses fine-tuning for a single-turn prompt as solving a multi-turn Markov decision process (MDP), where the initial state is the prompt. Inspired by principles in online imitation learning and reinforcement learning, we propose strategies for multi-turn data collection and training so as to imbue an LLM with the capability to recursively detect and correct its previous mistakes in subsequent iterations. Our experiments show that RISE enables Llama2, Llama3, and Mistral models to improve themselves with more turns on math reasoning tasks, outperforming several single-turn strategies given an equal amount of inference-time computation. We also find that RISE scales well, often attaining larger benefits with more capable models. Our analysis shows that RISE makes meaningful improvements to responses to arrive at the correct solution for challenging prompts, without disrupting one-turn abilities as a result of expressing more complex distributions.",
        "code": "",
        "category": [
            [
                "Training",
                "Fine tuning"
            ],
            [
                "Technique For Enhancement",
                "Feedback&Reflection"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.18219"
    },
    "34aaf4bfd9b58c615f19522948a79562": {
        "title": "AppWorld: A Controllable World of Apps and People for Benchmarking Interactive Coding Agents",
        "authors": [
            "Harsh Trivedi",
            "Tushar Khot",
            "Mareike Hartmann",
            "Ruskin Manku",
            "Vinty Dong",
            "Edward Li",
            "Shashank Gupta",
            "Ashish Sabharwal",
            "Niranjan Balasubramanian"
        ],
        "date": "2024/07/26",
        "pdf": "http://arxiv.org/pdf/2407.18901",
        "abstract": "Autonomous agents that address day-to-day digital tasks (e.g., ordering groceries for a household), must not only operate multiple apps (e.g., notes, messaging, shopping app) via APIs, but also generate rich code with complex control flow in an iterative manner based on their interaction with the environment. However, existing benchmarks for tool use are inadequate, as they only cover tasks that require a simple sequence of API calls. To remedy this gap, we built $\\textbf{AppWorld Engine}$, a high-quality execution environment (60K lines of code) of 9 day-to-day apps operable via 457 APIs and populated with realistic digital activities simulating the lives of ~100 fictitious users. We then created $\\textbf{AppWorld Benchmark}$ (40K lines of code), a suite of 750 natural, diverse, and challenging autonomous agent tasks requiring rich and interactive code generation. It supports robust programmatic evaluation with state-based unit tests, allowing for different ways of completing a task while also checking for unexpected changes, i.e., collateral damage. The state-of-the-art LLM, GPT-4o, solves only ~49% of our &#39;normal&#39; tasks and ~30% of &#39;challenge&#39; tasks, while other models solve at least 16% fewer. This highlights the benchmark&#39;s difficulty and AppWorld&#39;s potential to push the frontiers of interactive coding agents. The project website is available at https://appworld.dev/.",
        "code": "https://github.com/stonybrooknlp/appworld",
        "category": [
            [
                "Infrastructure",
                "Benchmark&Evaluation"
            ],
            [
                "Interaction",
                "Tool Usage"
            ],
            [
                "Application",
                "Software Engineering"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.18901"
    },
    "488d771b639b8027165f862ade87c0de": {
        "title": "An Autonomous GIS Agent Framework for Geospatial Data Retrieval",
        "authors": [
            "Huan Ning",
            "Zhenlong Li",
            "Temitope Akinboyewa",
            "M. Naser Lessani"
        ],
        "date": "2024/07/13",
        "pdf": "http://arxiv.org/pdf/2407.21024",
        "abstract": "Powered by the emerging large language models (LLMs), autonomous geographic information systems (GIS) agents have the potential to accomplish spatial analyses and cartographic tasks. However, a research gap exists to support fully autonomous GIS agents: how to enable agents to discover and download the necessary data for geospatial analyses. This study proposes an autonomous GIS agent framework capable of retrieving required geospatial data by generating, executing, and debugging programs. The framework utilizes the LLM as the decision-maker, selects the appropriate data source (s) from a pre-defined source list, and fetches the data from the chosen source. Each data source has a handbook that records the metadata and technical details for data retrieval. The proposed framework is designed in a plug-and-play style to ensure flexibility and extensibility. Human users or autonomous data scrawlers can add new data sources by adding new handbooks. We developed a prototype agent based on the framework, released as a QGIS plugin (GeoData Retrieve Agent) and a Python program. Experiment results demonstrate its capability of retrieving data from various sources including OpenStreetMap, administrative boundaries and demographic data from the US Census Bureau, satellite basemaps from ESRI World Imagery, global digital elevation model (DEM) from OpenTopography.org, weather data from a commercial provider, the COVID-19 cases from the NYTimes GitHub. Our study is among the first attempts to develop an autonomous geospatial data retrieval agent.",
        "code": "",
        "category": [
            [
                "Application",
                "Geography"
            ]
        ],
        "url": "https://arxiv.org/abs/2407.21024"
    },
    "340f5e4367036a333e81bf97cd732408": {
        "title": "ClinicalAgent: Clinical Trial Multi-Agent System with Large Language Model-based Reasoning",
        "authors": [
            "Ling Yue",
            "Sixue Xing",
            "Jintai Chen",
            "Tianfan Fu"
        ],
        "date": "2024/04/23",
        "pdf": "http://arxiv.org/pdf/2404.14777",
        "abstract": "Large Language Models (LLMs) and multi-agent systems have shown impressive capabilities in natural language tasks but face challenges in clinical trial applications, primarily due to limited access to external knowledge. Recognizing the potential of advanced clinical trial tools that aggregate and predict based on the latest medical data, we propose an integrated solution to enhance their accessibility and utility. We introduce Clinical Agent System (ClinicalAgent), a clinical multi-agent system designed for clinical trial tasks, leveraging GPT-4, multi-agent architectures, LEAST-TO-MOST, and ReAct reasoning technology. This integration not only boosts LLM performance in clinical contexts but also introduces novel functionalities. The proposed method achieves competitive predictive performance in clinical trial outcome prediction (0.7908 PR-AUC), obtaining a 0.3326 improvement over the standard prompt Method. Publicly available code can be found at https://anonymous.4open.science/r/ClinicalAgent-6671.",
        "code": "",
        "category": [
            [
                "Scaling",
                "Multi-Agent System"
            ],
            [
                "Application",
                "Medicine"
            ]
        ],
        "url": "https://arxiv.org/abs/2404.14777"
    }
}